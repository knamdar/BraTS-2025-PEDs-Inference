
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-07-08 00:16:05.629503: Using torch.compile... 
2025-07-08 00:16:07.705468: do_dummy_2d_data_aug: False 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': [128, 128, 128], 'median_image_size_in_voxels': [143.0, 170.0, 138.0], 'spacing': [1.0, 1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization'], 'use_mask_for_norm': [True, True, True, True], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': [32, 64, 128, 256, 320, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': False} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset006_BraTS2025_PedSynthstripedWholeTumor', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.0, 1.0, 1.0], 'original_median_shape_after_transp': [143, 170, 138], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 9941.9990234375, 'mean': 541.5750732421875, 'median': 334.0987243652344, 'min': -6.919532299041748, 'percentile_00_5': 0.0, 'percentile_99_5': 2940.05810546875, 'std': 575.95703125}, '1': {'max': 14559.1748046875, 'mean': 543.7495727539062, 'median': 332.2574768066406, 'min': 0.0, 'percentile_00_5': 0.0, 'percentile_99_5': 4634.1328125, 'std': 679.7374877929688}, '2': {'max': 11606.9990234375, 'mean': 857.2710571289062, 'median': 700.0648803710938, 'min': 0.0, 'percentile_00_5': 0.0, 'percentile_99_5': 4216.70556640625, 'std': 647.5850219726562}, '3': {'max': 24291.5, 'mean': 641.4476318359375, 'median': 451.75885009765625, 'min': 0.0, 'percentile_00_5': 0.0, 'percentile_99_5': 5033.11376953125, 'std': 1230.9371337890625}}} 
 
2025-07-08 00:16:16.330672: Unable to plot network architecture: nnUNet_compile is enabled! 
2025-07-08 00:16:16.364031:  
2025-07-08 00:16:16.365317: Epoch 0 
2025-07-08 00:16:16.365866: Current learning rate: 0.01 
2025-07-08 00:17:52.770150: train_loss -0.5244 
2025-07-08 00:17:52.770617: val_loss -0.6698 
2025-07-08 00:17:52.770695: Pseudo dice [np.float32(0.7408)] 
2025-07-08 00:17:52.770793: Epoch time: 96.41 s 
2025-07-08 00:17:52.770860: Yayy! New best EMA pseudo Dice: 0.7408000230789185 
2025-07-08 00:17:54.622096:  
2025-07-08 00:17:54.622447: Epoch 1 
2025-07-08 00:17:54.622661: Current learning rate: 0.00999 
2025-07-08 00:18:45.929446: train_loss -0.6802 
2025-07-08 00:18:45.932085: val_loss -0.7259 
2025-07-08 00:18:45.932849: Pseudo dice [np.float32(0.8185)] 
2025-07-08 00:18:45.933501: Epoch time: 51.31 s 
2025-07-08 00:18:45.934360: Yayy! New best EMA pseudo Dice: 0.7486000061035156 
2025-07-08 00:18:48.110672:  
2025-07-08 00:18:48.111033: Epoch 2 
2025-07-08 00:18:48.111393: Current learning rate: 0.00998 
2025-07-08 00:19:38.494828: train_loss -0.7025 
2025-07-08 00:19:38.495212: val_loss -0.7077 
2025-07-08 00:19:38.495290: Pseudo dice [np.float32(0.7611)] 
2025-07-08 00:19:38.495394: Epoch time: 50.39 s 
2025-07-08 00:19:38.495466: Yayy! New best EMA pseudo Dice: 0.7498000264167786 
2025-07-08 00:19:40.571583:  
2025-07-08 00:19:40.572304: Epoch 3 
2025-07-08 00:19:40.572492: Current learning rate: 0.00997 
2025-07-08 00:20:31.430355: train_loss -0.7187 
2025-07-08 00:20:31.431216: val_loss -0.7833 
2025-07-08 00:20:31.431320: Pseudo dice [np.float32(0.8545)] 
2025-07-08 00:20:31.431532: Epoch time: 50.86 s 
2025-07-08 00:20:31.431694: Yayy! New best EMA pseudo Dice: 0.7602999806404114 
2025-07-08 00:20:33.446318:  
2025-07-08 00:20:33.446694: Epoch 4 
2025-07-08 00:20:33.446893: Current learning rate: 0.00996 
2025-07-08 00:21:24.369863: train_loss -0.7357 
2025-07-08 00:21:24.370953: val_loss -0.783 
2025-07-08 00:21:24.371556: Pseudo dice [np.float32(0.8355)] 
2025-07-08 00:21:24.371781: Epoch time: 50.92 s 
2025-07-08 00:21:24.371914: Yayy! New best EMA pseudo Dice: 0.767799973487854 
2025-07-08 00:21:26.389672:  
2025-07-08 00:21:26.389875: Epoch 5 
2025-07-08 00:21:26.389974: Current learning rate: 0.00995 
2025-07-08 00:22:15.035055: train_loss -0.7496 
2025-07-08 00:22:15.035712: val_loss -0.7742 
2025-07-08 00:22:15.035925: Pseudo dice [np.float32(0.8267)] 
2025-07-08 00:22:15.036075: Epoch time: 48.65 s 
2025-07-08 00:22:15.036209: Yayy! New best EMA pseudo Dice: 0.7736999988555908 
2025-07-08 00:22:17.156814:  
2025-07-08 00:22:17.157378: Epoch 6 
2025-07-08 00:22:17.157630: Current learning rate: 0.00995 
2025-07-08 00:23:06.313492: train_loss -0.7651 
2025-07-08 00:23:06.315759: val_loss -0.7871 
2025-07-08 00:23:06.315987: Pseudo dice [np.float32(0.8421)] 
2025-07-08 00:23:06.316209: Epoch time: 49.16 s 
2025-07-08 00:23:06.316348: Yayy! New best EMA pseudo Dice: 0.7806000113487244 
2025-07-08 00:23:08.333166:  
2025-07-08 00:23:08.333466: Epoch 7 
2025-07-08 00:23:08.333710: Current learning rate: 0.00994 
2025-07-08 00:23:58.068617: train_loss -0.7796 
2025-07-08 00:23:58.069090: val_loss -0.8172 
2025-07-08 00:23:58.069174: Pseudo dice [np.float32(0.8621)] 
2025-07-08 00:23:58.069281: Epoch time: 49.74 s 
2025-07-08 00:23:58.069363: Yayy! New best EMA pseudo Dice: 0.7886999845504761 
2025-07-08 00:24:00.111376:  
2025-07-08 00:24:00.111791: Epoch 8 
2025-07-08 00:24:00.112016: Current learning rate: 0.00993 
2025-07-08 00:24:49.979041: train_loss -0.7849 
2025-07-08 00:24:49.979468: val_loss -0.8095 
2025-07-08 00:24:49.979559: Pseudo dice [np.float32(0.8373)] 
2025-07-08 00:24:49.979663: Epoch time: 49.87 s 
2025-07-08 00:24:49.979793: Yayy! New best EMA pseudo Dice: 0.7936000227928162 
2025-07-08 00:24:52.038269:  
2025-07-08 00:24:52.038556: Epoch 9 
2025-07-08 00:24:52.038688: Current learning rate: 0.00992 
2025-07-08 00:25:42.691571: train_loss -0.797 
2025-07-08 00:25:42.692757: val_loss -0.7927 
2025-07-08 00:25:42.692880: Pseudo dice [np.float32(0.8491)] 
2025-07-08 00:25:42.693012: Epoch time: 50.65 s 
2025-07-08 00:25:42.693105: Yayy! New best EMA pseudo Dice: 0.7990999817848206 
2025-07-08 00:25:45.782220:  
2025-07-08 00:25:45.782919: Epoch 10 
2025-07-08 00:25:45.783530: Current learning rate: 0.00991 
2025-07-08 00:26:35.305525: train_loss -0.8046 
2025-07-08 00:26:35.305960: val_loss -0.8365 
2025-07-08 00:26:35.306040: Pseudo dice [np.float32(0.8896)] 
2025-07-08 00:26:35.306181: Epoch time: 49.53 s 
2025-07-08 00:26:35.306317: Yayy! New best EMA pseudo Dice: 0.8082000017166138 
2025-07-08 00:26:37.513389:  
2025-07-08 00:26:37.513645: Epoch 11 
2025-07-08 00:26:37.513780: Current learning rate: 0.0099 
2025-07-08 00:27:27.926773: train_loss -0.7972 
2025-07-08 00:27:27.927222: val_loss -0.8103 
2025-07-08 00:27:27.927315: Pseudo dice [np.float32(0.8345)] 
2025-07-08 00:27:27.927565: Epoch time: 50.41 s 
2025-07-08 00:27:27.927656: Yayy! New best EMA pseudo Dice: 0.8108000159263611 
2025-07-08 00:27:30.008793:  
2025-07-08 00:27:30.009229: Epoch 12 
2025-07-08 00:27:30.009534: Current learning rate: 0.00989 
2025-07-08 00:28:18.192892: train_loss -0.7965 
2025-07-08 00:28:18.193842: val_loss -0.7963 
2025-07-08 00:28:18.193993: Pseudo dice [np.float32(0.8573)] 
2025-07-08 00:28:18.194174: Epoch time: 48.19 s 
2025-07-08 00:28:18.194280: Yayy! New best EMA pseudo Dice: 0.8154000043869019 
2025-07-08 00:28:20.255712:  
2025-07-08 00:28:20.256011: Epoch 13 
2025-07-08 00:28:20.256205: Current learning rate: 0.00988 
2025-07-08 00:29:10.540431: train_loss -0.7867 
2025-07-08 00:29:10.541396: val_loss -0.7995 
2025-07-08 00:29:10.541507: Pseudo dice [np.float32(0.8532)] 
2025-07-08 00:29:10.541707: Epoch time: 50.29 s 
2025-07-08 00:29:10.541794: Yayy! New best EMA pseudo Dice: 0.8191999793052673 
2025-07-08 00:29:12.640949:  
2025-07-08 00:29:12.641304: Epoch 14 
2025-07-08 00:29:12.641592: Current learning rate: 0.00987 
2025-07-08 00:30:03.493775: train_loss -0.8071 
2025-07-08 00:30:03.494406: val_loss -0.8403 
2025-07-08 00:30:03.494613: Pseudo dice [np.float32(0.8738)] 
2025-07-08 00:30:03.494808: Epoch time: 50.85 s 
2025-07-08 00:30:03.494908: Yayy! New best EMA pseudo Dice: 0.8246999979019165 
2025-07-08 00:30:05.634704:  
2025-07-08 00:30:05.635020: Epoch 15 
2025-07-08 00:30:05.635271: Current learning rate: 0.00986 
2025-07-08 00:30:56.085956: train_loss -0.8158 
2025-07-08 00:30:56.087154: val_loss -0.8296 
2025-07-08 00:30:56.087326: Pseudo dice [np.float32(0.8648)] 
2025-07-08 00:30:56.087509: Epoch time: 50.45 s 
2025-07-08 00:30:56.087651: Yayy! New best EMA pseudo Dice: 0.8287000060081482 
2025-07-08 00:30:58.195579:  
2025-07-08 00:30:58.195941: Epoch 16 
2025-07-08 00:30:58.196147: Current learning rate: 0.00986 
2025-07-08 00:31:47.882133: train_loss -0.8295 
2025-07-08 00:31:47.883101: val_loss -0.837 
2025-07-08 00:31:47.883203: Pseudo dice [np.float32(0.8758)] 
2025-07-08 00:31:47.883321: Epoch time: 49.69 s 
2025-07-08 00:31:47.883400: Yayy! New best EMA pseudo Dice: 0.8334000110626221 
2025-07-08 00:31:50.013508:  
2025-07-08 00:31:50.014123: Epoch 17 
2025-07-08 00:31:50.014308: Current learning rate: 0.00985 
2025-07-08 00:32:39.644290: train_loss -0.8452 
2025-07-08 00:32:39.644826: val_loss -0.8317 
2025-07-08 00:32:39.644921: Pseudo dice [np.float32(0.8575)] 
2025-07-08 00:32:39.645032: Epoch time: 49.63 s 
2025-07-08 00:32:39.645121: Yayy! New best EMA pseudo Dice: 0.8357999920845032 
2025-07-08 00:32:41.831737:  
2025-07-08 00:32:41.832230: Epoch 18 
2025-07-08 00:32:41.832580: Current learning rate: 0.00984 
2025-07-08 00:33:28.851693: train_loss -0.8336 
2025-07-08 00:33:28.852240: val_loss -0.8467 
2025-07-08 00:33:28.852342: Pseudo dice [np.float32(0.8906)] 
2025-07-08 00:33:28.852457: Epoch time: 47.02 s 
2025-07-08 00:33:28.852566: Yayy! New best EMA pseudo Dice: 0.8413000106811523 
2025-07-08 00:33:30.938129:  
2025-07-08 00:33:30.938362: Epoch 19 
2025-07-08 00:33:30.938720: Current learning rate: 0.00983 
2025-07-08 00:34:21.538036: train_loss -0.8387 
2025-07-08 00:34:21.538512: val_loss -0.8557 
2025-07-08 00:34:21.538670: Pseudo dice [np.float32(0.886)] 
2025-07-08 00:34:21.538842: Epoch time: 50.6 s 
2025-07-08 00:34:21.538922: Yayy! New best EMA pseudo Dice: 0.84579998254776 
2025-07-08 00:34:23.617557:  
2025-07-08 00:34:23.617964: Epoch 20 
2025-07-08 00:34:23.618097: Current learning rate: 0.00982 
2025-07-08 00:35:12.022394: train_loss -0.8432 
2025-07-08 00:35:12.023018: val_loss -0.8281 
2025-07-08 00:35:12.023182: Pseudo dice [np.float32(0.8816)] 
2025-07-08 00:35:12.023323: Epoch time: 48.41 s 
2025-07-08 00:35:12.023412: Yayy! New best EMA pseudo Dice: 0.8493000268936157 
2025-07-08 00:35:14.149580:  
2025-07-08 00:35:14.149912: Epoch 21 
2025-07-08 00:35:14.150228: Current learning rate: 0.00981 
2025-07-08 00:36:02.626363: train_loss -0.847 
2025-07-08 00:36:02.626974: val_loss -0.8704 
2025-07-08 00:36:02.627069: Pseudo dice [np.float32(0.8954)] 
2025-07-08 00:36:02.627185: Epoch time: 48.48 s 
2025-07-08 00:36:02.627278: Yayy! New best EMA pseudo Dice: 0.8539000153541565 
2025-07-08 00:36:04.771779:  
2025-07-08 00:36:04.772032: Epoch 22 
2025-07-08 00:36:04.772169: Current learning rate: 0.0098 
2025-07-08 00:36:52.561904: train_loss -0.859 
2025-07-08 00:36:52.562463: val_loss -0.8588 
2025-07-08 00:36:52.562590: Pseudo dice [np.float32(0.8898)] 
2025-07-08 00:36:52.562700: Epoch time: 47.79 s 
2025-07-08 00:36:52.562777: Yayy! New best EMA pseudo Dice: 0.8575000166893005 
2025-07-08 00:36:54.694866:  
2025-07-08 00:36:54.695340: Epoch 23 
2025-07-08 00:36:54.695718: Current learning rate: 0.00979 
2025-07-08 00:37:42.283293: train_loss -0.8382 
2025-07-08 00:37:42.283817: val_loss -0.8438 
2025-07-08 00:37:42.283898: Pseudo dice [np.float32(0.8743)] 
2025-07-08 00:37:42.284007: Epoch time: 47.59 s 
2025-07-08 00:37:42.284083: Yayy! New best EMA pseudo Dice: 0.8592000007629395 
2025-07-08 00:37:45.239014:  
2025-07-08 00:37:45.239497: Epoch 24 
2025-07-08 00:37:45.239697: Current learning rate: 0.00978 
2025-07-08 00:38:33.022171: train_loss -0.8309 
2025-07-08 00:38:33.022653: val_loss -0.8532 
2025-07-08 00:38:33.022737: Pseudo dice [np.float32(0.8993)] 
2025-07-08 00:38:33.022850: Epoch time: 47.78 s 
2025-07-08 00:38:33.022926: Yayy! New best EMA pseudo Dice: 0.8632000088691711 
2025-07-08 00:38:35.026452:  
2025-07-08 00:38:35.026788: Epoch 25 
2025-07-08 00:38:35.026944: Current learning rate: 0.00977 
2025-07-08 00:39:26.725468: train_loss -0.8443 
2025-07-08 00:39:26.726026: val_loss -0.862 
2025-07-08 00:39:26.726107: Pseudo dice [np.float32(0.9115)] 
2025-07-08 00:39:26.726219: Epoch time: 51.7 s 
2025-07-08 00:39:26.726294: Yayy! New best EMA pseudo Dice: 0.8679999709129333 
2025-07-08 00:39:28.768790:  
2025-07-08 00:39:28.769137: Epoch 26 
2025-07-08 00:39:28.769526: Current learning rate: 0.00977 
2025-07-08 00:40:19.270277: train_loss -0.8403 
2025-07-08 00:40:19.270957: val_loss -0.8604 
2025-07-08 00:40:19.271057: Pseudo dice [np.float32(0.8927)] 
2025-07-08 00:40:19.271197: Epoch time: 50.5 s 
2025-07-08 00:40:19.271298: Yayy! New best EMA pseudo Dice: 0.8705000281333923 
2025-07-08 00:40:21.351228:  
2025-07-08 00:40:21.351677: Epoch 27 
2025-07-08 00:40:21.351922: Current learning rate: 0.00976 
2025-07-08 00:41:12.469074: train_loss -0.8498 
2025-07-08 00:41:12.470064: val_loss -0.862 
2025-07-08 00:41:12.470186: Pseudo dice [np.float32(0.8824)] 
2025-07-08 00:41:12.470366: Epoch time: 51.12 s 
2025-07-08 00:41:12.470468: Yayy! New best EMA pseudo Dice: 0.8716999888420105 
2025-07-08 00:41:14.457113:  
2025-07-08 00:41:14.457235: Epoch 28 
2025-07-08 00:41:14.457381: Current learning rate: 0.00975 
2025-07-08 00:42:06.418418: train_loss -0.8443 
2025-07-08 00:42:06.418786: val_loss -0.8593 
2025-07-08 00:42:06.418872: Pseudo dice [np.float32(0.8827)] 
2025-07-08 00:42:06.418983: Epoch time: 51.96 s 
2025-07-08 00:42:06.419182: Yayy! New best EMA pseudo Dice: 0.8727999925613403 
2025-07-08 00:42:08.631183:  
2025-07-08 00:42:08.631612: Epoch 29 
2025-07-08 00:42:08.631951: Current learning rate: 0.00974 
2025-07-08 00:42:58.661509: train_loss -0.8463 
2025-07-08 00:42:58.662389: val_loss -0.873 
2025-07-08 00:42:58.662482: Pseudo dice [np.float32(0.9025)] 
2025-07-08 00:42:58.662606: Epoch time: 50.03 s 
2025-07-08 00:42:58.662693: Yayy! New best EMA pseudo Dice: 0.8758000135421753 
2025-07-08 00:43:00.666523:  
2025-07-08 00:43:00.667161: Epoch 30 
2025-07-08 00:43:00.667314: Current learning rate: 0.00973 
2025-07-08 00:43:49.337281: train_loss -0.8349 
2025-07-08 00:43:49.338136: val_loss -0.8219 
2025-07-08 00:43:49.338250: Pseudo dice [np.float32(0.8647)] 
2025-07-08 00:43:49.338373: Epoch time: 48.67 s 
2025-07-08 00:43:50.467854:  
2025-07-08 00:43:50.468073: Epoch 31 
2025-07-08 00:43:50.468208: Current learning rate: 0.00972 
2025-07-08 00:44:41.303991: train_loss -0.8331 
2025-07-08 00:44:41.304407: val_loss -0.8589 
2025-07-08 00:44:41.304490: Pseudo dice [np.float32(0.9043)] 
2025-07-08 00:44:41.304606: Epoch time: 50.84 s 
2025-07-08 00:44:41.304682: Yayy! New best EMA pseudo Dice: 0.8776000142097473 
2025-07-08 00:44:43.349336:  
2025-07-08 00:44:43.349901: Epoch 32 
2025-07-08 00:44:43.350105: Current learning rate: 0.00971 
2025-07-08 00:45:33.927216: train_loss -0.836 
2025-07-08 00:45:33.928240: val_loss -0.8586 
2025-07-08 00:45:33.928433: Pseudo dice [np.float32(0.8927)] 
2025-07-08 00:45:33.928674: Epoch time: 50.58 s 
2025-07-08 00:45:33.928807: Yayy! New best EMA pseudo Dice: 0.8791000247001648 
2025-07-08 00:45:36.118928:  
2025-07-08 00:45:36.119315: Epoch 33 
2025-07-08 00:45:36.119508: Current learning rate: 0.0097 
2025-07-08 00:46:25.700707: train_loss -0.853 
2025-07-08 00:46:25.701402: val_loss -0.8677 
2025-07-08 00:46:25.701486: Pseudo dice [np.float32(0.8988)] 
2025-07-08 00:46:25.701636: Epoch time: 49.58 s 
2025-07-08 00:46:25.701726: Yayy! New best EMA pseudo Dice: 0.8810999989509583 
2025-07-08 00:46:27.742815:  
2025-07-08 00:46:27.743382: Epoch 34 
2025-07-08 00:46:27.743733: Current learning rate: 0.00969 
2025-07-08 00:47:16.953221: train_loss -0.8517 
2025-07-08 00:47:16.954166: val_loss -0.8627 
2025-07-08 00:47:16.954316: Pseudo dice [np.float32(0.898)] 
2025-07-08 00:47:16.954456: Epoch time: 49.21 s 
2025-07-08 00:47:16.954559: Yayy! New best EMA pseudo Dice: 0.8827999830245972 
2025-07-08 00:47:19.092600:  
2025-07-08 00:47:19.093100: Epoch 35 
2025-07-08 00:47:19.093492: Current learning rate: 0.00968 
2025-07-08 00:48:08.186313: train_loss -0.8525 
2025-07-08 00:48:08.186713: val_loss -0.8545 
2025-07-08 00:48:08.186794: Pseudo dice [np.float32(0.8876)] 
2025-07-08 00:48:08.187031: Epoch time: 49.09 s 
2025-07-08 00:48:08.187179: Yayy! New best EMA pseudo Dice: 0.8833000063896179 
2025-07-08 00:48:10.218484:  
2025-07-08 00:48:10.218610: Epoch 36 
2025-07-08 00:48:10.218708: Current learning rate: 0.00968 
2025-07-08 00:49:01.677751: train_loss -0.8413 
2025-07-08 00:49:01.678794: val_loss -0.8421 
2025-07-08 00:49:01.678997: Pseudo dice [np.float32(0.8879)] 
2025-07-08 00:49:01.679169: Epoch time: 51.46 s 
2025-07-08 00:49:01.679370: Yayy! New best EMA pseudo Dice: 0.8837000131607056 
2025-07-08 00:49:03.826146:  
2025-07-08 00:49:03.826762: Epoch 37 
2025-07-08 00:49:03.826931: Current learning rate: 0.00967 
2025-07-08 00:49:53.213902: train_loss -0.8526 
2025-07-08 00:49:53.214437: val_loss -0.856 
2025-07-08 00:49:53.214515: Pseudo dice [np.float32(0.8931)] 
2025-07-08 00:49:53.214629: Epoch time: 49.39 s 
2025-07-08 00:49:53.214700: Yayy! New best EMA pseudo Dice: 0.8847000002861023 
2025-07-08 00:49:55.389903:  
2025-07-08 00:49:55.390212: Epoch 38 
2025-07-08 00:49:55.390336: Current learning rate: 0.00966 
2025-07-08 00:50:43.873209: train_loss -0.8392 
2025-07-08 00:50:43.873795: val_loss -0.8737 
2025-07-08 00:50:43.873888: Pseudo dice [np.float32(0.8969)] 
2025-07-08 00:50:43.874019: Epoch time: 48.48 s 
2025-07-08 00:50:43.874101: Yayy! New best EMA pseudo Dice: 0.8859000205993652 
2025-07-08 00:50:46.987523:  
2025-07-08 00:50:46.988096: Epoch 39 
2025-07-08 00:50:46.988368: Current learning rate: 0.00965 
2025-07-08 00:51:36.244732: train_loss -0.8555 
2025-07-08 00:51:36.245170: val_loss -0.8363 
2025-07-08 00:51:36.245261: Pseudo dice [np.float32(0.901)] 
2025-07-08 00:51:36.245386: Epoch time: 49.26 s 
2025-07-08 00:51:36.245461: Yayy! New best EMA pseudo Dice: 0.8873999714851379 
2025-07-08 00:51:38.336148:  
2025-07-08 00:51:38.336447: Epoch 40 
2025-07-08 00:51:38.336806: Current learning rate: 0.00964 
2025-07-08 00:52:27.276571: train_loss -0.8605 
2025-07-08 00:52:27.277379: val_loss -0.8726 
2025-07-08 00:52:27.277493: Pseudo dice [np.float32(0.9022)] 
2025-07-08 00:52:27.277664: Epoch time: 48.94 s 
2025-07-08 00:52:27.277761: Yayy! New best EMA pseudo Dice: 0.8888999819755554 
2025-07-08 00:52:29.459467:  
2025-07-08 00:52:29.459740: Epoch 41 
2025-07-08 00:52:29.459937: Current learning rate: 0.00963 
2025-07-08 00:53:19.336149: train_loss -0.8585 
2025-07-08 00:53:19.338336: val_loss -0.8701 
2025-07-08 00:53:19.338476: Pseudo dice [np.float32(0.8992)] 
2025-07-08 00:53:19.338662: Epoch time: 49.88 s 
2025-07-08 00:53:19.338748: Yayy! New best EMA pseudo Dice: 0.8899000287055969 
2025-07-08 00:53:21.436736:  
2025-07-08 00:53:21.437146: Epoch 42 
2025-07-08 00:53:21.437267: Current learning rate: 0.00962 
2025-07-08 00:54:11.274520: train_loss -0.8505 
2025-07-08 00:54:11.275010: val_loss -0.8586 
2025-07-08 00:54:11.275125: Pseudo dice [np.float32(0.8834)] 
2025-07-08 00:54:11.275406: Epoch time: 49.84 s 
2025-07-08 00:54:12.471509:  
2025-07-08 00:54:12.471970: Epoch 43 
2025-07-08 00:54:12.472147: Current learning rate: 0.00961 
2025-07-08 00:55:00.331708: train_loss -0.8449 
2025-07-08 00:55:00.332455: val_loss -0.8665 
2025-07-08 00:55:00.332594: Pseudo dice [np.float32(0.903)] 
2025-07-08 00:55:00.332743: Epoch time: 47.86 s 
2025-07-08 00:55:00.332841: Yayy! New best EMA pseudo Dice: 0.8906000256538391 
2025-07-08 00:55:02.511953:  
2025-07-08 00:55:02.512585: Epoch 44 
2025-07-08 00:55:02.512997: Current learning rate: 0.0096 
2025-07-08 00:55:50.347785: train_loss -0.8383 
2025-07-08 00:55:50.348441: val_loss -0.8433 
2025-07-08 00:55:50.348580: Pseudo dice [np.float32(0.8847)] 
2025-07-08 00:55:50.348743: Epoch time: 47.84 s 
2025-07-08 00:55:51.544092:  
2025-07-08 00:55:51.544465: Epoch 45 
2025-07-08 00:55:51.544665: Current learning rate: 0.00959 
2025-07-08 00:56:40.390413: train_loss -0.8648 
2025-07-08 00:56:40.391212: val_loss -0.8617 
2025-07-08 00:56:40.391321: Pseudo dice [np.float32(0.8922)] 
2025-07-08 00:56:40.391445: Epoch time: 48.85 s 
2025-07-08 00:56:41.461164:  
2025-07-08 00:56:41.461401: Epoch 46 
2025-07-08 00:56:41.461531: Current learning rate: 0.00959 
2025-07-08 00:57:28.956622: train_loss -0.875 
2025-07-08 00:57:28.957794: val_loss -0.8838 
2025-07-08 00:57:28.957896: Pseudo dice [np.float32(0.9155)] 
2025-07-08 00:57:28.958025: Epoch time: 47.5 s 
2025-07-08 00:57:28.958109: Yayy! New best EMA pseudo Dice: 0.892799973487854 
2025-07-08 00:57:31.065231:  
2025-07-08 00:57:31.065481: Epoch 47 
2025-07-08 00:57:31.065617: Current learning rate: 0.00958 
2025-07-08 00:58:18.818336: train_loss -0.8667 
2025-07-08 00:58:18.818965: val_loss -0.877 
2025-07-08 00:58:18.819109: Pseudo dice [np.float32(0.8983)] 
2025-07-08 00:58:18.819239: Epoch time: 47.75 s 
2025-07-08 00:58:18.819329: Yayy! New best EMA pseudo Dice: 0.8932999968528748 
2025-07-08 00:58:20.774178:  
2025-07-08 00:58:20.774410: Epoch 48 
2025-07-08 00:58:20.774534: Current learning rate: 0.00957 
2025-07-08 00:59:07.746854: train_loss -0.8516 
2025-07-08 00:59:07.747558: val_loss -0.8675 
2025-07-08 00:59:07.747677: Pseudo dice [np.float32(0.8957)] 
2025-07-08 00:59:07.747829: Epoch time: 46.97 s 
2025-07-08 00:59:07.747927: Yayy! New best EMA pseudo Dice: 0.8935999870300293 
2025-07-08 00:59:09.833407:  
2025-07-08 00:59:09.834084: Epoch 49 
2025-07-08 00:59:09.834409: Current learning rate: 0.00956 
2025-07-08 00:59:58.629176: train_loss -0.85 
2025-07-08 00:59:58.629598: val_loss -0.8689 
2025-07-08 00:59:58.629680: Pseudo dice [np.float32(0.9064)] 
2025-07-08 00:59:58.629780: Epoch time: 48.8 s 
2025-07-08 00:59:59.535830: Yayy! New best EMA pseudo Dice: 0.8949000239372253 
2025-07-08 01:00:01.473272:  
2025-07-08 01:00:01.473465: Epoch 50 
2025-07-08 01:00:01.473603: Current learning rate: 0.00955 
2025-07-08 01:00:50.286737: train_loss -0.867 
2025-07-08 01:00:50.287557: val_loss -0.8725 
2025-07-08 01:00:50.287672: Pseudo dice [np.float32(0.9001)] 
2025-07-08 01:00:50.287790: Epoch time: 48.81 s 
2025-07-08 01:00:50.287874: Yayy! New best EMA pseudo Dice: 0.8953999876976013 
2025-07-08 01:00:52.334902:  
2025-07-08 01:00:52.335118: Epoch 51 
2025-07-08 01:00:52.335239: Current learning rate: 0.00954 
2025-07-08 01:01:42.641396: train_loss -0.8654 
2025-07-08 01:01:42.641923: val_loss -0.8941 
2025-07-08 01:01:42.642018: Pseudo dice [np.float32(0.9142)] 
2025-07-08 01:01:42.642170: Epoch time: 50.31 s 
2025-07-08 01:01:42.642256: Yayy! New best EMA pseudo Dice: 0.8973000049591064 
2025-07-08 01:01:44.777538:  
2025-07-08 01:01:44.777697: Epoch 52 
2025-07-08 01:01:44.777819: Current learning rate: 0.00953 
2025-07-08 01:02:35.567896: train_loss -0.8665 
2025-07-08 01:02:35.568716: val_loss -0.8884 
2025-07-08 01:02:35.568892: Pseudo dice [np.float32(0.9182)] 
2025-07-08 01:02:35.569059: Epoch time: 50.79 s 
2025-07-08 01:02:35.569155: Yayy! New best EMA pseudo Dice: 0.899399995803833 
2025-07-08 01:02:37.605727:  
2025-07-08 01:02:37.606136: Epoch 53 
2025-07-08 01:02:37.606446: Current learning rate: 0.00952 
2025-07-08 01:03:27.130525: train_loss -0.8713 
2025-07-08 01:03:27.132767: val_loss -0.8697 
2025-07-08 01:03:27.133284: Pseudo dice [np.float32(0.8954)] 
2025-07-08 01:03:27.134049: Epoch time: 49.53 s 
2025-07-08 01:03:29.458241:  
2025-07-08 01:03:29.458944: Epoch 54 
2025-07-08 01:03:29.459206: Current learning rate: 0.00951 
2025-07-08 01:04:17.026199: train_loss -0.851 
2025-07-08 01:04:17.026874: val_loss -0.8716 
2025-07-08 01:04:17.026994: Pseudo dice [np.float32(0.8991)] 
2025-07-08 01:04:17.027133: Epoch time: 47.57 s 
2025-07-08 01:04:18.257547:  
2025-07-08 01:04:18.257756: Epoch 55 
2025-07-08 01:04:18.257941: Current learning rate: 0.0095 
2025-07-08 01:05:08.002134: train_loss -0.8581 
2025-07-08 01:05:08.002583: val_loss -0.8591 
2025-07-08 01:05:08.002674: Pseudo dice [np.float32(0.8873)] 
2025-07-08 01:05:08.002800: Epoch time: 49.75 s 
2025-07-08 01:05:09.146281:  
2025-07-08 01:05:09.146566: Epoch 56 
2025-07-08 01:05:09.146734: Current learning rate: 0.00949 
2025-07-08 01:05:57.786357: train_loss -0.8594 
2025-07-08 01:05:57.786731: val_loss -0.8629 
2025-07-08 01:05:57.786808: Pseudo dice [np.float32(0.902)] 
2025-07-08 01:05:57.786918: Epoch time: 48.64 s 
2025-07-08 01:05:58.874335:  
2025-07-08 01:05:58.874669: Epoch 57 
2025-07-08 01:05:58.874794: Current learning rate: 0.00949 
2025-07-08 01:06:47.652342: train_loss -0.8533 
2025-07-08 01:06:47.653188: val_loss -0.8396 
2025-07-08 01:06:47.653336: Pseudo dice [np.float32(0.8921)] 
2025-07-08 01:06:47.653484: Epoch time: 48.78 s 
2025-07-08 01:06:48.904183:  
2025-07-08 01:06:48.904626: Epoch 58 
2025-07-08 01:06:48.904760: Current learning rate: 0.00948 
2025-07-08 01:07:37.874919: train_loss -0.862 
2025-07-08 01:07:37.875773: val_loss -0.8797 
2025-07-08 01:07:37.875904: Pseudo dice [np.float32(0.9029)] 
2025-07-08 01:07:37.876081: Epoch time: 48.97 s 
2025-07-08 01:07:39.216378:  
2025-07-08 01:07:39.216883: Epoch 59 
2025-07-08 01:07:39.217044: Current learning rate: 0.00947 
2025-07-08 01:08:28.299833: train_loss -0.875 
2025-07-08 01:08:28.300533: val_loss -0.8788 
2025-07-08 01:08:28.300641: Pseudo dice [np.float32(0.9061)] 
2025-07-08 01:08:28.300769: Epoch time: 49.09 s 
2025-07-08 01:08:29.580666:  
2025-07-08 01:08:29.581142: Epoch 60 
2025-07-08 01:08:29.581336: Current learning rate: 0.00946 
2025-07-08 01:09:19.186948: train_loss -0.8647 
2025-07-08 01:09:19.187798: val_loss -0.8711 
2025-07-08 01:09:19.187876: Pseudo dice [np.float32(0.9025)] 
2025-07-08 01:09:19.188014: Epoch time: 49.61 s 
2025-07-08 01:09:20.470830:  
2025-07-08 01:09:20.470949: Epoch 61 
2025-07-08 01:09:20.471050: Current learning rate: 0.00945 
2025-07-08 01:10:08.234297: train_loss -0.8646 
2025-07-08 01:10:08.234697: val_loss -0.8814 
2025-07-08 01:10:08.234790: Pseudo dice [np.float32(0.9155)] 
2025-07-08 01:10:08.234906: Epoch time: 47.76 s 
2025-07-08 01:10:08.235122: Yayy! New best EMA pseudo Dice: 0.9009000062942505 
2025-07-08 01:10:10.267831:  
2025-07-08 01:10:10.268369: Epoch 62 
2025-07-08 01:10:10.268635: Current learning rate: 0.00944 
2025-07-08 01:10:59.638761: train_loss -0.8755 
2025-07-08 01:10:59.639805: val_loss -0.8851 
2025-07-08 01:10:59.639958: Pseudo dice [np.float32(0.9075)] 
2025-07-08 01:10:59.640153: Epoch time: 49.37 s 
2025-07-08 01:10:59.640282: Yayy! New best EMA pseudo Dice: 0.9016000032424927 
2025-07-08 01:11:01.738398:  
2025-07-08 01:11:01.738813: Epoch 63 
2025-07-08 01:11:01.738991: Current learning rate: 0.00943 
2025-07-08 01:11:48.788939: train_loss -0.8805 
2025-07-08 01:11:48.789498: val_loss -0.8817 
2025-07-08 01:11:48.789598: Pseudo dice [np.float32(0.907)] 
2025-07-08 01:11:48.789697: Epoch time: 47.05 s 
2025-07-08 01:11:48.789768: Yayy! New best EMA pseudo Dice: 0.9021000266075134 
2025-07-08 01:11:50.852674:  
2025-07-08 01:11:50.852939: Epoch 64 
2025-07-08 01:11:50.853151: Current learning rate: 0.00942 
2025-07-08 01:12:40.155437: train_loss -0.8698 
2025-07-08 01:12:40.156236: val_loss -0.9029 
2025-07-08 01:12:40.156339: Pseudo dice [np.float32(0.9237)] 
2025-07-08 01:12:40.156470: Epoch time: 49.3 s 
2025-07-08 01:12:40.156569: Yayy! New best EMA pseudo Dice: 0.9042999744415283 
2025-07-08 01:12:42.269183:  
2025-07-08 01:12:42.269472: Epoch 65 
2025-07-08 01:12:42.269728: Current learning rate: 0.00941 
2025-07-08 01:13:31.344567: train_loss -0.8709 
2025-07-08 01:13:31.345224: val_loss -0.8734 
2025-07-08 01:13:31.345332: Pseudo dice [np.float32(0.8915)] 
2025-07-08 01:13:31.345488: Epoch time: 49.08 s 
2025-07-08 01:13:32.569220:  
2025-07-08 01:13:32.569470: Epoch 66 
2025-07-08 01:13:32.569679: Current learning rate: 0.0094 
2025-07-08 01:14:21.306582: train_loss -0.8708 
2025-07-08 01:14:21.308144: val_loss -0.8881 
2025-07-08 01:14:21.308387: Pseudo dice [np.float32(0.9112)] 
2025-07-08 01:14:21.308592: Epoch time: 48.74 s 
2025-07-08 01:14:22.591865:  
2025-07-08 01:14:22.592081: Epoch 67 
2025-07-08 01:14:22.592200: Current learning rate: 0.00939 
2025-07-08 01:15:10.442772: train_loss -0.8577 
2025-07-08 01:15:10.443397: val_loss -0.8584 
2025-07-08 01:15:10.443480: Pseudo dice [np.float32(0.8898)] 
2025-07-08 01:15:10.443603: Epoch time: 47.85 s 
2025-07-08 01:15:11.554526:  
2025-07-08 01:15:11.554792: Epoch 68 
2025-07-08 01:15:11.554920: Current learning rate: 0.00939 
2025-07-08 01:16:01.487926: train_loss -0.851 
2025-07-08 01:16:01.488606: val_loss -0.8821 
2025-07-08 01:16:01.488731: Pseudo dice [np.float32(0.9117)] 
2025-07-08 01:16:01.488869: Epoch time: 49.93 s 
2025-07-08 01:16:03.750047:  
2025-07-08 01:16:03.750395: Epoch 69 
2025-07-08 01:16:03.750711: Current learning rate: 0.00938 
2025-07-08 01:16:50.969689: train_loss -0.8751 
2025-07-08 01:16:50.970660: val_loss -0.8737 
2025-07-08 01:16:50.970761: Pseudo dice [np.float32(0.9061)] 
2025-07-08 01:16:50.970892: Epoch time: 47.22 s 
2025-07-08 01:16:52.201248:  
2025-07-08 01:16:52.201645: Epoch 70 
2025-07-08 01:16:52.201747: Current learning rate: 0.00937 
2025-07-08 01:17:39.646591: train_loss -0.8755 
2025-07-08 01:17:39.647824: val_loss -0.881 
2025-07-08 01:17:39.648005: Pseudo dice [np.float32(0.9099)] 
2025-07-08 01:17:39.648192: Epoch time: 47.45 s 
2025-07-08 01:17:40.892888:  
2025-07-08 01:17:40.893225: Epoch 71 
2025-07-08 01:17:40.893506: Current learning rate: 0.00936 
2025-07-08 01:18:29.291607: train_loss -0.8684 
2025-07-08 01:18:29.292194: val_loss -0.8832 
2025-07-08 01:18:29.292341: Pseudo dice [np.float32(0.9108)] 
2025-07-08 01:18:29.292577: Epoch time: 48.4 s 
2025-07-08 01:18:29.292788: Yayy! New best EMA pseudo Dice: 0.9049000144004822 
2025-07-08 01:18:31.394241:  
2025-07-08 01:18:31.394924: Epoch 72 
2025-07-08 01:18:31.395054: Current learning rate: 0.00935 
2025-07-08 01:19:20.481810: train_loss -0.8683 
2025-07-08 01:19:20.482362: val_loss -0.8759 
2025-07-08 01:19:20.482492: Pseudo dice [np.float32(0.9048)] 
2025-07-08 01:19:20.482676: Epoch time: 49.09 s 
2025-07-08 01:19:21.601866:  
2025-07-08 01:19:21.602049: Epoch 73 
2025-07-08 01:19:21.602425: Current learning rate: 0.00934 
2025-07-08 01:20:09.539443: train_loss -0.8803 
2025-07-08 01:20:09.539812: val_loss -0.8724 
2025-07-08 01:20:09.539898: Pseudo dice [np.float32(0.9046)] 
2025-07-08 01:20:09.539999: Epoch time: 47.94 s 
2025-07-08 01:20:10.677602:  
2025-07-08 01:20:10.677888: Epoch 74 
2025-07-08 01:20:10.678056: Current learning rate: 0.00933 
2025-07-08 01:20:59.211037: train_loss -0.886 
2025-07-08 01:20:59.212308: val_loss -0.8862 
2025-07-08 01:20:59.212571: Pseudo dice [np.float32(0.9037)] 
2025-07-08 01:20:59.212913: Epoch time: 48.53 s 
2025-07-08 01:21:00.709364:  
2025-07-08 01:21:00.709603: Epoch 75 
2025-07-08 01:21:00.709795: Current learning rate: 0.00932 
2025-07-08 01:21:49.083573: train_loss -0.8914 
2025-07-08 01:21:49.084133: val_loss -0.8906 
2025-07-08 01:21:49.084216: Pseudo dice [np.float32(0.9123)] 
2025-07-08 01:21:49.084333: Epoch time: 48.38 s 
2025-07-08 01:21:49.084412: Yayy! New best EMA pseudo Dice: 0.9054999947547913 
2025-07-08 01:21:51.129413:  
2025-07-08 01:21:51.129903: Epoch 76 
2025-07-08 01:21:51.130219: Current learning rate: 0.00931 
2025-07-08 01:22:39.957776: train_loss -0.8832 
2025-07-08 01:22:39.958686: val_loss -0.888 
2025-07-08 01:22:39.958782: Pseudo dice [np.float32(0.9159)] 
2025-07-08 01:22:39.958948: Epoch time: 48.83 s 
2025-07-08 01:22:39.959026: Yayy! New best EMA pseudo Dice: 0.906499981880188 
2025-07-08 01:22:42.010699:  
2025-07-08 01:22:42.011094: Epoch 77 
2025-07-08 01:22:42.011489: Current learning rate: 0.0093 
2025-07-08 01:23:29.577557: train_loss -0.8847 
2025-07-08 01:23:29.578097: val_loss -0.8826 
2025-07-08 01:23:29.578185: Pseudo dice [np.float32(0.9005)] 
2025-07-08 01:23:29.578293: Epoch time: 47.57 s 
2025-07-08 01:23:30.751765:  
2025-07-08 01:23:30.752188: Epoch 78 
2025-07-08 01:23:30.752528: Current learning rate: 0.0093 
2025-07-08 01:24:18.031760: train_loss -0.8648 
2025-07-08 01:24:18.032259: val_loss -0.8927 
2025-07-08 01:24:18.032365: Pseudo dice [np.float32(0.9093)] 
2025-07-08 01:24:18.032485: Epoch time: 47.28 s 
2025-07-08 01:24:19.244624:  
2025-07-08 01:24:19.245116: Epoch 79 
2025-07-08 01:24:19.245289: Current learning rate: 0.00929 
2025-07-08 01:25:09.630561: train_loss -0.8687 
2025-07-08 01:25:09.631016: val_loss -0.8661 
2025-07-08 01:25:09.631103: Pseudo dice [np.float32(0.8943)] 
2025-07-08 01:25:09.631213: Epoch time: 50.39 s 
2025-07-08 01:25:10.918995:  
2025-07-08 01:25:10.919725: Epoch 80 
2025-07-08 01:25:10.919966: Current learning rate: 0.00928 
2025-07-08 01:25:59.044392: train_loss -0.8759 
2025-07-08 01:25:59.044963: val_loss -0.8555 
2025-07-08 01:25:59.045048: Pseudo dice [np.float32(0.8914)] 
2025-07-08 01:25:59.045155: Epoch time: 48.13 s 
2025-07-08 01:26:00.344054:  
2025-07-08 01:26:00.344578: Epoch 81 
2025-07-08 01:26:00.344827: Current learning rate: 0.00927 
2025-07-08 01:26:50.314698: train_loss -0.8701 
2025-07-08 01:26:50.315973: val_loss -0.8658 
2025-07-08 01:26:50.316238: Pseudo dice [np.float32(0.892)] 
2025-07-08 01:26:50.316471: Epoch time: 49.97 s 
2025-07-08 01:26:51.490341:  
2025-07-08 01:26:51.490647: Epoch 82 
2025-07-08 01:26:51.490876: Current learning rate: 0.00926 
2025-07-08 01:27:40.207724: train_loss -0.8676 
2025-07-08 01:27:40.208172: val_loss -0.8926 
2025-07-08 01:27:40.208298: Pseudo dice [np.float32(0.9134)] 
2025-07-08 01:27:40.208420: Epoch time: 48.72 s 
2025-07-08 01:27:41.385273:  
2025-07-08 01:27:41.385525: Epoch 83 
2025-07-08 01:27:41.385661: Current learning rate: 0.00925 
2025-07-08 01:28:31.207815: train_loss -0.8824 
2025-07-08 01:28:31.208960: val_loss -0.9014 
2025-07-08 01:28:31.210770: Pseudo dice [np.float32(0.9206)] 
2025-07-08 01:28:31.211045: Epoch time: 49.82 s 
2025-07-08 01:28:33.362269:  
2025-07-08 01:28:33.362644: Epoch 84 
2025-07-08 01:28:33.362825: Current learning rate: 0.00924 
2025-07-08 01:29:22.580753: train_loss -0.8818 
2025-07-08 01:29:22.581635: val_loss -0.8934 
2025-07-08 01:29:22.581797: Pseudo dice [np.float32(0.9153)] 
2025-07-08 01:29:22.581939: Epoch time: 49.22 s 
2025-07-08 01:29:23.773765:  
2025-07-08 01:29:23.774262: Epoch 85 
2025-07-08 01:29:23.774565: Current learning rate: 0.00923 
2025-07-08 01:30:11.457643: train_loss -0.8728 
2025-07-08 01:30:11.458123: val_loss -0.8336 
2025-07-08 01:30:11.458221: Pseudo dice [np.float32(0.8564)] 
2025-07-08 01:30:11.458331: Epoch time: 47.69 s 
2025-07-08 01:30:12.568474:  
2025-07-08 01:30:12.569046: Epoch 86 
2025-07-08 01:30:12.569147: Current learning rate: 0.00922 
2025-07-08 01:31:02.515157: train_loss -0.8408 
2025-07-08 01:31:02.516039: val_loss -0.8673 
2025-07-08 01:31:02.516140: Pseudo dice [np.float32(0.8996)] 
2025-07-08 01:31:02.516256: Epoch time: 49.95 s 
2025-07-08 01:31:03.694536:  
2025-07-08 01:31:03.694777: Epoch 87 
2025-07-08 01:31:03.694894: Current learning rate: 0.00921 
2025-07-08 01:31:51.517067: train_loss -0.8666 
2025-07-08 01:31:51.517703: val_loss -0.8825 
2025-07-08 01:31:51.517817: Pseudo dice [np.float32(0.9065)] 
2025-07-08 01:31:51.517960: Epoch time: 47.82 s 
2025-07-08 01:31:52.656768:  
2025-07-08 01:31:52.657179: Epoch 88 
2025-07-08 01:31:52.657312: Current learning rate: 0.0092 
2025-07-08 01:32:42.716530: train_loss -0.8859 
2025-07-08 01:32:42.716882: val_loss -0.89 
2025-07-08 01:32:42.716962: Pseudo dice [np.float32(0.9177)] 
2025-07-08 01:32:42.717056: Epoch time: 50.06 s 
2025-07-08 01:32:43.883019:  
2025-07-08 01:32:43.883327: Epoch 89 
2025-07-08 01:32:43.883562: Current learning rate: 0.0092 
2025-07-08 01:33:33.215879: train_loss -0.8872 
2025-07-08 01:33:33.216141: val_loss -0.8672 
2025-07-08 01:33:33.216210: Pseudo dice [np.float32(0.8998)] 
2025-07-08 01:33:33.216297: Epoch time: 49.33 s 
2025-07-08 01:33:34.365750:  
2025-07-08 01:33:34.366020: Epoch 90 
2025-07-08 01:33:34.366148: Current learning rate: 0.00919 
2025-07-08 01:34:22.942608: train_loss -0.8696 
2025-07-08 01:34:22.943214: val_loss -0.8819 
2025-07-08 01:34:22.943341: Pseudo dice [np.float32(0.9036)] 
2025-07-08 01:34:22.943490: Epoch time: 48.58 s 
2025-07-08 01:34:24.130656:  
2025-07-08 01:34:24.131148: Epoch 91 
2025-07-08 01:34:24.131325: Current learning rate: 0.00918 
2025-07-08 01:35:14.011560: train_loss -0.8888 
2025-07-08 01:35:14.012533: val_loss -0.866 
2025-07-08 01:35:14.012692: Pseudo dice [np.float32(0.9065)] 
2025-07-08 01:35:14.012916: Epoch time: 49.88 s 
2025-07-08 01:35:15.163562:  
2025-07-08 01:35:15.163783: Epoch 92 
2025-07-08 01:35:15.163906: Current learning rate: 0.00917 
2025-07-08 01:36:04.376798: train_loss -0.8748 
2025-07-08 01:36:04.377277: val_loss -0.866 
2025-07-08 01:36:04.377378: Pseudo dice [np.float32(0.9058)] 
2025-07-08 01:36:04.377488: Epoch time: 49.21 s 
2025-07-08 01:36:05.527525:  
2025-07-08 01:36:05.528003: Epoch 93 
2025-07-08 01:36:05.528218: Current learning rate: 0.00916 
2025-07-08 01:36:56.009126: train_loss -0.8775 
2025-07-08 01:36:56.009969: val_loss -0.8807 
2025-07-08 01:36:56.010113: Pseudo dice [np.float32(0.9013)] 
2025-07-08 01:36:56.010256: Epoch time: 50.48 s 
2025-07-08 01:36:57.154508:  
2025-07-08 01:36:57.154849: Epoch 94 
2025-07-08 01:36:57.154980: Current learning rate: 0.00915 
2025-07-08 01:37:47.048367: train_loss -0.8557 
2025-07-08 01:37:47.048836: val_loss -0.8834 
2025-07-08 01:37:47.048925: Pseudo dice [np.float32(0.903)] 
2025-07-08 01:37:47.049052: Epoch time: 49.89 s 
2025-07-08 01:37:48.344031:  
2025-07-08 01:37:48.344444: Epoch 95 
2025-07-08 01:37:48.344588: Current learning rate: 0.00914 
2025-07-08 01:38:37.629062: train_loss -0.8518 
2025-07-08 01:38:37.629798: val_loss -0.8401 
2025-07-08 01:38:37.629994: Pseudo dice [np.float32(0.8851)] 
2025-07-08 01:38:37.630127: Epoch time: 49.29 s 
2025-07-08 01:38:38.816952:  
2025-07-08 01:38:38.817309: Epoch 96 
2025-07-08 01:38:38.817435: Current learning rate: 0.00913 
2025-07-08 01:39:28.266952: train_loss -0.8659 
2025-07-08 01:39:28.267692: val_loss -0.8851 
2025-07-08 01:39:28.267782: Pseudo dice [np.float32(0.9151)] 
2025-07-08 01:39:28.267893: Epoch time: 49.45 s 
2025-07-08 01:39:29.410186:  
2025-07-08 01:39:29.410447: Epoch 97 
2025-07-08 01:39:29.410631: Current learning rate: 0.00912 
2025-07-08 01:40:18.919189: train_loss -0.8684 
2025-07-08 01:40:18.920072: val_loss -0.8729 
2025-07-08 01:40:18.920231: Pseudo dice [np.float32(0.9053)] 
2025-07-08 01:40:18.920401: Epoch time: 49.51 s 
2025-07-08 01:40:20.177508:  
2025-07-08 01:40:20.178020: Epoch 98 
2025-07-08 01:40:20.178297: Current learning rate: 0.00911 
2025-07-08 01:41:08.941929: train_loss -0.8717 
2025-07-08 01:41:08.942741: val_loss -0.8612 
2025-07-08 01:41:08.942859: Pseudo dice [np.float32(0.8822)] 
2025-07-08 01:41:08.943007: Epoch time: 48.77 s 
2025-07-08 01:41:11.201596:  
2025-07-08 01:41:11.202186: Epoch 99 
2025-07-08 01:41:11.202411: Current learning rate: 0.0091 
2025-07-08 01:42:01.644743: train_loss -0.8808 
2025-07-08 01:42:01.646005: val_loss -0.8966 
2025-07-08 01:42:01.646191: Pseudo dice [np.float32(0.9182)] 
2025-07-08 01:42:01.646360: Epoch time: 50.44 s 
2025-07-08 01:42:03.836797:  
2025-07-08 01:42:03.837007: Epoch 100 
2025-07-08 01:42:03.837117: Current learning rate: 0.0091 
2025-07-08 01:42:53.085088: train_loss -0.8838 
2025-07-08 01:42:53.085661: val_loss -0.8735 
2025-07-08 01:42:53.085759: Pseudo dice [np.float32(0.9061)] 
2025-07-08 01:42:53.085860: Epoch time: 49.25 s 
2025-07-08 01:42:54.258900:  
2025-07-08 01:42:54.259227: Epoch 101 
2025-07-08 01:42:54.259362: Current learning rate: 0.00909 
2025-07-08 01:43:44.475609: train_loss -0.8878 
2025-07-08 01:43:44.476510: val_loss -0.8989 
2025-07-08 01:43:44.476858: Pseudo dice [np.float32(0.9212)] 
2025-07-08 01:43:44.477026: Epoch time: 50.22 s 
2025-07-08 01:43:45.638256:  
2025-07-08 01:43:45.638600: Epoch 102 
2025-07-08 01:43:45.638923: Current learning rate: 0.00908 
2025-07-08 01:44:35.829050: train_loss -0.8781 
2025-07-08 01:44:35.829918: val_loss -0.8829 
2025-07-08 01:44:35.830048: Pseudo dice [np.float32(0.9174)] 
2025-07-08 01:44:35.830202: Epoch time: 50.19 s 
2025-07-08 01:44:37.196060:  
2025-07-08 01:44:37.196869: Epoch 103 
2025-07-08 01:44:37.197027: Current learning rate: 0.00907 
2025-07-08 01:45:26.614791: train_loss -0.8817 
2025-07-08 01:45:26.615330: val_loss -0.8918 
2025-07-08 01:45:26.615457: Pseudo dice [np.float32(0.9194)] 
2025-07-08 01:45:26.615675: Epoch time: 49.42 s 
2025-07-08 01:45:26.615784: Yayy! New best EMA pseudo Dice: 0.9075000286102295 
2025-07-08 01:45:28.635399:  
2025-07-08 01:45:28.635602: Epoch 104 
2025-07-08 01:45:28.635722: Current learning rate: 0.00906 
2025-07-08 01:46:17.584210: train_loss -0.8804 
2025-07-08 01:46:17.584828: val_loss -0.8768 
2025-07-08 01:46:17.584942: Pseudo dice [np.float32(0.9117)] 
2025-07-08 01:46:17.585075: Epoch time: 48.95 s 
2025-07-08 01:46:17.585168: Yayy! New best EMA pseudo Dice: 0.9078999757766724 
2025-07-08 01:46:19.526343:  
2025-07-08 01:46:19.526746: Epoch 105 
2025-07-08 01:46:19.527000: Current learning rate: 0.00905 
2025-07-08 01:47:09.932201: train_loss -0.8875 
2025-07-08 01:47:09.932754: val_loss -0.9036 
2025-07-08 01:47:09.932841: Pseudo dice [np.float32(0.9191)] 
2025-07-08 01:47:09.932957: Epoch time: 50.41 s 
2025-07-08 01:47:09.933035: Yayy! New best EMA pseudo Dice: 0.9089999794960022 
2025-07-08 01:47:12.032822:  
2025-07-08 01:47:12.033133: Epoch 106 
2025-07-08 01:47:12.033342: Current learning rate: 0.00904 
2025-07-08 01:47:58.966004: train_loss -0.886 
2025-07-08 01:47:58.966577: val_loss -0.8853 
2025-07-08 01:47:58.966677: Pseudo dice [np.float32(0.9)] 
2025-07-08 01:47:58.966818: Epoch time: 46.93 s 
2025-07-08 01:48:00.146594:  
2025-07-08 01:48:00.146865: Epoch 107 
2025-07-08 01:48:00.147103: Current learning rate: 0.00903 
2025-07-08 01:48:49.691356: train_loss -0.8822 
2025-07-08 01:48:49.692149: val_loss -0.9014 
2025-07-08 01:48:49.692308: Pseudo dice [np.float32(0.9229)] 
2025-07-08 01:48:49.692464: Epoch time: 49.55 s 
2025-07-08 01:48:49.692595: Yayy! New best EMA pseudo Dice: 0.909600019454956 
2025-07-08 01:48:51.747745:  
2025-07-08 01:48:51.748242: Epoch 108 
2025-07-08 01:48:51.748374: Current learning rate: 0.00902 
2025-07-08 01:49:40.916215: train_loss -0.8876 
2025-07-08 01:49:40.916782: val_loss -0.8868 
2025-07-08 01:49:40.916869: Pseudo dice [np.float32(0.9085)] 
2025-07-08 01:49:40.916987: Epoch time: 49.17 s 
2025-07-08 01:49:42.063259:  
2025-07-08 01:49:42.063910: Epoch 109 
2025-07-08 01:49:42.064070: Current learning rate: 0.00901 
2025-07-08 01:50:31.035153: train_loss -0.8892 
2025-07-08 01:50:31.036420: val_loss -0.8986 
2025-07-08 01:50:31.036598: Pseudo dice [np.float32(0.921)] 
2025-07-08 01:50:31.036881: Epoch time: 48.97 s 
2025-07-08 01:50:31.037014: Yayy! New best EMA pseudo Dice: 0.9106000065803528 
2025-07-08 01:50:33.259030:  
2025-07-08 01:50:33.259384: Epoch 110 
2025-07-08 01:50:33.259484: Current learning rate: 0.009 
2025-07-08 01:51:23.307118: train_loss -0.8872 
2025-07-08 01:51:23.308318: val_loss -0.8915 
2025-07-08 01:51:23.308424: Pseudo dice [np.float32(0.9161)] 
2025-07-08 01:51:23.308560: Epoch time: 50.05 s 
2025-07-08 01:51:23.308652: Yayy! New best EMA pseudo Dice: 0.9111999869346619 
2025-07-08 01:51:25.385136:  
2025-07-08 01:51:25.388366: Epoch 111 
2025-07-08 01:51:25.388626: Current learning rate: 0.009 
2025-07-08 01:52:14.472247: train_loss -0.8875 
2025-07-08 01:52:14.472832: val_loss -0.9056 
2025-07-08 01:52:14.472930: Pseudo dice [np.float32(0.9267)] 
2025-07-08 01:52:14.473049: Epoch time: 49.09 s 
2025-07-08 01:52:14.473127: Yayy! New best EMA pseudo Dice: 0.9126999974250793 
2025-07-08 01:52:16.518176:  
2025-07-08 01:52:16.518665: Epoch 112 
2025-07-08 01:52:16.518798: Current learning rate: 0.00899 
2025-07-08 01:53:06.994060: train_loss -0.8806 
2025-07-08 01:53:06.994862: val_loss -0.8934 
2025-07-08 01:53:06.994992: Pseudo dice [np.float32(0.9205)] 
2025-07-08 01:53:06.995134: Epoch time: 50.48 s 
2025-07-08 01:53:06.995225: Yayy! New best EMA pseudo Dice: 0.9135000109672546 
2025-07-08 01:53:09.041761:  
2025-07-08 01:53:09.042194: Epoch 113 
2025-07-08 01:53:09.042465: Current learning rate: 0.00898 
2025-07-08 01:53:59.401723: train_loss -0.8775 
2025-07-08 01:53:59.402202: val_loss -0.8851 
2025-07-08 01:53:59.402290: Pseudo dice [np.float32(0.9149)] 
2025-07-08 01:53:59.402405: Epoch time: 50.36 s 
2025-07-08 01:53:59.402487: Yayy! New best EMA pseudo Dice: 0.9136000275611877 
2025-07-08 01:54:01.517049:  
2025-07-08 01:54:01.517483: Epoch 114 
2025-07-08 01:54:01.517634: Current learning rate: 0.00897 
2025-07-08 01:54:50.331162: train_loss -0.8797 
2025-07-08 01:54:50.331702: val_loss -0.882 
2025-07-08 01:54:50.331787: Pseudo dice [np.float32(0.9105)] 
2025-07-08 01:54:50.331892: Epoch time: 48.82 s 
2025-07-08 01:54:52.554251:  
2025-07-08 01:54:52.554627: Epoch 115 
2025-07-08 01:54:52.554812: Current learning rate: 0.00896 
2025-07-08 01:55:43.139402: train_loss -0.8855 
2025-07-08 01:55:43.140434: val_loss -0.8918 
2025-07-08 01:55:43.140555: Pseudo dice [np.float32(0.9088)] 
2025-07-08 01:55:43.140697: Epoch time: 50.59 s 
2025-07-08 01:55:44.379452:  
2025-07-08 01:55:44.379785: Epoch 116 
2025-07-08 01:55:44.379981: Current learning rate: 0.00895 
2025-07-08 01:56:34.427902: train_loss -0.8903 
2025-07-08 01:56:34.428692: val_loss -0.8917 
2025-07-08 01:56:34.428808: Pseudo dice [np.float32(0.9197)] 
2025-07-08 01:56:34.428930: Epoch time: 50.05 s 
2025-07-08 01:56:35.758842:  
2025-07-08 01:56:35.759254: Epoch 117 
2025-07-08 01:56:35.759423: Current learning rate: 0.00894 
2025-07-08 01:57:24.829159: train_loss -0.893 
2025-07-08 01:57:24.829528: val_loss -0.8846 
2025-07-08 01:57:24.829639: Pseudo dice [np.float32(0.9083)] 
2025-07-08 01:57:24.829756: Epoch time: 49.07 s 
2025-07-08 01:57:26.040584:  
2025-07-08 01:57:26.041214: Epoch 118 
2025-07-08 01:57:26.041418: Current learning rate: 0.00893 
2025-07-08 01:58:17.110455: train_loss -0.8919 
2025-07-08 01:58:17.111381: val_loss -0.8796 
2025-07-08 01:58:17.114956: Pseudo dice [np.float32(0.9072)] 
2025-07-08 01:58:17.115391: Epoch time: 51.07 s 
2025-07-08 01:58:18.353120:  
2025-07-08 01:58:18.353579: Epoch 119 
2025-07-08 01:58:18.353712: Current learning rate: 0.00892 
2025-07-08 01:59:07.271342: train_loss -0.8908 
2025-07-08 01:59:07.271996: val_loss -0.8909 
2025-07-08 01:59:07.272074: Pseudo dice [np.float32(0.9006)] 
2025-07-08 01:59:07.272230: Epoch time: 48.92 s 
2025-07-08 01:59:08.509151:  
2025-07-08 01:59:08.509606: Epoch 120 
2025-07-08 01:59:08.509717: Current learning rate: 0.00891 
2025-07-08 01:59:57.675463: train_loss -0.8891 
2025-07-08 01:59:57.676088: val_loss -0.896 
2025-07-08 01:59:57.676183: Pseudo dice [np.float32(0.9144)] 
2025-07-08 01:59:57.676290: Epoch time: 49.17 s 
2025-07-08 01:59:58.795844:  
2025-07-08 01:59:58.796086: Epoch 121 
2025-07-08 01:59:58.796426: Current learning rate: 0.0089 
2025-07-08 02:00:48.388679: train_loss -0.8956 
2025-07-08 02:00:48.389505: val_loss -0.8989 
2025-07-08 02:00:48.389644: Pseudo dice [np.float32(0.9215)] 
2025-07-08 02:00:48.389783: Epoch time: 49.59 s 
2025-07-08 02:00:49.592305:  
2025-07-08 02:00:49.593081: Epoch 122 
2025-07-08 02:00:49.593312: Current learning rate: 0.00889 
2025-07-08 02:01:37.318253: train_loss -0.8954 
2025-07-08 02:01:37.318873: val_loss -0.8982 
2025-07-08 02:01:37.318976: Pseudo dice [np.float32(0.9193)] 
2025-07-08 02:01:37.319140: Epoch time: 47.73 s 
2025-07-08 02:01:38.511273:  
2025-07-08 02:01:38.511419: Epoch 123 
2025-07-08 02:01:38.511607: Current learning rate: 0.00889 
2025-07-08 02:02:26.940002: train_loss -0.8999 
2025-07-08 02:02:26.940513: val_loss -0.916 
2025-07-08 02:02:26.940617: Pseudo dice [np.float32(0.9329)] 
2025-07-08 02:02:26.940732: Epoch time: 48.43 s 
2025-07-08 02:02:26.940806: Yayy! New best EMA pseudo Dice: 0.9151999950408936 
2025-07-08 02:02:29.091873:  
2025-07-08 02:02:29.092573: Epoch 124 
2025-07-08 02:02:29.093090: Current learning rate: 0.00888 
2025-07-08 02:03:17.687403: train_loss -0.8798 
2025-07-08 02:03:17.688045: val_loss -0.8942 
2025-07-08 02:03:17.688146: Pseudo dice [np.float32(0.9214)] 
2025-07-08 02:03:17.688287: Epoch time: 48.6 s 
2025-07-08 02:03:17.688371: Yayy! New best EMA pseudo Dice: 0.9157999753952026 
2025-07-08 02:03:19.822919:  
2025-07-08 02:03:19.823681: Epoch 125 
2025-07-08 02:03:19.824294: Current learning rate: 0.00887 
2025-07-08 02:04:09.540419: train_loss -0.8817 
2025-07-08 02:04:09.541066: val_loss -0.8988 
2025-07-08 02:04:09.541154: Pseudo dice [np.float32(0.9266)] 
2025-07-08 02:04:09.541273: Epoch time: 49.72 s 
2025-07-08 02:04:09.541356: Yayy! New best EMA pseudo Dice: 0.9168999791145325 
2025-07-08 02:04:11.636381:  
2025-07-08 02:04:11.636855: Epoch 126 
2025-07-08 02:04:11.637060: Current learning rate: 0.00886 
2025-07-08 02:05:00.686047: train_loss -0.8847 
2025-07-08 02:05:00.686926: val_loss -0.8743 
2025-07-08 02:05:00.687075: Pseudo dice [np.float32(0.9035)] 
2025-07-08 02:05:00.687281: Epoch time: 49.05 s 
2025-07-08 02:05:01.922152:  
2025-07-08 02:05:01.922507: Epoch 127 
2025-07-08 02:05:01.922675: Current learning rate: 0.00885 
2025-07-08 02:05:50.506922: train_loss -0.8784 
2025-07-08 02:05:50.508121: val_loss -0.8699 
2025-07-08 02:05:50.508245: Pseudo dice [np.float32(0.8883)] 
2025-07-08 02:05:50.508409: Epoch time: 48.59 s 
2025-07-08 02:05:51.722498:  
2025-07-08 02:05:51.722686: Epoch 128 
2025-07-08 02:05:51.722844: Current learning rate: 0.00884 
2025-07-08 02:06:41.359004: train_loss -0.8773 
2025-07-08 02:06:41.359465: val_loss -0.8693 
2025-07-08 02:06:41.359549: Pseudo dice [np.float32(0.9042)] 
2025-07-08 02:06:41.359658: Epoch time: 49.64 s 
2025-07-08 02:06:42.481454:  
2025-07-08 02:06:42.481645: Epoch 129 
2025-07-08 02:06:42.481763: Current learning rate: 0.00883 
2025-07-08 02:07:31.824422: train_loss -0.8686 
2025-07-08 02:07:31.824820: val_loss -0.8658 
2025-07-08 02:07:31.824905: Pseudo dice [np.float32(0.8919)] 
2025-07-08 02:07:31.825005: Epoch time: 49.34 s 
2025-07-08 02:07:33.911227:  
2025-07-08 02:07:33.911715: Epoch 130 
2025-07-08 02:07:33.912060: Current learning rate: 0.00882 
2025-07-08 02:08:24.768726: train_loss -0.8769 
2025-07-08 02:08:24.769130: val_loss -0.876 
2025-07-08 02:08:24.772557: Pseudo dice [np.float32(0.8915)] 
2025-07-08 02:08:24.772707: Epoch time: 50.86 s 
2025-07-08 02:08:25.944998:  
2025-07-08 02:08:25.945514: Epoch 131 
2025-07-08 02:08:25.945716: Current learning rate: 0.00881 
2025-07-08 02:09:14.944889: train_loss -0.883 
2025-07-08 02:09:14.945528: val_loss -0.8955 
2025-07-08 02:09:14.945661: Pseudo dice [np.float32(0.9225)] 
2025-07-08 02:09:14.945792: Epoch time: 49.0 s 
2025-07-08 02:09:16.188700:  
2025-07-08 02:09:16.189368: Epoch 132 
2025-07-08 02:09:16.189707: Current learning rate: 0.0088 
2025-07-08 02:10:04.445397: train_loss -0.8728 
2025-07-08 02:10:04.446025: val_loss -0.8801 
2025-07-08 02:10:04.446125: Pseudo dice [np.float32(0.9106)] 
2025-07-08 02:10:04.446258: Epoch time: 48.26 s 
2025-07-08 02:10:05.633290:  
2025-07-08 02:10:05.633458: Epoch 133 
2025-07-08 02:10:05.633579: Current learning rate: 0.00879 
2025-07-08 02:10:54.137452: train_loss -0.877 
2025-07-08 02:10:54.138778: val_loss -0.9024 
2025-07-08 02:10:54.138953: Pseudo dice [np.float32(0.9241)] 
2025-07-08 02:10:54.139139: Epoch time: 48.51 s 
2025-07-08 02:10:55.396942:  
2025-07-08 02:10:55.397265: Epoch 134 
2025-07-08 02:10:55.397390: Current learning rate: 0.00879 
2025-07-08 02:11:44.885655: train_loss -0.8883 
2025-07-08 02:11:44.886246: val_loss -0.8971 
2025-07-08 02:11:44.886339: Pseudo dice [np.float32(0.9174)] 
2025-07-08 02:11:44.886450: Epoch time: 49.49 s 
2025-07-08 02:11:45.976715:  
2025-07-08 02:11:45.977108: Epoch 135 
2025-07-08 02:11:45.977234: Current learning rate: 0.00878 
2025-07-08 02:12:36.012993: train_loss -0.8966 
2025-07-08 02:12:36.013535: val_loss -0.8895 
2025-07-08 02:12:36.013630: Pseudo dice [np.float32(0.9067)] 
2025-07-08 02:12:36.013734: Epoch time: 50.04 s 
2025-07-08 02:12:37.172201:  
2025-07-08 02:12:37.172529: Epoch 136 
2025-07-08 02:12:37.172787: Current learning rate: 0.00877 
2025-07-08 02:13:26.021672: train_loss -0.8885 
2025-07-08 02:13:26.022076: val_loss -0.8998 
2025-07-08 02:13:26.022159: Pseudo dice [np.float32(0.9216)] 
2025-07-08 02:13:26.022269: Epoch time: 48.85 s 
2025-07-08 02:13:27.114032:  
2025-07-08 02:13:27.114302: Epoch 137 
2025-07-08 02:13:27.114419: Current learning rate: 0.00876 
2025-07-08 02:14:16.048960: train_loss -0.8925 
2025-07-08 02:14:16.049562: val_loss -0.8971 
2025-07-08 02:14:16.049758: Pseudo dice [np.float32(0.9241)] 
2025-07-08 02:14:16.049887: Epoch time: 48.94 s 
2025-07-08 02:14:17.335102:  
2025-07-08 02:14:17.335499: Epoch 138 
2025-07-08 02:14:17.335776: Current learning rate: 0.00875 
2025-07-08 02:15:08.336395: train_loss -0.8859 
2025-07-08 02:15:08.336855: val_loss -0.9038 
2025-07-08 02:15:08.337009: Pseudo dice [np.float32(0.9105)] 
2025-07-08 02:15:08.337141: Epoch time: 51.0 s 
2025-07-08 02:15:09.552369:  
2025-07-08 02:15:09.552570: Epoch 139 
2025-07-08 02:15:09.552693: Current learning rate: 0.00874 
2025-07-08 02:15:59.934726: train_loss -0.8911 
2025-07-08 02:15:59.935220: val_loss -0.8786 
2025-07-08 02:15:59.935307: Pseudo dice [np.float32(0.913)] 
2025-07-08 02:15:59.935405: Epoch time: 50.38 s 
2025-07-08 02:16:01.162092:  
2025-07-08 02:16:01.162548: Epoch 140 
2025-07-08 02:16:01.162700: Current learning rate: 0.00873 
2025-07-08 02:16:50.763031: train_loss -0.8912 
2025-07-08 02:16:50.764144: val_loss -0.9021 
2025-07-08 02:16:50.764307: Pseudo dice [np.float32(0.9312)] 
2025-07-08 02:16:50.764445: Epoch time: 49.6 s 
2025-07-08 02:16:52.222626:  
2025-07-08 02:16:52.223120: Epoch 141 
2025-07-08 02:16:52.223287: Current learning rate: 0.00872 
2025-07-08 02:17:40.339753: train_loss -0.8872 
2025-07-08 02:17:40.340090: val_loss -0.88 
2025-07-08 02:17:40.340163: Pseudo dice [np.float32(0.9043)] 
2025-07-08 02:17:40.340258: Epoch time: 48.12 s 
2025-07-08 02:17:41.498854:  
2025-07-08 02:17:41.499260: Epoch 142 
2025-07-08 02:17:41.499624: Current learning rate: 0.00871 
2025-07-08 02:18:30.790462: train_loss -0.8971 
2025-07-08 02:18:30.791078: val_loss -0.8919 
2025-07-08 02:18:30.791164: Pseudo dice [np.float32(0.9144)] 
2025-07-08 02:18:30.791274: Epoch time: 49.29 s 
2025-07-08 02:18:31.875044:  
2025-07-08 02:18:31.875341: Epoch 143 
2025-07-08 02:18:31.875565: Current learning rate: 0.0087 
2025-07-08 02:19:22.890070: train_loss -0.8862 
2025-07-08 02:19:22.890764: val_loss -0.8981 
2025-07-08 02:19:22.890877: Pseudo dice [np.float32(0.9213)] 
2025-07-08 02:19:22.891026: Epoch time: 51.02 s 
2025-07-08 02:19:25.333313:  
2025-07-08 02:19:25.333829: Epoch 144 
2025-07-08 02:19:25.334102: Current learning rate: 0.00869 
2025-07-08 02:20:13.545760: train_loss -0.8973 
2025-07-08 02:20:13.546307: val_loss -0.8866 
2025-07-08 02:20:13.546509: Pseudo dice [np.float32(0.8969)] 
2025-07-08 02:20:13.546656: Epoch time: 48.21 s 
2025-07-08 02:20:14.763621:  
2025-07-08 02:20:14.763891: Epoch 145 
2025-07-08 02:20:14.764019: Current learning rate: 0.00868 
2025-07-08 02:21:06.330577: train_loss -0.882 
2025-07-08 02:21:06.331229: val_loss -0.8985 
2025-07-08 02:21:06.331322: Pseudo dice [np.float32(0.9178)] 
2025-07-08 02:21:06.331443: Epoch time: 51.57 s 
2025-07-08 02:21:07.493692:  
2025-07-08 02:21:07.493936: Epoch 146 
2025-07-08 02:21:07.494061: Current learning rate: 0.00868 
2025-07-08 02:21:57.668960: train_loss -0.8888 
2025-07-08 02:21:57.670717: val_loss -0.8903 
2025-07-08 02:21:57.671063: Pseudo dice [np.float32(0.9233)] 
2025-07-08 02:21:57.671285: Epoch time: 50.18 s 
2025-07-08 02:21:58.964298:  
2025-07-08 02:21:58.964728: Epoch 147 
2025-07-08 02:21:58.964848: Current learning rate: 0.00867 
2025-07-08 02:22:47.856171: train_loss -0.8928 
2025-07-08 02:22:47.857014: val_loss -0.9009 
2025-07-08 02:22:47.857106: Pseudo dice [np.float32(0.9259)] 
2025-07-08 02:22:47.857229: Epoch time: 48.89 s 
2025-07-08 02:22:49.105880:  
2025-07-08 02:22:49.106133: Epoch 148 
2025-07-08 02:22:49.106236: Current learning rate: 0.00866 
2025-07-08 02:23:38.747731: train_loss -0.8853 
2025-07-08 02:23:38.748180: val_loss -0.8968 
2025-07-08 02:23:38.748256: Pseudo dice [np.float32(0.9173)] 
2025-07-08 02:23:38.748350: Epoch time: 49.64 s 
2025-07-08 02:23:39.872449:  
2025-07-08 02:23:39.873052: Epoch 149 
2025-07-08 02:23:39.873174: Current learning rate: 0.00865 
2025-07-08 02:24:29.776040: train_loss -0.8879 
2025-07-08 02:24:29.777016: val_loss -0.8991 
2025-07-08 02:24:29.777178: Pseudo dice [np.float32(0.9138)] 
2025-07-08 02:24:29.777311: Epoch time: 49.9 s 
2025-07-08 02:24:31.932161:  
2025-07-08 02:24:31.932686: Epoch 150 
2025-07-08 02:24:31.933076: Current learning rate: 0.00864 
2025-07-08 02:25:21.479091: train_loss -0.8784 
2025-07-08 02:25:21.480130: val_loss -0.8866 
2025-07-08 02:25:21.480242: Pseudo dice [np.float32(0.9118)] 
2025-07-08 02:25:21.480366: Epoch time: 49.55 s 
2025-07-08 02:25:22.737954:  
2025-07-08 02:25:22.738440: Epoch 151 
2025-07-08 02:25:22.738594: Current learning rate: 0.00863 
2025-07-08 02:26:13.718425: train_loss -0.8918 
2025-07-08 02:26:13.719038: val_loss -0.9141 
2025-07-08 02:26:13.719248: Pseudo dice [np.float32(0.9333)] 
2025-07-08 02:26:13.719359: Epoch time: 50.98 s 
2025-07-08 02:26:13.719440: Yayy! New best EMA pseudo Dice: 0.9169999957084656 
2025-07-08 02:26:15.898678:  
2025-07-08 02:26:15.898918: Epoch 152 
2025-07-08 02:26:15.899380: Current learning rate: 0.00862 
2025-07-08 02:27:07.029860: train_loss -0.8864 
2025-07-08 02:27:07.030465: val_loss -0.8834 
2025-07-08 02:27:07.030562: Pseudo dice [np.float32(0.9196)] 
2025-07-08 02:27:07.030674: Epoch time: 51.13 s 
2025-07-08 02:27:07.030752: Yayy! New best EMA pseudo Dice: 0.9172000288963318 
2025-07-08 02:27:09.094864:  
2025-07-08 02:27:09.095173: Epoch 153 
2025-07-08 02:27:09.095360: Current learning rate: 0.00861 
2025-07-08 02:27:58.561280: train_loss -0.8709 
2025-07-08 02:27:58.562436: val_loss -0.8808 
2025-07-08 02:27:58.562562: Pseudo dice [np.float32(0.9161)] 
2025-07-08 02:27:58.562727: Epoch time: 49.47 s 
2025-07-08 02:27:59.773191:  
2025-07-08 02:27:59.773740: Epoch 154 
2025-07-08 02:27:59.773875: Current learning rate: 0.0086 
2025-07-08 02:28:49.301680: train_loss -0.8909 
2025-07-08 02:28:49.302320: val_loss -0.8946 
2025-07-08 02:28:49.302408: Pseudo dice [np.float32(0.9172)] 
2025-07-08 02:28:49.302516: Epoch time: 49.53 s 
2025-07-08 02:28:50.494157:  
2025-07-08 02:28:50.494412: Epoch 155 
2025-07-08 02:28:50.494553: Current learning rate: 0.00859 
2025-07-08 02:29:41.347138: train_loss -0.8953 
2025-07-08 02:29:41.347596: val_loss -0.886 
2025-07-08 02:29:41.347761: Pseudo dice [np.float32(0.9094)] 
2025-07-08 02:29:41.347871: Epoch time: 50.85 s 
2025-07-08 02:29:42.535958:  
2025-07-08 02:29:42.536446: Epoch 156 
2025-07-08 02:29:42.536600: Current learning rate: 0.00858 
2025-07-08 02:30:30.959417: train_loss -0.8867 
2025-07-08 02:30:30.960307: val_loss -0.9091 
2025-07-08 02:30:30.960395: Pseudo dice [np.float32(0.9295)] 
2025-07-08 02:30:30.960511: Epoch time: 48.42 s 
2025-07-08 02:30:30.960604: Yayy! New best EMA pseudo Dice: 0.9176999926567078 
2025-07-08 02:30:33.015907:  
2025-07-08 02:30:33.016066: Epoch 157 
2025-07-08 02:30:33.016182: Current learning rate: 0.00858 
2025-07-08 02:31:21.855714: train_loss -0.9029 
2025-07-08 02:31:21.856065: val_loss -0.8929 
2025-07-08 02:31:21.856224: Pseudo dice [np.float32(0.9211)] 
2025-07-08 02:31:21.856337: Epoch time: 48.84 s 
2025-07-08 02:31:21.856411: Yayy! New best EMA pseudo Dice: 0.9179999828338623 
2025-07-08 02:31:23.851913:  
2025-07-08 02:31:23.852222: Epoch 158 
2025-07-08 02:31:23.852430: Current learning rate: 0.00857 
2025-07-08 02:32:13.097132: train_loss -0.8913 
2025-07-08 02:32:13.097587: val_loss -0.8703 
2025-07-08 02:32:13.097669: Pseudo dice [np.float32(0.9018)] 
2025-07-08 02:32:13.097786: Epoch time: 49.25 s 
2025-07-08 02:32:15.064874:  
2025-07-08 02:32:15.065261: Epoch 159 
2025-07-08 02:32:15.065497: Current learning rate: 0.00856 
2025-07-08 02:33:04.370384: train_loss -0.8598 
2025-07-08 02:33:04.371460: val_loss -0.8958 
2025-07-08 02:33:04.371925: Pseudo dice [np.float32(0.916)] 
2025-07-08 02:33:04.372838: Epoch time: 49.31 s 
2025-07-08 02:33:05.576100:  
2025-07-08 02:33:05.576572: Epoch 160 
2025-07-08 02:33:05.576844: Current learning rate: 0.00855 
2025-07-08 02:33:56.333683: train_loss -0.8866 
2025-07-08 02:33:56.334266: val_loss -0.899 
2025-07-08 02:33:56.334361: Pseudo dice [np.float32(0.9138)] 
2025-07-08 02:33:56.334497: Epoch time: 50.76 s 
2025-07-08 02:33:57.565677:  
2025-07-08 02:33:57.566062: Epoch 161 
2025-07-08 02:33:57.566337: Current learning rate: 0.00854 
2025-07-08 02:34:46.611014: train_loss -0.8875 
2025-07-08 02:34:46.612220: val_loss -0.8826 
2025-07-08 02:34:46.612347: Pseudo dice [np.float32(0.9122)] 
2025-07-08 02:34:46.612499: Epoch time: 49.05 s 
2025-07-08 02:34:47.791976:  
2025-07-08 02:34:47.792962: Epoch 162 
2025-07-08 02:34:47.793321: Current learning rate: 0.00853 
2025-07-08 02:35:35.969852: train_loss -0.8926 
2025-07-08 02:35:35.970818: val_loss -0.8991 
2025-07-08 02:35:35.970956: Pseudo dice [np.float32(0.9246)] 
2025-07-08 02:35:35.971139: Epoch time: 48.18 s 
2025-07-08 02:35:37.341293:  
2025-07-08 02:35:37.342013: Epoch 163 
2025-07-08 02:35:37.342387: Current learning rate: 0.00852 
2025-07-08 02:36:26.569857: train_loss -0.8959 
2025-07-08 02:36:26.570510: val_loss -0.8863 
2025-07-08 02:36:26.570649: Pseudo dice [np.float32(0.908)] 
2025-07-08 02:36:26.570797: Epoch time: 49.23 s 
2025-07-08 02:36:27.786131:  
2025-07-08 02:36:27.786460: Epoch 164 
2025-07-08 02:36:27.786749: Current learning rate: 0.00851 
2025-07-08 02:37:16.027449: train_loss -0.893 
2025-07-08 02:37:16.027906: val_loss -0.9106 
2025-07-08 02:37:16.027993: Pseudo dice [np.float32(0.9297)] 
2025-07-08 02:37:16.028103: Epoch time: 48.24 s 
2025-07-08 02:37:17.282049:  
2025-07-08 02:37:17.282388: Epoch 165 
2025-07-08 02:37:17.282611: Current learning rate: 0.0085 
2025-07-08 02:38:05.392169: train_loss -0.8902 
2025-07-08 02:38:05.392562: val_loss -0.9054 
2025-07-08 02:38:05.392645: Pseudo dice [np.float32(0.9263)] 
2025-07-08 02:38:05.392749: Epoch time: 48.11 s 
2025-07-08 02:38:05.392827: Yayy! New best EMA pseudo Dice: 0.9179999828338623 
2025-07-08 02:38:07.402650:  
2025-07-08 02:38:07.403126: Epoch 166 
2025-07-08 02:38:07.403435: Current learning rate: 0.00849 
2025-07-08 02:38:57.347433: train_loss -0.8988 
2025-07-08 02:38:57.348319: val_loss -0.9114 
2025-07-08 02:38:57.348472: Pseudo dice [np.float32(0.9304)] 
2025-07-08 02:38:57.348681: Epoch time: 49.95 s 
2025-07-08 02:38:57.348807: Yayy! New best EMA pseudo Dice: 0.9193000197410583 
2025-07-08 02:38:59.455897:  
2025-07-08 02:38:59.456286: Epoch 167 
2025-07-08 02:38:59.456624: Current learning rate: 0.00848 
2025-07-08 02:39:49.757022: train_loss -0.8924 
2025-07-08 02:39:49.757457: val_loss -0.9001 
2025-07-08 02:39:49.757555: Pseudo dice [np.float32(0.9178)] 
2025-07-08 02:39:49.757703: Epoch time: 50.3 s 
2025-07-08 02:39:50.926706:  
2025-07-08 02:39:50.926958: Epoch 168 
2025-07-08 02:39:50.927084: Current learning rate: 0.00847 
2025-07-08 02:40:40.165962: train_loss -0.8927 
2025-07-08 02:40:40.166626: val_loss -0.8978 
2025-07-08 02:40:40.166713: Pseudo dice [np.float32(0.9164)] 
2025-07-08 02:40:40.166811: Epoch time: 49.24 s 
2025-07-08 02:40:41.322307:  
2025-07-08 02:40:41.322471: Epoch 169 
2025-07-08 02:40:41.322654: Current learning rate: 0.00847 
2025-07-08 02:41:29.788553: train_loss -0.8977 
2025-07-08 02:41:29.788930: val_loss -0.909 
2025-07-08 02:41:29.789009: Pseudo dice [np.float32(0.9275)] 
2025-07-08 02:41:29.789112: Epoch time: 48.47 s 
2025-07-08 02:41:29.789195: Yayy! New best EMA pseudo Dice: 0.919700026512146 
2025-07-08 02:41:31.944445:  
2025-07-08 02:41:31.944839: Epoch 170 
2025-07-08 02:41:31.944980: Current learning rate: 0.00846 
2025-07-08 02:42:22.537268: train_loss -0.8935 
2025-07-08 02:42:22.537895: val_loss -0.9093 
2025-07-08 02:42:22.537989: Pseudo dice [np.float32(0.926)] 
2025-07-08 02:42:22.538107: Epoch time: 50.59 s 
2025-07-08 02:42:22.538186: Yayy! New best EMA pseudo Dice: 0.9203000068664551 
2025-07-08 02:42:24.686691:  
2025-07-08 02:42:24.687044: Epoch 171 
2025-07-08 02:42:24.687259: Current learning rate: 0.00845 
2025-07-08 02:43:12.874856: train_loss -0.9012 
2025-07-08 02:43:12.875919: val_loss -0.8912 
2025-07-08 02:43:12.876114: Pseudo dice [np.float32(0.915)] 
2025-07-08 02:43:12.876331: Epoch time: 48.19 s 
2025-07-08 02:43:14.124189:  
2025-07-08 02:43:14.124567: Epoch 172 
2025-07-08 02:43:14.124705: Current learning rate: 0.00844 
2025-07-08 02:44:04.257374: train_loss -0.8959 
2025-07-08 02:44:04.257873: val_loss -0.9039 
2025-07-08 02:44:04.257957: Pseudo dice [np.float32(0.9298)] 
2025-07-08 02:44:04.258062: Epoch time: 50.13 s 
2025-07-08 02:44:04.258146: Yayy! New best EMA pseudo Dice: 0.920799970626831 
2025-07-08 02:44:07.282766:  
2025-07-08 02:44:07.283146: Epoch 173 
2025-07-08 02:44:07.283308: Current learning rate: 0.00843 
2025-07-08 02:44:57.804528: train_loss -0.8978 
2025-07-08 02:44:57.805224: val_loss -0.9013 
2025-07-08 02:44:57.805318: Pseudo dice [np.float32(0.9254)] 
2025-07-08 02:44:57.805440: Epoch time: 50.52 s 
2025-07-08 02:44:57.805516: Yayy! New best EMA pseudo Dice: 0.9212999939918518 
2025-07-08 02:44:59.948548:  
2025-07-08 02:44:59.948852: Epoch 174 
2025-07-08 02:44:59.949189: Current learning rate: 0.00842 
2025-07-08 02:45:48.719514: train_loss -0.8992 
2025-07-08 02:45:48.719948: val_loss -0.8956 
2025-07-08 02:45:48.720026: Pseudo dice [np.float32(0.9119)] 
2025-07-08 02:45:48.720120: Epoch time: 48.77 s 
2025-07-08 02:45:50.027251:  
2025-07-08 02:45:50.027528: Epoch 175 
2025-07-08 02:45:50.027771: Current learning rate: 0.00841 
2025-07-08 02:46:39.264497: train_loss -0.9047 
2025-07-08 02:46:39.265101: val_loss -0.9032 
2025-07-08 02:46:39.265268: Pseudo dice [np.float32(0.9295)] 
2025-07-08 02:46:39.265387: Epoch time: 49.24 s 
2025-07-08 02:46:40.396382:  
2025-07-08 02:46:40.396877: Epoch 176 
2025-07-08 02:46:40.397045: Current learning rate: 0.0084 
2025-07-08 02:47:29.709837: train_loss -0.9006 
2025-07-08 02:47:29.711081: val_loss -0.9133 
2025-07-08 02:47:29.711284: Pseudo dice [np.float32(0.9279)] 
2025-07-08 02:47:29.711515: Epoch time: 49.31 s 
2025-07-08 02:47:29.711655: Yayy! New best EMA pseudo Dice: 0.9218999743461609 
2025-07-08 02:47:31.802454:  
2025-07-08 02:47:31.802856: Epoch 177 
2025-07-08 02:47:31.802989: Current learning rate: 0.00839 
2025-07-08 02:48:20.988554: train_loss -0.8999 
2025-07-08 02:48:20.989309: val_loss -0.9173 
2025-07-08 02:48:20.989457: Pseudo dice [np.float32(0.9373)] 
2025-07-08 02:48:20.989607: Epoch time: 49.19 s 
2025-07-08 02:48:20.989694: Yayy! New best EMA pseudo Dice: 0.9235000014305115 
2025-07-08 02:48:23.080743:  
2025-07-08 02:48:23.080992: Epoch 178 
2025-07-08 02:48:23.081114: Current learning rate: 0.00838 
2025-07-08 02:49:13.304592: train_loss -0.9088 
2025-07-08 02:49:13.305660: val_loss -0.9141 
2025-07-08 02:49:13.305831: Pseudo dice [np.float32(0.9285)] 
2025-07-08 02:49:13.306015: Epoch time: 50.22 s 
2025-07-08 02:49:13.306154: Yayy! New best EMA pseudo Dice: 0.9240000247955322 
2025-07-08 02:49:15.457783:  
2025-07-08 02:49:15.458269: Epoch 179 
2025-07-08 02:49:15.458612: Current learning rate: 0.00837 
2025-07-08 02:50:06.285399: train_loss -0.8919 
2025-07-08 02:50:06.286445: val_loss -0.9006 
2025-07-08 02:50:06.286676: Pseudo dice [np.float32(0.9187)] 
2025-07-08 02:50:06.286852: Epoch time: 50.83 s 
2025-07-08 02:50:07.449309:  
2025-07-08 02:50:07.449792: Epoch 180 
2025-07-08 02:50:07.449926: Current learning rate: 0.00836 
2025-07-08 02:50:57.873197: train_loss -0.8916 
2025-07-08 02:50:57.873812: val_loss -0.9075 
2025-07-08 02:50:57.873898: Pseudo dice [np.float32(0.9261)] 
2025-07-08 02:50:57.874033: Epoch time: 50.43 s 
2025-07-08 02:50:59.127342:  
2025-07-08 02:50:59.127733: Epoch 181 
2025-07-08 02:50:59.127992: Current learning rate: 0.00836 
2025-07-08 02:51:48.680027: train_loss -0.8996 
2025-07-08 02:51:48.680846: val_loss -0.8973 
2025-07-08 02:51:48.680944: Pseudo dice [np.float32(0.9204)] 
2025-07-08 02:51:48.681088: Epoch time: 49.55 s 
2025-07-08 02:51:49.947897:  
2025-07-08 02:51:49.948027: Epoch 182 
2025-07-08 02:51:49.948136: Current learning rate: 0.00835 
2025-07-08 02:52:40.347070: train_loss -0.9032 
2025-07-08 02:52:40.347680: val_loss -0.8967 
2025-07-08 02:52:40.347762: Pseudo dice [np.float32(0.9201)] 
2025-07-08 02:52:40.347877: Epoch time: 50.4 s 
2025-07-08 02:52:41.602485:  
2025-07-08 02:52:41.602875: Epoch 183 
2025-07-08 02:52:41.603074: Current learning rate: 0.00834 
2025-07-08 02:53:30.061719: train_loss -0.9 
2025-07-08 02:53:30.062287: val_loss -0.9043 
2025-07-08 02:53:30.062397: Pseudo dice [np.float32(0.9256)] 
2025-07-08 02:53:30.062560: Epoch time: 48.46 s 
2025-07-08 02:53:31.315752:  
2025-07-08 02:53:31.316081: Epoch 184 
2025-07-08 02:53:31.316242: Current learning rate: 0.00833 
2025-07-08 02:54:20.722176: train_loss -0.8977 
2025-07-08 02:54:20.722981: val_loss -0.8944 
2025-07-08 02:54:20.723247: Pseudo dice [np.float32(0.9198)] 
2025-07-08 02:54:20.723423: Epoch time: 49.41 s 
2025-07-08 02:54:21.972394:  
2025-07-08 02:54:21.972586: Epoch 185 
2025-07-08 02:54:21.972831: Current learning rate: 0.00832 
2025-07-08 02:55:12.400848: train_loss -0.9004 
2025-07-08 02:55:12.401312: val_loss -0.9062 
2025-07-08 02:55:12.401417: Pseudo dice [np.float32(0.9192)] 
2025-07-08 02:55:12.401565: Epoch time: 50.43 s 
2025-07-08 02:55:13.625097:  
2025-07-08 02:55:13.625230: Epoch 186 
2025-07-08 02:55:13.625334: Current learning rate: 0.00831 
2025-07-08 02:56:02.666677: train_loss -0.8952 
2025-07-08 02:56:02.667340: val_loss -0.9088 
2025-07-08 02:56:02.667431: Pseudo dice [np.float32(0.9251)] 
2025-07-08 02:56:02.667535: Epoch time: 49.04 s 
2025-07-08 02:56:04.804919:  
2025-07-08 02:56:04.805158: Epoch 187 
2025-07-08 02:56:04.805264: Current learning rate: 0.0083 
2025-07-08 02:56:53.854357: train_loss -0.8855 
2025-07-08 02:56:53.854997: val_loss -0.8902 
2025-07-08 02:56:53.855088: Pseudo dice [np.float32(0.9196)] 
2025-07-08 02:56:53.855236: Epoch time: 49.05 s 
2025-07-08 02:56:55.076759:  
2025-07-08 02:56:55.077219: Epoch 188 
2025-07-08 02:56:55.077386: Current learning rate: 0.00829 
2025-07-08 02:57:45.965511: train_loss -0.8989 
2025-07-08 02:57:45.966795: val_loss -0.9025 
2025-07-08 02:57:45.966918: Pseudo dice [np.float32(0.9266)] 
2025-07-08 02:57:45.967078: Epoch time: 50.89 s 
2025-07-08 02:57:47.211211:  
2025-07-08 02:57:47.211494: Epoch 189 
2025-07-08 02:57:47.211812: Current learning rate: 0.00828 
2025-07-08 02:58:35.668895: train_loss -0.8969 
2025-07-08 02:58:35.669380: val_loss -0.9047 
2025-07-08 02:58:35.669460: Pseudo dice [np.float32(0.9268)] 
2025-07-08 02:58:35.669578: Epoch time: 48.46 s 
2025-07-08 02:58:36.873170:  
2025-07-08 02:58:36.873736: Epoch 190 
2025-07-08 02:58:36.874452: Current learning rate: 0.00827 
2025-07-08 02:59:26.496747: train_loss -0.8973 
2025-07-08 02:59:26.497830: val_loss -0.902 
2025-07-08 02:59:26.498178: Pseudo dice [np.float32(0.9219)] 
2025-07-08 02:59:26.498415: Epoch time: 49.63 s 
2025-07-08 02:59:27.659398:  
2025-07-08 02:59:27.659811: Epoch 191 
2025-07-08 02:59:27.660021: Current learning rate: 0.00826 
2025-07-08 03:00:17.481563: train_loss -0.9004 
2025-07-08 03:00:17.481903: val_loss -0.9088 
2025-07-08 03:00:17.481986: Pseudo dice [np.float32(0.9278)] 
2025-07-08 03:00:17.482086: Epoch time: 49.82 s 
2025-07-08 03:00:18.631924:  
2025-07-08 03:00:18.632182: Epoch 192 
2025-07-08 03:00:18.632313: Current learning rate: 0.00825 
2025-07-08 03:01:06.998585: train_loss -0.896 
2025-07-08 03:01:06.999249: val_loss -0.9008 
2025-07-08 03:01:06.999348: Pseudo dice [np.float32(0.9163)] 
2025-07-08 03:01:06.999482: Epoch time: 48.37 s 
2025-07-08 03:01:08.233906:  
2025-07-08 03:01:08.234277: Epoch 193 
2025-07-08 03:01:08.234411: Current learning rate: 0.00824 
2025-07-08 03:01:56.861386: train_loss -0.8909 
2025-07-08 03:01:56.861877: val_loss -0.8922 
2025-07-08 03:01:56.861960: Pseudo dice [np.float32(0.9086)] 
2025-07-08 03:01:56.862062: Epoch time: 48.63 s 
2025-07-08 03:01:58.062611:  
2025-07-08 03:01:58.062821: Epoch 194 
2025-07-08 03:01:58.062953: Current learning rate: 0.00824 
2025-07-08 03:02:48.060424: train_loss -0.8763 
2025-07-08 03:02:48.061448: val_loss -0.8913 
2025-07-08 03:02:48.061577: Pseudo dice [np.float32(0.905)] 
2025-07-08 03:02:48.061737: Epoch time: 50.0 s 
2025-07-08 03:02:49.231592:  
2025-07-08 03:02:49.231891: Epoch 195 
2025-07-08 03:02:49.232073: Current learning rate: 0.00823 
2025-07-08 03:03:40.437070: train_loss -0.8828 
2025-07-08 03:03:40.438773: val_loss -0.8792 
2025-07-08 03:03:40.439089: Pseudo dice [np.float32(0.9175)] 
2025-07-08 03:03:40.439422: Epoch time: 51.21 s 
2025-07-08 03:03:41.931401:  
2025-07-08 03:03:41.931880: Epoch 196 
2025-07-08 03:03:41.932163: Current learning rate: 0.00822 
2025-07-08 03:04:30.168411: train_loss -0.8641 
2025-07-08 03:04:30.169307: val_loss -0.819 
2025-07-08 03:04:30.169441: Pseudo dice [np.float32(0.8382)] 
2025-07-08 03:04:30.169613: Epoch time: 48.24 s 
2025-07-08 03:04:31.422851:  
2025-07-08 03:04:31.423213: Epoch 197 
2025-07-08 03:04:31.423473: Current learning rate: 0.00821 
2025-07-08 03:05:22.251344: train_loss -0.796 
2025-07-08 03:05:22.252125: val_loss -0.8485 
2025-07-08 03:05:22.252225: Pseudo dice [np.float32(0.8794)] 
2025-07-08 03:05:22.252357: Epoch time: 50.83 s 
2025-07-08 03:05:23.402155:  
2025-07-08 03:05:23.402571: Epoch 198 
2025-07-08 03:05:23.402934: Current learning rate: 0.0082 
2025-07-08 03:06:14.507230: train_loss -0.837 
2025-07-08 03:06:14.507556: val_loss -0.8742 
2025-07-08 03:06:14.507649: Pseudo dice [np.float32(0.8965)] 
2025-07-08 03:06:14.507782: Epoch time: 51.11 s 
2025-07-08 03:06:15.632513:  
2025-07-08 03:06:15.633122: Epoch 199 
2025-07-08 03:06:15.633262: Current learning rate: 0.00819 
2025-07-08 03:07:05.057753: train_loss -0.8716 
2025-07-08 03:07:05.058788: val_loss -0.8372 
2025-07-08 03:07:05.058933: Pseudo dice [np.float32(0.8763)] 
2025-07-08 03:07:05.059131: Epoch time: 49.43 s 
2025-07-08 03:07:07.367820:  
2025-07-08 03:07:07.368215: Epoch 200 
2025-07-08 03:07:07.368520: Current learning rate: 0.00818 
2025-07-08 03:07:57.802057: train_loss -0.8653 
2025-07-08 03:07:57.802578: val_loss -0.8677 
2025-07-08 03:07:57.802666: Pseudo dice [np.float32(0.8936)] 
2025-07-08 03:07:57.802829: Epoch time: 50.44 s 
2025-07-08 03:07:59.688930:  
2025-07-08 03:07:59.689178: Epoch 201 
2025-07-08 03:07:59.689312: Current learning rate: 0.00817 
2025-07-08 03:08:48.964857: train_loss -0.8688 
2025-07-08 03:08:48.965343: val_loss -0.8657 
2025-07-08 03:08:48.965424: Pseudo dice [np.float32(0.8975)] 
2025-07-08 03:08:48.965518: Epoch time: 49.28 s 
2025-07-08 03:08:50.232602:  
2025-07-08 03:08:50.234180: Epoch 202 
2025-07-08 03:08:50.234401: Current learning rate: 0.00816 
2025-07-08 03:09:37.878392: train_loss -0.8787 
2025-07-08 03:09:37.878776: val_loss -0.8849 
2025-07-08 03:09:37.878864: Pseudo dice [np.float32(0.9129)] 
2025-07-08 03:09:37.878968: Epoch time: 47.65 s 
2025-07-08 03:09:39.066588:  
2025-07-08 03:09:39.067001: Epoch 203 
2025-07-08 03:09:39.067146: Current learning rate: 0.00815 
2025-07-08 03:10:29.416162: train_loss -0.8864 
2025-07-08 03:10:29.417100: val_loss -0.8862 
2025-07-08 03:10:29.417231: Pseudo dice [np.float32(0.9112)] 
2025-07-08 03:10:29.417374: Epoch time: 50.35 s 
2025-07-08 03:10:30.673987:  
2025-07-08 03:10:30.674465: Epoch 204 
2025-07-08 03:10:30.674696: Current learning rate: 0.00814 
2025-07-08 03:11:19.798487: train_loss -0.8877 
2025-07-08 03:11:19.799122: val_loss -0.9062 
2025-07-08 03:11:19.799207: Pseudo dice [np.float32(0.9262)] 
2025-07-08 03:11:19.799312: Epoch time: 49.13 s 
2025-07-08 03:11:21.029261:  
2025-07-08 03:11:21.029614: Epoch 205 
2025-07-08 03:11:21.029968: Current learning rate: 0.00813 
2025-07-08 03:12:12.114950: train_loss -0.897 
2025-07-08 03:12:12.115642: val_loss -0.9055 
2025-07-08 03:12:12.115733: Pseudo dice [np.float32(0.9312)] 
2025-07-08 03:12:12.115851: Epoch time: 51.09 s 
2025-07-08 03:12:13.406268:  
2025-07-08 03:12:13.406742: Epoch 206 
2025-07-08 03:12:13.406960: Current learning rate: 0.00813 
2025-07-08 03:13:02.410012: train_loss -0.8667 
2025-07-08 03:13:02.410499: val_loss -0.8887 
2025-07-08 03:13:02.410600: Pseudo dice [np.float32(0.9191)] 
2025-07-08 03:13:02.410717: Epoch time: 49.0 s 
2025-07-08 03:13:03.565723:  
2025-07-08 03:13:03.565966: Epoch 207 
2025-07-08 03:13:03.566091: Current learning rate: 0.00812 
2025-07-08 03:13:51.280143: train_loss -0.8727 
2025-07-08 03:13:51.280818: val_loss -0.8678 
2025-07-08 03:13:51.280925: Pseudo dice [np.float32(0.9074)] 
2025-07-08 03:13:51.281080: Epoch time: 47.72 s 
2025-07-08 03:13:52.524423:  
2025-07-08 03:13:52.524861: Epoch 208 
2025-07-08 03:13:52.525104: Current learning rate: 0.00811 
2025-07-08 03:14:41.732808: train_loss -0.8564 
2025-07-08 03:14:41.733460: val_loss -0.8733 
2025-07-08 03:14:41.733592: Pseudo dice [np.float32(0.91)] 
2025-07-08 03:14:41.733747: Epoch time: 49.21 s 
2025-07-08 03:14:42.928960:  
2025-07-08 03:14:42.929211: Epoch 209 
2025-07-08 03:14:42.929379: Current learning rate: 0.0081 
2025-07-08 03:15:32.333944: train_loss -0.863 
2025-07-08 03:15:32.334592: val_loss -0.8907 
2025-07-08 03:15:32.334688: Pseudo dice [np.float32(0.9175)] 
2025-07-08 03:15:32.334815: Epoch time: 49.41 s 
2025-07-08 03:15:33.538113:  
2025-07-08 03:15:33.538357: Epoch 210 
2025-07-08 03:15:33.538486: Current learning rate: 0.00809 
2025-07-08 03:16:23.586332: train_loss -0.887 
2025-07-08 03:16:23.586821: val_loss -0.8928 
2025-07-08 03:16:23.586995: Pseudo dice [np.float32(0.9136)] 
2025-07-08 03:16:23.587241: Epoch time: 50.05 s 
2025-07-08 03:16:24.729754:  
2025-07-08 03:16:24.730138: Epoch 211 
2025-07-08 03:16:24.730314: Current learning rate: 0.00808 
2025-07-08 03:17:14.277267: train_loss -0.8765 
2025-07-08 03:17:14.278178: val_loss -0.89 
2025-07-08 03:17:14.278322: Pseudo dice [np.float32(0.9112)] 
2025-07-08 03:17:14.278463: Epoch time: 49.55 s 
2025-07-08 03:17:15.483091:  
2025-07-08 03:17:15.483485: Epoch 212 
2025-07-08 03:17:15.483658: Current learning rate: 0.00807 
2025-07-08 03:18:04.645695: train_loss -0.8951 
2025-07-08 03:18:04.647539: val_loss -0.9032 
2025-07-08 03:18:04.648187: Pseudo dice [np.float32(0.9207)] 
2025-07-08 03:18:04.649446: Epoch time: 49.16 s 
2025-07-08 03:18:05.918123:  
2025-07-08 03:18:05.918607: Epoch 213 
2025-07-08 03:18:05.918748: Current learning rate: 0.00806 
2025-07-08 03:18:56.028512: train_loss -0.8947 
2025-07-08 03:18:56.029012: val_loss -0.9012 
2025-07-08 03:18:56.029106: Pseudo dice [np.float32(0.9222)] 
2025-07-08 03:18:56.029213: Epoch time: 50.11 s 
2025-07-08 03:18:57.212318:  
2025-07-08 03:18:57.212473: Epoch 214 
2025-07-08 03:18:57.212592: Current learning rate: 0.00805 
2025-07-08 03:19:45.796499: train_loss -0.8991 
2025-07-08 03:19:45.796970: val_loss -0.9042 
2025-07-08 03:19:45.797053: Pseudo dice [np.float32(0.929)] 
2025-07-08 03:19:45.797157: Epoch time: 48.59 s 
2025-07-08 03:19:47.030330:  
2025-07-08 03:19:47.030584: Epoch 215 
2025-07-08 03:19:47.030794: Current learning rate: 0.00804 
2025-07-08 03:20:35.437042: train_loss -0.892 
2025-07-08 03:20:35.437593: val_loss -0.9093 
2025-07-08 03:20:35.437699: Pseudo dice [np.float32(0.9292)] 
2025-07-08 03:20:35.437826: Epoch time: 48.41 s 
2025-07-08 03:20:37.697731:  
2025-07-08 03:20:37.698185: Epoch 216 
2025-07-08 03:20:37.698348: Current learning rate: 0.00803 
2025-07-08 03:21:25.958678: train_loss -0.8963 
2025-07-08 03:21:25.959532: val_loss -0.9002 
2025-07-08 03:21:25.959661: Pseudo dice [np.float32(0.9217)] 
2025-07-08 03:21:25.959837: Epoch time: 48.26 s 
2025-07-08 03:21:27.212415:  
2025-07-08 03:21:27.212678: Epoch 217 
2025-07-08 03:21:27.212778: Current learning rate: 0.00802 
2025-07-08 03:22:17.328797: train_loss -0.8981 
2025-07-08 03:22:17.329342: val_loss -0.9 
2025-07-08 03:22:17.332822: Pseudo dice [np.float32(0.9219)] 
2025-07-08 03:22:17.332947: Epoch time: 50.12 s 
2025-07-08 03:22:18.542934:  
2025-07-08 03:22:18.543364: Epoch 218 
2025-07-08 03:22:18.543674: Current learning rate: 0.00801 
2025-07-08 03:23:07.988423: train_loss -0.8962 
2025-07-08 03:23:07.988868: val_loss -0.9041 
2025-07-08 03:23:07.988979: Pseudo dice [np.float32(0.9238)] 
2025-07-08 03:23:07.989182: Epoch time: 49.45 s 
2025-07-08 03:23:09.178731:  
2025-07-08 03:23:09.179283: Epoch 219 
2025-07-08 03:23:09.179486: Current learning rate: 0.00801 
2025-07-08 03:23:58.426653: train_loss -0.9003 
2025-07-08 03:23:58.427231: val_loss -0.9139 
2025-07-08 03:23:58.427320: Pseudo dice [np.float32(0.9299)] 
2025-07-08 03:23:58.427436: Epoch time: 49.25 s 
2025-07-08 03:23:59.655401:  
2025-07-08 03:23:59.655710: Epoch 220 
2025-07-08 03:23:59.655836: Current learning rate: 0.008 
2025-07-08 03:24:48.767419: train_loss -0.9028 
2025-07-08 03:24:48.768274: val_loss -0.9056 
2025-07-08 03:24:48.768422: Pseudo dice [np.float32(0.927)] 
2025-07-08 03:24:48.768589: Epoch time: 49.11 s 
2025-07-08 03:24:49.951553:  
2025-07-08 03:24:49.951942: Epoch 221 
2025-07-08 03:24:49.952269: Current learning rate: 0.00799 
2025-07-08 03:25:40.830054: train_loss -0.9084 
2025-07-08 03:25:40.830746: val_loss -0.9096 
2025-07-08 03:25:40.830945: Pseudo dice [np.float32(0.9281)] 
2025-07-08 03:25:40.831203: Epoch time: 50.88 s 
2025-07-08 03:25:42.011202:  
2025-07-08 03:25:42.011647: Epoch 222 
2025-07-08 03:25:42.011790: Current learning rate: 0.00798 
2025-07-08 03:26:31.263428: train_loss -0.9036 
2025-07-08 03:26:31.264498: val_loss -0.9103 
2025-07-08 03:26:31.264635: Pseudo dice [np.float32(0.9329)] 
2025-07-08 03:26:31.264766: Epoch time: 49.25 s 
2025-07-08 03:26:32.451499:  
2025-07-08 03:26:32.451737: Epoch 223 
2025-07-08 03:26:32.452055: Current learning rate: 0.00797 
2025-07-08 03:27:23.166779: train_loss -0.905 
2025-07-08 03:27:23.167632: val_loss -0.9087 
2025-07-08 03:27:23.167884: Pseudo dice [np.float32(0.926)] 
2025-07-08 03:27:23.168116: Epoch time: 50.72 s 
2025-07-08 03:27:24.306061:  
2025-07-08 03:27:24.306236: Epoch 224 
2025-07-08 03:27:24.306335: Current learning rate: 0.00796 
2025-07-08 03:28:11.922463: train_loss -0.9078 
2025-07-08 03:28:11.923216: val_loss -0.9109 
2025-07-08 03:28:11.923312: Pseudo dice [np.float32(0.9249)] 
2025-07-08 03:28:11.923434: Epoch time: 47.62 s 
2025-07-08 03:28:13.074195:  
2025-07-08 03:28:13.074406: Epoch 225 
2025-07-08 03:28:13.074510: Current learning rate: 0.00795 
2025-07-08 03:29:02.609145: train_loss -0.9042 
2025-07-08 03:29:02.609699: val_loss -0.9077 
2025-07-08 03:29:02.609796: Pseudo dice [np.float32(0.9286)] 
2025-07-08 03:29:02.609908: Epoch time: 49.54 s 
2025-07-08 03:29:03.746262:  
2025-07-08 03:29:03.746567: Epoch 226 
2025-07-08 03:29:03.746918: Current learning rate: 0.00794 
2025-07-08 03:29:53.828321: train_loss -0.9021 
2025-07-08 03:29:53.828827: val_loss -0.9039 
2025-07-08 03:29:53.832741: Pseudo dice [np.float32(0.9235)] 
2025-07-08 03:29:53.832983: Epoch time: 50.08 s 
2025-07-08 03:29:55.000268:  
2025-07-08 03:29:55.000624: Epoch 227 
2025-07-08 03:29:55.000839: Current learning rate: 0.00793 
2025-07-08 03:30:42.921124: train_loss -0.9048 
2025-07-08 03:30:42.921691: val_loss -0.9182 
2025-07-08 03:30:42.921784: Pseudo dice [np.float32(0.9286)] 
2025-07-08 03:30:42.921900: Epoch time: 47.92 s 
2025-07-08 03:30:44.129007:  
2025-07-08 03:30:44.129334: Epoch 228 
2025-07-08 03:30:44.129558: Current learning rate: 0.00792 
2025-07-08 03:31:32.693326: train_loss -0.9042 
2025-07-08 03:31:32.694325: val_loss -0.9166 
2025-07-08 03:31:32.694430: Pseudo dice [np.float32(0.9285)] 
2025-07-08 03:31:32.694584: Epoch time: 48.57 s 
2025-07-08 03:31:32.694678: Yayy! New best EMA pseudo Dice: 0.9241999983787537 
2025-07-08 03:31:34.749225:  
2025-07-08 03:31:34.749662: Epoch 229 
2025-07-08 03:31:34.749848: Current learning rate: 0.00791 
2025-07-08 03:32:25.087925: train_loss -0.895 
2025-07-08 03:32:25.088437: val_loss -0.9116 
2025-07-08 03:32:25.088518: Pseudo dice [np.float32(0.9301)] 
2025-07-08 03:32:25.088631: Epoch time: 50.34 s 
2025-07-08 03:32:25.088702: Yayy! New best EMA pseudo Dice: 0.9247999787330627 
2025-07-08 03:32:27.121853:  
2025-07-08 03:32:27.122108: Epoch 230 
2025-07-08 03:32:27.122275: Current learning rate: 0.0079 
2025-07-08 03:33:15.665028: train_loss -0.8954 
2025-07-08 03:33:15.665339: val_loss -0.8929 
2025-07-08 03:33:15.665414: Pseudo dice [np.float32(0.9242)] 
2025-07-08 03:33:15.665515: Epoch time: 48.54 s 
2025-07-08 03:33:16.797496:  
2025-07-08 03:33:16.797828: Epoch 231 
2025-07-08 03:33:16.798141: Current learning rate: 0.00789 
2025-07-08 03:34:06.097383: train_loss -0.8954 
2025-07-08 03:34:06.098264: val_loss -0.8939 
2025-07-08 03:34:06.098377: Pseudo dice [np.float32(0.917)] 
2025-07-08 03:34:06.098526: Epoch time: 49.3 s 
2025-07-08 03:34:07.991823:  
2025-07-08 03:34:07.992013: Epoch 232 
2025-07-08 03:34:07.992280: Current learning rate: 0.00789 
2025-07-08 03:34:57.495112: train_loss -0.8925 
2025-07-08 03:34:57.495556: val_loss -0.8963 
2025-07-08 03:34:57.495647: Pseudo dice [np.float32(0.9168)] 
2025-07-08 03:34:57.495762: Epoch time: 49.51 s 
2025-07-08 03:34:58.602827:  
2025-07-08 03:34:58.603144: Epoch 233 
2025-07-08 03:34:58.603396: Current learning rate: 0.00788 
2025-07-08 03:35:48.342282: train_loss -0.8988 
2025-07-08 03:35:48.342930: val_loss -0.9093 
2025-07-08 03:35:48.343142: Pseudo dice [np.float32(0.9271)] 
2025-07-08 03:35:48.343259: Epoch time: 49.74 s 
2025-07-08 03:35:49.508310:  
2025-07-08 03:35:49.508579: Epoch 234 
2025-07-08 03:35:49.508936: Current learning rate: 0.00787 
2025-07-08 03:36:39.211244: train_loss -0.9055 
2025-07-08 03:36:39.211652: val_loss -0.9069 
2025-07-08 03:36:39.211732: Pseudo dice [np.float32(0.923)] 
2025-07-08 03:36:39.211828: Epoch time: 49.7 s 
2025-07-08 03:36:40.313034:  
2025-07-08 03:36:40.313420: Epoch 235 
2025-07-08 03:36:40.313647: Current learning rate: 0.00786 
2025-07-08 03:37:29.345754: train_loss -0.894 
2025-07-08 03:37:29.346276: val_loss -0.899 
2025-07-08 03:37:29.346369: Pseudo dice [np.float32(0.9212)] 
2025-07-08 03:37:29.346483: Epoch time: 49.03 s 
2025-07-08 03:37:30.515429:  
2025-07-08 03:37:30.515786: Epoch 236 
2025-07-08 03:37:30.515965: Current learning rate: 0.00785 
2025-07-08 03:38:21.353138: train_loss -0.8621 
2025-07-08 03:38:21.353873: val_loss -0.8794 
2025-07-08 03:38:21.353961: Pseudo dice [np.float32(0.8991)] 
2025-07-08 03:38:21.354080: Epoch time: 50.84 s 
2025-07-08 03:38:22.584558:  
2025-07-08 03:38:22.584769: Epoch 237 
2025-07-08 03:38:22.585006: Current learning rate: 0.00784 
2025-07-08 03:39:13.393413: train_loss -0.8897 
2025-07-08 03:39:13.394263: val_loss -0.8827 
2025-07-08 03:39:13.394364: Pseudo dice [np.float32(0.9084)] 
2025-07-08 03:39:13.394531: Epoch time: 50.81 s 
2025-07-08 03:39:14.548947:  
2025-07-08 03:39:14.549095: Epoch 238 
2025-07-08 03:39:14.549202: Current learning rate: 0.00783 
2025-07-08 03:40:04.223314: train_loss -0.8741 
2025-07-08 03:40:04.223850: val_loss -0.8944 
2025-07-08 03:40:04.223947: Pseudo dice [np.float32(0.9076)] 
2025-07-08 03:40:04.224069: Epoch time: 49.68 s 
2025-07-08 03:40:05.417380:  
2025-07-08 03:40:05.417723: Epoch 239 
2025-07-08 03:40:05.417888: Current learning rate: 0.00782 
2025-07-08 03:40:56.268131: train_loss -0.8786 
2025-07-08 03:40:56.268864: val_loss -0.8921 
2025-07-08 03:40:56.268953: Pseudo dice [np.float32(0.914)] 
2025-07-08 03:40:56.269066: Epoch time: 50.85 s 
2025-07-08 03:40:57.413954:  
2025-07-08 03:40:57.414391: Epoch 240 
2025-07-08 03:40:57.414511: Current learning rate: 0.00781 
2025-07-08 03:41:47.990574: train_loss -0.8853 
2025-07-08 03:41:47.991629: val_loss -0.9037 
2025-07-08 03:41:47.991812: Pseudo dice [np.float32(0.9165)] 
2025-07-08 03:41:47.992047: Epoch time: 50.58 s 
2025-07-08 03:41:49.184765:  
2025-07-08 03:41:49.185202: Epoch 241 
2025-07-08 03:41:49.185470: Current learning rate: 0.0078 
2025-07-08 03:42:38.926899: train_loss -0.8946 
2025-07-08 03:42:38.927632: val_loss -0.9027 
2025-07-08 03:42:38.927761: Pseudo dice [np.float32(0.9249)] 
2025-07-08 03:42:38.927895: Epoch time: 49.74 s 
2025-07-08 03:42:40.120231:  
2025-07-08 03:42:40.120745: Epoch 242 
2025-07-08 03:42:40.120976: Current learning rate: 0.00779 
2025-07-08 03:43:29.507297: train_loss -0.8973 
2025-07-08 03:43:29.507792: val_loss -0.885 
2025-07-08 03:43:29.507883: Pseudo dice [np.float32(0.9052)] 
2025-07-08 03:43:29.507995: Epoch time: 49.39 s 
2025-07-08 03:43:30.675503:  
2025-07-08 03:43:30.675747: Epoch 243 
2025-07-08 03:43:30.675879: Current learning rate: 0.00778 
2025-07-08 03:44:19.927666: train_loss -0.8943 
2025-07-08 03:44:19.928030: val_loss -0.9011 
2025-07-08 03:44:19.928112: Pseudo dice [np.float32(0.9221)] 
2025-07-08 03:44:19.928213: Epoch time: 49.25 s 
2025-07-08 03:44:21.074881:  
2025-07-08 03:44:21.075082: Epoch 244 
2025-07-08 03:44:21.075336: Current learning rate: 0.00777 
2025-07-08 03:45:09.890746: train_loss -0.8992 
2025-07-08 03:45:09.891208: val_loss -0.9052 
2025-07-08 03:45:09.891300: Pseudo dice [np.float32(0.9201)] 
2025-07-08 03:45:09.891410: Epoch time: 48.82 s 
2025-07-08 03:45:11.121682:  
2025-07-08 03:45:11.121830: Epoch 245 
2025-07-08 03:45:11.121945: Current learning rate: 0.00777 
2025-07-08 03:46:00.887336: train_loss -0.8833 
2025-07-08 03:46:00.889356: val_loss -0.871 
2025-07-08 03:46:00.889574: Pseudo dice [np.float32(0.8989)] 
2025-07-08 03:46:00.889799: Epoch time: 49.77 s 
2025-07-08 03:46:02.050975:  
2025-07-08 03:46:02.051358: Epoch 246 
2025-07-08 03:46:02.051487: Current learning rate: 0.00776 
2025-07-08 03:46:53.160562: train_loss -0.8753 
2025-07-08 03:46:53.161707: val_loss -0.8829 
2025-07-08 03:46:53.162017: Pseudo dice [np.float32(0.9122)] 
2025-07-08 03:46:53.162281: Epoch time: 51.11 s 
2025-07-08 03:46:54.282383:  
2025-07-08 03:46:54.282587: Epoch 247 
2025-07-08 03:46:54.282714: Current learning rate: 0.00775 
2025-07-08 03:47:43.449225: train_loss -0.8712 
2025-07-08 03:47:43.449904: val_loss -0.8478 
2025-07-08 03:47:43.449991: Pseudo dice [np.float32(0.8898)] 
2025-07-08 03:47:43.450093: Epoch time: 49.17 s 
2025-07-08 03:47:45.272965:  
2025-07-08 03:47:45.273442: Epoch 248 
2025-07-08 03:47:45.273587: Current learning rate: 0.00774 
2025-07-08 03:48:35.654334: train_loss -0.8856 
2025-07-08 03:48:35.654880: val_loss -0.8945 
2025-07-08 03:48:35.654960: Pseudo dice [np.float32(0.9176)] 
2025-07-08 03:48:35.655067: Epoch time: 50.38 s 
2025-07-08 03:48:36.855837:  
2025-07-08 03:48:36.856223: Epoch 249 
2025-07-08 03:48:36.856508: Current learning rate: 0.00773 
2025-07-08 03:49:26.670037: train_loss -0.8898 
2025-07-08 03:49:26.670913: val_loss -0.893 
2025-07-08 03:49:26.671030: Pseudo dice [np.float32(0.9149)] 
2025-07-08 03:49:26.671166: Epoch time: 49.82 s 
2025-07-08 03:49:28.787530:  
2025-07-08 03:49:28.787950: Epoch 250 
2025-07-08 03:49:28.788082: Current learning rate: 0.00772 
2025-07-08 03:50:18.622337: train_loss -0.8975 
2025-07-08 03:50:18.623030: val_loss -0.8993 
2025-07-08 03:50:18.623446: Pseudo dice [np.float32(0.9264)] 
2025-07-08 03:50:18.624110: Epoch time: 49.84 s 
2025-07-08 03:50:19.778002:  
2025-07-08 03:50:19.778224: Epoch 251 
2025-07-08 03:50:19.778549: Current learning rate: 0.00771 
2025-07-08 03:51:10.193530: train_loss -0.901 
2025-07-08 03:51:10.194100: val_loss -0.8855 
2025-07-08 03:51:10.194209: Pseudo dice [np.float32(0.9249)] 
2025-07-08 03:51:10.194330: Epoch time: 50.42 s 
2025-07-08 03:51:11.360425:  
2025-07-08 03:51:11.360702: Epoch 252 
2025-07-08 03:51:11.361106: Current learning rate: 0.0077 
2025-07-08 03:52:01.581825: train_loss -0.8978 
2025-07-08 03:52:01.582239: val_loss -0.9048 
2025-07-08 03:52:01.582419: Pseudo dice [np.float32(0.921)] 
2025-07-08 03:52:01.582550: Epoch time: 50.22 s 
2025-07-08 03:52:02.775951:  
2025-07-08 03:52:02.776394: Epoch 253 
2025-07-08 03:52:02.776682: Current learning rate: 0.00769 
2025-07-08 03:52:51.576298: train_loss -0.9032 
2025-07-08 03:52:51.577284: val_loss -0.9033 
2025-07-08 03:52:51.577393: Pseudo dice [np.float32(0.9313)] 
2025-07-08 03:52:51.577612: Epoch time: 48.8 s 
2025-07-08 03:52:52.764272:  
2025-07-08 03:52:52.764798: Epoch 254 
2025-07-08 03:52:52.765016: Current learning rate: 0.00768 
2025-07-08 03:53:42.074726: train_loss -0.8991 
2025-07-08 03:53:42.075531: val_loss -0.8984 
2025-07-08 03:53:42.075645: Pseudo dice [np.float32(0.9212)] 
2025-07-08 03:53:42.075793: Epoch time: 49.31 s 
2025-07-08 03:53:43.286098:  
2025-07-08 03:53:43.286592: Epoch 255 
2025-07-08 03:53:43.286818: Current learning rate: 0.00767 
2025-07-08 03:54:33.542465: train_loss -0.902 
2025-07-08 03:54:33.542888: val_loss -0.9015 
2025-07-08 03:54:33.542970: Pseudo dice [np.float32(0.9258)] 
2025-07-08 03:54:33.543076: Epoch time: 50.26 s 
2025-07-08 03:54:34.693454:  
2025-07-08 03:54:34.693933: Epoch 256 
2025-07-08 03:54:34.694065: Current learning rate: 0.00766 
2025-07-08 03:55:23.706256: train_loss -0.906 
2025-07-08 03:55:23.706874: val_loss -0.9054 
2025-07-08 03:55:23.706964: Pseudo dice [np.float32(0.9233)] 
2025-07-08 03:55:23.707105: Epoch time: 49.01 s 
2025-07-08 03:55:24.972744:  
2025-07-08 03:55:24.973110: Epoch 257 
2025-07-08 03:55:24.973368: Current learning rate: 0.00765 
2025-07-08 03:56:14.837503: train_loss -0.9015 
2025-07-08 03:56:14.838032: val_loss -0.9083 
2025-07-08 03:56:14.838154: Pseudo dice [np.float32(0.9287)] 
2025-07-08 03:56:14.838308: Epoch time: 49.87 s 
2025-07-08 03:56:16.068211:  
2025-07-08 03:56:16.068809: Epoch 258 
2025-07-08 03:56:16.069115: Current learning rate: 0.00764 
2025-07-08 03:57:06.253482: train_loss -0.8922 
2025-07-08 03:57:06.253956: val_loss -0.8882 
2025-07-08 03:57:06.254046: Pseudo dice [np.float32(0.9173)] 
2025-07-08 03:57:06.254173: Epoch time: 50.19 s 
2025-07-08 03:57:07.495344:  
2025-07-08 03:57:07.495879: Epoch 259 
2025-07-08 03:57:07.496039: Current learning rate: 0.00764 
2025-07-08 03:57:55.938087: train_loss -0.8609 
2025-07-08 03:57:55.938469: val_loss -0.85 
2025-07-08 03:57:55.938557: Pseudo dice [np.float32(0.88)] 
2025-07-08 03:57:55.938671: Epoch time: 48.44 s 
2025-07-08 03:57:57.082110:  
2025-07-08 03:57:57.082397: Epoch 260 
2025-07-08 03:57:57.082741: Current learning rate: 0.00763 
2025-07-08 03:58:45.633549: train_loss -0.8553 
2025-07-08 03:58:45.634196: val_loss -0.8793 
2025-07-08 03:58:45.634288: Pseudo dice [np.float32(0.8992)] 
2025-07-08 03:58:45.634413: Epoch time: 48.55 s 
2025-07-08 03:58:46.849254:  
2025-07-08 03:58:46.849403: Epoch 261 
2025-07-08 03:58:46.849721: Current learning rate: 0.00762 
2025-07-08 03:59:36.108696: train_loss -0.8742 
2025-07-08 03:59:36.109535: val_loss -0.897 
2025-07-08 03:59:36.109668: Pseudo dice [np.float32(0.9071)] 
2025-07-08 03:59:36.109807: Epoch time: 49.26 s 
2025-07-08 03:59:37.295234:  
2025-07-08 03:59:37.295791: Epoch 262 
2025-07-08 03:59:37.295944: Current learning rate: 0.00761 
2025-07-08 04:00:27.300525: train_loss -0.8898 
2025-07-08 04:00:27.302226: val_loss -0.8855 
2025-07-08 04:00:27.302458: Pseudo dice [np.float32(0.9081)] 
2025-07-08 04:00:27.302817: Epoch time: 50.01 s 
2025-07-08 04:00:28.736888:  
2025-07-08 04:00:28.737219: Epoch 263 
2025-07-08 04:00:28.737351: Current learning rate: 0.0076 
2025-07-08 04:01:20.525977: train_loss -0.8941 
2025-07-08 04:01:20.526463: val_loss -0.8996 
2025-07-08 04:01:20.526567: Pseudo dice [np.float32(0.9148)] 
2025-07-08 04:01:20.526686: Epoch time: 51.79 s 
2025-07-08 04:01:22.679233:  
2025-07-08 04:01:22.679674: Epoch 264 
2025-07-08 04:01:22.679913: Current learning rate: 0.00759 
2025-07-08 04:02:13.361150: train_loss -0.8936 
2025-07-08 04:02:13.361589: val_loss -0.8934 
2025-07-08 04:02:13.361682: Pseudo dice [np.float32(0.9185)] 
2025-07-08 04:02:13.361799: Epoch time: 50.68 s 
2025-07-08 04:02:14.572707:  
2025-07-08 04:02:14.573254: Epoch 265 
2025-07-08 04:02:14.573398: Current learning rate: 0.00758 
2025-07-08 04:03:04.336572: train_loss -0.8965 
2025-07-08 04:03:04.337303: val_loss -0.9012 
2025-07-08 04:03:04.337436: Pseudo dice [np.float32(0.9268)] 
2025-07-08 04:03:04.337593: Epoch time: 49.76 s 
2025-07-08 04:03:05.649587:  
2025-07-08 04:03:05.649974: Epoch 266 
2025-07-08 04:03:05.650304: Current learning rate: 0.00757 
2025-07-08 04:03:54.237990: train_loss -0.8936 
2025-07-08 04:03:54.238865: val_loss -0.9024 
2025-07-08 04:03:54.238963: Pseudo dice [np.float32(0.9226)] 
2025-07-08 04:03:54.239100: Epoch time: 48.59 s 
2025-07-08 04:03:55.516195:  
2025-07-08 04:03:55.516601: Epoch 267 
2025-07-08 04:03:55.516734: Current learning rate: 0.00756 
2025-07-08 04:04:43.996753: train_loss -0.9065 
2025-07-08 04:04:43.997211: val_loss -0.893 
2025-07-08 04:04:43.997307: Pseudo dice [np.float32(0.9138)] 
2025-07-08 04:04:43.997415: Epoch time: 48.48 s 
2025-07-08 04:04:45.203683:  
2025-07-08 04:04:45.204167: Epoch 268 
2025-07-08 04:04:45.204386: Current learning rate: 0.00755 
2025-07-08 04:05:34.091485: train_loss -0.8929 
2025-07-08 04:05:34.093836: val_loss -0.9094 
2025-07-08 04:05:34.094440: Pseudo dice [np.float32(0.921)] 
2025-07-08 04:05:34.095132: Epoch time: 48.89 s 
2025-07-08 04:05:35.505532:  
2025-07-08 04:05:35.505985: Epoch 269 
2025-07-08 04:05:35.506124: Current learning rate: 0.00754 
2025-07-08 04:06:24.468391: train_loss -0.9029 
2025-07-08 04:06:24.468800: val_loss -0.8943 
2025-07-08 04:06:24.468966: Pseudo dice [np.float32(0.9256)] 
2025-07-08 04:06:24.469101: Epoch time: 48.96 s 
2025-07-08 04:06:25.661098:  
2025-07-08 04:06:25.661448: Epoch 270 
2025-07-08 04:06:25.661649: Current learning rate: 0.00753 
2025-07-08 04:07:16.646152: train_loss -0.8904 
2025-07-08 04:07:16.646953: val_loss -0.8752 
2025-07-08 04:07:16.647086: Pseudo dice [np.float32(0.9253)] 
2025-07-08 04:07:16.647230: Epoch time: 50.99 s 
2025-07-08 04:07:17.806519:  
2025-07-08 04:07:17.806950: Epoch 271 
2025-07-08 04:07:17.807093: Current learning rate: 0.00752 
2025-07-08 04:08:08.154316: train_loss -0.8716 
2025-07-08 04:08:08.159007: val_loss -0.8867 
2025-07-08 04:08:08.159511: Pseudo dice [np.float32(0.8995)] 
2025-07-08 04:08:08.159806: Epoch time: 50.35 s 
2025-07-08 04:08:09.375516:  
2025-07-08 04:08:09.375877: Epoch 272 
2025-07-08 04:08:09.376156: Current learning rate: 0.00751 
2025-07-08 04:08:57.935020: train_loss -0.8859 
2025-07-08 04:08:57.935900: val_loss -0.8991 
2025-07-08 04:08:57.936023: Pseudo dice [np.float32(0.9233)] 
2025-07-08 04:08:57.936193: Epoch time: 48.56 s 
2025-07-08 04:08:59.171708:  
2025-07-08 04:08:59.172139: Epoch 273 
2025-07-08 04:08:59.172328: Current learning rate: 0.00751 
2025-07-08 04:09:49.169640: train_loss -0.8885 
2025-07-08 04:09:49.170341: val_loss -0.8962 
2025-07-08 04:09:49.170436: Pseudo dice [np.float32(0.9177)] 
2025-07-08 04:09:49.170567: Epoch time: 50.0 s 
2025-07-08 04:09:50.412231:  
2025-07-08 04:09:50.412391: Epoch 274 
2025-07-08 04:09:50.412571: Current learning rate: 0.0075 
2025-07-08 04:10:39.216049: train_loss -0.8954 
2025-07-08 04:10:39.216425: val_loss -0.9138 
2025-07-08 04:10:39.216502: Pseudo dice [np.float32(0.932)] 
2025-07-08 04:10:39.216887: Epoch time: 48.8 s 
2025-07-08 04:10:40.369993:  
2025-07-08 04:10:40.370299: Epoch 275 
2025-07-08 04:10:40.370440: Current learning rate: 0.00749 
2025-07-08 04:11:28.279619: train_loss -0.8985 
2025-07-08 04:11:28.280361: val_loss -0.8898 
2025-07-08 04:11:28.280457: Pseudo dice [np.float32(0.9199)] 
2025-07-08 04:11:28.280612: Epoch time: 47.91 s 
2025-07-08 04:11:29.426939:  
2025-07-08 04:11:29.427136: Epoch 276 
2025-07-08 04:11:29.427266: Current learning rate: 0.00748 
2025-07-08 04:12:18.333475: train_loss -0.8956 
2025-07-08 04:12:18.334291: val_loss -0.9093 
2025-07-08 04:12:18.334438: Pseudo dice [np.float32(0.922)] 
2025-07-08 04:12:18.334679: Epoch time: 48.91 s 
2025-07-08 04:12:19.510153:  
2025-07-08 04:12:19.510494: Epoch 277 
2025-07-08 04:12:19.510692: Current learning rate: 0.00747 
2025-07-08 04:13:08.900286: train_loss -0.9037 
2025-07-08 04:13:08.900746: val_loss -0.9091 
2025-07-08 04:13:08.900826: Pseudo dice [np.float32(0.9268)] 
2025-07-08 04:13:08.900930: Epoch time: 49.39 s 
2025-07-08 04:13:10.042479:  
2025-07-08 04:13:10.042682: Epoch 278 
2025-07-08 04:13:10.042895: Current learning rate: 0.00746 
2025-07-08 04:14:00.503095: train_loss -0.897 
2025-07-08 04:14:00.504211: val_loss -0.8877 
2025-07-08 04:14:00.504339: Pseudo dice [np.float32(0.9148)] 
2025-07-08 04:14:00.504493: Epoch time: 50.46 s 
2025-07-08 04:14:02.966370:  
2025-07-08 04:14:02.966622: Epoch 279 
2025-07-08 04:14:02.966773: Current learning rate: 0.00745 
2025-07-08 04:14:52.501266: train_loss -0.8763 
2025-07-08 04:14:52.502244: val_loss -0.8954 
2025-07-08 04:14:52.506165: Pseudo dice [np.float32(0.9149)] 
2025-07-08 04:14:52.506839: Epoch time: 49.54 s 
2025-07-08 04:14:53.648731:  
2025-07-08 04:14:53.649155: Epoch 280 
2025-07-08 04:14:53.649420: Current learning rate: 0.00744 
2025-07-08 04:15:42.417164: train_loss -0.8897 
2025-07-08 04:15:42.417703: val_loss -0.8954 
2025-07-08 04:15:42.417788: Pseudo dice [np.float32(0.9204)] 
2025-07-08 04:15:42.417880: Epoch time: 48.77 s 
2025-07-08 04:15:43.549671:  
2025-07-08 04:15:43.550082: Epoch 281 
2025-07-08 04:15:43.550210: Current learning rate: 0.00743 
2025-07-08 04:16:31.834286: train_loss -0.8892 
2025-07-08 04:16:31.835085: val_loss -0.9071 
2025-07-08 04:16:31.835295: Pseudo dice [np.float32(0.9234)] 
2025-07-08 04:16:31.835514: Epoch time: 48.29 s 
2025-07-08 04:16:33.017636:  
2025-07-08 04:16:33.018048: Epoch 282 
2025-07-08 04:16:33.018190: Current learning rate: 0.00742 
2025-07-08 04:17:23.415297: train_loss -0.9001 
2025-07-08 04:17:23.416076: val_loss -0.8926 
2025-07-08 04:17:23.416203: Pseudo dice [np.float32(0.9281)] 
2025-07-08 04:17:23.416339: Epoch time: 50.4 s 
2025-07-08 04:17:24.553959:  
2025-07-08 04:17:24.554327: Epoch 283 
2025-07-08 04:17:24.554534: Current learning rate: 0.00741 
2025-07-08 04:18:15.874030: train_loss -0.8561 
2025-07-08 04:18:15.874639: val_loss -0.8979 
2025-07-08 04:18:15.874740: Pseudo dice [np.float32(0.9203)] 
2025-07-08 04:18:15.874869: Epoch time: 51.32 s 
2025-07-08 04:18:17.050710:  
2025-07-08 04:18:17.050940: Epoch 284 
2025-07-08 04:18:17.051065: Current learning rate: 0.0074 
2025-07-08 04:19:06.914459: train_loss -0.8577 
2025-07-08 04:19:06.915149: val_loss -0.8829 
2025-07-08 04:19:06.915251: Pseudo dice [np.float32(0.9053)] 
2025-07-08 04:19:06.915383: Epoch time: 49.87 s 
2025-07-08 04:19:08.141053:  
2025-07-08 04:19:08.141382: Epoch 285 
2025-07-08 04:19:08.141620: Current learning rate: 0.00739 
2025-07-08 04:19:56.181400: train_loss -0.8747 
2025-07-08 04:19:56.182268: val_loss -0.8672 
2025-07-08 04:19:56.182497: Pseudo dice [np.float32(0.8874)] 
2025-07-08 04:19:56.182655: Epoch time: 48.04 s 
2025-07-08 04:19:57.410648:  
2025-07-08 04:19:57.410961: Epoch 286 
2025-07-08 04:19:57.411222: Current learning rate: 0.00738 
2025-07-08 04:20:47.267338: train_loss -0.8815 
2025-07-08 04:20:47.267799: val_loss -0.8916 
2025-07-08 04:20:47.267897: Pseudo dice [np.float32(0.9221)] 
2025-07-08 04:20:47.268015: Epoch time: 49.86 s 
2025-07-08 04:20:48.489689:  
2025-07-08 04:20:48.490088: Epoch 287 
2025-07-08 04:20:48.490281: Current learning rate: 0.00738 
2025-07-08 04:21:37.575985: train_loss -0.8914 
2025-07-08 04:21:37.576510: val_loss -0.8935 
2025-07-08 04:21:37.576632: Pseudo dice [np.float32(0.922)] 
2025-07-08 04:21:37.576770: Epoch time: 49.09 s 
2025-07-08 04:21:38.920897:  
2025-07-08 04:21:38.921272: Epoch 288 
2025-07-08 04:21:38.921407: Current learning rate: 0.00737 
2025-07-08 04:22:27.377645: train_loss -0.8852 
2025-07-08 04:22:27.378127: val_loss -0.8937 
2025-07-08 04:22:27.378215: Pseudo dice [np.float32(0.9169)] 
2025-07-08 04:22:27.378328: Epoch time: 48.46 s 
2025-07-08 04:22:28.609159:  
2025-07-08 04:22:28.609637: Epoch 289 
2025-07-08 04:22:28.609847: Current learning rate: 0.00736 
2025-07-08 04:23:18.377848: train_loss -0.8829 
2025-07-08 04:23:18.378786: val_loss -0.9077 
2025-07-08 04:23:18.378876: Pseudo dice [np.float32(0.9215)] 
2025-07-08 04:23:18.379028: Epoch time: 49.77 s 
2025-07-08 04:23:19.684246:  
2025-07-08 04:23:19.684512: Epoch 290 
2025-07-08 04:23:19.684641: Current learning rate: 0.00735 
2025-07-08 04:24:07.457460: train_loss -0.8932 
2025-07-08 04:24:07.457850: val_loss -0.9121 
2025-07-08 04:24:07.457930: Pseudo dice [np.float32(0.9271)] 
2025-07-08 04:24:07.458032: Epoch time: 47.77 s 
2025-07-08 04:24:08.702980:  
2025-07-08 04:24:08.703292: Epoch 291 
2025-07-08 04:24:08.703413: Current learning rate: 0.00734 
2025-07-08 04:24:57.643219: train_loss -0.8949 
2025-07-08 04:24:57.643835: val_loss -0.892 
2025-07-08 04:24:57.643914: Pseudo dice [np.float32(0.918)] 
2025-07-08 04:24:57.644011: Epoch time: 48.94 s 
2025-07-08 04:24:58.767506:  
2025-07-08 04:24:58.768222: Epoch 292 
2025-07-08 04:24:58.768349: Current learning rate: 0.00733 
2025-07-08 04:25:48.037340: train_loss -0.8896 
2025-07-08 04:25:48.037964: val_loss -0.8992 
2025-07-08 04:25:48.038159: Pseudo dice [np.float32(0.9129)] 
2025-07-08 04:25:48.038304: Epoch time: 49.27 s 
2025-07-08 04:25:49.320149:  
2025-07-08 04:25:49.320482: Epoch 293 
2025-07-08 04:25:49.320649: Current learning rate: 0.00732 
2025-07-08 04:26:38.230413: train_loss -0.8792 
2025-07-08 04:26:38.231199: val_loss -0.883 
2025-07-08 04:26:38.231353: Pseudo dice [np.float32(0.9122)] 
2025-07-08 04:26:38.231526: Epoch time: 48.91 s 
2025-07-08 04:26:40.425743:  
2025-07-08 04:26:40.426045: Epoch 294 
2025-07-08 04:26:40.426592: Current learning rate: 0.00731 
2025-07-08 04:27:30.563467: train_loss -0.8957 
2025-07-08 04:27:30.563962: val_loss -0.9001 
2025-07-08 04:27:30.564095: Pseudo dice [np.float32(0.9183)] 
2025-07-08 04:27:30.564203: Epoch time: 50.14 s 
2025-07-08 04:27:31.782413:  
2025-07-08 04:27:31.782876: Epoch 295 
2025-07-08 04:27:31.783184: Current learning rate: 0.0073 
2025-07-08 04:28:20.981128: train_loss -0.8824 
2025-07-08 04:28:20.981605: val_loss -0.9024 
2025-07-08 04:28:20.981691: Pseudo dice [np.float32(0.9245)] 
2025-07-08 04:28:20.981793: Epoch time: 49.2 s 
2025-07-08 04:28:22.138135:  
2025-07-08 04:28:22.139049: Epoch 296 
2025-07-08 04:28:22.139284: Current learning rate: 0.00729 
2025-07-08 04:29:09.560902: train_loss -0.8869 
2025-07-08 04:29:09.561342: val_loss -0.9016 
2025-07-08 04:29:09.561422: Pseudo dice [np.float32(0.9177)] 
2025-07-08 04:29:09.561521: Epoch time: 47.43 s 
2025-07-08 04:29:10.736419:  
2025-07-08 04:29:10.737118: Epoch 297 
2025-07-08 04:29:10.737314: Current learning rate: 0.00728 
2025-07-08 04:29:58.904079: train_loss -0.8938 
2025-07-08 04:29:58.905106: val_loss -0.9017 
2025-07-08 04:29:58.905227: Pseudo dice [np.float32(0.922)] 
2025-07-08 04:29:58.905363: Epoch time: 48.17 s 
2025-07-08 04:30:00.152483:  
2025-07-08 04:30:00.152915: Epoch 298 
2025-07-08 04:30:00.153049: Current learning rate: 0.00727 
2025-07-08 04:30:49.193909: train_loss -0.8895 
2025-07-08 04:30:49.195126: val_loss -0.8752 
2025-07-08 04:30:49.198882: Pseudo dice [np.float32(0.8949)] 
2025-07-08 04:30:49.199293: Epoch time: 49.04 s 
2025-07-08 04:30:50.339663:  
2025-07-08 04:30:50.340029: Epoch 299 
2025-07-08 04:30:50.340156: Current learning rate: 0.00726 
2025-07-08 04:31:39.436906: train_loss -0.8956 
2025-07-08 04:31:39.438747: val_loss -0.9111 
2025-07-08 04:31:39.438972: Pseudo dice [np.float32(0.9274)] 
2025-07-08 04:31:39.439204: Epoch time: 49.1 s 
2025-07-08 04:31:41.672770:  
2025-07-08 04:31:41.673343: Epoch 300 
2025-07-08 04:31:41.673597: Current learning rate: 0.00725 
2025-07-08 04:32:31.629274: train_loss -0.9029 
2025-07-08 04:32:31.629874: val_loss -0.9031 
2025-07-08 04:32:31.629963: Pseudo dice [np.float32(0.9256)] 
2025-07-08 04:32:31.630069: Epoch time: 49.96 s 
2025-07-08 04:32:32.761860:  
2025-07-08 04:32:32.762165: Epoch 301 
2025-07-08 04:32:32.762347: Current learning rate: 0.00724 
2025-07-08 04:33:22.431171: train_loss -0.9011 
2025-07-08 04:33:22.431830: val_loss -0.9066 
2025-07-08 04:33:22.431932: Pseudo dice [np.float32(0.9259)] 
2025-07-08 04:33:22.432065: Epoch time: 49.67 s 
2025-07-08 04:33:23.631313:  
2025-07-08 04:33:23.631813: Epoch 302 
2025-07-08 04:33:23.632028: Current learning rate: 0.00724 
2025-07-08 04:34:13.644622: train_loss -0.9012 
2025-07-08 04:34:13.645085: val_loss -0.9109 
2025-07-08 04:34:13.645180: Pseudo dice [np.float32(0.9271)] 
2025-07-08 04:34:13.645292: Epoch time: 50.01 s 
2025-07-08 04:34:14.885046:  
2025-07-08 04:34:14.885399: Epoch 303 
2025-07-08 04:34:14.885564: Current learning rate: 0.00723 
2025-07-08 04:35:03.742094: train_loss -0.9053 
2025-07-08 04:35:03.742829: val_loss -0.9078 
2025-07-08 04:35:03.742969: Pseudo dice [np.float32(0.9232)] 
2025-07-08 04:35:03.743123: Epoch time: 48.86 s 
2025-07-08 04:35:05.067970:  
2025-07-08 04:35:05.068399: Epoch 304 
2025-07-08 04:35:05.068569: Current learning rate: 0.00722 
2025-07-08 04:35:55.683244: train_loss -0.902 
2025-07-08 04:35:55.683906: val_loss -0.9213 
2025-07-08 04:35:55.687746: Pseudo dice [np.float32(0.939)] 
2025-07-08 04:35:55.688153: Epoch time: 50.62 s 
2025-07-08 04:35:56.916759:  
2025-07-08 04:35:56.916912: Epoch 305 
2025-07-08 04:35:56.917034: Current learning rate: 0.00721 
2025-07-08 04:36:47.854814: train_loss -0.8918 
2025-07-08 04:36:47.855412: val_loss -0.8984 
2025-07-08 04:36:47.855517: Pseudo dice [np.float32(0.9164)] 
2025-07-08 04:36:47.855681: Epoch time: 50.94 s 
2025-07-08 04:36:49.051309:  
2025-07-08 04:36:49.051615: Epoch 306 
2025-07-08 04:36:49.051765: Current learning rate: 0.0072 
2025-07-08 04:37:36.817170: train_loss -0.8983 
2025-07-08 04:37:36.818264: val_loss -0.901 
2025-07-08 04:37:36.818364: Pseudo dice [np.float32(0.9258)] 
2025-07-08 04:37:36.818549: Epoch time: 47.77 s 
2025-07-08 04:37:38.078635:  
2025-07-08 04:37:38.078918: Epoch 307 
2025-07-08 04:37:38.079184: Current learning rate: 0.00719 
2025-07-08 04:38:29.091839: train_loss -0.9013 
2025-07-08 04:38:29.092737: val_loss -0.9004 
2025-07-08 04:38:29.092841: Pseudo dice [np.float32(0.9148)] 
2025-07-08 04:38:29.092992: Epoch time: 51.01 s 
2025-07-08 04:38:30.246142:  
2025-07-08 04:38:30.246493: Epoch 308 
2025-07-08 04:38:30.246679: Current learning rate: 0.00718 
2025-07-08 04:39:18.732206: train_loss -0.9053 
2025-07-08 04:39:18.732757: val_loss -0.9085 
2025-07-08 04:39:18.732842: Pseudo dice [np.float32(0.9269)] 
2025-07-08 04:39:18.732951: Epoch time: 48.49 s 
2025-07-08 04:39:19.880700:  
2025-07-08 04:39:19.880869: Epoch 309 
2025-07-08 04:39:19.880993: Current learning rate: 0.00717 
2025-07-08 04:40:09.595845: train_loss -0.9055 
2025-07-08 04:40:09.596390: val_loss -0.9052 
2025-07-08 04:40:09.599819: Pseudo dice [np.float32(0.9325)] 
2025-07-08 04:40:09.600027: Epoch time: 49.72 s 
2025-07-08 04:40:11.825293:  
2025-07-08 04:40:11.825549: Epoch 310 
2025-07-08 04:40:11.825829: Current learning rate: 0.00716 
2025-07-08 04:41:01.747059: train_loss -0.9068 
2025-07-08 04:41:01.747506: val_loss -0.9067 
2025-07-08 04:41:01.747598: Pseudo dice [np.float32(0.9267)] 
2025-07-08 04:41:01.747703: Epoch time: 49.92 s 
2025-07-08 04:41:02.941241:  
2025-07-08 04:41:02.941498: Epoch 311 
2025-07-08 04:41:02.941739: Current learning rate: 0.00715 
2025-07-08 04:41:52.790509: train_loss -0.8935 
2025-07-08 04:41:52.791115: val_loss -0.8931 
2025-07-08 04:41:52.791210: Pseudo dice [np.float32(0.9007)] 
2025-07-08 04:41:52.791310: Epoch time: 49.85 s 
2025-07-08 04:41:53.958723:  
2025-07-08 04:41:53.959057: Epoch 312 
2025-07-08 04:41:53.959161: Current learning rate: 0.00714 
2025-07-08 04:42:43.506013: train_loss -0.8965 
2025-07-08 04:42:43.506514: val_loss -0.8957 
2025-07-08 04:42:43.506616: Pseudo dice [np.float32(0.9087)] 
2025-07-08 04:42:43.506727: Epoch time: 49.55 s 
2025-07-08 04:42:44.754377:  
2025-07-08 04:42:44.754892: Epoch 313 
2025-07-08 04:42:44.755109: Current learning rate: 0.00713 
2025-07-08 04:43:32.774938: train_loss -0.8941 
2025-07-08 04:43:32.775496: val_loss -0.9121 
2025-07-08 04:43:32.775747: Pseudo dice [np.float32(0.9279)] 
2025-07-08 04:43:32.775863: Epoch time: 48.02 s 
2025-07-08 04:43:33.957433:  
2025-07-08 04:43:33.957778: Epoch 314 
2025-07-08 04:43:33.958057: Current learning rate: 0.00712 
2025-07-08 04:44:22.330338: train_loss -0.9095 
2025-07-08 04:44:22.330868: val_loss -0.9177 
2025-07-08 04:44:22.330955: Pseudo dice [np.float32(0.9375)] 
2025-07-08 04:44:22.331054: Epoch time: 48.37 s 
2025-07-08 04:44:23.558452:  
2025-07-08 04:44:23.559331: Epoch 315 
2025-07-08 04:44:23.559446: Current learning rate: 0.00711 
2025-07-08 04:45:14.730397: train_loss -0.8722 
2025-07-08 04:45:14.730795: val_loss -0.8689 
2025-07-08 04:45:14.730896: Pseudo dice [np.float32(0.9083)] 
2025-07-08 04:45:14.731001: Epoch time: 51.17 s 
2025-07-08 04:45:15.899014:  
2025-07-08 04:45:15.899601: Epoch 316 
2025-07-08 04:45:15.899866: Current learning rate: 0.0071 
2025-07-08 04:46:05.514557: train_loss -0.8926 
2025-07-08 04:46:05.515150: val_loss -0.9073 
2025-07-08 04:46:05.515254: Pseudo dice [np.float32(0.9137)] 
2025-07-08 04:46:05.515379: Epoch time: 49.62 s 
2025-07-08 04:46:06.869115:  
2025-07-08 04:46:06.869685: Epoch 317 
2025-07-08 04:46:06.869951: Current learning rate: 0.0071 
2025-07-08 04:46:55.557637: train_loss -0.8962 
2025-07-08 04:46:55.558860: val_loss -0.9025 
2025-07-08 04:46:55.559024: Pseudo dice [np.float32(0.9146)] 
2025-07-08 04:46:55.559210: Epoch time: 48.69 s 
2025-07-08 04:46:56.915438:  
2025-07-08 04:46:56.915873: Epoch 318 
2025-07-08 04:46:56.916142: Current learning rate: 0.00709 
2025-07-08 04:47:45.087493: train_loss -0.8952 
2025-07-08 04:47:45.088456: val_loss -0.9075 
2025-07-08 04:47:45.088627: Pseudo dice [np.float32(0.9249)] 
2025-07-08 04:47:45.088807: Epoch time: 48.17 s 
2025-07-08 04:47:46.359957:  
2025-07-08 04:47:46.360176: Epoch 319 
2025-07-08 04:47:46.360435: Current learning rate: 0.00708 
2025-07-08 04:48:35.999048: train_loss -0.8964 
2025-07-08 04:48:35.999753: val_loss -0.9128 
2025-07-08 04:48:36.000011: Pseudo dice [np.float32(0.9339)] 
2025-07-08 04:48:36.000169: Epoch time: 49.64 s 
2025-07-08 04:48:37.258647:  
2025-07-08 04:48:37.259073: Epoch 320 
2025-07-08 04:48:37.259260: Current learning rate: 0.00707 
2025-07-08 04:49:26.724804: train_loss -0.8993 
2025-07-08 04:49:26.725412: val_loss -0.8934 
2025-07-08 04:49:26.725517: Pseudo dice [np.float32(0.9224)] 
2025-07-08 04:49:26.725678: Epoch time: 49.47 s 
2025-07-08 04:49:28.034926:  
2025-07-08 04:49:28.035214: Epoch 321 
2025-07-08 04:49:28.035362: Current learning rate: 0.00706 
2025-07-08 04:50:18.127517: train_loss -0.8975 
2025-07-08 04:50:18.127895: val_loss -0.911 
2025-07-08 04:50:18.129200: Pseudo dice [np.float32(0.93)] 
2025-07-08 04:50:18.129328: Epoch time: 50.09 s 
2025-07-08 04:50:19.333492:  
2025-07-08 04:50:19.333904: Epoch 322 
2025-07-08 04:50:19.334044: Current learning rate: 0.00705 
2025-07-08 04:51:08.521456: train_loss -0.906 
2025-07-08 04:51:08.521959: val_loss -0.905 
2025-07-08 04:51:08.522111: Pseudo dice [np.float32(0.9252)] 
2025-07-08 04:51:08.522218: Epoch time: 49.19 s 
2025-07-08 04:51:09.888593:  
2025-07-08 04:51:09.889291: Epoch 323 
2025-07-08 04:51:09.889537: Current learning rate: 0.00704 
2025-07-08 04:51:59.001093: train_loss -0.9007 
2025-07-08 04:51:59.001501: val_loss -0.8972 
2025-07-08 04:51:59.001594: Pseudo dice [np.float32(0.9229)] 
2025-07-08 04:51:59.001702: Epoch time: 49.11 s 
2025-07-08 04:52:01.167301:  
2025-07-08 04:52:01.167678: Epoch 324 
2025-07-08 04:52:01.167854: Current learning rate: 0.00703 
2025-07-08 04:52:50.817341: train_loss -0.8951 
2025-07-08 04:52:50.817799: val_loss -0.9108 
2025-07-08 04:52:50.817892: Pseudo dice [np.float32(0.927)] 
2025-07-08 04:52:50.818074: Epoch time: 49.65 s 
2025-07-08 04:52:52.098260:  
2025-07-08 04:52:52.098485: Epoch 325 
2025-07-08 04:52:52.098717: Current learning rate: 0.00702 
2025-07-08 04:53:41.012339: train_loss -0.902 
2025-07-08 04:53:41.012862: val_loss -0.9118 
2025-07-08 04:53:41.012947: Pseudo dice [np.float32(0.9248)] 
2025-07-08 04:53:41.013073: Epoch time: 48.92 s 
2025-07-08 04:53:42.175185:  
2025-07-08 04:53:42.175488: Epoch 326 
2025-07-08 04:53:42.175669: Current learning rate: 0.00701 
2025-07-08 04:54:31.928502: train_loss -0.9038 
2025-07-08 04:54:31.929219: val_loss -0.8976 
2025-07-08 04:54:31.929310: Pseudo dice [np.float32(0.927)] 
2025-07-08 04:54:31.929438: Epoch time: 49.75 s 
2025-07-08 04:54:33.137972:  
2025-07-08 04:54:33.138179: Epoch 327 
2025-07-08 04:54:33.138302: Current learning rate: 0.007 
2025-07-08 04:55:22.006832: train_loss -0.8953 
2025-07-08 04:55:22.007241: val_loss -0.8948 
2025-07-08 04:55:22.007324: Pseudo dice [np.float32(0.9227)] 
2025-07-08 04:55:22.007440: Epoch time: 48.87 s 
2025-07-08 04:55:23.178269:  
2025-07-08 04:55:23.179018: Epoch 328 
2025-07-08 04:55:23.179403: Current learning rate: 0.00699 
2025-07-08 04:56:13.429819: train_loss -0.8999 
2025-07-08 04:56:13.430619: val_loss -0.9054 
2025-07-08 04:56:13.430724: Pseudo dice [np.float32(0.9286)] 
2025-07-08 04:56:13.430866: Epoch time: 50.25 s 
2025-07-08 04:56:14.632002:  
2025-07-08 04:56:14.632298: Epoch 329 
2025-07-08 04:56:14.632404: Current learning rate: 0.00698 
2025-07-08 04:57:05.625412: train_loss -0.9044 
2025-07-08 04:57:05.625864: val_loss -0.9145 
2025-07-08 04:57:05.626000: Pseudo dice [np.float32(0.9342)] 
2025-07-08 04:57:05.626188: Epoch time: 50.99 s 
2025-07-08 04:57:05.626271: Yayy! New best EMA pseudo Dice: 0.9251000285148621 
2025-07-08 04:57:07.785727:  
2025-07-08 04:57:07.785944: Epoch 330 
2025-07-08 04:57:07.786108: Current learning rate: 0.00697 
2025-07-08 04:57:54.150946: train_loss -0.895 
2025-07-08 04:57:54.151427: val_loss -0.9075 
2025-07-08 04:57:54.151502: Pseudo dice [np.float32(0.9211)] 
2025-07-08 04:57:54.151616: Epoch time: 46.37 s 
2025-07-08 04:57:55.386602:  
2025-07-08 04:57:55.386986: Epoch 331 
2025-07-08 04:57:55.387118: Current learning rate: 0.00696 
2025-07-08 04:58:45.970235: train_loss -0.9028 
2025-07-08 04:58:45.970674: val_loss -0.9099 
2025-07-08 04:58:45.970762: Pseudo dice [np.float32(0.9268)] 
2025-07-08 04:58:45.970869: Epoch time: 50.58 s 
2025-07-08 04:58:47.140586:  
2025-07-08 04:58:47.141034: Epoch 332 
2025-07-08 04:58:47.141157: Current learning rate: 0.00696 
2025-07-08 04:59:36.816588: train_loss -0.9059 
2025-07-08 04:59:36.817809: val_loss -0.915 
2025-07-08 04:59:36.817999: Pseudo dice [np.float32(0.93)] 
2025-07-08 04:59:36.818152: Epoch time: 49.68 s 
2025-07-08 04:59:36.818247: Yayy! New best EMA pseudo Dice: 0.9254000186920166 
2025-07-08 04:59:38.985432:  
2025-07-08 04:59:38.986074: Epoch 333 
2025-07-08 04:59:38.986290: Current learning rate: 0.00695 
2025-07-08 05:00:29.695421: train_loss -0.9102 
2025-07-08 05:00:29.696044: val_loss -0.9124 
2025-07-08 05:00:29.696160: Pseudo dice [np.float32(0.9398)] 
2025-07-08 05:00:29.696290: Epoch time: 50.71 s 
2025-07-08 05:00:29.696398: Yayy! New best EMA pseudo Dice: 0.9269000291824341 
2025-07-08 05:00:31.737369:  
2025-07-08 05:00:31.737778: Epoch 334 
2025-07-08 05:00:31.737949: Current learning rate: 0.00694 
2025-07-08 05:01:21.145146: train_loss -0.9026 
2025-07-08 05:01:21.145904: val_loss -0.9143 
2025-07-08 05:01:21.146000: Pseudo dice [np.float32(0.9329)] 
2025-07-08 05:01:21.146131: Epoch time: 49.41 s 
2025-07-08 05:01:21.146223: Yayy! New best EMA pseudo Dice: 0.9275000095367432 
2025-07-08 05:01:23.502519:  
2025-07-08 05:01:23.502914: Epoch 335 
2025-07-08 05:01:23.503093: Current learning rate: 0.00693 
2025-07-08 05:02:11.619791: train_loss -0.8742 
2025-07-08 05:02:11.620529: val_loss -0.8971 
2025-07-08 05:02:11.620749: Pseudo dice [np.float32(0.9173)] 
2025-07-08 05:02:11.620894: Epoch time: 48.12 s 
2025-07-08 05:02:12.807133:  
2025-07-08 05:02:12.807438: Epoch 336 
2025-07-08 05:02:12.807588: Current learning rate: 0.00692 
2025-07-08 05:03:03.011973: train_loss -0.8629 
2025-07-08 05:03:03.012665: val_loss -0.8796 
2025-07-08 05:03:03.012829: Pseudo dice [np.float32(0.9074)] 
2025-07-08 05:03:03.012959: Epoch time: 50.21 s 
2025-07-08 05:03:04.296133:  
2025-07-08 05:03:04.296448: Epoch 337 
2025-07-08 05:03:04.296664: Current learning rate: 0.00691 
2025-07-08 05:03:52.672936: train_loss -0.8815 
2025-07-08 05:03:52.673981: val_loss -0.8878 
2025-07-08 05:03:52.674206: Pseudo dice [np.float32(0.9082)] 
2025-07-08 05:03:52.674370: Epoch time: 48.38 s 
2025-07-08 05:03:53.880943:  
2025-07-08 05:03:53.881338: Epoch 338 
2025-07-08 05:03:53.881500: Current learning rate: 0.0069 
2025-07-08 05:04:43.407420: train_loss -0.8914 
2025-07-08 05:04:43.407933: val_loss -0.9005 
2025-07-08 05:04:43.408032: Pseudo dice [np.float32(0.9239)] 
2025-07-08 05:04:43.408150: Epoch time: 49.53 s 
2025-07-08 05:04:45.573159:  
2025-07-08 05:04:45.573611: Epoch 339 
2025-07-08 05:04:45.574065: Current learning rate: 0.00689 
2025-07-08 05:05:33.976052: train_loss -0.9024 
2025-07-08 05:05:33.976910: val_loss -0.8898 
2025-07-08 05:05:33.977019: Pseudo dice [np.float32(0.9142)] 
2025-07-08 05:05:33.977178: Epoch time: 48.4 s 
2025-07-08 05:05:35.153876:  
2025-07-08 05:05:35.154165: Epoch 340 
2025-07-08 05:05:35.154290: Current learning rate: 0.00688 
2025-07-08 05:06:24.616528: train_loss -0.9043 
2025-07-08 05:06:24.617191: val_loss -0.908 
2025-07-08 05:06:24.617286: Pseudo dice [np.float32(0.9262)] 
2025-07-08 05:06:24.617415: Epoch time: 49.46 s 
2025-07-08 05:06:25.838395:  
2025-07-08 05:06:25.838750: Epoch 341 
2025-07-08 05:06:25.838916: Current learning rate: 0.00687 
2025-07-08 05:07:13.851572: train_loss -0.8999 
2025-07-08 05:07:13.852188: val_loss -0.8982 
2025-07-08 05:07:13.852284: Pseudo dice [np.float32(0.9196)] 
2025-07-08 05:07:13.852401: Epoch time: 48.01 s 
2025-07-08 05:07:14.985631:  
2025-07-08 05:07:14.986075: Epoch 342 
2025-07-08 05:07:14.986193: Current learning rate: 0.00686 
2025-07-08 05:08:04.224127: train_loss -0.9111 
2025-07-08 05:08:04.224788: val_loss -0.9148 
2025-07-08 05:08:04.224876: Pseudo dice [np.float32(0.931)] 
2025-07-08 05:08:04.224966: Epoch time: 49.24 s 
2025-07-08 05:08:05.534903:  
2025-07-08 05:08:05.535161: Epoch 343 
2025-07-08 05:08:05.535556: Current learning rate: 0.00685 
2025-07-08 05:08:52.753794: train_loss -0.9083 
2025-07-08 05:08:52.754554: val_loss -0.9156 
2025-07-08 05:08:52.754983: Pseudo dice [np.float32(0.94)] 
2025-07-08 05:08:52.755449: Epoch time: 47.22 s 
2025-07-08 05:08:54.005113:  
2025-07-08 05:08:54.005335: Epoch 344 
2025-07-08 05:08:54.005587: Current learning rate: 0.00684 
2025-07-08 05:09:43.086832: train_loss -0.9093 
2025-07-08 05:09:43.087978: val_loss -0.9072 
2025-07-08 05:09:43.088125: Pseudo dice [np.float32(0.9298)] 
2025-07-08 05:09:43.088291: Epoch time: 49.08 s 
2025-07-08 05:09:44.294824:  
2025-07-08 05:09:44.295089: Epoch 345 
2025-07-08 05:09:44.295227: Current learning rate: 0.00683 
2025-07-08 05:10:33.149021: train_loss -0.9099 
2025-07-08 05:10:33.150003: val_loss -0.9074 
2025-07-08 05:10:33.150234: Pseudo dice [np.float32(0.927)] 
2025-07-08 05:10:33.150432: Epoch time: 48.86 s 
2025-07-08 05:10:34.452129:  
2025-07-08 05:10:34.452610: Epoch 346 
2025-07-08 05:10:34.452820: Current learning rate: 0.00682 
2025-07-08 05:11:22.531717: train_loss -0.91 
2025-07-08 05:11:22.532326: val_loss -0.922 
2025-07-08 05:11:22.532407: Pseudo dice [np.float32(0.9351)] 
2025-07-08 05:11:22.532510: Epoch time: 48.08 s 
2025-07-08 05:11:23.778742:  
2025-07-08 05:11:23.779175: Epoch 347 
2025-07-08 05:11:23.779385: Current learning rate: 0.00681 
2025-07-08 05:12:13.155769: train_loss -0.9123 
2025-07-08 05:12:13.156765: val_loss -0.9113 
2025-07-08 05:12:13.157010: Pseudo dice [np.float32(0.9276)] 
2025-07-08 05:12:13.157283: Epoch time: 49.38 s 
2025-07-08 05:12:14.480322:  
2025-07-08 05:12:14.480809: Epoch 348 
2025-07-08 05:12:14.480935: Current learning rate: 0.0068 
2025-07-08 05:13:03.896369: train_loss -0.9084 
2025-07-08 05:13:03.897342: val_loss -0.9161 
2025-07-08 05:13:03.897466: Pseudo dice [np.float32(0.9379)] 
2025-07-08 05:13:03.897620: Epoch time: 49.42 s 
2025-07-08 05:13:03.897717: Yayy! New best EMA pseudo Dice: 0.9276999831199646 
2025-07-08 05:13:06.041626:  
2025-07-08 05:13:06.041794: Epoch 349 
2025-07-08 05:13:06.041976: Current learning rate: 0.0068 
2025-07-08 05:13:55.038903: train_loss -0.909 
2025-07-08 05:13:55.039336: val_loss -0.9129 
2025-07-08 05:13:55.039414: Pseudo dice [np.float32(0.9322)] 
2025-07-08 05:13:55.039516: Epoch time: 49.0 s 
2025-07-08 05:13:56.032928: Yayy! New best EMA pseudo Dice: 0.9280999898910522 
2025-07-08 05:13:57.983957:  
2025-07-08 05:13:57.984141: Epoch 350 
2025-07-08 05:13:57.984402: Current learning rate: 0.00679 
2025-07-08 05:14:47.480565: train_loss -0.9101 
2025-07-08 05:14:47.481303: val_loss -0.9199 
2025-07-08 05:14:47.481394: Pseudo dice [np.float32(0.9364)] 
2025-07-08 05:14:47.481502: Epoch time: 49.5 s 
2025-07-08 05:14:47.481590: Yayy! New best EMA pseudo Dice: 0.9290000200271606 
2025-07-08 05:14:49.648583:  
2025-07-08 05:14:49.648802: Epoch 351 
2025-07-08 05:14:49.648916: Current learning rate: 0.00678 
2025-07-08 05:15:37.798085: train_loss -0.9123 
2025-07-08 05:15:37.798658: val_loss -0.9144 
2025-07-08 05:15:37.798753: Pseudo dice [np.float32(0.9262)] 
2025-07-08 05:15:37.798860: Epoch time: 48.15 s 
2025-07-08 05:15:39.085272:  
2025-07-08 05:15:39.085632: Epoch 352 
2025-07-08 05:15:39.085909: Current learning rate: 0.00677 
2025-07-08 05:16:29.202930: train_loss -0.9056 
2025-07-08 05:16:29.203507: val_loss -0.9002 
2025-07-08 05:16:29.203625: Pseudo dice [np.float32(0.9197)] 
2025-07-08 05:16:29.203748: Epoch time: 50.12 s 
2025-07-08 05:16:30.544633:  
2025-07-08 05:16:30.545182: Epoch 353 
2025-07-08 05:16:30.545345: Current learning rate: 0.00676 
2025-07-08 05:17:20.428209: train_loss -0.8952 
2025-07-08 05:17:20.428717: val_loss -0.9154 
2025-07-08 05:17:20.428804: Pseudo dice [np.float32(0.9349)] 
2025-07-08 05:17:20.428909: Epoch time: 49.88 s 
2025-07-08 05:17:22.635328:  
2025-07-08 05:17:22.636000: Epoch 354 
2025-07-08 05:17:22.636225: Current learning rate: 0.00675 
2025-07-08 05:18:11.583270: train_loss -0.9006 
2025-07-08 05:18:11.583960: val_loss -0.8991 
2025-07-08 05:18:11.584095: Pseudo dice [np.float32(0.9216)] 
2025-07-08 05:18:11.584272: Epoch time: 48.95 s 
2025-07-08 05:18:12.941912:  
2025-07-08 05:18:12.942608: Epoch 355 
2025-07-08 05:18:12.942748: Current learning rate: 0.00674 
2025-07-08 05:19:01.983246: train_loss -0.903 
2025-07-08 05:19:01.983938: val_loss -0.9111 
2025-07-08 05:19:01.984138: Pseudo dice [np.float32(0.9303)] 
2025-07-08 05:19:01.984360: Epoch time: 49.04 s 
2025-07-08 05:19:03.164416:  
2025-07-08 05:19:03.164823: Epoch 356 
2025-07-08 05:19:03.164970: Current learning rate: 0.00673 
2025-07-08 05:19:52.961076: train_loss -0.8871 
2025-07-08 05:19:52.961818: val_loss -0.9051 
2025-07-08 05:19:52.961922: Pseudo dice [np.float32(0.9239)] 
2025-07-08 05:19:52.962122: Epoch time: 49.8 s 
2025-07-08 05:19:54.235403:  
2025-07-08 05:19:54.235801: Epoch 357 
2025-07-08 05:19:54.235920: Current learning rate: 0.00672 
2025-07-08 05:20:44.332493: train_loss -0.9001 
2025-07-08 05:20:44.333565: val_loss -0.9134 
2025-07-08 05:20:44.333677: Pseudo dice [np.float32(0.9338)] 
2025-07-08 05:20:44.333812: Epoch time: 50.1 s 
2025-07-08 05:20:45.573714:  
2025-07-08 05:20:45.573969: Epoch 358 
2025-07-08 05:20:45.574080: Current learning rate: 0.00671 
2025-07-08 05:21:37.259811: train_loss -0.8957 
2025-07-08 05:21:37.260432: val_loss -0.9014 
2025-07-08 05:21:37.260531: Pseudo dice [np.float32(0.9243)] 
2025-07-08 05:21:37.260659: Epoch time: 51.69 s 
2025-07-08 05:21:38.466018:  
2025-07-08 05:21:38.466315: Epoch 359 
2025-07-08 05:21:38.466494: Current learning rate: 0.0067 
2025-07-08 05:22:26.991373: train_loss -0.9046 
2025-07-08 05:22:26.991920: val_loss -0.9067 
2025-07-08 05:22:26.992047: Pseudo dice [np.float32(0.922)] 
2025-07-08 05:22:26.992210: Epoch time: 48.53 s 
2025-07-08 05:22:28.210547:  
2025-07-08 05:22:28.211150: Epoch 360 
2025-07-08 05:22:28.211367: Current learning rate: 0.00669 
2025-07-08 05:23:17.142999: train_loss -0.9072 
2025-07-08 05:23:17.143304: val_loss -0.908 
2025-07-08 05:23:17.143394: Pseudo dice [np.float32(0.9211)] 
2025-07-08 05:23:17.143510: Epoch time: 48.93 s 
2025-07-08 05:23:18.336834:  
2025-07-08 05:23:18.337283: Epoch 361 
2025-07-08 05:23:18.337403: Current learning rate: 0.00668 
2025-07-08 05:24:08.688680: train_loss -0.9048 
2025-07-08 05:24:08.689640: val_loss -0.9067 
2025-07-08 05:24:08.689836: Pseudo dice [np.float32(0.9271)] 
2025-07-08 05:24:08.690025: Epoch time: 50.35 s 
2025-07-08 05:24:09.925956:  
2025-07-08 05:24:09.926194: Epoch 362 
2025-07-08 05:24:09.926314: Current learning rate: 0.00667 
2025-07-08 05:24:59.033369: train_loss -0.8933 
2025-07-08 05:24:59.033937: val_loss -0.9045 
2025-07-08 05:24:59.034038: Pseudo dice [np.float32(0.914)] 
2025-07-08 05:24:59.034175: Epoch time: 49.11 s 
2025-07-08 05:25:00.210682:  
2025-07-08 05:25:00.211038: Epoch 363 
2025-07-08 05:25:00.211173: Current learning rate: 0.00666 
2025-07-08 05:25:50.163145: train_loss -0.8991 
2025-07-08 05:25:50.163849: val_loss -0.8936 
2025-07-08 05:25:50.163955: Pseudo dice [np.float32(0.9154)] 
2025-07-08 05:25:50.164085: Epoch time: 49.95 s 
2025-07-08 05:25:51.394201:  
2025-07-08 05:25:51.394545: Epoch 364 
2025-07-08 05:25:51.394838: Current learning rate: 0.00665 
2025-07-08 05:26:40.927086: train_loss -0.8989 
2025-07-08 05:26:40.928335: val_loss -0.9082 
2025-07-08 05:26:40.928579: Pseudo dice [np.float32(0.9243)] 
2025-07-08 05:26:40.928760: Epoch time: 49.53 s 
2025-07-08 05:26:42.203268:  
2025-07-08 05:26:42.203760: Epoch 365 
2025-07-08 05:26:42.203988: Current learning rate: 0.00665 
2025-07-08 05:27:30.599081: train_loss -0.9003 
2025-07-08 05:27:30.599714: val_loss -0.8924 
2025-07-08 05:27:30.599811: Pseudo dice [np.float32(0.9194)] 
2025-07-08 05:27:30.599935: Epoch time: 48.4 s 
2025-07-08 05:27:31.927270:  
2025-07-08 05:27:31.927650: Epoch 366 
2025-07-08 05:27:31.927816: Current learning rate: 0.00664 
2025-07-08 05:28:22.730133: train_loss -0.9063 
2025-07-08 05:28:22.730461: val_loss -0.9154 
2025-07-08 05:28:22.730698: Pseudo dice [np.float32(0.9305)] 
2025-07-08 05:28:22.730808: Epoch time: 50.8 s 
2025-07-08 05:28:23.919314:  
2025-07-08 05:28:23.919907: Epoch 367 
2025-07-08 05:28:23.920055: Current learning rate: 0.00663 
2025-07-08 05:29:12.934931: train_loss -0.9078 
2025-07-08 05:29:12.935851: val_loss -0.9108 
2025-07-08 05:29:12.935995: Pseudo dice [np.float32(0.9266)] 
2025-07-08 05:29:12.936182: Epoch time: 49.02 s 
2025-07-08 05:29:15.157284:  
2025-07-08 05:29:15.157591: Epoch 368 
2025-07-08 05:29:15.157737: Current learning rate: 0.00662 
2025-07-08 05:30:05.361221: train_loss -0.9041 
2025-07-08 05:30:05.361739: val_loss -0.9039 
2025-07-08 05:30:05.361827: Pseudo dice [np.float32(0.9264)] 
2025-07-08 05:30:05.361952: Epoch time: 50.21 s 
2025-07-08 05:30:06.617406:  
2025-07-08 05:30:06.617638: Epoch 369 
2025-07-08 05:30:06.618089: Current learning rate: 0.00661 
2025-07-08 05:30:56.573966: train_loss -0.9043 
2025-07-08 05:30:56.574440: val_loss -0.9126 
2025-07-08 05:30:56.574532: Pseudo dice [np.float32(0.9332)] 
2025-07-08 05:30:56.574666: Epoch time: 49.96 s 
2025-07-08 05:30:57.789496:  
2025-07-08 05:30:57.789845: Epoch 370 
2025-07-08 05:30:57.790047: Current learning rate: 0.0066 
2025-07-08 05:31:47.009305: train_loss -0.9105 
2025-07-08 05:31:47.009866: val_loss -0.9135 
2025-07-08 05:31:47.009982: Pseudo dice [np.float32(0.9274)] 
2025-07-08 05:31:47.010122: Epoch time: 49.22 s 
2025-07-08 05:31:48.216594:  
2025-07-08 05:31:48.216855: Epoch 371 
2025-07-08 05:31:48.217189: Current learning rate: 0.00659 
2025-07-08 05:32:39.585907: train_loss -0.913 
2025-07-08 05:32:39.586334: val_loss -0.9145 
2025-07-08 05:32:39.586429: Pseudo dice [np.float32(0.9335)] 
2025-07-08 05:32:39.586589: Epoch time: 51.37 s 
2025-07-08 05:32:40.791349:  
2025-07-08 05:32:40.791612: Epoch 372 
2025-07-08 05:32:40.791925: Current learning rate: 0.00658 
2025-07-08 05:33:30.210449: train_loss -0.9129 
2025-07-08 05:33:30.211373: val_loss -0.9185 
2025-07-08 05:33:30.211475: Pseudo dice [np.float32(0.9315)] 
2025-07-08 05:33:30.211643: Epoch time: 49.42 s 
2025-07-08 05:33:31.590005:  
2025-07-08 05:33:31.590322: Epoch 373 
2025-07-08 05:33:31.590453: Current learning rate: 0.00657 
2025-07-08 05:34:20.639307: train_loss -0.914 
2025-07-08 05:34:20.640668: val_loss -0.9156 
2025-07-08 05:34:20.640972: Pseudo dice [np.float32(0.931)] 
2025-07-08 05:34:20.641297: Epoch time: 49.05 s 
2025-07-08 05:34:21.947508:  
2025-07-08 05:34:21.947729: Epoch 374 
2025-07-08 05:34:21.947985: Current learning rate: 0.00656 
2025-07-08 05:35:12.030535: train_loss -0.9121 
2025-07-08 05:35:12.030969: val_loss -0.9213 
2025-07-08 05:35:12.031049: Pseudo dice [np.float32(0.9372)] 
2025-07-08 05:35:12.031155: Epoch time: 50.08 s 
2025-07-08 05:35:13.264437:  
2025-07-08 05:35:13.264814: Epoch 375 
2025-07-08 05:35:13.264982: Current learning rate: 0.00655 
2025-07-08 05:36:03.423578: train_loss -0.9146 
2025-07-08 05:36:03.423944: val_loss -0.9156 
2025-07-08 05:36:03.424039: Pseudo dice [np.float32(0.9348)] 
2025-07-08 05:36:03.424150: Epoch time: 50.16 s 
2025-07-08 05:36:03.424231: Yayy! New best EMA pseudo Dice: 0.929099977016449 
2025-07-08 05:36:05.612907:  
2025-07-08 05:36:05.613410: Epoch 376 
2025-07-08 05:36:05.613600: Current learning rate: 0.00654 
2025-07-08 05:36:55.585821: train_loss -0.91 
2025-07-08 05:36:55.586529: val_loss -0.9203 
2025-07-08 05:36:55.586647: Pseudo dice [np.float32(0.9364)] 
2025-07-08 05:36:55.586787: Epoch time: 49.97 s 
2025-07-08 05:36:55.586875: Yayy! New best EMA pseudo Dice: 0.9298999905586243 
2025-07-08 05:36:57.772022:  
2025-07-08 05:36:57.772329: Epoch 377 
2025-07-08 05:36:57.772601: Current learning rate: 0.00653 
2025-07-08 05:37:48.224450: train_loss -0.9159 
2025-07-08 05:37:48.225250: val_loss -0.9171 
2025-07-08 05:37:48.225375: Pseudo dice [np.float32(0.9319)] 
2025-07-08 05:37:48.225523: Epoch time: 50.45 s 
2025-07-08 05:37:48.225638: Yayy! New best EMA pseudo Dice: 0.9301000237464905 
2025-07-08 05:37:50.375603:  
2025-07-08 05:37:50.375931: Epoch 378 
2025-07-08 05:37:50.376127: Current learning rate: 0.00652 
2025-07-08 05:38:40.188905: train_loss -0.912 
2025-07-08 05:38:40.189592: val_loss -0.9192 
2025-07-08 05:38:40.189684: Pseudo dice [np.float32(0.9365)] 
2025-07-08 05:38:40.189816: Epoch time: 49.81 s 
2025-07-08 05:38:40.189900: Yayy! New best EMA pseudo Dice: 0.9307000041007996 
2025-07-08 05:38:42.427289:  
2025-07-08 05:38:42.427695: Epoch 379 
2025-07-08 05:38:42.428039: Current learning rate: 0.00651 
2025-07-08 05:39:32.358577: train_loss -0.9147 
2025-07-08 05:39:32.359230: val_loss -0.9207 
2025-07-08 05:39:32.359329: Pseudo dice [np.float32(0.9402)] 
2025-07-08 05:39:32.359468: Epoch time: 49.93 s 
2025-07-08 05:39:32.359573: Yayy! New best EMA pseudo Dice: 0.9316999912261963 
2025-07-08 05:39:34.461748:  
2025-07-08 05:39:34.462070: Epoch 380 
2025-07-08 05:39:34.462237: Current learning rate: 0.0065 
2025-07-08 05:40:23.654342: train_loss -0.914 
2025-07-08 05:40:23.654919: val_loss -0.9142 
2025-07-08 05:40:23.655013: Pseudo dice [np.float32(0.9278)] 
2025-07-08 05:40:23.655120: Epoch time: 49.19 s 
2025-07-08 05:40:24.924466:  
2025-07-08 05:40:24.924825: Epoch 381 
2025-07-08 05:40:24.925171: Current learning rate: 0.00649 
2025-07-08 05:41:14.781478: train_loss -0.9157 
2025-07-08 05:41:14.782069: val_loss -0.9191 
2025-07-08 05:41:14.782186: Pseudo dice [np.float32(0.9338)] 
2025-07-08 05:41:14.782343: Epoch time: 49.86 s 
2025-07-08 05:41:16.892787:  
2025-07-08 05:41:16.893067: Epoch 382 
2025-07-08 05:41:16.893204: Current learning rate: 0.00648 
2025-07-08 05:42:06.637134: train_loss -0.9114 
2025-07-08 05:42:06.637692: val_loss -0.9108 
2025-07-08 05:42:06.637830: Pseudo dice [np.float32(0.9283)] 
2025-07-08 05:42:06.638001: Epoch time: 49.75 s 
2025-07-08 05:42:07.783176:  
2025-07-08 05:42:07.783573: Epoch 383 
2025-07-08 05:42:07.783718: Current learning rate: 0.00648 
2025-07-08 05:42:57.390033: train_loss -0.9179 
2025-07-08 05:42:57.390517: val_loss -0.9135 
2025-07-08 05:42:57.390625: Pseudo dice [np.float32(0.9286)] 
2025-07-08 05:42:57.390746: Epoch time: 49.61 s 
2025-07-08 05:42:58.632838:  
2025-07-08 05:42:58.633320: Epoch 384 
2025-07-08 05:42:58.633449: Current learning rate: 0.00647 
2025-07-08 05:43:46.852649: train_loss -0.9153 
2025-07-08 05:43:46.853443: val_loss -0.915 
2025-07-08 05:43:46.853534: Pseudo dice [np.float32(0.935)] 
2025-07-08 05:43:46.853705: Epoch time: 48.22 s 
2025-07-08 05:43:48.042449:  
2025-07-08 05:43:48.042796: Epoch 385 
2025-07-08 05:43:48.043016: Current learning rate: 0.00646 
2025-07-08 05:44:38.610197: train_loss -0.908 
2025-07-08 05:44:38.611558: val_loss -0.9196 
2025-07-08 05:44:38.611743: Pseudo dice [np.float32(0.9389)] 
2025-07-08 05:44:38.611945: Epoch time: 50.57 s 
2025-07-08 05:44:38.612083: Yayy! New best EMA pseudo Dice: 0.9320999979972839 
2025-07-08 05:44:40.810366:  
2025-07-08 05:44:40.810648: Epoch 386 
2025-07-08 05:44:40.810939: Current learning rate: 0.00645 
2025-07-08 05:45:30.270952: train_loss -0.9062 
2025-07-08 05:45:30.271380: val_loss -0.8863 
2025-07-08 05:45:30.271465: Pseudo dice [np.float32(0.9127)] 
2025-07-08 05:45:30.271659: Epoch time: 49.46 s 
2025-07-08 05:45:31.533822:  
2025-07-08 05:45:31.534163: Epoch 387 
2025-07-08 05:45:31.534317: Current learning rate: 0.00644 
2025-07-08 05:46:20.935968: train_loss -0.8694 
2025-07-08 05:46:20.936237: val_loss -0.889 
2025-07-08 05:46:20.936325: Pseudo dice [np.float32(0.911)] 
2025-07-08 05:46:20.936423: Epoch time: 49.4 s 
2025-07-08 05:46:22.130350:  
2025-07-08 05:46:22.130708: Epoch 388 
2025-07-08 05:46:22.130942: Current learning rate: 0.00643 
2025-07-08 05:47:11.756468: train_loss -0.8753 
2025-07-08 05:47:11.757009: val_loss -0.8763 
2025-07-08 05:47:11.757102: Pseudo dice [np.float32(0.8924)] 
2025-07-08 05:47:11.757225: Epoch time: 49.63 s 
2025-07-08 05:47:12.916914:  
2025-07-08 05:47:12.917398: Epoch 389 
2025-07-08 05:47:12.917524: Current learning rate: 0.00642 
2025-07-08 05:48:00.470855: train_loss -0.8828 
2025-07-08 05:48:00.471355: val_loss -0.8838 
2025-07-08 05:48:00.471446: Pseudo dice [np.float32(0.9069)] 
2025-07-08 05:48:00.471581: Epoch time: 47.56 s 
2025-07-08 05:48:01.640848:  
2025-07-08 05:48:01.641190: Epoch 390 
2025-07-08 05:48:01.641367: Current learning rate: 0.00641 
2025-07-08 05:48:52.748300: train_loss -0.8867 
2025-07-08 05:48:52.749478: val_loss -0.9043 
2025-07-08 05:48:52.749614: Pseudo dice [np.float32(0.9201)] 
2025-07-08 05:48:52.749806: Epoch time: 51.11 s 
2025-07-08 05:48:53.980421:  
2025-07-08 05:48:53.980649: Epoch 391 
2025-07-08 05:48:53.980753: Current learning rate: 0.0064 
2025-07-08 05:49:42.927051: train_loss -0.8889 
2025-07-08 05:49:42.927560: val_loss -0.8668 
2025-07-08 05:49:42.927643: Pseudo dice [np.float32(0.902)] 
2025-07-08 05:49:42.927746: Epoch time: 48.95 s 
2025-07-08 05:49:44.137237:  
2025-07-08 05:49:44.137439: Epoch 392 
2025-07-08 05:49:44.137816: Current learning rate: 0.00639 
2025-07-08 05:50:33.023580: train_loss -0.86 
2025-07-08 05:50:33.023947: val_loss -0.8574 
2025-07-08 05:50:33.024029: Pseudo dice [np.float32(0.8852)] 
2025-07-08 05:50:33.024125: Epoch time: 48.89 s 
2025-07-08 05:50:34.264672:  
2025-07-08 05:50:34.264888: Epoch 393 
2025-07-08 05:50:34.264991: Current learning rate: 0.00638 
2025-07-08 05:51:24.072903: train_loss -0.875 
2025-07-08 05:51:24.073435: val_loss -0.8856 
2025-07-08 05:51:24.073516: Pseudo dice [np.float32(0.9183)] 
2025-07-08 05:51:24.073637: Epoch time: 49.81 s 
2025-07-08 05:51:25.265554:  
2025-07-08 05:51:25.266034: Epoch 394 
2025-07-08 05:51:25.266199: Current learning rate: 0.00637 
2025-07-08 05:52:13.815514: train_loss -0.9003 
2025-07-08 05:52:13.816119: val_loss -0.8953 
2025-07-08 05:52:13.816214: Pseudo dice [np.float32(0.9122)] 
2025-07-08 05:52:13.816328: Epoch time: 48.55 s 
2025-07-08 05:52:15.098720:  
2025-07-08 05:52:15.099245: Epoch 395 
2025-07-08 05:52:15.099367: Current learning rate: 0.00636 
2025-07-08 05:53:05.865206: train_loss -0.8897 
2025-07-08 05:53:05.865683: val_loss -0.8968 
2025-07-08 05:53:05.865765: Pseudo dice [np.float32(0.9184)] 
2025-07-08 05:53:05.865868: Epoch time: 50.77 s 
2025-07-08 05:53:08.105112:  
2025-07-08 05:53:08.105554: Epoch 396 
2025-07-08 05:53:08.105713: Current learning rate: 0.00635 
2025-07-08 05:53:55.641350: train_loss -0.8958 
2025-07-08 05:53:55.641743: val_loss -0.9039 
2025-07-08 05:53:55.641819: Pseudo dice [np.float32(0.9295)] 
2025-07-08 05:53:55.641912: Epoch time: 47.54 s 
2025-07-08 05:53:57.062913:  
2025-07-08 05:53:57.063258: Epoch 397 
2025-07-08 05:53:57.063498: Current learning rate: 0.00634 
2025-07-08 05:54:46.412465: train_loss -0.8983 
2025-07-08 05:54:46.412912: val_loss -0.9038 
2025-07-08 05:54:46.414222: Pseudo dice [np.float32(0.9233)] 
2025-07-08 05:54:46.414362: Epoch time: 49.35 s 
2025-07-08 05:54:47.646813:  
2025-07-08 05:54:47.647041: Epoch 398 
2025-07-08 05:54:47.647345: Current learning rate: 0.00633 
2025-07-08 05:55:36.908465: train_loss -0.9075 
2025-07-08 05:55:36.908970: val_loss -0.8939 
2025-07-08 05:55:36.909059: Pseudo dice [np.float32(0.9146)] 
2025-07-08 05:55:36.909173: Epoch time: 49.26 s 
2025-07-08 05:55:38.173937:  
2025-07-08 05:55:38.174338: Epoch 399 
2025-07-08 05:55:38.174468: Current learning rate: 0.00632 
2025-07-08 05:56:26.809325: train_loss -0.9045 
2025-07-08 05:56:26.810144: val_loss -0.9135 
2025-07-08 05:56:26.810238: Pseudo dice [np.float32(0.9352)] 
2025-07-08 05:56:26.810390: Epoch time: 48.64 s 
2025-07-08 05:56:28.931255:  
2025-07-08 05:56:28.931605: Epoch 400 
2025-07-08 05:56:28.931735: Current learning rate: 0.00631 
2025-07-08 05:57:18.480409: train_loss -0.9094 
2025-07-08 05:57:18.480895: val_loss -0.9134 
2025-07-08 05:57:18.480980: Pseudo dice [np.float32(0.9354)] 
2025-07-08 05:57:18.481107: Epoch time: 49.55 s 
2025-07-08 05:57:19.720881:  
2025-07-08 05:57:19.721419: Epoch 401 
2025-07-08 05:57:19.721626: Current learning rate: 0.0063 
2025-07-08 05:58:09.388963: train_loss -0.9103 
2025-07-08 05:58:09.389506: val_loss -0.9109 
2025-07-08 05:58:09.389607: Pseudo dice [np.float32(0.9314)] 
2025-07-08 05:58:09.389725: Epoch time: 49.67 s 
2025-07-08 05:58:10.631649:  
2025-07-08 05:58:10.631913: Epoch 402 
2025-07-08 05:58:10.632044: Current learning rate: 0.0063 
2025-07-08 05:58:59.229120: train_loss -0.9096 
2025-07-08 05:58:59.229684: val_loss -0.9238 
2025-07-08 05:58:59.229768: Pseudo dice [np.float32(0.9383)] 
2025-07-08 05:58:59.229881: Epoch time: 48.6 s 
2025-07-08 05:59:00.446776:  
2025-07-08 05:59:00.447103: Epoch 403 
2025-07-08 05:59:00.447373: Current learning rate: 0.00629 
2025-07-08 05:59:48.725013: train_loss -0.9118 
2025-07-08 05:59:48.725735: val_loss -0.9093 
2025-07-08 05:59:48.725822: Pseudo dice [np.float32(0.9312)] 
2025-07-08 05:59:48.725932: Epoch time: 48.28 s 
2025-07-08 05:59:49.950196:  
2025-07-08 05:59:49.950614: Epoch 404 
2025-07-08 05:59:49.950778: Current learning rate: 0.00628 
2025-07-08 06:00:38.840612: train_loss -0.9161 
2025-07-08 06:00:38.841511: val_loss -0.9248 
2025-07-08 06:00:38.841731: Pseudo dice [np.float32(0.9386)] 
2025-07-08 06:00:38.841912: Epoch time: 48.89 s 
2025-07-08 06:00:40.121695:  
2025-07-08 06:00:40.122223: Epoch 405 
2025-07-08 06:00:40.122418: Current learning rate: 0.00627 
2025-07-08 06:01:28.708148: train_loss -0.9123 
2025-07-08 06:01:28.708756: val_loss -0.9163 
2025-07-08 06:01:28.708878: Pseudo dice [np.float32(0.9309)] 
2025-07-08 06:01:28.709000: Epoch time: 48.59 s 
2025-07-08 06:01:29.933367:  
2025-07-08 06:01:29.933704: Epoch 406 
2025-07-08 06:01:29.933915: Current learning rate: 0.00626 
2025-07-08 06:02:18.710801: train_loss -0.9172 
2025-07-08 06:02:18.711281: val_loss -0.9221 
2025-07-08 06:02:18.711367: Pseudo dice [np.float32(0.9371)] 
2025-07-08 06:02:18.711473: Epoch time: 48.78 s 
2025-07-08 06:02:19.879782:  
2025-07-08 06:02:19.880067: Epoch 407 
2025-07-08 06:02:19.880355: Current learning rate: 0.00625 
2025-07-08 06:03:10.825734: train_loss -0.9142 
2025-07-08 06:03:10.826190: val_loss -0.9262 
2025-07-08 06:03:10.826270: Pseudo dice [np.float32(0.9389)] 
2025-07-08 06:03:10.826369: Epoch time: 50.95 s 
2025-07-08 06:03:12.025927:  
2025-07-08 06:03:12.026414: Epoch 408 
2025-07-08 06:03:12.026551: Current learning rate: 0.00624 
2025-07-08 06:03:58.660158: train_loss -0.9152 
2025-07-08 06:03:58.660878: val_loss -0.9209 
2025-07-08 06:03:58.660984: Pseudo dice [np.float32(0.9394)] 
2025-07-08 06:03:58.661131: Epoch time: 46.64 s 
2025-07-08 06:03:59.952373:  
2025-07-08 06:03:59.952698: Epoch 409 
2025-07-08 06:03:59.952993: Current learning rate: 0.00623 
2025-07-08 06:04:50.113611: train_loss -0.9083 
2025-07-08 06:04:50.114096: val_loss -0.9163 
2025-07-08 06:04:50.114177: Pseudo dice [np.float32(0.9286)] 
2025-07-08 06:04:50.114284: Epoch time: 50.16 s 
2025-07-08 06:04:52.292127:  
2025-07-08 06:04:52.292389: Epoch 410 
2025-07-08 06:04:52.292612: Current learning rate: 0.00622 
2025-07-08 06:05:39.963589: train_loss -0.9115 
2025-07-08 06:05:39.964015: val_loss -0.909 
2025-07-08 06:05:39.964095: Pseudo dice [np.float32(0.9306)] 
2025-07-08 06:05:39.964202: Epoch time: 47.67 s 
2025-07-08 06:05:41.162021:  
2025-07-08 06:05:41.162770: Epoch 411 
2025-07-08 06:05:41.162924: Current learning rate: 0.00621 
2025-07-08 06:06:31.365509: train_loss -0.9141 
2025-07-08 06:06:31.366185: val_loss -0.9134 
2025-07-08 06:06:31.366297: Pseudo dice [np.float32(0.924)] 
2025-07-08 06:06:31.366423: Epoch time: 50.2 s 
2025-07-08 06:06:32.608495:  
2025-07-08 06:06:32.608987: Epoch 412 
2025-07-08 06:06:32.609250: Current learning rate: 0.0062 
2025-07-08 06:07:21.531615: train_loss -0.9136 
2025-07-08 06:07:21.532176: val_loss -0.9125 
2025-07-08 06:07:21.532272: Pseudo dice [np.float32(0.9314)] 
2025-07-08 06:07:21.532410: Epoch time: 48.92 s 
2025-07-08 06:07:22.658777:  
2025-07-08 06:07:22.659182: Epoch 413 
2025-07-08 06:07:22.659320: Current learning rate: 0.00619 
2025-07-08 06:08:12.043888: train_loss -0.9161 
2025-07-08 06:08:12.044354: val_loss -0.924 
2025-07-08 06:08:12.044432: Pseudo dice [np.float32(0.9413)] 
2025-07-08 06:08:12.044554: Epoch time: 49.39 s 
2025-07-08 06:08:13.328013:  
2025-07-08 06:08:13.328509: Epoch 414 
2025-07-08 06:08:13.328679: Current learning rate: 0.00618 
2025-07-08 06:09:02.722075: train_loss -0.9138 
2025-07-08 06:09:02.722565: val_loss -0.9149 
2025-07-08 06:09:02.722661: Pseudo dice [np.float32(0.9366)] 
2025-07-08 06:09:02.722855: Epoch time: 49.4 s 
2025-07-08 06:09:03.876936:  
2025-07-08 06:09:03.877290: Epoch 415 
2025-07-08 06:09:03.877416: Current learning rate: 0.00617 
2025-07-08 06:09:55.426863: train_loss -0.9159 
2025-07-08 06:09:55.428076: val_loss -0.9163 
2025-07-08 06:09:55.431885: Pseudo dice [np.float32(0.9349)] 
2025-07-08 06:09:55.432346: Epoch time: 51.55 s 
2025-07-08 06:09:56.667552:  
2025-07-08 06:09:56.668000: Epoch 416 
2025-07-08 06:09:56.668106: Current learning rate: 0.00616 
2025-07-08 06:10:47.268444: train_loss -0.9166 
2025-07-08 06:10:47.269011: val_loss -0.9245 
2025-07-08 06:10:47.269098: Pseudo dice [np.float32(0.9437)] 
2025-07-08 06:10:47.269217: Epoch time: 50.6 s 
2025-07-08 06:10:47.269300: Yayy! New best EMA pseudo Dice: 0.9327999949455261 
2025-07-08 06:10:49.427143:  
2025-07-08 06:10:49.427658: Epoch 417 
2025-07-08 06:10:49.427846: Current learning rate: 0.00615 
2025-07-08 06:11:39.581375: train_loss -0.912 
2025-07-08 06:11:39.581941: val_loss -0.9171 
2025-07-08 06:11:39.582021: Pseudo dice [np.float32(0.9404)] 
2025-07-08 06:11:39.582162: Epoch time: 50.16 s 
2025-07-08 06:11:39.582236: Yayy! New best EMA pseudo Dice: 0.9336000084877014 
2025-07-08 06:11:41.740602:  
2025-07-08 06:11:41.740833: Epoch 418 
2025-07-08 06:11:41.740937: Current learning rate: 0.00614 
2025-07-08 06:12:30.190001: train_loss -0.9147 
2025-07-08 06:12:30.190718: val_loss -0.917 
2025-07-08 06:12:30.190820: Pseudo dice [np.float32(0.9369)] 
2025-07-08 06:12:30.190944: Epoch time: 48.45 s 
2025-07-08 06:12:30.191033: Yayy! New best EMA pseudo Dice: 0.933899998664856 
2025-07-08 06:12:32.229185:  
2025-07-08 06:12:32.229502: Epoch 419 
2025-07-08 06:12:32.229815: Current learning rate: 0.00613 
2025-07-08 06:13:21.117917: train_loss -0.9149 
2025-07-08 06:13:21.118371: val_loss -0.9204 
2025-07-08 06:13:21.118468: Pseudo dice [np.float32(0.9413)] 
2025-07-08 06:13:21.118581: Epoch time: 48.89 s 
2025-07-08 06:13:21.118660: Yayy! New best EMA pseudo Dice: 0.9345999956130981 
2025-07-08 06:13:23.172619:  
2025-07-08 06:13:23.172884: Epoch 420 
2025-07-08 06:13:23.173029: Current learning rate: 0.00612 
2025-07-08 06:14:13.082672: train_loss -0.9111 
2025-07-08 06:14:13.083061: val_loss -0.9106 
2025-07-08 06:14:13.083134: Pseudo dice [np.float32(0.9295)] 
2025-07-08 06:14:13.083234: Epoch time: 49.91 s 
2025-07-08 06:14:14.220591:  
2025-07-08 06:14:14.220934: Epoch 421 
2025-07-08 06:14:14.221095: Current learning rate: 0.00612 
2025-07-08 06:15:03.510504: train_loss -0.9139 
2025-07-08 06:15:03.510842: val_loss -0.9091 
2025-07-08 06:15:03.514305: Pseudo dice [np.float32(0.926)] 
2025-07-08 06:15:03.514536: Epoch time: 49.29 s 
2025-07-08 06:15:04.784067:  
2025-07-08 06:15:04.784220: Epoch 422 
2025-07-08 06:15:04.784458: Current learning rate: 0.00611 
2025-07-08 06:15:51.986968: train_loss -0.9148 
2025-07-08 06:15:51.987914: val_loss -0.9216 
2025-07-08 06:15:51.988009: Pseudo dice [np.float32(0.9403)] 
2025-07-08 06:15:51.988137: Epoch time: 47.2 s 
2025-07-08 06:15:53.201592:  
2025-07-08 06:15:53.201812: Epoch 423 
2025-07-08 06:15:53.202091: Current learning rate: 0.0061 
2025-07-08 06:16:42.370081: train_loss -0.9135 
2025-07-08 06:16:42.371171: val_loss -0.9214 
2025-07-08 06:16:42.375632: Pseudo dice [np.float32(0.9388)] 
2025-07-08 06:16:42.375896: Epoch time: 49.17 s 
2025-07-08 06:16:43.606403:  
2025-07-08 06:16:43.607023: Epoch 424 
2025-07-08 06:16:43.607234: Current learning rate: 0.00609 
2025-07-08 06:17:33.514503: train_loss -0.9163 
2025-07-08 06:17:33.516252: val_loss -0.9228 
2025-07-08 06:17:33.516342: Pseudo dice [np.float32(0.9332)] 
2025-07-08 06:17:33.516451: Epoch time: 49.91 s 
2025-07-08 06:17:35.688130:  
2025-07-08 06:17:35.688442: Epoch 425 
2025-07-08 06:17:35.688599: Current learning rate: 0.00608 
2025-07-08 06:18:25.699507: train_loss -0.9086 
2025-07-08 06:18:25.700486: val_loss -0.9237 
2025-07-08 06:18:25.700723: Pseudo dice [np.float32(0.9404)] 
2025-07-08 06:18:25.700879: Epoch time: 50.01 s 
2025-07-08 06:18:25.700983: Yayy! New best EMA pseudo Dice: 0.9350000023841858 
2025-07-08 06:18:27.760860:  
2025-07-08 06:18:27.761113: Epoch 426 
2025-07-08 06:18:27.761239: Current learning rate: 0.00607 
2025-07-08 06:19:18.105642: train_loss -0.9165 
2025-07-08 06:19:18.106180: val_loss -0.9223 
2025-07-08 06:19:18.106267: Pseudo dice [np.float32(0.937)] 
2025-07-08 06:19:18.106384: Epoch time: 50.35 s 
2025-07-08 06:19:18.106459: Yayy! New best EMA pseudo Dice: 0.9351999759674072 
2025-07-08 06:19:20.397036:  
2025-07-08 06:19:20.397480: Epoch 427 
2025-07-08 06:19:20.397636: Current learning rate: 0.00606 
2025-07-08 06:20:10.864501: train_loss -0.9084 
2025-07-08 06:20:10.865108: val_loss -0.919 
2025-07-08 06:20:10.865196: Pseudo dice [np.float32(0.9318)] 
2025-07-08 06:20:10.865368: Epoch time: 50.47 s 
2025-07-08 06:20:11.986311:  
2025-07-08 06:20:11.986911: Epoch 428 
2025-07-08 06:20:11.987146: Current learning rate: 0.00605 
2025-07-08 06:21:01.805048: train_loss -0.907 
2025-07-08 06:21:01.805760: val_loss -0.9101 
2025-07-08 06:21:01.805925: Pseudo dice [np.float32(0.9319)] 
2025-07-08 06:21:01.806107: Epoch time: 49.82 s 
2025-07-08 06:21:03.023730:  
2025-07-08 06:21:03.023965: Epoch 429 
2025-07-08 06:21:03.024264: Current learning rate: 0.00604 
2025-07-08 06:21:51.644208: train_loss -0.895 
2025-07-08 06:21:51.644948: val_loss -0.9059 
2025-07-08 06:21:51.645054: Pseudo dice [np.float32(0.9285)] 
2025-07-08 06:21:51.645184: Epoch time: 48.62 s 
2025-07-08 06:21:52.815076:  
2025-07-08 06:21:52.815360: Epoch 430 
2025-07-08 06:21:52.815489: Current learning rate: 0.00603 
2025-07-08 06:22:41.999580: train_loss -0.8738 
2025-07-08 06:22:42.000290: val_loss -0.8873 
2025-07-08 06:22:42.000397: Pseudo dice [np.float32(0.9014)] 
2025-07-08 06:22:42.000551: Epoch time: 49.19 s 
2025-07-08 06:22:43.245791:  
2025-07-08 06:22:43.246230: Epoch 431 
2025-07-08 06:22:43.246415: Current learning rate: 0.00602 
2025-07-08 06:23:32.459834: train_loss -0.8931 
2025-07-08 06:23:32.460424: val_loss -0.8937 
2025-07-08 06:23:32.460996: Pseudo dice [np.float32(0.9184)] 
2025-07-08 06:23:32.461237: Epoch time: 49.22 s 
2025-07-08 06:23:33.715315:  
2025-07-08 06:23:33.715633: Epoch 432 
2025-07-08 06:23:33.715956: Current learning rate: 0.00601 
2025-07-08 06:24:22.903858: train_loss -0.8958 
2025-07-08 06:24:22.904239: val_loss -0.9081 
2025-07-08 06:24:22.904313: Pseudo dice [np.float32(0.9242)] 
2025-07-08 06:24:22.904414: Epoch time: 49.19 s 
2025-07-08 06:24:24.111917:  
2025-07-08 06:24:24.112093: Epoch 433 
2025-07-08 06:24:24.112213: Current learning rate: 0.006 
2025-07-08 06:25:12.685832: train_loss -0.8985 
2025-07-08 06:25:12.687381: val_loss -0.8982 
2025-07-08 06:25:12.687650: Pseudo dice [np.float32(0.9203)] 
2025-07-08 06:25:12.687927: Epoch time: 48.57 s 
2025-07-08 06:25:13.900001:  
2025-07-08 06:25:13.900212: Epoch 434 
2025-07-08 06:25:13.900334: Current learning rate: 0.00599 
2025-07-08 06:26:02.643133: train_loss -0.872 
2025-07-08 06:26:02.643627: val_loss -0.8545 
2025-07-08 06:26:02.643713: Pseudo dice [np.float32(0.8909)] 
2025-07-08 06:26:02.643835: Epoch time: 48.74 s 
2025-07-08 06:26:03.852093:  
2025-07-08 06:26:03.852297: Epoch 435 
2025-07-08 06:26:03.852642: Current learning rate: 0.00598 
2025-07-08 06:26:53.536511: train_loss -0.8674 
2025-07-08 06:26:53.537023: val_loss -0.8927 
2025-07-08 06:26:53.537121: Pseudo dice [np.float32(0.9144)] 
2025-07-08 06:26:53.537289: Epoch time: 49.69 s 
2025-07-08 06:26:54.692092:  
2025-07-08 06:26:54.692383: Epoch 436 
2025-07-08 06:26:54.692529: Current learning rate: 0.00597 
2025-07-08 06:27:43.495272: train_loss -0.8881 
2025-07-08 06:27:43.495885: val_loss -0.896 
2025-07-08 06:27:43.495970: Pseudo dice [np.float32(0.9232)] 
2025-07-08 06:27:43.496076: Epoch time: 48.81 s 
2025-07-08 06:27:44.697999:  
2025-07-08 06:27:44.698293: Epoch 437 
2025-07-08 06:27:44.698432: Current learning rate: 0.00596 
2025-07-08 06:28:32.517030: train_loss -0.8833 
2025-07-08 06:28:32.518086: val_loss -0.8744 
2025-07-08 06:28:32.518190: Pseudo dice [np.float32(0.8998)] 
2025-07-08 06:28:32.518322: Epoch time: 47.82 s 
2025-07-08 06:28:33.745504:  
2025-07-08 06:28:33.745821: Epoch 438 
2025-07-08 06:28:33.746038: Current learning rate: 0.00595 
2025-07-08 06:29:22.339700: train_loss -0.8792 
2025-07-08 06:29:22.340292: val_loss -0.8982 
2025-07-08 06:29:22.340390: Pseudo dice [np.float32(0.9192)] 
2025-07-08 06:29:22.340519: Epoch time: 48.6 s 
2025-07-08 06:29:23.654738:  
2025-07-08 06:29:23.655044: Epoch 439 
2025-07-08 06:29:23.655158: Current learning rate: 0.00594 
2025-07-08 06:30:13.295869: train_loss -0.893 
2025-07-08 06:30:13.296937: val_loss -0.9076 
2025-07-08 06:30:13.297457: Pseudo dice [np.float32(0.9262)] 
2025-07-08 06:30:13.298158: Epoch time: 49.64 s 
2025-07-08 06:30:15.697591:  
2025-07-08 06:30:15.697994: Epoch 440 
2025-07-08 06:30:15.698129: Current learning rate: 0.00593 
2025-07-08 06:31:03.719027: train_loss -0.8937 
2025-07-08 06:31:03.720193: val_loss -0.9014 
2025-07-08 06:31:03.720608: Pseudo dice [np.float32(0.9246)] 
2025-07-08 06:31:03.720918: Epoch time: 48.02 s 
2025-07-08 06:31:04.984431:  
2025-07-08 06:31:04.984641: Epoch 441 
2025-07-08 06:31:04.984784: Current learning rate: 0.00592 
2025-07-08 06:31:53.302588: train_loss -0.8843 
2025-07-08 06:31:53.303192: val_loss -0.8801 
2025-07-08 06:31:53.303458: Pseudo dice [np.float32(0.9047)] 
2025-07-08 06:31:53.303727: Epoch time: 48.32 s 
2025-07-08 06:31:54.523719:  
2025-07-08 06:31:54.524026: Epoch 442 
2025-07-08 06:31:54.524346: Current learning rate: 0.00592 
2025-07-08 06:32:43.598242: train_loss -0.8666 
2025-07-08 06:32:43.598878: val_loss -0.8969 
2025-07-08 06:32:43.599015: Pseudo dice [np.float32(0.923)] 
2025-07-08 06:32:43.599157: Epoch time: 49.08 s 
2025-07-08 06:32:44.839291:  
2025-07-08 06:32:44.839660: Epoch 443 
2025-07-08 06:32:44.839798: Current learning rate: 0.00591 
2025-07-08 06:33:36.152549: train_loss -0.8929 
2025-07-08 06:33:36.153254: val_loss -0.8922 
2025-07-08 06:33:36.153415: Pseudo dice [np.float32(0.9219)] 
2025-07-08 06:33:36.153623: Epoch time: 51.31 s 
2025-07-08 06:33:37.551732:  
2025-07-08 06:33:37.552049: Epoch 444 
2025-07-08 06:33:37.552192: Current learning rate: 0.0059 
2025-07-08 06:34:34.792693: train_loss -0.8946 
2025-07-08 06:34:34.793691: val_loss -0.8855 
2025-07-08 06:34:34.793813: Pseudo dice [np.float32(0.9124)] 
2025-07-08 06:34:34.793952: Epoch time: 57.24 s 
2025-07-08 06:34:36.038868:  
2025-07-08 06:34:36.039317: Epoch 445 
2025-07-08 06:34:36.039493: Current learning rate: 0.00589 
2025-07-08 06:35:23.876963: train_loss -0.8961 
2025-07-08 06:35:23.877587: val_loss -0.8962 
2025-07-08 06:35:23.877805: Pseudo dice [np.float32(0.913)] 
2025-07-08 06:35:23.877925: Epoch time: 47.84 s 
2025-07-08 06:35:25.075290:  
2025-07-08 06:35:25.075469: Epoch 446 
2025-07-08 06:35:25.075625: Current learning rate: 0.00588 
2025-07-08 06:36:14.519454: train_loss -0.9014 
2025-07-08 06:36:14.519956: val_loss -0.9052 
2025-07-08 06:36:14.520036: Pseudo dice [np.float32(0.9215)] 
2025-07-08 06:36:14.520134: Epoch time: 49.45 s 
2025-07-08 06:36:15.641909:  
2025-07-08 06:36:15.642193: Epoch 447 
2025-07-08 06:36:15.642471: Current learning rate: 0.00587 
2025-07-08 06:37:05.926944: train_loss -0.9055 
2025-07-08 06:37:05.927456: val_loss -0.9058 
2025-07-08 06:37:05.927563: Pseudo dice [np.float32(0.9238)] 
2025-07-08 06:37:05.927691: Epoch time: 50.29 s 
2025-07-08 06:37:07.098920:  
2025-07-08 06:37:07.099323: Epoch 448 
2025-07-08 06:37:07.099523: Current learning rate: 0.00586 
2025-07-08 06:37:57.211447: train_loss -0.9087 
2025-07-08 06:37:57.212034: val_loss -0.9183 
2025-07-08 06:37:57.212159: Pseudo dice [np.float32(0.9354)] 
2025-07-08 06:37:57.212350: Epoch time: 50.11 s 
2025-07-08 06:37:58.462482:  
2025-07-08 06:37:58.463096: Epoch 449 
2025-07-08 06:37:58.463303: Current learning rate: 0.00585 
2025-07-08 06:38:49.090395: train_loss -0.9114 
2025-07-08 06:38:49.091054: val_loss -0.9156 
2025-07-08 06:38:49.091156: Pseudo dice [np.float32(0.9336)] 
2025-07-08 06:38:49.091277: Epoch time: 50.63 s 
2025-07-08 06:38:51.257670:  
2025-07-08 06:38:51.258134: Epoch 450 
2025-07-08 06:38:51.258272: Current learning rate: 0.00584 
2025-07-08 06:39:39.910751: train_loss -0.9124 
2025-07-08 06:39:39.911280: val_loss -0.9256 
2025-07-08 06:39:39.915151: Pseudo dice [np.float32(0.9417)] 
2025-07-08 06:39:39.915585: Epoch time: 48.65 s 
2025-07-08 06:39:41.115805:  
2025-07-08 06:39:41.116273: Epoch 451 
2025-07-08 06:39:41.116483: Current learning rate: 0.00583 
2025-07-08 06:40:31.099936: train_loss -0.9118 
2025-07-08 06:40:31.100523: val_loss -0.9154 
2025-07-08 06:40:31.100625: Pseudo dice [np.float32(0.9294)] 
2025-07-08 06:40:31.100734: Epoch time: 49.99 s 
2025-07-08 06:40:32.255986:  
2025-07-08 06:40:32.256294: Epoch 452 
2025-07-08 06:40:32.256426: Current learning rate: 0.00582 
2025-07-08 06:41:20.178416: train_loss -0.9091 
2025-07-08 06:41:20.179611: val_loss -0.9058 
2025-07-08 06:41:20.179726: Pseudo dice [np.float32(0.9353)] 
2025-07-08 06:41:20.179879: Epoch time: 47.92 s 
2025-07-08 06:41:21.340189:  
2025-07-08 06:41:21.340465: Epoch 453 
2025-07-08 06:41:21.340772: Current learning rate: 0.00581 
2025-07-08 06:42:10.222871: train_loss -0.9121 
2025-07-08 06:42:10.223795: val_loss -0.9198 
2025-07-08 06:42:10.224074: Pseudo dice [np.float32(0.9339)] 
2025-07-08 06:42:10.224356: Epoch time: 48.88 s 
2025-07-08 06:42:11.462966:  
2025-07-08 06:42:11.463228: Epoch 454 
2025-07-08 06:42:11.463401: Current learning rate: 0.0058 
2025-07-08 06:43:00.162730: train_loss -0.9124 
2025-07-08 06:43:00.163326: val_loss -0.915 
2025-07-08 06:43:00.163421: Pseudo dice [np.float32(0.9344)] 
2025-07-08 06:43:00.163635: Epoch time: 48.7 s 
2025-07-08 06:43:01.350879:  
2025-07-08 06:43:01.351113: Epoch 455 
2025-07-08 06:43:01.351260: Current learning rate: 0.00579 
2025-07-08 06:43:51.023963: train_loss -0.9082 
2025-07-08 06:43:51.024784: val_loss -0.9186 
2025-07-08 06:43:51.024870: Pseudo dice [np.float32(0.9326)] 
2025-07-08 06:43:51.024993: Epoch time: 49.67 s 
2025-07-08 06:43:52.971517:  
2025-07-08 06:43:52.971662: Epoch 456 
2025-07-08 06:43:52.971830: Current learning rate: 0.00578 
2025-07-08 06:44:41.553588: train_loss -0.9103 
2025-07-08 06:44:41.554152: val_loss -0.9216 
2025-07-08 06:44:41.554268: Pseudo dice [np.float32(0.9406)] 
2025-07-08 06:44:41.554399: Epoch time: 48.58 s 
2025-07-08 06:44:42.693732:  
2025-07-08 06:44:42.694198: Epoch 457 
2025-07-08 06:44:42.694338: Current learning rate: 0.00577 
2025-07-08 06:45:31.071465: train_loss -0.9109 
2025-07-08 06:45:31.072440: val_loss -0.9202 
2025-07-08 06:45:31.072569: Pseudo dice [np.float32(0.9375)] 
2025-07-08 06:45:31.072715: Epoch time: 48.38 s 
2025-07-08 06:45:32.385503:  
2025-07-08 06:45:32.385928: Epoch 458 
2025-07-08 06:45:32.386245: Current learning rate: 0.00576 
2025-07-08 06:46:22.653515: train_loss -0.9067 
2025-07-08 06:46:22.653938: val_loss -0.9109 
2025-07-08 06:46:22.654021: Pseudo dice [np.float32(0.9283)] 
2025-07-08 06:46:22.654136: Epoch time: 50.27 s 
2025-07-08 06:46:23.853577:  
2025-07-08 06:46:23.853797: Epoch 459 
2025-07-08 06:46:23.853968: Current learning rate: 0.00575 
2025-07-08 06:47:12.902288: train_loss -0.9062 
2025-07-08 06:47:12.903137: val_loss -0.9139 
2025-07-08 06:47:12.903421: Pseudo dice [np.float32(0.9327)] 
2025-07-08 06:47:12.903594: Epoch time: 49.05 s 
2025-07-08 06:47:14.093226:  
2025-07-08 06:47:14.093489: Epoch 460 
2025-07-08 06:47:14.093857: Current learning rate: 0.00574 
2025-07-08 06:48:02.609848: train_loss -0.9077 
2025-07-08 06:48:02.610587: val_loss -0.92 
2025-07-08 06:48:02.610681: Pseudo dice [np.float32(0.9367)] 
2025-07-08 06:48:02.610805: Epoch time: 48.52 s 
2025-07-08 06:48:03.853033:  
2025-07-08 06:48:03.853426: Epoch 461 
2025-07-08 06:48:03.853683: Current learning rate: 0.00573 
2025-07-08 06:48:52.782647: train_loss -0.9101 
2025-07-08 06:48:52.783099: val_loss -0.9194 
2025-07-08 06:48:52.783184: Pseudo dice [np.float32(0.9391)] 
2025-07-08 06:48:52.783292: Epoch time: 48.93 s 
2025-07-08 06:48:53.966461:  
2025-07-08 06:48:53.967015: Epoch 462 
2025-07-08 06:48:53.967179: Current learning rate: 0.00572 
2025-07-08 06:49:43.066293: train_loss -0.9119 
2025-07-08 06:49:43.066827: val_loss -0.9148 
2025-07-08 06:49:43.066916: Pseudo dice [np.float32(0.9333)] 
2025-07-08 06:49:43.067174: Epoch time: 49.1 s 
2025-07-08 06:49:44.217061:  
2025-07-08 06:49:44.217698: Epoch 463 
2025-07-08 06:49:44.217807: Current learning rate: 0.00571 
2025-07-08 06:50:32.501169: train_loss -0.9134 
2025-07-08 06:50:32.501724: val_loss -0.9147 
2025-07-08 06:50:32.501810: Pseudo dice [np.float32(0.9295)] 
2025-07-08 06:50:32.501914: Epoch time: 48.29 s 
2025-07-08 06:50:33.733683:  
2025-07-08 06:50:33.734169: Epoch 464 
2025-07-08 06:50:33.734354: Current learning rate: 0.0057 
2025-07-08 06:51:23.194789: train_loss -0.9114 
2025-07-08 06:51:23.195346: val_loss -0.9149 
2025-07-08 06:51:23.195448: Pseudo dice [np.float32(0.9355)] 
2025-07-08 06:51:23.195581: Epoch time: 49.46 s 
2025-07-08 06:51:24.397121:  
2025-07-08 06:51:24.397687: Epoch 465 
2025-07-08 06:51:24.398004: Current learning rate: 0.0057 
2025-07-08 06:52:14.206148: train_loss -0.9131 
2025-07-08 06:52:14.208620: val_loss -0.9095 
2025-07-08 06:52:14.208971: Pseudo dice [np.float32(0.9362)] 
2025-07-08 06:52:14.209378: Epoch time: 49.81 s 
2025-07-08 06:52:15.364398:  
2025-07-08 06:52:15.364725: Epoch 466 
2025-07-08 06:52:15.364949: Current learning rate: 0.00569 
2025-07-08 06:53:05.696892: train_loss -0.9175 
2025-07-08 06:53:05.697485: val_loss -0.9205 
2025-07-08 06:53:05.697606: Pseudo dice [np.float32(0.9372)] 
2025-07-08 06:53:05.697738: Epoch time: 50.33 s 
2025-07-08 06:53:06.900447:  
2025-07-08 06:53:06.900847: Epoch 467 
2025-07-08 06:53:06.901007: Current learning rate: 0.00568 
2025-07-08 06:53:56.121074: train_loss -0.9223 
2025-07-08 06:53:56.121805: val_loss -0.9227 
2025-07-08 06:53:56.121930: Pseudo dice [np.float32(0.9368)] 
2025-07-08 06:53:56.122065: Epoch time: 49.22 s 
2025-07-08 06:53:57.383698:  
2025-07-08 06:53:57.383846: Epoch 468 
2025-07-08 06:53:57.383965: Current learning rate: 0.00567 
2025-07-08 06:54:48.697373: train_loss -0.9145 
2025-07-08 06:54:48.698054: val_loss -0.9265 
2025-07-08 06:54:48.698141: Pseudo dice [np.float32(0.9416)] 
2025-07-08 06:54:48.698271: Epoch time: 51.32 s 
2025-07-08 06:54:49.891179:  
2025-07-08 06:54:49.891747: Epoch 469 
2025-07-08 06:54:49.891887: Current learning rate: 0.00566 
2025-07-08 06:55:39.217404: train_loss -0.913 
2025-07-08 06:55:39.218104: val_loss -0.919 
2025-07-08 06:55:39.218271: Pseudo dice [np.float32(0.9395)] 
2025-07-08 06:55:39.218383: Epoch time: 49.33 s 
2025-07-08 06:55:40.423319:  
2025-07-08 06:55:40.423808: Epoch 470 
2025-07-08 06:55:40.424034: Current learning rate: 0.00565 
2025-07-08 06:56:29.468755: train_loss -0.9174 
2025-07-08 06:56:29.469901: val_loss -0.9149 
2025-07-08 06:56:29.470007: Pseudo dice [np.float32(0.9369)] 
2025-07-08 06:56:29.470198: Epoch time: 49.05 s 
2025-07-08 06:56:30.638385:  
2025-07-08 06:56:30.638603: Epoch 471 
2025-07-08 06:56:30.638772: Current learning rate: 0.00564 
2025-07-08 06:57:20.331910: train_loss -0.9147 
2025-07-08 06:57:20.332389: val_loss -0.9291 
2025-07-08 06:57:20.332480: Pseudo dice [np.float32(0.9428)] 
2025-07-08 06:57:20.332619: Epoch time: 49.7 s 
2025-07-08 06:57:20.332707: Yayy! New best EMA pseudo Dice: 0.935699999332428 
2025-07-08 06:57:23.458984:  
2025-07-08 06:57:23.459390: Epoch 472 
2025-07-08 06:57:23.459553: Current learning rate: 0.00563 
2025-07-08 06:58:11.895397: train_loss -0.9165 
2025-07-08 06:58:11.896181: val_loss -0.9203 
2025-07-08 06:58:11.896273: Pseudo dice [np.float32(0.9351)] 
2025-07-08 06:58:11.896389: Epoch time: 48.44 s 
2025-07-08 06:58:13.070798:  
2025-07-08 06:58:13.071194: Epoch 473 
2025-07-08 06:58:13.071478: Current learning rate: 0.00562 
2025-07-08 06:59:04.131548: train_loss -0.9173 
2025-07-08 06:59:04.131948: val_loss -0.91 
2025-07-08 06:59:04.132036: Pseudo dice [np.float32(0.9325)] 
2025-07-08 06:59:04.132145: Epoch time: 51.06 s 
2025-07-08 06:59:05.239793:  
2025-07-08 06:59:05.240275: Epoch 474 
2025-07-08 06:59:05.240411: Current learning rate: 0.00561 
2025-07-08 06:59:55.896215: train_loss -0.9169 
2025-07-08 06:59:55.896790: val_loss -0.918 
2025-07-08 06:59:55.896873: Pseudo dice [np.float32(0.9336)] 
2025-07-08 06:59:55.896977: Epoch time: 50.66 s 
2025-07-08 06:59:57.041659:  
2025-07-08 06:59:57.042694: Epoch 475 
2025-07-08 06:59:57.042876: Current learning rate: 0.0056 
2025-07-08 07:00:46.203752: train_loss -0.9128 
2025-07-08 07:00:46.204234: val_loss -0.9154 
2025-07-08 07:00:46.204314: Pseudo dice [np.float32(0.9331)] 
2025-07-08 07:00:46.204440: Epoch time: 49.16 s 
2025-07-08 07:00:47.446477:  
2025-07-08 07:00:47.446870: Epoch 476 
2025-07-08 07:00:47.447017: Current learning rate: 0.00559 
2025-07-08 07:01:38.292823: train_loss -0.9076 
2025-07-08 07:01:38.294605: val_loss -0.9133 
2025-07-08 07:01:38.294876: Pseudo dice [np.float32(0.9307)] 
2025-07-08 07:01:38.295046: Epoch time: 50.85 s 
2025-07-08 07:01:39.528923:  
2025-07-08 07:01:39.529127: Epoch 477 
2025-07-08 07:01:39.529332: Current learning rate: 0.00558 
2025-07-08 07:02:29.891850: train_loss -0.9147 
2025-07-08 07:02:29.892370: val_loss -0.9143 
2025-07-08 07:02:29.892503: Pseudo dice [np.float32(0.9331)] 
2025-07-08 07:02:29.892683: Epoch time: 50.36 s 
2025-07-08 07:02:31.076548:  
2025-07-08 07:02:31.076916: Epoch 478 
2025-07-08 07:02:31.077073: Current learning rate: 0.00557 
2025-07-08 07:03:21.944803: train_loss -0.9125 
2025-07-08 07:03:21.945155: val_loss -0.9144 
2025-07-08 07:03:21.945237: Pseudo dice [np.float32(0.9312)] 
2025-07-08 07:03:21.945337: Epoch time: 50.87 s 
2025-07-08 07:03:23.111055:  
2025-07-08 07:03:23.111384: Epoch 479 
2025-07-08 07:03:23.111508: Current learning rate: 0.00556 
2025-07-08 07:04:13.906066: train_loss -0.9158 
2025-07-08 07:04:13.906888: val_loss -0.9194 
2025-07-08 07:04:13.907006: Pseudo dice [np.float32(0.9353)] 
2025-07-08 07:04:13.907126: Epoch time: 50.8 s 
2025-07-08 07:04:15.174732:  
2025-07-08 07:04:15.175053: Epoch 480 
2025-07-08 07:04:15.175154: Current learning rate: 0.00555 
2025-07-08 07:05:03.443929: train_loss -0.9199 
2025-07-08 07:05:03.445089: val_loss -0.9209 
2025-07-08 07:05:03.445256: Pseudo dice [np.float32(0.9294)] 
2025-07-08 07:05:03.445524: Epoch time: 48.27 s 
2025-07-08 07:05:04.681692:  
2025-07-08 07:05:04.681873: Epoch 481 
2025-07-08 07:05:04.682025: Current learning rate: 0.00554 
2025-07-08 07:05:54.131804: train_loss -0.9115 
2025-07-08 07:05:54.132166: val_loss -0.9166 
2025-07-08 07:05:54.132242: Pseudo dice [np.float32(0.9318)] 
2025-07-08 07:05:54.132328: Epoch time: 49.45 s 
2025-07-08 07:05:55.298518:  
2025-07-08 07:05:55.298730: Epoch 482 
2025-07-08 07:05:55.298832: Current learning rate: 0.00553 
2025-07-08 07:06:47.270224: train_loss -0.9139 
2025-07-08 07:06:47.270608: val_loss -0.9139 
2025-07-08 07:06:47.270697: Pseudo dice [np.float32(0.9321)] 
2025-07-08 07:06:47.270797: Epoch time: 51.97 s 
2025-07-08 07:06:48.485164:  
2025-07-08 07:06:48.485432: Epoch 483 
2025-07-08 07:06:48.485549: Current learning rate: 0.00552 
2025-07-08 07:07:38.330460: train_loss -0.9078 
2025-07-08 07:07:38.330951: val_loss -0.9143 
2025-07-08 07:07:38.331038: Pseudo dice [np.float32(0.9346)] 
2025-07-08 07:07:38.331155: Epoch time: 49.85 s 
2025-07-08 07:07:39.617057:  
2025-07-08 07:07:39.617581: Epoch 484 
2025-07-08 07:07:39.617722: Current learning rate: 0.00551 
2025-07-08 07:08:29.880995: train_loss -0.9133 
2025-07-08 07:08:29.881974: val_loss -0.916 
2025-07-08 07:08:29.882070: Pseudo dice [np.float32(0.9338)] 
2025-07-08 07:08:29.882284: Epoch time: 50.27 s 
2025-07-08 07:08:31.159228:  
2025-07-08 07:08:31.159549: Epoch 485 
2025-07-08 07:08:31.159707: Current learning rate: 0.0055 
2025-07-08 07:09:21.273338: train_loss -0.8997 
2025-07-08 07:09:21.274670: val_loss -0.8715 
2025-07-08 07:09:21.274859: Pseudo dice [np.float32(0.8823)] 
2025-07-08 07:09:21.275057: Epoch time: 50.12 s 
2025-07-08 07:09:22.553987:  
2025-07-08 07:09:22.554201: Epoch 486 
2025-07-08 07:09:22.554324: Current learning rate: 0.00549 
2025-07-08 07:10:11.689636: train_loss -0.8766 
2025-07-08 07:10:11.690010: val_loss -0.885 
2025-07-08 07:10:11.690090: Pseudo dice [np.float32(0.9131)] 
2025-07-08 07:10:11.690189: Epoch time: 49.14 s 
2025-07-08 07:10:12.860446:  
2025-07-08 07:10:12.860744: Epoch 487 
2025-07-08 07:10:12.860920: Current learning rate: 0.00548 
2025-07-08 07:11:02.495340: train_loss -0.8702 
2025-07-08 07:11:02.495914: val_loss -0.8966 
2025-07-08 07:11:02.499436: Pseudo dice [np.float32(0.9176)] 
2025-07-08 07:11:02.499705: Epoch time: 49.64 s 
2025-07-08 07:11:04.659875:  
2025-07-08 07:11:04.660306: Epoch 488 
2025-07-08 07:11:04.660686: Current learning rate: 0.00547 
2025-07-08 07:11:54.453866: train_loss -0.8692 
2025-07-08 07:11:54.454639: val_loss -0.8849 
2025-07-08 07:11:54.454757: Pseudo dice [np.float32(0.9008)] 
2025-07-08 07:11:54.454896: Epoch time: 49.8 s 
2025-07-08 07:11:55.759790:  
2025-07-08 07:11:55.760108: Epoch 489 
2025-07-08 07:11:55.760268: Current learning rate: 0.00546 
2025-07-08 07:12:44.563134: train_loss -0.8927 
2025-07-08 07:12:44.563682: val_loss -0.8846 
2025-07-08 07:12:44.563776: Pseudo dice [np.float32(0.9115)] 
2025-07-08 07:12:44.563896: Epoch time: 48.8 s 
2025-07-08 07:12:45.777137:  
2025-07-08 07:12:45.777456: Epoch 490 
2025-07-08 07:12:45.777586: Current learning rate: 0.00546 
2025-07-08 07:13:34.415658: train_loss -0.8766 
2025-07-08 07:13:34.416506: val_loss -0.8971 
2025-07-08 07:13:34.416633: Pseudo dice [np.float32(0.9263)] 
2025-07-08 07:13:34.416763: Epoch time: 48.64 s 
2025-07-08 07:13:35.590387:  
2025-07-08 07:13:35.590642: Epoch 491 
2025-07-08 07:13:35.590939: Current learning rate: 0.00545 
2025-07-08 07:14:25.314732: train_loss -0.8901 
2025-07-08 07:14:25.315038: val_loss -0.9026 
2025-07-08 07:14:25.315120: Pseudo dice [np.float32(0.9272)] 
2025-07-08 07:14:25.315215: Epoch time: 49.73 s 
2025-07-08 07:14:26.464456:  
2025-07-08 07:14:26.464777: Epoch 492 
2025-07-08 07:14:26.464878: Current learning rate: 0.00544 
2025-07-08 07:15:15.396675: train_loss -0.9048 
2025-07-08 07:15:15.397155: val_loss -0.9141 
2025-07-08 07:15:15.397249: Pseudo dice [np.float32(0.9313)] 
2025-07-08 07:15:15.397359: Epoch time: 48.93 s 
2025-07-08 07:15:16.599499:  
2025-07-08 07:15:16.599913: Epoch 493 
2025-07-08 07:15:16.600104: Current learning rate: 0.00543 
2025-07-08 07:16:04.920479: train_loss -0.9058 
2025-07-08 07:16:04.921277: val_loss -0.9176 
2025-07-08 07:16:04.921364: Pseudo dice [np.float32(0.933)] 
2025-07-08 07:16:04.921476: Epoch time: 48.32 s 
2025-07-08 07:16:06.123520:  
2025-07-08 07:16:06.124045: Epoch 494 
2025-07-08 07:16:06.124208: Current learning rate: 0.00542 
2025-07-08 07:16:54.093673: train_loss -0.9129 
2025-07-08 07:16:54.094211: val_loss -0.9134 
2025-07-08 07:16:54.094298: Pseudo dice [np.float32(0.9313)] 
2025-07-08 07:16:54.094410: Epoch time: 47.97 s 
2025-07-08 07:16:55.218475:  
2025-07-08 07:16:55.218790: Epoch 495 
2025-07-08 07:16:55.218926: Current learning rate: 0.00541 
2025-07-08 07:17:43.596225: train_loss -0.9072 
2025-07-08 07:17:43.596974: val_loss -0.9127 
2025-07-08 07:17:43.597075: Pseudo dice [np.float32(0.9297)] 
2025-07-08 07:17:43.597193: Epoch time: 48.38 s 
2025-07-08 07:17:44.825791:  
2025-07-08 07:17:44.826174: Epoch 496 
2025-07-08 07:17:44.826332: Current learning rate: 0.0054 
2025-07-08 07:18:33.234585: train_loss -0.9178 
2025-07-08 07:18:33.235256: val_loss -0.9236 
2025-07-08 07:18:33.235355: Pseudo dice [np.float32(0.9399)] 
2025-07-08 07:18:33.235492: Epoch time: 48.41 s 
2025-07-08 07:18:34.541826:  
2025-07-08 07:18:34.542260: Epoch 497 
2025-07-08 07:18:34.542368: Current learning rate: 0.00539 
2025-07-08 07:19:24.645840: train_loss -0.9115 
2025-07-08 07:19:24.646256: val_loss -0.923 
2025-07-08 07:19:24.646335: Pseudo dice [np.float32(0.9367)] 
2025-07-08 07:19:24.646439: Epoch time: 50.11 s 
2025-07-08 07:19:25.875859:  
2025-07-08 07:19:25.876350: Epoch 498 
2025-07-08 07:19:25.876489: Current learning rate: 0.00538 
2025-07-08 07:20:15.129379: train_loss -0.9162 
2025-07-08 07:20:15.130224: val_loss -0.9184 
2025-07-08 07:20:15.130397: Pseudo dice [np.float32(0.9357)] 
2025-07-08 07:20:15.130605: Epoch time: 49.25 s 
2025-07-08 07:20:16.428709:  
2025-07-08 07:20:16.429162: Epoch 499 
2025-07-08 07:20:16.429346: Current learning rate: 0.00537 
2025-07-08 07:21:05.997476: train_loss -0.9141 
2025-07-08 07:21:05.997910: val_loss -0.9217 
2025-07-08 07:21:05.997993: Pseudo dice [np.float32(0.9329)] 
2025-07-08 07:21:05.998089: Epoch time: 49.57 s 
2025-07-08 07:21:08.047444:  
2025-07-08 07:21:08.047747: Epoch 500 
2025-07-08 07:21:08.047985: Current learning rate: 0.00536 
2025-07-08 07:21:57.359233: train_loss -0.9164 
2025-07-08 07:21:57.360223: val_loss -0.9212 
2025-07-08 07:21:57.360355: Pseudo dice [np.float32(0.937)] 
2025-07-08 07:21:57.360555: Epoch time: 49.31 s 
2025-07-08 07:21:58.577250:  
2025-07-08 07:21:58.577424: Epoch 501 
2025-07-08 07:21:58.577552: Current learning rate: 0.00535 
2025-07-08 07:22:49.502196: train_loss -0.9055 
2025-07-08 07:22:49.502718: val_loss -0.9114 
2025-07-08 07:22:49.502800: Pseudo dice [np.float32(0.9297)] 
2025-07-08 07:22:49.502911: Epoch time: 50.93 s 
2025-07-08 07:22:50.695989:  
2025-07-08 07:22:50.696360: Epoch 502 
2025-07-08 07:22:50.696505: Current learning rate: 0.00534 
2025-07-08 07:23:39.706748: train_loss -0.9087 
2025-07-08 07:23:39.707300: val_loss -0.9179 
2025-07-08 07:23:39.707396: Pseudo dice [np.float32(0.9366)] 
2025-07-08 07:23:39.707511: Epoch time: 49.01 s 
2025-07-08 07:23:41.950560:  
2025-07-08 07:23:41.950963: Epoch 503 
2025-07-08 07:23:41.951098: Current learning rate: 0.00533 
2025-07-08 07:24:32.181962: train_loss -0.9043 
2025-07-08 07:24:32.182353: val_loss -0.911 
2025-07-08 07:24:32.182439: Pseudo dice [np.float32(0.9274)] 
2025-07-08 07:24:32.182548: Epoch time: 50.23 s 
2025-07-08 07:24:33.401140:  
2025-07-08 07:24:33.401557: Epoch 504 
2025-07-08 07:24:33.401731: Current learning rate: 0.00532 
2025-07-08 07:25:22.524360: train_loss -0.9092 
2025-07-08 07:25:22.524920: val_loss -0.912 
2025-07-08 07:25:22.525021: Pseudo dice [np.float32(0.9301)] 
2025-07-08 07:25:22.525128: Epoch time: 49.12 s 
2025-07-08 07:25:23.728442:  
2025-07-08 07:25:23.729031: Epoch 505 
2025-07-08 07:25:23.729167: Current learning rate: 0.00531 
2025-07-08 07:26:12.977721: train_loss -0.9122 
2025-07-08 07:26:12.978045: val_loss -0.9188 
2025-07-08 07:26:12.978126: Pseudo dice [np.float32(0.9329)] 
2025-07-08 07:26:12.978232: Epoch time: 49.25 s 
2025-07-08 07:26:14.203722:  
2025-07-08 07:26:14.204139: Epoch 506 
2025-07-08 07:26:14.204275: Current learning rate: 0.0053 
2025-07-08 07:27:03.014645: train_loss -0.9075 
2025-07-08 07:27:03.015046: val_loss -0.9132 
2025-07-08 07:27:03.015145: Pseudo dice [np.float32(0.9305)] 
2025-07-08 07:27:03.015254: Epoch time: 48.81 s 
2025-07-08 07:27:04.256010:  
2025-07-08 07:27:04.256467: Epoch 507 
2025-07-08 07:27:04.256619: Current learning rate: 0.00529 
2025-07-08 07:27:54.796083: train_loss -0.9123 
2025-07-08 07:27:54.796463: val_loss -0.9144 
2025-07-08 07:27:54.796560: Pseudo dice [np.float32(0.9342)] 
2025-07-08 07:27:54.796666: Epoch time: 50.54 s 
2025-07-08 07:27:55.983828:  
2025-07-08 07:27:55.984129: Epoch 508 
2025-07-08 07:27:55.984278: Current learning rate: 0.00528 
2025-07-08 07:28:45.970871: train_loss -0.9164 
2025-07-08 07:28:45.971521: val_loss -0.914 
2025-07-08 07:28:45.971652: Pseudo dice [np.float32(0.9407)] 
2025-07-08 07:28:45.971786: Epoch time: 49.99 s 
2025-07-08 07:28:47.204640:  
2025-07-08 07:28:47.205033: Epoch 509 
2025-07-08 07:28:47.205187: Current learning rate: 0.00527 
2025-07-08 07:29:38.122244: train_loss -0.9172 
2025-07-08 07:29:38.123402: val_loss -0.9224 
2025-07-08 07:29:38.123799: Pseudo dice [np.float32(0.9352)] 
2025-07-08 07:29:38.124096: Epoch time: 50.92 s 
2025-07-08 07:29:39.275563:  
2025-07-08 07:29:39.275867: Epoch 510 
2025-07-08 07:29:39.276057: Current learning rate: 0.00526 
2025-07-08 07:30:29.931211: train_loss -0.9118 
2025-07-08 07:30:29.931750: val_loss -0.9195 
2025-07-08 07:30:29.931846: Pseudo dice [np.float32(0.9418)] 
2025-07-08 07:30:29.931969: Epoch time: 50.66 s 
2025-07-08 07:30:31.127015:  
2025-07-08 07:30:31.127578: Epoch 511 
2025-07-08 07:30:31.127860: Current learning rate: 0.00525 
2025-07-08 07:31:23.180984: train_loss -0.9162 
2025-07-08 07:31:23.181515: val_loss -0.9225 
2025-07-08 07:31:23.181727: Pseudo dice [np.float32(0.9365)] 
2025-07-08 07:31:23.181919: Epoch time: 52.06 s 
2025-07-08 07:31:24.352844:  
2025-07-08 07:31:24.353105: Epoch 512 
2025-07-08 07:31:24.353270: Current learning rate: 0.00524 
2025-07-08 07:32:14.373355: train_loss -0.9187 
2025-07-08 07:32:14.374322: val_loss -0.9233 
2025-07-08 07:32:14.374431: Pseudo dice [np.float32(0.9382)] 
2025-07-08 07:32:14.374572: Epoch time: 50.02 s 
2025-07-08 07:32:15.543321:  
2025-07-08 07:32:15.543598: Epoch 513 
2025-07-08 07:32:15.543717: Current learning rate: 0.00523 
2025-07-08 07:33:05.412749: train_loss -0.9175 
2025-07-08 07:33:05.413652: val_loss -0.9206 
2025-07-08 07:33:05.413865: Pseudo dice [np.float32(0.9381)] 
2025-07-08 07:33:05.414090: Epoch time: 49.87 s 
2025-07-08 07:33:06.662926:  
2025-07-08 07:33:06.663290: Epoch 514 
2025-07-08 07:33:06.663412: Current learning rate: 0.00522 
2025-07-08 07:33:57.435252: train_loss -0.9172 
2025-07-08 07:33:57.436584: val_loss -0.9192 
2025-07-08 07:33:57.437282: Pseudo dice [np.float32(0.9358)] 
2025-07-08 07:33:57.437745: Epoch time: 50.77 s 
2025-07-08 07:33:58.684448:  
2025-07-08 07:33:58.684753: Epoch 515 
2025-07-08 07:33:58.684985: Current learning rate: 0.00521 
2025-07-08 07:34:50.154499: train_loss -0.9144 
2025-07-08 07:34:50.156665: val_loss -0.9178 
2025-07-08 07:34:50.157091: Pseudo dice [np.float32(0.9361)] 
2025-07-08 07:34:50.157764: Epoch time: 51.47 s 
2025-07-08 07:34:51.564779:  
2025-07-08 07:34:51.565157: Epoch 516 
2025-07-08 07:34:51.565285: Current learning rate: 0.0052 
2025-07-08 07:35:42.974059: train_loss -0.9063 
2025-07-08 07:35:42.974599: val_loss -0.9196 
2025-07-08 07:35:42.974698: Pseudo dice [np.float32(0.9338)] 
2025-07-08 07:35:42.974822: Epoch time: 51.41 s 
2025-07-08 07:35:44.172722:  
2025-07-08 07:35:44.173118: Epoch 517 
2025-07-08 07:35:44.173251: Current learning rate: 0.00519 
2025-07-08 07:36:33.788582: train_loss -0.9133 
2025-07-08 07:36:33.789177: val_loss -0.9221 
2025-07-08 07:36:33.789303: Pseudo dice [np.float32(0.9378)] 
2025-07-08 07:36:33.789454: Epoch time: 49.62 s 
2025-07-08 07:36:34.950254:  
2025-07-08 07:36:34.950570: Epoch 518 
2025-07-08 07:36:34.950713: Current learning rate: 0.00518 
2025-07-08 07:37:25.401211: train_loss -0.9173 
2025-07-08 07:37:25.402375: val_loss -0.9226 
2025-07-08 07:37:25.402616: Pseudo dice [np.float32(0.9392)] 
2025-07-08 07:37:25.402848: Epoch time: 50.45 s 
2025-07-08 07:37:27.816303:  
2025-07-08 07:37:27.816533: Epoch 519 
2025-07-08 07:37:27.816701: Current learning rate: 0.00518 
2025-07-08 07:38:16.642319: train_loss -0.9104 
2025-07-08 07:38:16.642879: val_loss -0.9197 
2025-07-08 07:38:16.642987: Pseudo dice [np.float32(0.9333)] 
2025-07-08 07:38:16.643105: Epoch time: 48.83 s 
2025-07-08 07:38:17.817793:  
2025-07-08 07:38:17.818295: Epoch 520 
2025-07-08 07:38:17.818568: Current learning rate: 0.00517 
2025-07-08 07:39:08.642376: train_loss -0.9142 
2025-07-08 07:39:08.642929: val_loss -0.9211 
2025-07-08 07:39:08.643014: Pseudo dice [np.float32(0.9355)] 
2025-07-08 07:39:08.643128: Epoch time: 50.83 s 
2025-07-08 07:39:09.858925:  
2025-07-08 07:39:09.859324: Epoch 521 
2025-07-08 07:39:09.859555: Current learning rate: 0.00516 
2025-07-08 07:40:00.574508: train_loss -0.9162 
2025-07-08 07:40:00.575027: val_loss -0.9157 
2025-07-08 07:40:00.575117: Pseudo dice [np.float32(0.9347)] 
2025-07-08 07:40:00.575228: Epoch time: 50.72 s 
2025-07-08 07:40:01.753630:  
2025-07-08 07:40:01.753866: Epoch 522 
2025-07-08 07:40:01.754078: Current learning rate: 0.00515 
2025-07-08 07:40:52.807937: train_loss -0.908 
2025-07-08 07:40:52.808609: val_loss -0.9103 
2025-07-08 07:40:52.808715: Pseudo dice [np.float32(0.9237)] 
2025-07-08 07:40:52.808840: Epoch time: 51.06 s 
2025-07-08 07:40:53.975962:  
2025-07-08 07:40:53.976275: Epoch 523 
2025-07-08 07:40:53.976398: Current learning rate: 0.00514 
2025-07-08 07:41:44.378223: train_loss -0.9087 
2025-07-08 07:41:44.378596: val_loss -0.9105 
2025-07-08 07:41:44.378683: Pseudo dice [np.float32(0.9297)] 
2025-07-08 07:41:44.378785: Epoch time: 50.4 s 
2025-07-08 07:41:45.578567:  
2025-07-08 07:41:45.579019: Epoch 524 
2025-07-08 07:41:45.579188: Current learning rate: 0.00513 
2025-07-08 07:42:35.834270: train_loss -0.9055 
2025-07-08 07:42:35.834610: val_loss -0.9203 
2025-07-08 07:42:35.834690: Pseudo dice [np.float32(0.9323)] 
2025-07-08 07:42:35.834791: Epoch time: 50.26 s 
2025-07-08 07:42:37.052077:  
2025-07-08 07:42:37.052626: Epoch 525 
2025-07-08 07:42:37.052795: Current learning rate: 0.00512 
2025-07-08 07:43:26.200027: train_loss -0.9158 
2025-07-08 07:43:26.200573: val_loss -0.928 
2025-07-08 07:43:26.200666: Pseudo dice [np.float32(0.9419)] 
2025-07-08 07:43:26.200786: Epoch time: 49.15 s 
2025-07-08 07:43:27.574179:  
2025-07-08 07:43:27.574445: Epoch 526 
2025-07-08 07:43:27.574586: Current learning rate: 0.00511 
2025-07-08 07:44:18.631637: train_loss -0.9169 
2025-07-08 07:44:18.632561: val_loss -0.9143 
2025-07-08 07:44:18.636860: Pseudo dice [np.float32(0.9336)] 
2025-07-08 07:44:18.637345: Epoch time: 51.06 s 
2025-07-08 07:44:19.895162:  
2025-07-08 07:44:19.895653: Epoch 527 
2025-07-08 07:44:19.895861: Current learning rate: 0.0051 
2025-07-08 07:45:09.997181: train_loss -0.9146 
2025-07-08 07:45:09.998494: val_loss -0.9292 
2025-07-08 07:45:09.998717: Pseudo dice [np.float32(0.9416)] 
2025-07-08 07:45:09.998917: Epoch time: 50.1 s 
2025-07-08 07:45:11.296045:  
2025-07-08 07:45:11.296458: Epoch 528 
2025-07-08 07:45:11.296775: Current learning rate: 0.00509 
2025-07-08 07:46:02.404709: train_loss -0.9178 
2025-07-08 07:46:02.405338: val_loss -0.9268 
2025-07-08 07:46:02.405455: Pseudo dice [np.float32(0.939)] 
2025-07-08 07:46:02.405648: Epoch time: 51.11 s 
2025-07-08 07:46:03.619984:  
2025-07-08 07:46:03.620320: Epoch 529 
2025-07-08 07:46:03.620481: Current learning rate: 0.00508 
2025-07-08 07:46:54.396865: train_loss -0.9223 
2025-07-08 07:46:54.397883: val_loss -0.9078 
2025-07-08 07:46:54.398247: Pseudo dice [np.float32(0.9286)] 
2025-07-08 07:46:54.398412: Epoch time: 50.78 s 
2025-07-08 07:46:55.661699:  
2025-07-08 07:46:55.662053: Epoch 530 
2025-07-08 07:46:55.662184: Current learning rate: 0.00507 
2025-07-08 07:47:44.786133: train_loss -0.9178 
2025-07-08 07:47:44.787328: val_loss -0.9208 
2025-07-08 07:47:44.787534: Pseudo dice [np.float32(0.9344)] 
2025-07-08 07:47:44.787789: Epoch time: 49.13 s 
2025-07-08 07:47:46.010668:  
2025-07-08 07:47:46.010896: Epoch 531 
2025-07-08 07:47:46.011202: Current learning rate: 0.00506 
2025-07-08 07:48:36.323087: train_loss -0.9141 
2025-07-08 07:48:36.323757: val_loss -0.916 
2025-07-08 07:48:36.323865: Pseudo dice [np.float32(0.9346)] 
2025-07-08 07:48:36.323991: Epoch time: 50.31 s 
2025-07-08 07:48:37.615910:  
2025-07-08 07:48:37.616087: Epoch 532 
2025-07-08 07:48:37.616340: Current learning rate: 0.00505 
2025-07-08 07:49:29.116846: train_loss -0.9142 
2025-07-08 07:49:29.117288: val_loss -0.9147 
2025-07-08 07:49:29.117366: Pseudo dice [np.float32(0.9331)] 
2025-07-08 07:49:29.117485: Epoch time: 51.5 s 
2025-07-08 07:49:30.295005:  
2025-07-08 07:49:30.295448: Epoch 533 
2025-07-08 07:49:30.295597: Current learning rate: 0.00504 
2025-07-08 07:50:21.534533: train_loss -0.9126 
2025-07-08 07:50:21.535012: val_loss -0.9192 
2025-07-08 07:50:21.535180: Pseudo dice [np.float32(0.9369)] 
2025-07-08 07:50:21.535300: Epoch time: 51.24 s 
2025-07-08 07:50:23.543772:  
2025-07-08 07:50:23.544031: Epoch 534 
2025-07-08 07:50:23.544307: Current learning rate: 0.00503 
2025-07-08 07:51:14.634071: train_loss -0.9214 
2025-07-08 07:51:14.634606: val_loss -0.9173 
2025-07-08 07:51:14.634770: Pseudo dice [np.float32(0.9338)] 
2025-07-08 07:51:14.634943: Epoch time: 51.09 s 
2025-07-08 07:51:15.909417:  
2025-07-08 07:51:15.909953: Epoch 535 
2025-07-08 07:51:15.910142: Current learning rate: 0.00502 
2025-07-08 07:52:05.400515: train_loss -0.9191 
2025-07-08 07:52:05.401072: val_loss -0.9202 
2025-07-08 07:52:05.401154: Pseudo dice [np.float32(0.9383)] 
2025-07-08 07:52:05.401273: Epoch time: 49.49 s 
2025-07-08 07:52:06.705275:  
2025-07-08 07:52:06.705652: Epoch 536 
2025-07-08 07:52:06.705836: Current learning rate: 0.00501 
2025-07-08 07:52:56.546275: train_loss -0.9231 
2025-07-08 07:52:56.547174: val_loss -0.9224 
2025-07-08 07:52:56.547295: Pseudo dice [np.float32(0.9363)] 
2025-07-08 07:52:56.547493: Epoch time: 49.84 s 
2025-07-08 07:52:57.756572:  
2025-07-08 07:52:57.756805: Epoch 537 
2025-07-08 07:52:57.756927: Current learning rate: 0.005 
2025-07-08 07:53:47.939203: train_loss -0.9188 
2025-07-08 07:53:47.941337: val_loss -0.9211 
2025-07-08 07:53:47.941812: Pseudo dice [np.float32(0.9352)] 
2025-07-08 07:53:47.942361: Epoch time: 50.18 s 
2025-07-08 07:53:49.140940:  
2025-07-08 07:53:49.141419: Epoch 538 
2025-07-08 07:53:49.141561: Current learning rate: 0.00499 
2025-07-08 07:54:37.634772: train_loss -0.9162 
2025-07-08 07:54:37.635849: val_loss -0.9193 
2025-07-08 07:54:37.636030: Pseudo dice [np.float32(0.9395)] 
2025-07-08 07:54:37.636265: Epoch time: 48.49 s 
2025-07-08 07:54:38.954276:  
2025-07-08 07:54:38.955475: Epoch 539 
2025-07-08 07:54:38.955805: Current learning rate: 0.00498 
2025-07-08 07:55:28.205505: train_loss -0.9194 
2025-07-08 07:55:28.206067: val_loss -0.9271 
2025-07-08 07:55:28.206152: Pseudo dice [np.float32(0.9401)] 
2025-07-08 07:55:28.206287: Epoch time: 49.25 s 
2025-07-08 07:55:28.206369: Yayy! New best EMA pseudo Dice: 0.9359999895095825 
2025-07-08 07:55:30.334734:  
2025-07-08 07:55:30.335109: Epoch 540 
2025-07-08 07:55:30.335296: Current learning rate: 0.00497 
2025-07-08 07:56:20.879943: train_loss -0.9196 
2025-07-08 07:56:20.880686: val_loss -0.9331 
2025-07-08 07:56:20.880801: Pseudo dice [np.float32(0.9484)] 
2025-07-08 07:56:20.880955: Epoch time: 50.55 s 
2025-07-08 07:56:20.881047: Yayy! New best EMA pseudo Dice: 0.9373000264167786 
2025-07-08 07:56:22.902915:  
2025-07-08 07:56:22.903113: Epoch 541 
2025-07-08 07:56:22.903230: Current learning rate: 0.00496 
2025-07-08 07:57:11.584021: train_loss -0.921 
2025-07-08 07:57:11.584442: val_loss -0.9282 
2025-07-08 07:57:11.584551: Pseudo dice [np.float32(0.9434)] 
2025-07-08 07:57:11.584701: Epoch time: 48.68 s 
2025-07-08 07:57:11.584779: Yayy! New best EMA pseudo Dice: 0.9379000067710876 
2025-07-08 07:57:13.702064:  
2025-07-08 07:57:13.702611: Epoch 542 
2025-07-08 07:57:13.702739: Current learning rate: 0.00495 
2025-07-08 07:58:02.088057: train_loss -0.922 
2025-07-08 07:58:02.089100: val_loss -0.932 
2025-07-08 07:58:02.089413: Pseudo dice [np.float32(0.9426)] 
2025-07-08 07:58:02.089757: Epoch time: 48.39 s 
2025-07-08 07:58:02.089943: Yayy! New best EMA pseudo Dice: 0.9383999705314636 
2025-07-08 07:58:04.296533:  
2025-07-08 07:58:04.297134: Epoch 543 
2025-07-08 07:58:04.297360: Current learning rate: 0.00494 
2025-07-08 07:58:53.423413: train_loss -0.9181 
2025-07-08 07:58:53.424006: val_loss -0.9358 
2025-07-08 07:58:53.424096: Pseudo dice [np.float32(0.9495)] 
2025-07-08 07:58:53.424241: Epoch time: 49.13 s 
2025-07-08 07:58:53.424323: Yayy! New best EMA pseudo Dice: 0.9394999742507935 
2025-07-08 07:58:55.436297:  
2025-07-08 07:58:55.436527: Epoch 544 
2025-07-08 07:58:55.436695: Current learning rate: 0.00493 
2025-07-08 07:59:44.899442: train_loss -0.9231 
2025-07-08 07:59:44.900207: val_loss -0.9268 
2025-07-08 07:59:44.900320: Pseudo dice [np.float32(0.9404)] 
2025-07-08 07:59:44.900471: Epoch time: 49.46 s 
2025-07-08 07:59:44.900584: Yayy! New best EMA pseudo Dice: 0.9395999908447266 
2025-07-08 07:59:47.005919:  
2025-07-08 07:59:47.006139: Epoch 545 
2025-07-08 07:59:47.006259: Current learning rate: 0.00492 
2025-07-08 08:00:37.854053: train_loss -0.9229 
2025-07-08 08:00:37.855129: val_loss -0.9186 
2025-07-08 08:00:37.855271: Pseudo dice [np.float32(0.9376)] 
2025-07-08 08:00:37.855477: Epoch time: 50.85 s 
2025-07-08 08:00:39.053276:  
2025-07-08 08:00:39.053595: Epoch 546 
2025-07-08 08:00:39.053772: Current learning rate: 0.00491 
2025-07-08 08:01:29.626711: train_loss -0.9146 
2025-07-08 08:01:29.627356: val_loss -0.9268 
2025-07-08 08:01:29.627527: Pseudo dice [np.float32(0.9432)] 
2025-07-08 08:01:29.627675: Epoch time: 50.57 s 
2025-07-08 08:01:29.627766: Yayy! New best EMA pseudo Dice: 0.9397000074386597 
2025-07-08 08:01:31.705363:  
2025-07-08 08:01:31.705665: Epoch 547 
2025-07-08 08:01:31.705918: Current learning rate: 0.0049 
2025-07-08 08:02:21.962154: train_loss -0.9176 
2025-07-08 08:02:21.962868: val_loss -0.9198 
2025-07-08 08:02:21.963024: Pseudo dice [np.float32(0.9387)] 
2025-07-08 08:02:21.963200: Epoch time: 50.26 s 
2025-07-08 08:02:23.154224:  
2025-07-08 08:02:23.154755: Epoch 548 
2025-07-08 08:02:23.154930: Current learning rate: 0.00489 
2025-07-08 08:03:14.507656: train_loss -0.9151 
2025-07-08 08:03:14.508342: val_loss -0.9198 
2025-07-08 08:03:14.508468: Pseudo dice [np.float32(0.9369)] 
2025-07-08 08:03:14.508647: Epoch time: 51.35 s 
2025-07-08 08:03:15.645723:  
2025-07-08 08:03:15.645916: Epoch 549 
2025-07-08 08:03:15.646053: Current learning rate: 0.00488 
2025-07-08 08:04:03.667665: train_loss -0.9164 
2025-07-08 08:04:03.668456: val_loss -0.9277 
2025-07-08 08:04:03.668563: Pseudo dice [np.float32(0.9416)] 
2025-07-08 08:04:03.668680: Epoch time: 48.02 s 
2025-07-08 08:04:06.846889:  
2025-07-08 08:04:06.847983: Epoch 550 
2025-07-08 08:04:06.848200: Current learning rate: 0.00487 
2025-07-08 08:04:58.385704: train_loss -0.9169 
2025-07-08 08:04:58.386239: val_loss -0.9214 
2025-07-08 08:04:58.386352: Pseudo dice [np.float32(0.9397)] 
2025-07-08 08:04:58.386496: Epoch time: 51.54 s 
2025-07-08 08:04:59.556254:  
2025-07-08 08:04:59.556810: Epoch 551 
2025-07-08 08:04:59.556969: Current learning rate: 0.00486 
2025-07-08 08:05:49.475394: train_loss -0.919 
2025-07-08 08:05:49.475826: val_loss -0.9236 
2025-07-08 08:05:49.475909: Pseudo dice [np.float32(0.9362)] 
2025-07-08 08:05:49.476032: Epoch time: 49.92 s 
2025-07-08 08:05:50.560848:  
2025-07-08 08:05:50.561160: Epoch 552 
2025-07-08 08:05:50.561333: Current learning rate: 0.00485 
2025-07-08 08:06:40.260356: train_loss -0.9193 
2025-07-08 08:06:40.260736: val_loss -0.9235 
2025-07-08 08:06:40.260816: Pseudo dice [np.float32(0.9421)] 
2025-07-08 08:06:40.260939: Epoch time: 49.7 s 
2025-07-08 08:06:41.376481:  
2025-07-08 08:06:41.376926: Epoch 553 
2025-07-08 08:06:41.377073: Current learning rate: 0.00484 
2025-07-08 08:07:29.897790: train_loss -0.9211 
2025-07-08 08:07:29.898219: val_loss -0.9208 
2025-07-08 08:07:29.898301: Pseudo dice [np.float32(0.9347)] 
2025-07-08 08:07:29.898397: Epoch time: 48.52 s 
2025-07-08 08:07:31.025675:  
2025-07-08 08:07:31.025885: Epoch 554 
2025-07-08 08:07:31.026060: Current learning rate: 0.00484 
2025-07-08 08:08:19.856308: train_loss -0.9201 
2025-07-08 08:08:19.856958: val_loss -0.9173 
2025-07-08 08:08:19.857048: Pseudo dice [np.float32(0.9369)] 
2025-07-08 08:08:19.857162: Epoch time: 48.83 s 
2025-07-08 08:08:21.146429:  
2025-07-08 08:08:21.146871: Epoch 555 
2025-07-08 08:08:21.147007: Current learning rate: 0.00483 
2025-07-08 08:09:11.137467: train_loss -0.9236 
2025-07-08 08:09:11.138089: val_loss -0.9245 
2025-07-08 08:09:11.138179: Pseudo dice [np.float32(0.9398)] 
2025-07-08 08:09:11.138293: Epoch time: 49.99 s 
2025-07-08 08:09:12.318959:  
2025-07-08 08:09:12.319555: Epoch 556 
2025-07-08 08:09:12.319839: Current learning rate: 0.00482 
2025-07-08 08:10:04.016055: train_loss -0.9201 
2025-07-08 08:10:04.016553: val_loss -0.9203 
2025-07-08 08:10:04.016646: Pseudo dice [np.float32(0.9339)] 
2025-07-08 08:10:04.016771: Epoch time: 51.7 s 
2025-07-08 08:10:05.156693:  
2025-07-08 08:10:05.157127: Epoch 557 
2025-07-08 08:10:05.157258: Current learning rate: 0.00481 
2025-07-08 08:10:53.943579: train_loss -0.9168 
2025-07-08 08:10:53.944711: val_loss -0.9216 
2025-07-08 08:10:53.944900: Pseudo dice [np.float32(0.9375)] 
2025-07-08 08:10:53.945116: Epoch time: 48.79 s 
2025-07-08 08:10:55.102802:  
2025-07-08 08:10:55.103169: Epoch 558 
2025-07-08 08:10:55.103299: Current learning rate: 0.0048 
2025-07-08 08:11:45.592989: train_loss -0.9165 
2025-07-08 08:11:45.593467: val_loss -0.9272 
2025-07-08 08:11:45.593570: Pseudo dice [np.float32(0.938)] 
2025-07-08 08:11:45.593722: Epoch time: 50.49 s 
2025-07-08 08:11:46.828810:  
2025-07-08 08:11:46.829144: Epoch 559 
2025-07-08 08:11:46.829373: Current learning rate: 0.00479 
2025-07-08 08:12:36.757863: train_loss -0.9248 
2025-07-08 08:12:36.758568: val_loss -0.9287 
2025-07-08 08:12:36.758868: Pseudo dice [np.float32(0.9398)] 
2025-07-08 08:12:36.759162: Epoch time: 49.93 s 
2025-07-08 08:12:37.938643:  
2025-07-08 08:12:37.938979: Epoch 560 
2025-07-08 08:12:37.939133: Current learning rate: 0.00478 
2025-07-08 08:13:26.793386: train_loss -0.9257 
2025-07-08 08:13:26.793850: val_loss -0.925 
2025-07-08 08:13:26.793935: Pseudo dice [np.float32(0.9437)] 
2025-07-08 08:13:26.794050: Epoch time: 48.86 s 
2025-07-08 08:13:27.903531:  
2025-07-08 08:13:27.904132: Epoch 561 
2025-07-08 08:13:27.904299: Current learning rate: 0.00477 
2025-07-08 08:14:17.708085: train_loss -0.9223 
2025-07-08 08:14:17.708650: val_loss -0.9242 
2025-07-08 08:14:17.712279: Pseudo dice [np.float32(0.9386)] 
2025-07-08 08:14:17.712416: Epoch time: 49.81 s 
2025-07-08 08:14:18.892218:  
2025-07-08 08:14:18.892507: Epoch 562 
2025-07-08 08:14:18.892649: Current learning rate: 0.00476 
2025-07-08 08:15:07.650192: train_loss -0.9264 
2025-07-08 08:15:07.650526: val_loss -0.9352 
2025-07-08 08:15:07.650625: Pseudo dice [np.float32(0.9486)] 
2025-07-08 08:15:07.650727: Epoch time: 48.76 s 
2025-07-08 08:15:07.650810: Yayy! New best EMA pseudo Dice: 0.9398999810218811 
2025-07-08 08:15:09.738470:  
2025-07-08 08:15:09.738997: Epoch 563 
2025-07-08 08:15:09.739244: Current learning rate: 0.00475 
2025-07-08 08:15:58.732874: train_loss -0.9197 
2025-07-08 08:15:58.733333: val_loss -0.924 
2025-07-08 08:15:58.733414: Pseudo dice [np.float32(0.9387)] 
2025-07-08 08:15:58.733513: Epoch time: 49.0 s 
2025-07-08 08:15:59.884224:  
2025-07-08 08:15:59.884558: Epoch 564 
2025-07-08 08:15:59.884690: Current learning rate: 0.00474 
2025-07-08 08:16:49.754684: train_loss -0.925 
2025-07-08 08:16:49.755471: val_loss -0.9237 
2025-07-08 08:16:49.755617: Pseudo dice [np.float32(0.9459)] 
2025-07-08 08:16:49.755797: Epoch time: 49.87 s 
2025-07-08 08:16:49.755902: Yayy! New best EMA pseudo Dice: 0.9404000043869019 
2025-07-08 08:16:51.826874:  
2025-07-08 08:16:51.827254: Epoch 565 
2025-07-08 08:16:51.827422: Current learning rate: 0.00473 
2025-07-08 08:17:40.174689: train_loss -0.9227 
2025-07-08 08:17:40.175455: val_loss -0.9266 
2025-07-08 08:17:40.175603: Pseudo dice [np.float32(0.9446)] 
2025-07-08 08:17:40.175744: Epoch time: 48.35 s 
2025-07-08 08:17:40.175841: Yayy! New best EMA pseudo Dice: 0.9408000111579895 
2025-07-08 08:17:42.183793:  
2025-07-08 08:17:42.184247: Epoch 566 
2025-07-08 08:17:42.184368: Current learning rate: 0.00472 
2025-07-08 08:18:33.458026: train_loss -0.9208 
2025-07-08 08:18:33.458599: val_loss -0.9247 
2025-07-08 08:18:33.459944: Pseudo dice [np.float32(0.9379)] 
2025-07-08 08:18:33.460050: Epoch time: 51.28 s 
2025-07-08 08:18:34.569890:  
2025-07-08 08:18:34.570224: Epoch 567 
2025-07-08 08:18:34.570343: Current learning rate: 0.00471 
2025-07-08 08:19:23.268798: train_loss -0.9215 
2025-07-08 08:19:23.269135: val_loss -0.9273 
2025-07-08 08:19:23.269211: Pseudo dice [np.float32(0.9401)] 
2025-07-08 08:19:23.269306: Epoch time: 48.7 s 
2025-07-08 08:19:24.372121:  
2025-07-08 08:19:24.372825: Epoch 568 
2025-07-08 08:19:24.372951: Current learning rate: 0.0047 
2025-07-08 08:20:14.857460: train_loss -0.9218 
2025-07-08 08:20:14.857992: val_loss -0.9258 
2025-07-08 08:20:14.858088: Pseudo dice [np.float32(0.9404)] 
2025-07-08 08:20:14.858199: Epoch time: 50.49 s 
2025-07-08 08:20:16.103422:  
2025-07-08 08:20:16.104068: Epoch 569 
2025-07-08 08:20:16.104205: Current learning rate: 0.00469 
2025-07-08 08:21:05.249447: train_loss -0.9201 
2025-07-08 08:21:05.249836: val_loss -0.9235 
2025-07-08 08:21:05.249927: Pseudo dice [np.float32(0.9399)] 
2025-07-08 08:21:05.250033: Epoch time: 49.15 s 
2025-07-08 08:21:06.390064:  
2025-07-08 08:21:06.390446: Epoch 570 
2025-07-08 08:21:06.390636: Current learning rate: 0.00468 
2025-07-08 08:21:56.411064: train_loss -0.9229 
2025-07-08 08:21:56.411389: val_loss -0.9388 
2025-07-08 08:21:56.411475: Pseudo dice [np.float32(0.9521)] 
2025-07-08 08:21:56.411594: Epoch time: 50.02 s 
2025-07-08 08:21:56.411675: Yayy! New best EMA pseudo Dice: 0.9416000247001648 
2025-07-08 08:21:58.355144:  
2025-07-08 08:21:58.355673: Epoch 571 
2025-07-08 08:21:58.355989: Current learning rate: 0.00467 
2025-07-08 08:22:47.148337: train_loss -0.9242 
2025-07-08 08:22:47.149139: val_loss -0.9325 
2025-07-08 08:22:47.149413: Pseudo dice [np.float32(0.9472)] 
2025-07-08 08:22:47.149878: Epoch time: 48.79 s 
2025-07-08 08:22:47.149980: Yayy! New best EMA pseudo Dice: 0.9420999884605408 
2025-07-08 08:22:49.165958:  
2025-07-08 08:22:49.166444: Epoch 572 
2025-07-08 08:22:49.166580: Current learning rate: 0.00466 
2025-07-08 08:23:39.795190: train_loss -0.9278 
2025-07-08 08:23:39.795660: val_loss -0.9201 
2025-07-08 08:23:39.795747: Pseudo dice [np.float32(0.9357)] 
2025-07-08 08:23:39.795889: Epoch time: 50.63 s 
2025-07-08 08:23:40.957507:  
2025-07-08 08:23:40.957793: Epoch 573 
2025-07-08 08:23:40.957911: Current learning rate: 0.00465 
2025-07-08 08:24:30.506123: train_loss -0.926 
2025-07-08 08:24:30.506548: val_loss -0.9343 
2025-07-08 08:24:30.506630: Pseudo dice [np.float32(0.9468)] 
2025-07-08 08:24:30.506742: Epoch time: 49.55 s 
2025-07-08 08:24:31.653683:  
2025-07-08 08:24:31.654091: Epoch 574 
2025-07-08 08:24:31.654213: Current learning rate: 0.00464 
2025-07-08 08:25:21.905339: train_loss -0.9201 
2025-07-08 08:25:21.905983: val_loss -0.9301 
2025-07-08 08:25:21.906075: Pseudo dice [np.float32(0.9407)] 
2025-07-08 08:25:21.906191: Epoch time: 50.25 s 
2025-07-08 08:25:23.051790:  
2025-07-08 08:25:23.052351: Epoch 575 
2025-07-08 08:25:23.052475: Current learning rate: 0.00463 
2025-07-08 08:26:12.236325: train_loss -0.9261 
2025-07-08 08:26:12.236723: val_loss -0.9305 
2025-07-08 08:26:12.236817: Pseudo dice [np.float32(0.9437)] 
2025-07-08 08:26:12.236933: Epoch time: 49.19 s 
2025-07-08 08:26:13.375466:  
2025-07-08 08:26:13.375787: Epoch 576 
2025-07-08 08:26:13.376072: Current learning rate: 0.00462 
2025-07-08 08:27:02.524797: train_loss -0.921 
2025-07-08 08:27:02.525246: val_loss -0.9268 
2025-07-08 08:27:02.528701: Pseudo dice [np.float32(0.9476)] 
2025-07-08 08:27:02.528924: Epoch time: 49.15 s 
2025-07-08 08:27:02.529042: Yayy! New best EMA pseudo Dice: 0.9426000118255615 
2025-07-08 08:27:04.546844:  
2025-07-08 08:27:04.547249: Epoch 577 
2025-07-08 08:27:04.547406: Current learning rate: 0.00461 
2025-07-08 08:27:52.740887: train_loss -0.9243 
2025-07-08 08:27:52.742702: val_loss -0.932 
2025-07-08 08:27:52.743006: Pseudo dice [np.float32(0.9448)] 
2025-07-08 08:27:52.743180: Epoch time: 48.2 s 
2025-07-08 08:27:52.743292: Yayy! New best EMA pseudo Dice: 0.942799985408783 
2025-07-08 08:27:54.779124:  
2025-07-08 08:27:54.779312: Epoch 578 
2025-07-08 08:27:54.779477: Current learning rate: 0.0046 
2025-07-08 08:28:41.671469: train_loss -0.9288 
2025-07-08 08:28:41.671819: val_loss -0.9233 
2025-07-08 08:28:41.671905: Pseudo dice [np.float32(0.9399)] 
2025-07-08 08:28:41.672010: Epoch time: 46.89 s 
2025-07-08 08:28:42.904752:  
2025-07-08 08:28:42.905060: Epoch 579 
2025-07-08 08:28:42.905372: Current learning rate: 0.00459 
2025-07-08 08:29:32.341486: train_loss -0.9255 
2025-07-08 08:29:32.341988: val_loss -0.9263 
2025-07-08 08:29:32.342103: Pseudo dice [np.float32(0.9445)] 
2025-07-08 08:29:32.342235: Epoch time: 49.44 s 
2025-07-08 08:29:33.613161:  
2025-07-08 08:29:33.613461: Epoch 580 
2025-07-08 08:29:33.613773: Current learning rate: 0.00458 
2025-07-08 08:30:23.983291: train_loss -0.9246 
2025-07-08 08:30:23.984162: val_loss -0.9324 
2025-07-08 08:30:23.984365: Pseudo dice [np.float32(0.9484)] 
2025-07-08 08:30:23.984609: Epoch time: 50.37 s 
2025-07-08 08:30:23.984826: Yayy! New best EMA pseudo Dice: 0.9433000087738037 
2025-07-08 08:30:27.118522:  
2025-07-08 08:30:27.119200: Epoch 581 
2025-07-08 08:30:27.119458: Current learning rate: 0.00457 
2025-07-08 08:31:17.574387: train_loss -0.9241 
2025-07-08 08:31:17.574860: val_loss -0.9222 
2025-07-08 08:31:17.574944: Pseudo dice [np.float32(0.9426)] 
2025-07-08 08:31:17.575053: Epoch time: 50.46 s 
2025-07-08 08:31:18.704890:  
2025-07-08 08:31:18.705259: Epoch 582 
2025-07-08 08:31:18.705446: Current learning rate: 0.00456 
2025-07-08 08:32:07.719451: train_loss -0.9301 
2025-07-08 08:32:07.720591: val_loss -0.9316 
2025-07-08 08:32:07.720842: Pseudo dice [np.float32(0.9448)] 
2025-07-08 08:32:07.721083: Epoch time: 49.02 s 
2025-07-08 08:32:07.721245: Yayy! New best EMA pseudo Dice: 0.9434000253677368 
2025-07-08 08:32:09.743346:  
2025-07-08 08:32:09.743551: Epoch 583 
2025-07-08 08:32:09.744017: Current learning rate: 0.00455 
2025-07-08 08:32:57.922802: train_loss -0.9263 
2025-07-08 08:32:57.923340: val_loss -0.9323 
2025-07-08 08:32:57.923418: Pseudo dice [np.float32(0.9462)] 
2025-07-08 08:32:57.923525: Epoch time: 48.18 s 
2025-07-08 08:32:57.923614: Yayy! New best EMA pseudo Dice: 0.9437000155448914 
2025-07-08 08:32:59.933608:  
2025-07-08 08:32:59.933856: Epoch 584 
2025-07-08 08:32:59.934047: Current learning rate: 0.00454 
2025-07-08 08:33:48.172697: train_loss -0.9265 
2025-07-08 08:33:48.173393: val_loss -0.9236 
2025-07-08 08:33:48.173503: Pseudo dice [np.float32(0.9405)] 
2025-07-08 08:33:48.173665: Epoch time: 48.24 s 
2025-07-08 08:33:49.625186:  
2025-07-08 08:33:49.625375: Epoch 585 
2025-07-08 08:33:49.625504: Current learning rate: 0.00453 
2025-07-08 08:34:38.791649: train_loss -0.925 
2025-07-08 08:34:38.792152: val_loss -0.9326 
2025-07-08 08:34:38.792234: Pseudo dice [np.float32(0.9432)] 
2025-07-08 08:34:38.792335: Epoch time: 49.17 s 
2025-07-08 08:34:40.011365:  
2025-07-08 08:34:40.011918: Epoch 586 
2025-07-08 08:34:40.012059: Current learning rate: 0.00452 
2025-07-08 08:35:30.090434: train_loss -0.9243 
2025-07-08 08:35:30.090882: val_loss -0.9333 
2025-07-08 08:35:30.090968: Pseudo dice [np.float32(0.9489)] 
2025-07-08 08:35:30.091068: Epoch time: 50.08 s 
2025-07-08 08:35:30.091145: Yayy! New best EMA pseudo Dice: 0.9438999891281128 
2025-07-08 08:35:32.181404:  
2025-07-08 08:35:32.181819: Epoch 587 
2025-07-08 08:35:32.181944: Current learning rate: 0.00451 
2025-07-08 08:36:21.388923: train_loss -0.9217 
2025-07-08 08:36:21.389679: val_loss -0.9233 
2025-07-08 08:36:21.389771: Pseudo dice [np.float32(0.9381)] 
2025-07-08 08:36:21.389896: Epoch time: 49.21 s 
2025-07-08 08:36:22.675367:  
2025-07-08 08:36:22.675815: Epoch 588 
2025-07-08 08:36:22.675942: Current learning rate: 0.0045 
2025-07-08 08:37:12.213089: train_loss -0.9204 
2025-07-08 08:37:12.213449: val_loss -0.9245 
2025-07-08 08:37:12.213536: Pseudo dice [np.float32(0.937)] 
2025-07-08 08:37:12.213649: Epoch time: 49.54 s 
2025-07-08 08:37:13.308611:  
2025-07-08 08:37:13.308926: Epoch 589 
2025-07-08 08:37:13.309177: Current learning rate: 0.00449 
2025-07-08 08:38:03.588796: train_loss -0.9259 
2025-07-08 08:38:03.589597: val_loss -0.9316 
2025-07-08 08:38:03.589719: Pseudo dice [np.float32(0.9441)] 
2025-07-08 08:38:03.589976: Epoch time: 50.28 s 
2025-07-08 08:38:04.730305:  
2025-07-08 08:38:04.730698: Epoch 590 
2025-07-08 08:38:04.730821: Current learning rate: 0.00448 
2025-07-08 08:38:54.833820: train_loss -0.9257 
2025-07-08 08:38:54.834257: val_loss -0.9266 
2025-07-08 08:38:54.834342: Pseudo dice [np.float32(0.9392)] 
2025-07-08 08:38:54.834445: Epoch time: 50.1 s 
2025-07-08 08:38:55.973374:  
2025-07-08 08:38:55.973746: Epoch 591 
2025-07-08 08:38:55.973876: Current learning rate: 0.00447 
2025-07-08 08:39:45.908770: train_loss -0.9246 
2025-07-08 08:39:45.909347: val_loss -0.9217 
2025-07-08 08:39:45.909438: Pseudo dice [np.float32(0.9347)] 
2025-07-08 08:39:45.909582: Epoch time: 49.94 s 
2025-07-08 08:39:47.088084:  
2025-07-08 08:39:47.088547: Epoch 592 
2025-07-08 08:39:47.088865: Current learning rate: 0.00446 
2025-07-08 08:40:36.677856: train_loss -0.9227 
2025-07-08 08:40:36.678224: val_loss -0.9168 
2025-07-08 08:40:36.678330: Pseudo dice [np.float32(0.9352)] 
2025-07-08 08:40:36.678432: Epoch time: 49.59 s 
2025-07-08 08:40:37.816884:  
2025-07-08 08:40:37.817197: Epoch 593 
2025-07-08 08:40:37.817425: Current learning rate: 0.00445 
2025-07-08 08:41:27.782783: train_loss -0.9165 
2025-07-08 08:41:27.783656: val_loss -0.929 
2025-07-08 08:41:27.783808: Pseudo dice [np.float32(0.9405)] 
2025-07-08 08:41:27.783961: Epoch time: 49.97 s 
2025-07-08 08:41:28.964391:  
2025-07-08 08:41:28.964666: Epoch 594 
2025-07-08 08:41:28.964834: Current learning rate: 0.00444 
2025-07-08 08:42:17.776479: train_loss -0.9232 
2025-07-08 08:42:17.777125: val_loss -0.9229 
2025-07-08 08:42:17.777240: Pseudo dice [np.float32(0.941)] 
2025-07-08 08:42:17.777469: Epoch time: 48.81 s 
2025-07-08 08:42:18.879910:  
2025-07-08 08:42:18.880283: Epoch 595 
2025-07-08 08:42:18.880398: Current learning rate: 0.00443 
2025-07-08 08:43:09.192211: train_loss -0.9253 
2025-07-08 08:43:09.192752: val_loss -0.9283 
2025-07-08 08:43:09.192840: Pseudo dice [np.float32(0.9408)] 
2025-07-08 08:43:09.192952: Epoch time: 50.31 s 
2025-07-08 08:43:11.200352:  
2025-07-08 08:43:11.201271: Epoch 596 
2025-07-08 08:43:11.201516: Current learning rate: 0.00442 
2025-07-08 08:43:59.515193: train_loss -0.9134 
2025-07-08 08:43:59.515570: val_loss -0.8953 
2025-07-08 08:43:59.515651: Pseudo dice [np.float32(0.9198)] 
2025-07-08 08:43:59.515757: Epoch time: 48.32 s 
2025-07-08 08:44:00.703131:  
2025-07-08 08:44:00.703731: Epoch 597 
2025-07-08 08:44:00.704049: Current learning rate: 0.00441 
2025-07-08 08:44:48.764811: train_loss -0.8991 
2025-07-08 08:44:48.766093: val_loss -0.9144 
2025-07-08 08:44:48.766188: Pseudo dice [np.float32(0.9339)] 
2025-07-08 08:44:48.766354: Epoch time: 48.06 s 
2025-07-08 08:44:49.961369:  
2025-07-08 08:44:49.961924: Epoch 598 
2025-07-08 08:44:49.962032: Current learning rate: 0.0044 
2025-07-08 08:45:38.234198: train_loss -0.9125 
2025-07-08 08:45:38.234758: val_loss -0.9166 
2025-07-08 08:45:38.234842: Pseudo dice [np.float32(0.9325)] 
2025-07-08 08:45:38.234950: Epoch time: 48.27 s 
2025-07-08 08:45:39.384489:  
2025-07-08 08:45:39.385042: Epoch 599 
2025-07-08 08:45:39.385194: Current learning rate: 0.00439 
2025-07-08 08:46:28.551737: train_loss -0.9162 
2025-07-08 08:46:28.552718: val_loss -0.9264 
2025-07-08 08:46:28.552867: Pseudo dice [np.float32(0.9407)] 
2025-07-08 08:46:28.553070: Epoch time: 49.17 s 
2025-07-08 08:46:30.655305:  
2025-07-08 08:46:30.655641: Epoch 600 
2025-07-08 08:46:30.655849: Current learning rate: 0.00438 
2025-07-08 08:47:20.482280: train_loss -0.9186 
2025-07-08 08:47:20.483233: val_loss -0.9226 
2025-07-08 08:47:20.483344: Pseudo dice [np.float32(0.9387)] 
2025-07-08 08:47:20.483485: Epoch time: 49.83 s 
2025-07-08 08:47:21.662212:  
2025-07-08 08:47:21.662957: Epoch 601 
2025-07-08 08:47:21.663177: Current learning rate: 0.00437 
2025-07-08 08:48:11.920067: train_loss -0.9174 
2025-07-08 08:48:11.920597: val_loss -0.92 
2025-07-08 08:48:11.920846: Pseudo dice [np.float32(0.9376)] 
2025-07-08 08:48:11.920984: Epoch time: 50.26 s 
2025-07-08 08:48:13.152264:  
2025-07-08 08:48:13.152503: Epoch 602 
2025-07-08 08:48:13.152655: Current learning rate: 0.00436 
2025-07-08 08:49:00.723785: train_loss -0.9173 
2025-07-08 08:49:00.724459: val_loss -0.9252 
2025-07-08 08:49:00.724566: Pseudo dice [np.float32(0.9404)] 
2025-07-08 08:49:00.724695: Epoch time: 47.57 s 
2025-07-08 08:49:02.075292:  
2025-07-08 08:49:02.075707: Epoch 603 
2025-07-08 08:49:02.075895: Current learning rate: 0.00435 
2025-07-08 08:49:51.058933: train_loss -0.9246 
2025-07-08 08:49:51.059756: val_loss -0.9287 
2025-07-08 08:49:51.059907: Pseudo dice [np.float32(0.9478)] 
2025-07-08 08:49:51.060086: Epoch time: 48.99 s 
2025-07-08 08:49:52.248707:  
2025-07-08 08:49:52.248928: Epoch 604 
2025-07-08 08:49:52.249104: Current learning rate: 0.00434 
2025-07-08 08:50:42.834563: train_loss -0.9256 
2025-07-08 08:50:42.835877: val_loss -0.9299 
2025-07-08 08:50:42.836121: Pseudo dice [np.float32(0.9458)] 
2025-07-08 08:50:42.836308: Epoch time: 50.59 s 
2025-07-08 08:50:44.028595:  
2025-07-08 08:50:44.028737: Epoch 605 
2025-07-08 08:50:44.028835: Current learning rate: 0.00433 
2025-07-08 08:51:32.797223: train_loss -0.9235 
2025-07-08 08:51:32.797801: val_loss -0.925 
2025-07-08 08:51:32.798049: Pseudo dice [np.float32(0.9397)] 
2025-07-08 08:51:32.798357: Epoch time: 48.77 s 
2025-07-08 08:51:33.923986:  
2025-07-08 08:51:33.924115: Epoch 606 
2025-07-08 08:51:33.924262: Current learning rate: 0.00432 
2025-07-08 08:52:22.087560: train_loss -0.9176 
2025-07-08 08:52:22.088016: val_loss -0.9178 
2025-07-08 08:52:22.088097: Pseudo dice [np.float32(0.9335)] 
2025-07-08 08:52:22.088196: Epoch time: 48.16 s 
2025-07-08 08:52:23.292184:  
2025-07-08 08:52:23.292373: Epoch 607 
2025-07-08 08:52:23.292497: Current learning rate: 0.00431 
2025-07-08 08:53:12.734205: train_loss -0.9104 
2025-07-08 08:53:12.734755: val_loss -0.915 
2025-07-08 08:53:12.734843: Pseudo dice [np.float32(0.9381)] 
2025-07-08 08:53:12.734951: Epoch time: 49.44 s 
2025-07-08 08:53:14.045370:  
2025-07-08 08:53:14.045700: Epoch 608 
2025-07-08 08:53:14.045902: Current learning rate: 0.0043 
2025-07-08 08:54:02.075989: train_loss -0.9111 
2025-07-08 08:54:02.076440: val_loss -0.8667 
2025-07-08 08:54:02.076519: Pseudo dice [np.float32(0.9012)] 
2025-07-08 08:54:02.076645: Epoch time: 48.03 s 
2025-07-08 08:54:03.264300:  
2025-07-08 08:54:03.264550: Epoch 609 
2025-07-08 08:54:03.264720: Current learning rate: 0.00429 
2025-07-08 08:54:52.629151: train_loss -0.8944 
2025-07-08 08:54:52.630026: val_loss -0.9233 
2025-07-08 08:54:52.630143: Pseudo dice [np.float32(0.9404)] 
2025-07-08 08:54:52.630291: Epoch time: 49.37 s 
2025-07-08 08:54:53.786053:  
2025-07-08 08:54:53.786479: Epoch 610 
2025-07-08 08:54:53.786664: Current learning rate: 0.00429 
2025-07-08 08:55:42.173126: train_loss -0.8807 
2025-07-08 08:55:42.174519: val_loss -0.864 
2025-07-08 08:55:42.174759: Pseudo dice [np.float32(0.9)] 
2025-07-08 08:55:42.175110: Epoch time: 48.39 s 
2025-07-08 08:55:43.412095:  
2025-07-08 08:55:43.412549: Epoch 611 
2025-07-08 08:55:43.412787: Current learning rate: 0.00428 
2025-07-08 08:56:31.776967: train_loss -0.862 
2025-07-08 08:56:31.777713: val_loss -0.8702 
2025-07-08 08:56:31.777897: Pseudo dice [np.float32(0.8949)] 
2025-07-08 08:56:31.778051: Epoch time: 48.37 s 
2025-07-08 08:56:33.787462:  
2025-07-08 08:56:33.787736: Epoch 612 
2025-07-08 08:56:33.787944: Current learning rate: 0.00427 
2025-07-08 08:57:22.957802: train_loss -0.8464 
2025-07-08 08:57:22.959573: val_loss -0.8598 
2025-07-08 08:57:22.959938: Pseudo dice [np.float32(0.8975)] 
2025-07-08 08:57:22.960255: Epoch time: 49.17 s 
2025-07-08 08:57:24.252813:  
2025-07-08 08:57:24.253154: Epoch 613 
2025-07-08 08:57:24.253352: Current learning rate: 0.00426 
2025-07-08 08:58:12.491491: train_loss -0.8698 
2025-07-08 08:58:12.491853: val_loss -0.8897 
2025-07-08 08:58:12.491928: Pseudo dice [np.float32(0.9131)] 
2025-07-08 08:58:12.492028: Epoch time: 48.24 s 
2025-07-08 08:58:13.756089:  
2025-07-08 08:58:13.756413: Epoch 614 
2025-07-08 08:58:13.756656: Current learning rate: 0.00425 
2025-07-08 08:59:03.714156: train_loss -0.8608 
2025-07-08 08:59:03.714933: val_loss -0.8537 
2025-07-08 08:59:03.718420: Pseudo dice [np.float32(0.8894)] 
2025-07-08 08:59:03.718633: Epoch time: 49.96 s 
2025-07-08 08:59:04.885745:  
2025-07-08 08:59:04.886101: Epoch 615 
2025-07-08 08:59:04.886275: Current learning rate: 0.00424 
2025-07-08 08:59:55.719935: train_loss -0.857 
2025-07-08 08:59:55.720622: val_loss -0.8393 
2025-07-08 08:59:55.720737: Pseudo dice [np.float32(0.8753)] 
2025-07-08 08:59:55.720854: Epoch time: 50.84 s 
2025-07-08 08:59:56.930559:  
2025-07-08 08:59:56.930894: Epoch 616 
2025-07-08 08:59:56.931048: Current learning rate: 0.00423 
2025-07-08 09:00:46.666572: train_loss -0.8601 
2025-07-08 09:00:46.666942: val_loss -0.8608 
2025-07-08 09:00:46.667025: Pseudo dice [np.float32(0.9005)] 
2025-07-08 09:00:46.667133: Epoch time: 49.74 s 
2025-07-08 09:00:47.790107:  
2025-07-08 09:00:47.790537: Epoch 617 
2025-07-08 09:00:47.790686: Current learning rate: 0.00422 
2025-07-08 09:01:36.918254: train_loss -0.8579 
2025-07-08 09:01:36.918602: val_loss -0.8746 
2025-07-08 09:01:36.918684: Pseudo dice [np.float32(0.9011)] 
2025-07-08 09:01:36.918780: Epoch time: 49.13 s 
2025-07-08 09:01:38.116355:  
2025-07-08 09:01:38.116601: Epoch 618 
2025-07-08 09:01:38.116769: Current learning rate: 0.00421 
2025-07-08 09:02:30.025579: train_loss -0.8741 
2025-07-08 09:02:30.026037: val_loss -0.8874 
2025-07-08 09:02:30.026111: Pseudo dice [np.float32(0.9101)] 
2025-07-08 09:02:30.026233: Epoch time: 51.91 s 
2025-07-08 09:02:31.253072:  
2025-07-08 09:02:31.253209: Epoch 619 
2025-07-08 09:02:31.253310: Current learning rate: 0.0042 
2025-07-08 09:03:21.225431: train_loss -0.881 
2025-07-08 09:03:21.226074: val_loss -0.8895 
2025-07-08 09:03:21.226162: Pseudo dice [np.float32(0.9161)] 
2025-07-08 09:03:21.226301: Epoch time: 49.97 s 
2025-07-08 09:03:22.466504:  
2025-07-08 09:03:22.466817: Epoch 620 
2025-07-08 09:03:22.467097: Current learning rate: 0.00419 
2025-07-08 09:04:11.446549: train_loss -0.8844 
2025-07-08 09:04:11.447355: val_loss -0.8848 
2025-07-08 09:04:11.447479: Pseudo dice [np.float32(0.9111)] 
2025-07-08 09:04:11.447749: Epoch time: 48.98 s 
2025-07-08 09:04:12.656781:  
2025-07-08 09:04:12.656954: Epoch 621 
2025-07-08 09:04:12.657077: Current learning rate: 0.00418 
2025-07-08 09:05:01.785650: train_loss -0.877 
2025-07-08 09:05:01.786177: val_loss -0.8787 
2025-07-08 09:05:01.786263: Pseudo dice [np.float32(0.9044)] 
2025-07-08 09:05:01.786391: Epoch time: 49.13 s 
2025-07-08 09:05:02.971914:  
2025-07-08 09:05:02.972172: Epoch 622 
2025-07-08 09:05:02.972401: Current learning rate: 0.00417 
2025-07-08 09:05:52.297232: train_loss -0.8611 
2025-07-08 09:05:52.298118: val_loss -0.8651 
2025-07-08 09:05:52.298201: Pseudo dice [np.float32(0.9045)] 
2025-07-08 09:05:52.298331: Epoch time: 49.33 s 
2025-07-08 09:05:53.524809:  
2025-07-08 09:05:53.525267: Epoch 623 
2025-07-08 09:05:53.525570: Current learning rate: 0.00416 
2025-07-08 09:06:42.417103: train_loss -0.8723 
2025-07-08 09:06:42.417626: val_loss -0.8817 
2025-07-08 09:06:42.417722: Pseudo dice [np.float32(0.9017)] 
2025-07-08 09:06:42.417845: Epoch time: 48.89 s 
2025-07-08 09:06:43.594603:  
2025-07-08 09:06:43.594983: Epoch 624 
2025-07-08 09:06:43.595121: Current learning rate: 0.00415 
2025-07-08 09:07:32.253294: train_loss -0.8725 
2025-07-08 09:07:32.254108: val_loss -0.8965 
2025-07-08 09:07:32.254219: Pseudo dice [np.float32(0.9141)] 
2025-07-08 09:07:32.254355: Epoch time: 48.66 s 
2025-07-08 09:07:33.562372:  
2025-07-08 09:07:33.562861: Epoch 625 
2025-07-08 09:07:33.562990: Current learning rate: 0.00414 
2025-07-08 09:08:22.766819: train_loss -0.8745 
2025-07-08 09:08:22.767985: val_loss -0.9097 
2025-07-08 09:08:22.768192: Pseudo dice [np.float32(0.9257)] 
2025-07-08 09:08:22.768436: Epoch time: 49.21 s 
2025-07-08 09:08:24.031148:  
2025-07-08 09:08:24.031719: Epoch 626 
2025-07-08 09:08:24.032018: Current learning rate: 0.00413 
2025-07-08 09:09:13.162307: train_loss -0.8964 
2025-07-08 09:09:13.162892: val_loss -0.8992 
2025-07-08 09:09:13.162976: Pseudo dice [np.float32(0.9208)] 
2025-07-08 09:09:13.163090: Epoch time: 49.13 s 
2025-07-08 09:09:14.439311:  
2025-07-08 09:09:14.439528: Epoch 627 
2025-07-08 09:09:14.439653: Current learning rate: 0.00412 
2025-07-08 09:10:04.440771: train_loss -0.9015 
2025-07-08 09:10:04.441186: val_loss -0.9145 
2025-07-08 09:10:04.441583: Pseudo dice [np.float32(0.9238)] 
2025-07-08 09:10:04.441740: Epoch time: 50.0 s 
2025-07-08 09:10:06.617712:  
2025-07-08 09:10:06.618090: Epoch 628 
2025-07-08 09:10:06.618233: Current learning rate: 0.00411 
2025-07-08 09:10:56.869776: train_loss -0.903 
2025-07-08 09:10:56.870087: val_loss -0.9123 
2025-07-08 09:10:56.870171: Pseudo dice [np.float32(0.9276)] 
2025-07-08 09:10:56.870281: Epoch time: 50.25 s 
2025-07-08 09:10:58.077518:  
2025-07-08 09:10:58.077825: Epoch 629 
2025-07-08 09:10:58.077983: Current learning rate: 0.0041 
2025-07-08 09:11:46.279407: train_loss -0.9043 
2025-07-08 09:11:46.279758: val_loss -0.9089 
2025-07-08 09:11:46.279839: Pseudo dice [np.float32(0.9333)] 
2025-07-08 09:11:46.279932: Epoch time: 48.2 s 
2025-07-08 09:11:47.425527:  
2025-07-08 09:11:47.426126: Epoch 630 
2025-07-08 09:11:47.426252: Current learning rate: 0.00409 
2025-07-08 09:12:36.630812: train_loss -0.9075 
2025-07-08 09:12:36.631392: val_loss -0.9159 
2025-07-08 09:12:36.631494: Pseudo dice [np.float32(0.9329)] 
2025-07-08 09:12:36.631639: Epoch time: 49.21 s 
2025-07-08 09:12:37.841618:  
2025-07-08 09:12:37.842032: Epoch 631 
2025-07-08 09:12:37.842167: Current learning rate: 0.00408 
2025-07-08 09:13:28.523029: train_loss -0.9109 
2025-07-08 09:13:28.523760: val_loss -0.9019 
2025-07-08 09:13:28.523889: Pseudo dice [np.float32(0.9321)] 
2025-07-08 09:13:28.524181: Epoch time: 50.68 s 
2025-07-08 09:13:29.783178:  
2025-07-08 09:13:29.783384: Epoch 632 
2025-07-08 09:13:29.783501: Current learning rate: 0.00407 
2025-07-08 09:14:19.986006: train_loss -0.9107 
2025-07-08 09:14:19.986837: val_loss -0.9199 
2025-07-08 09:14:19.986939: Pseudo dice [np.float32(0.9288)] 
2025-07-08 09:14:19.987076: Epoch time: 50.2 s 
2025-07-08 09:14:21.208123:  
2025-07-08 09:14:21.208341: Epoch 633 
2025-07-08 09:14:21.208479: Current learning rate: 0.00406 
2025-07-08 09:15:11.063964: train_loss -0.9114 
2025-07-08 09:15:11.064501: val_loss -0.9062 
2025-07-08 09:15:11.064607: Pseudo dice [np.float32(0.9322)] 
2025-07-08 09:15:11.064730: Epoch time: 49.86 s 
2025-07-08 09:15:12.243893:  
2025-07-08 09:15:12.244165: Epoch 634 
2025-07-08 09:15:12.244387: Current learning rate: 0.00405 
2025-07-08 09:16:04.218648: train_loss -0.887 
2025-07-08 09:16:04.219202: val_loss -0.9123 
2025-07-08 09:16:04.219297: Pseudo dice [np.float32(0.9284)] 
2025-07-08 09:16:04.219422: Epoch time: 51.98 s 
2025-07-08 09:16:05.454407:  
2025-07-08 09:16:05.454960: Epoch 635 
2025-07-08 09:16:05.455130: Current learning rate: 0.00404 
2025-07-08 09:16:55.385634: train_loss -0.8926 
2025-07-08 09:16:55.386297: val_loss -0.8907 
2025-07-08 09:16:55.386430: Pseudo dice [np.float32(0.9215)] 
2025-07-08 09:16:55.386575: Epoch time: 49.93 s 
2025-07-08 09:16:56.672960:  
2025-07-08 09:16:56.673316: Epoch 636 
2025-07-08 09:16:56.673456: Current learning rate: 0.00403 
2025-07-08 09:17:46.300881: train_loss -0.8686 
2025-07-08 09:17:46.301809: val_loss -0.8918 
2025-07-08 09:17:46.301934: Pseudo dice [np.float32(0.9115)] 
2025-07-08 09:17:46.302071: Epoch time: 49.63 s 
2025-07-08 09:17:47.480374:  
2025-07-08 09:17:47.480693: Epoch 637 
2025-07-08 09:17:47.480927: Current learning rate: 0.00402 
2025-07-08 09:18:37.273224: train_loss -0.8765 
2025-07-08 09:18:37.273935: val_loss -0.8969 
2025-07-08 09:18:37.274035: Pseudo dice [np.float32(0.9217)] 
2025-07-08 09:18:37.274172: Epoch time: 49.79 s 
2025-07-08 09:18:38.439315:  
2025-07-08 09:18:38.439559: Epoch 638 
2025-07-08 09:18:38.439663: Current learning rate: 0.00401 
2025-07-08 09:19:27.304863: train_loss -0.8946 
2025-07-08 09:19:27.305362: val_loss -0.9086 
2025-07-08 09:19:27.305442: Pseudo dice [np.float32(0.931)] 
2025-07-08 09:19:27.305537: Epoch time: 48.87 s 
2025-07-08 09:19:28.422638:  
2025-07-08 09:19:28.422986: Epoch 639 
2025-07-08 09:19:28.423225: Current learning rate: 0.004 
2025-07-08 09:20:18.087755: train_loss -0.9033 
2025-07-08 09:20:18.088354: val_loss -0.9067 
2025-07-08 09:20:18.088453: Pseudo dice [np.float32(0.9246)] 
2025-07-08 09:20:18.088579: Epoch time: 49.67 s 
2025-07-08 09:20:19.246297:  
2025-07-08 09:20:19.246627: Epoch 640 
2025-07-08 09:20:19.246838: Current learning rate: 0.00399 
2025-07-08 09:21:07.975986: train_loss -0.8872 
2025-07-08 09:21:07.976595: val_loss -0.8971 
2025-07-08 09:21:07.976931: Pseudo dice [np.float32(0.9313)] 
2025-07-08 09:21:07.977069: Epoch time: 48.73 s 
2025-07-08 09:21:09.190281:  
2025-07-08 09:21:09.190560: Epoch 641 
2025-07-08 09:21:09.190692: Current learning rate: 0.00398 
2025-07-08 09:21:59.604315: train_loss -0.8946 
2025-07-08 09:21:59.605033: val_loss -0.8784 
2025-07-08 09:21:59.605149: Pseudo dice [np.float32(0.9148)] 
2025-07-08 09:21:59.605267: Epoch time: 50.42 s 
2025-07-08 09:22:00.836776:  
2025-07-08 09:22:00.837228: Epoch 642 
2025-07-08 09:22:00.837445: Current learning rate: 0.00397 
2025-07-08 09:22:51.421639: train_loss -0.894 
2025-07-08 09:22:51.422360: val_loss -0.9059 
2025-07-08 09:22:51.422508: Pseudo dice [np.float32(0.9201)] 
2025-07-08 09:22:51.422722: Epoch time: 50.59 s 
2025-07-08 09:22:52.676390:  
2025-07-08 09:22:52.676576: Epoch 643 
2025-07-08 09:22:52.676782: Current learning rate: 0.00396 
2025-07-08 09:23:42.043358: train_loss -0.8983 
2025-07-08 09:23:42.043777: val_loss -0.9045 
2025-07-08 09:23:42.043926: Pseudo dice [np.float32(0.9261)] 
2025-07-08 09:23:42.044129: Epoch time: 49.37 s 
2025-07-08 09:23:44.154883:  
2025-07-08 09:23:44.155076: Epoch 644 
2025-07-08 09:23:44.155223: Current learning rate: 0.00395 
2025-07-08 09:24:32.545956: train_loss -0.9051 
2025-07-08 09:24:32.546689: val_loss -0.9161 
2025-07-08 09:24:32.546797: Pseudo dice [np.float32(0.9283)] 
2025-07-08 09:24:32.546922: Epoch time: 48.39 s 
2025-07-08 09:24:33.726220:  
2025-07-08 09:24:33.726562: Epoch 645 
2025-07-08 09:24:33.726840: Current learning rate: 0.00394 
2025-07-08 09:25:22.781475: train_loss -0.9043 
2025-07-08 09:25:22.781964: val_loss -0.9188 
2025-07-08 09:25:22.782260: Pseudo dice [np.float32(0.9351)] 
2025-07-08 09:25:22.782382: Epoch time: 49.06 s 
2025-07-08 09:25:23.925811:  
2025-07-08 09:25:23.926185: Epoch 646 
2025-07-08 09:25:23.926392: Current learning rate: 0.00393 
2025-07-08 09:26:13.609234: train_loss -0.9143 
2025-07-08 09:26:13.610267: val_loss -0.9172 
2025-07-08 09:26:13.610411: Pseudo dice [np.float32(0.9271)] 
2025-07-08 09:26:13.610579: Epoch time: 49.68 s 
2025-07-08 09:26:14.841820:  
2025-07-08 09:26:14.842331: Epoch 647 
2025-07-08 09:26:14.842463: Current learning rate: 0.00392 
2025-07-08 09:27:03.926876: train_loss -0.9144 
2025-07-08 09:27:03.927248: val_loss -0.9215 
2025-07-08 09:27:03.927327: Pseudo dice [np.float32(0.9354)] 
2025-07-08 09:27:03.927448: Epoch time: 49.09 s 
2025-07-08 09:27:05.122264:  
2025-07-08 09:27:05.122842: Epoch 648 
2025-07-08 09:27:05.123060: Current learning rate: 0.00391 
2025-07-08 09:27:53.085773: train_loss -0.9176 
2025-07-08 09:27:53.086226: val_loss -0.9131 
2025-07-08 09:27:53.086299: Pseudo dice [np.float32(0.9354)] 
2025-07-08 09:27:53.086388: Epoch time: 47.96 s 
2025-07-08 09:27:54.231001:  
2025-07-08 09:27:54.231337: Epoch 649 
2025-07-08 09:27:54.231519: Current learning rate: 0.0039 
2025-07-08 09:28:43.389398: train_loss -0.9138 
2025-07-08 09:28:43.390054: val_loss -0.9214 
2025-07-08 09:28:43.390161: Pseudo dice [np.float32(0.9409)] 
2025-07-08 09:28:43.390280: Epoch time: 49.16 s 
2025-07-08 09:28:45.582847:  
2025-07-08 09:28:45.583305: Epoch 650 
2025-07-08 09:28:45.583476: Current learning rate: 0.00389 
2025-07-08 09:29:33.218569: train_loss -0.9105 
2025-07-08 09:29:33.219181: val_loss -0.9164 
2025-07-08 09:29:33.219306: Pseudo dice [np.float32(0.9322)] 
2025-07-08 09:29:33.219453: Epoch time: 47.64 s 
2025-07-08 09:29:34.472650:  
2025-07-08 09:29:34.472849: Epoch 651 
2025-07-08 09:29:34.473261: Current learning rate: 0.00388 
2025-07-08 09:30:24.141926: train_loss -0.9189 
2025-07-08 09:30:24.142364: val_loss -0.9144 
2025-07-08 09:30:24.142483: Pseudo dice [np.float32(0.93)] 
2025-07-08 09:30:24.142629: Epoch time: 49.67 s 
2025-07-08 09:30:25.338506:  
2025-07-08 09:30:25.338796: Epoch 652 
2025-07-08 09:30:25.338917: Current learning rate: 0.00387 
2025-07-08 09:31:15.495497: train_loss -0.9184 
2025-07-08 09:31:15.498512: val_loss -0.925 
2025-07-08 09:31:15.499864: Pseudo dice [np.float32(0.9416)] 
2025-07-08 09:31:15.501514: Epoch time: 50.16 s 
2025-07-08 09:31:16.914581:  
2025-07-08 09:31:16.915226: Epoch 653 
2025-07-08 09:31:16.915440: Current learning rate: 0.00386 
2025-07-08 09:32:06.206943: train_loss -0.9169 
2025-07-08 09:32:06.208535: val_loss -0.9113 
2025-07-08 09:32:06.208791: Pseudo dice [np.float32(0.9305)] 
2025-07-08 09:32:06.209264: Epoch time: 49.29 s 
2025-07-08 09:32:07.478281:  
2025-07-08 09:32:07.478556: Epoch 654 
2025-07-08 09:32:07.478711: Current learning rate: 0.00385 
2025-07-08 09:32:55.670228: train_loss -0.9185 
2025-07-08 09:32:55.670863: val_loss -0.9269 
2025-07-08 09:32:55.670983: Pseudo dice [np.float32(0.9399)] 
2025-07-08 09:32:55.671121: Epoch time: 48.19 s 
2025-07-08 09:32:56.909268:  
2025-07-08 09:32:56.909841: Epoch 655 
2025-07-08 09:32:56.910013: Current learning rate: 0.00384 
2025-07-08 09:33:46.614660: train_loss -0.9193 
2025-07-08 09:33:46.615582: val_loss -0.9199 
2025-07-08 09:33:46.615690: Pseudo dice [np.float32(0.9365)] 
2025-07-08 09:33:46.615812: Epoch time: 49.71 s 
2025-07-08 09:33:47.868199:  
2025-07-08 09:33:47.868486: Epoch 656 
2025-07-08 09:33:47.868671: Current learning rate: 0.00383 
2025-07-08 09:34:38.233696: train_loss -0.9213 
2025-07-08 09:34:38.234283: val_loss -0.9211 
2025-07-08 09:34:38.234385: Pseudo dice [np.float32(0.9375)] 
2025-07-08 09:34:38.234520: Epoch time: 50.37 s 
2025-07-08 09:34:39.384290:  
2025-07-08 09:34:39.384577: Epoch 657 
2025-07-08 09:34:39.384774: Current learning rate: 0.00382 
2025-07-08 09:35:28.576558: train_loss -0.9195 
2025-07-08 09:35:28.577411: val_loss -0.9183 
2025-07-08 09:35:28.577662: Pseudo dice [np.float32(0.9396)] 
2025-07-08 09:35:28.577857: Epoch time: 49.19 s 
2025-07-08 09:35:29.846503:  
2025-07-08 09:35:29.846814: Epoch 658 
2025-07-08 09:35:29.846991: Current learning rate: 0.00381 
2025-07-08 09:36:19.058019: train_loss -0.9182 
2025-07-08 09:36:19.058693: val_loss -0.9271 
2025-07-08 09:36:19.058796: Pseudo dice [np.float32(0.9422)] 
2025-07-08 09:36:19.058922: Epoch time: 49.21 s 
2025-07-08 09:36:20.293670:  
2025-07-08 09:36:20.294032: Epoch 659 
2025-07-08 09:36:20.294205: Current learning rate: 0.0038 
2025-07-08 09:37:09.054973: train_loss -0.9199 
2025-07-08 09:37:09.055597: val_loss -0.9255 
2025-07-08 09:37:09.055691: Pseudo dice [np.float32(0.9426)] 
2025-07-08 09:37:09.055816: Epoch time: 48.76 s 
2025-07-08 09:37:11.290570:  
2025-07-08 09:37:11.290859: Epoch 660 
2025-07-08 09:37:11.291146: Current learning rate: 0.00379 
2025-07-08 09:38:00.232950: train_loss -0.9196 
2025-07-08 09:38:00.233679: val_loss -0.9269 
2025-07-08 09:38:00.233773: Pseudo dice [np.float32(0.9444)] 
2025-07-08 09:38:00.233913: Epoch time: 48.94 s 
2025-07-08 09:38:01.477279:  
2025-07-08 09:38:01.477621: Epoch 661 
2025-07-08 09:38:01.477948: Current learning rate: 0.00378 
2025-07-08 09:38:51.007814: train_loss -0.9234 
2025-07-08 09:38:51.008463: val_loss -0.9241 
2025-07-08 09:38:51.008579: Pseudo dice [np.float32(0.9371)] 
2025-07-08 09:38:51.008721: Epoch time: 49.53 s 
2025-07-08 09:38:52.319563:  
2025-07-08 09:38:52.319807: Epoch 662 
2025-07-08 09:38:52.319944: Current learning rate: 0.00377 
2025-07-08 09:39:41.388698: train_loss -0.9159 
2025-07-08 09:39:41.389213: val_loss -0.9294 
2025-07-08 09:39:41.389304: Pseudo dice [np.float32(0.9433)] 
2025-07-08 09:39:41.389412: Epoch time: 49.07 s 
2025-07-08 09:39:42.559964:  
2025-07-08 09:39:42.560326: Epoch 663 
2025-07-08 09:39:42.560586: Current learning rate: 0.00376 
2025-07-08 09:40:31.056074: train_loss -0.922 
2025-07-08 09:40:31.056621: val_loss -0.9226 
2025-07-08 09:40:31.056875: Pseudo dice [np.float32(0.9403)] 
2025-07-08 09:40:31.056985: Epoch time: 48.5 s 
2025-07-08 09:40:32.444658:  
2025-07-08 09:40:32.445492: Epoch 664 
2025-07-08 09:40:32.445692: Current learning rate: 0.00375 
2025-07-08 09:41:22.576220: train_loss -0.9221 
2025-07-08 09:41:22.576600: val_loss -0.9246 
2025-07-08 09:41:22.576726: Pseudo dice [np.float32(0.9388)] 
2025-07-08 09:41:22.576825: Epoch time: 50.13 s 
2025-07-08 09:41:23.769813:  
2025-07-08 09:41:23.770177: Epoch 665 
2025-07-08 09:41:23.770308: Current learning rate: 0.00374 
2025-07-08 09:42:11.514347: train_loss -0.9187 
2025-07-08 09:42:11.514732: val_loss -0.9149 
2025-07-08 09:42:11.514811: Pseudo dice [np.float32(0.9316)] 
2025-07-08 09:42:11.514915: Epoch time: 47.75 s 
2025-07-08 09:42:12.679585:  
2025-07-08 09:42:12.680036: Epoch 666 
2025-07-08 09:42:12.680232: Current learning rate: 0.00373 
2025-07-08 09:43:01.968285: train_loss -0.9215 
2025-07-08 09:43:01.968891: val_loss -0.9338 
2025-07-08 09:43:01.969008: Pseudo dice [np.float32(0.9473)] 
2025-07-08 09:43:01.969162: Epoch time: 49.29 s 
2025-07-08 09:43:03.224165:  
2025-07-08 09:43:03.224447: Epoch 667 
2025-07-08 09:43:03.224638: Current learning rate: 0.00372 
2025-07-08 09:43:52.740085: train_loss -0.9167 
2025-07-08 09:43:52.740767: val_loss -0.9312 
2025-07-08 09:43:52.740882: Pseudo dice [np.float32(0.9429)] 
2025-07-08 09:43:52.741030: Epoch time: 49.52 s 
2025-07-08 09:43:53.979045:  
2025-07-08 09:43:53.979573: Epoch 668 
2025-07-08 09:43:53.979861: Current learning rate: 0.00371 
2025-07-08 09:44:43.804660: train_loss -0.9149 
2025-07-08 09:44:43.805428: val_loss -0.9261 
2025-07-08 09:44:43.805534: Pseudo dice [np.float32(0.9408)] 
2025-07-08 09:44:43.805702: Epoch time: 49.83 s 
2025-07-08 09:44:45.013496:  
2025-07-08 09:44:45.013940: Epoch 669 
2025-07-08 09:44:45.014084: Current learning rate: 0.0037 
2025-07-08 09:45:33.253051: train_loss -0.9186 
2025-07-08 09:45:33.253726: val_loss -0.9288 
2025-07-08 09:45:33.253815: Pseudo dice [np.float32(0.9425)] 
2025-07-08 09:45:33.253934: Epoch time: 48.24 s 
2025-07-08 09:45:34.417217:  
2025-07-08 09:45:34.417586: Epoch 670 
2025-07-08 09:45:34.417883: Current learning rate: 0.00369 
2025-07-08 09:46:24.269371: train_loss -0.9226 
2025-07-08 09:46:24.270305: val_loss -0.9234 
2025-07-08 09:46:24.270395: Pseudo dice [np.float32(0.9323)] 
2025-07-08 09:46:24.270594: Epoch time: 49.85 s 
2025-07-08 09:46:25.473072:  
2025-07-08 09:46:25.473465: Epoch 671 
2025-07-08 09:46:25.473604: Current learning rate: 0.00368 
2025-07-08 09:47:14.412001: train_loss -0.9144 
2025-07-08 09:47:14.412696: val_loss -0.9264 
2025-07-08 09:47:14.412791: Pseudo dice [np.float32(0.9418)] 
2025-07-08 09:47:14.412914: Epoch time: 48.94 s 
2025-07-08 09:47:15.680875:  
2025-07-08 09:47:15.681063: Epoch 672 
2025-07-08 09:47:15.681198: Current learning rate: 0.00367 
2025-07-08 09:48:05.514941: train_loss -0.9149 
2025-07-08 09:48:05.515682: val_loss -0.9146 
2025-07-08 09:48:05.515835: Pseudo dice [np.float32(0.9281)] 
2025-07-08 09:48:05.515996: Epoch time: 49.84 s 
2025-07-08 09:48:06.773371:  
2025-07-08 09:48:06.773758: Epoch 673 
2025-07-08 09:48:06.773904: Current learning rate: 0.00366 
2025-07-08 09:48:55.072607: train_loss -0.9078 
2025-07-08 09:48:55.073087: val_loss -0.9208 
2025-07-08 09:48:55.073170: Pseudo dice [np.float32(0.9384)] 
2025-07-08 09:48:55.073282: Epoch time: 48.3 s 
2025-07-08 09:48:56.406840:  
2025-07-08 09:48:56.407438: Epoch 674 
2025-07-08 09:48:56.407680: Current learning rate: 0.00365 
2025-07-08 09:49:45.909669: train_loss -0.9104 
2025-07-08 09:49:45.910858: val_loss -0.9064 
2025-07-08 09:49:45.910980: Pseudo dice [np.float32(0.9212)] 
2025-07-08 09:49:45.911191: Epoch time: 49.5 s 
2025-07-08 09:49:48.076493:  
2025-07-08 09:49:48.076856: Epoch 675 
2025-07-08 09:49:48.076988: Current learning rate: 0.00364 
2025-07-08 09:50:36.793047: train_loss -0.9107 
2025-07-08 09:50:36.793712: val_loss -0.9202 
2025-07-08 09:50:36.793817: Pseudo dice [np.float32(0.9354)] 
2025-07-08 09:50:36.793963: Epoch time: 48.72 s 
2025-07-08 09:50:38.087604:  
2025-07-08 09:50:38.087834: Epoch 676 
2025-07-08 09:50:38.088172: Current learning rate: 0.00363 
2025-07-08 09:51:27.055526: train_loss -0.9206 
2025-07-08 09:51:27.056170: val_loss -0.9219 
2025-07-08 09:51:27.056270: Pseudo dice [np.float32(0.9405)] 
2025-07-08 09:51:27.056393: Epoch time: 48.97 s 
2025-07-08 09:51:28.395142:  
2025-07-08 09:51:28.395346: Epoch 677 
2025-07-08 09:51:28.395467: Current learning rate: 0.00362 
2025-07-08 09:52:16.335454: train_loss -0.9227 
2025-07-08 09:52:16.335842: val_loss -0.9338 
2025-07-08 09:52:16.336019: Pseudo dice [np.float32(0.947)] 
2025-07-08 09:52:16.336172: Epoch time: 47.94 s 
2025-07-08 09:52:17.592554:  
2025-07-08 09:52:17.592960: Epoch 678 
2025-07-08 09:52:17.593127: Current learning rate: 0.00361 
2025-07-08 09:53:05.772044: train_loss -0.9192 
2025-07-08 09:53:05.772622: val_loss -0.9264 
2025-07-08 09:53:05.772757: Pseudo dice [np.float32(0.9442)] 
2025-07-08 09:53:05.772903: Epoch time: 48.18 s 
2025-07-08 09:53:07.012053:  
2025-07-08 09:53:07.012248: Epoch 679 
2025-07-08 09:53:07.012476: Current learning rate: 0.0036 
2025-07-08 09:53:57.747334: train_loss -0.9215 
2025-07-08 09:53:57.747941: val_loss -0.9276 
2025-07-08 09:53:57.748036: Pseudo dice [np.float32(0.9421)] 
2025-07-08 09:53:57.748157: Epoch time: 50.74 s 
2025-07-08 09:53:58.963228:  
2025-07-08 09:53:58.963693: Epoch 680 
2025-07-08 09:53:58.963819: Current learning rate: 0.00359 
2025-07-08 09:54:48.539515: train_loss -0.9231 
2025-07-08 09:54:48.539939: val_loss -0.9329 
2025-07-08 09:54:48.540018: Pseudo dice [np.float32(0.9492)] 
2025-07-08 09:54:48.540123: Epoch time: 49.58 s 
2025-07-08 09:54:49.730976:  
2025-07-08 09:54:49.731184: Epoch 681 
2025-07-08 09:54:49.731424: Current learning rate: 0.00358 
2025-07-08 09:55:39.350802: train_loss -0.9246 
2025-07-08 09:55:39.351180: val_loss -0.931 
2025-07-08 09:55:39.351257: Pseudo dice [np.float32(0.9486)] 
2025-07-08 09:55:39.351358: Epoch time: 49.62 s 
2025-07-08 09:55:40.536786:  
2025-07-08 09:55:40.537219: Epoch 682 
2025-07-08 09:55:40.537377: Current learning rate: 0.00357 
2025-07-08 09:56:27.972625: train_loss -0.9211 
2025-07-08 09:56:27.973459: val_loss -0.9282 
2025-07-08 09:56:27.973569: Pseudo dice [np.float32(0.9396)] 
2025-07-08 09:56:27.973714: Epoch time: 47.44 s 
2025-07-08 09:56:29.176407:  
2025-07-08 09:56:29.176701: Epoch 683 
2025-07-08 09:56:29.176880: Current learning rate: 0.00356 
2025-07-08 09:57:16.909506: train_loss -0.9225 
2025-07-08 09:57:16.909959: val_loss -0.923 
2025-07-08 09:57:16.910051: Pseudo dice [np.float32(0.9387)] 
2025-07-08 09:57:16.910169: Epoch time: 47.73 s 
2025-07-08 09:57:18.172772:  
2025-07-08 09:57:18.173130: Epoch 684 
2025-07-08 09:57:18.173296: Current learning rate: 0.00355 
2025-07-08 09:58:07.203440: train_loss -0.9275 
2025-07-08 09:58:07.203955: val_loss -0.923 
2025-07-08 09:58:07.204039: Pseudo dice [np.float32(0.9483)] 
2025-07-08 09:58:07.204142: Epoch time: 49.03 s 
2025-07-08 09:58:08.353364:  
2025-07-08 09:58:08.353729: Epoch 685 
2025-07-08 09:58:08.353885: Current learning rate: 0.00354 
2025-07-08 09:58:57.681723: train_loss -0.9245 
2025-07-08 09:58:57.682791: val_loss -0.9297 
2025-07-08 09:58:57.683039: Pseudo dice [np.float32(0.9459)] 
2025-07-08 09:58:57.683264: Epoch time: 49.33 s 
2025-07-08 09:58:59.171661:  
2025-07-08 09:58:59.172020: Epoch 686 
2025-07-08 09:58:59.172149: Current learning rate: 0.00353 
2025-07-08 09:59:47.676183: train_loss -0.9192 
2025-07-08 09:59:47.676901: val_loss -0.9308 
2025-07-08 09:59:47.677181: Pseudo dice [np.float32(0.9481)] 
2025-07-08 09:59:47.677315: Epoch time: 48.51 s 
2025-07-08 09:59:48.905599:  
2025-07-08 09:59:48.905952: Epoch 687 
2025-07-08 09:59:48.906165: Current learning rate: 0.00352 
2025-07-08 10:00:38.102369: train_loss -0.9252 
2025-07-08 10:00:38.102726: val_loss -0.9349 
2025-07-08 10:00:38.102798: Pseudo dice [np.float32(0.9509)] 
2025-07-08 10:00:38.102894: Epoch time: 49.2 s 
2025-07-08 10:00:39.231308:  
2025-07-08 10:00:39.231547: Epoch 688 
2025-07-08 10:00:39.231680: Current learning rate: 0.00351 
2025-07-08 10:01:28.494191: train_loss -0.9193 
2025-07-08 10:01:28.494561: val_loss -0.9222 
2025-07-08 10:01:28.494726: Pseudo dice [np.float32(0.9406)] 
2025-07-08 10:01:28.494966: Epoch time: 49.26 s 
2025-07-08 10:01:29.687751:  
2025-07-08 10:01:29.687979: Epoch 689 
2025-07-08 10:01:29.688169: Current learning rate: 0.0035 
2025-07-08 10:02:20.565110: train_loss -0.9211 
2025-07-08 10:02:20.565635: val_loss -0.9223 
2025-07-08 10:02:20.565723: Pseudo dice [np.float32(0.9366)] 
2025-07-08 10:02:20.565826: Epoch time: 50.88 s 
2025-07-08 10:02:21.711848:  
2025-07-08 10:02:21.712128: Epoch 690 
2025-07-08 10:02:21.712257: Current learning rate: 0.00349 
2025-07-08 10:03:11.069783: train_loss -0.9227 
2025-07-08 10:03:11.070134: val_loss -0.9327 
2025-07-08 10:03:11.070220: Pseudo dice [np.float32(0.9445)] 
2025-07-08 10:03:11.070328: Epoch time: 49.36 s 
2025-07-08 10:03:13.198183:  
2025-07-08 10:03:13.198641: Epoch 691 
2025-07-08 10:03:13.198982: Current learning rate: 0.00348 
2025-07-08 10:04:02.375462: train_loss -0.9236 
2025-07-08 10:04:02.376361: val_loss -0.9325 
2025-07-08 10:04:02.376483: Pseudo dice [np.float32(0.9499)] 
2025-07-08 10:04:02.376661: Epoch time: 49.18 s 
2025-07-08 10:04:03.692177:  
2025-07-08 10:04:03.692592: Epoch 692 
2025-07-08 10:04:03.692719: Current learning rate: 0.00346 
2025-07-08 10:04:54.992459: train_loss -0.9179 
2025-07-08 10:04:54.993573: val_loss -0.935 
2025-07-08 10:04:54.993732: Pseudo dice [np.float32(0.948)] 
2025-07-08 10:04:54.993909: Epoch time: 51.3 s 
2025-07-08 10:04:56.359339:  
2025-07-08 10:04:56.359608: Epoch 693 
2025-07-08 10:04:56.359718: Current learning rate: 0.00345 
2025-07-08 10:05:46.324636: train_loss -0.9252 
2025-07-08 10:05:46.325692: val_loss -0.9361 
2025-07-08 10:05:46.325814: Pseudo dice [np.float32(0.9459)] 
2025-07-08 10:05:46.325939: Epoch time: 49.97 s 
2025-07-08 10:05:47.545171:  
2025-07-08 10:05:47.545468: Epoch 694 
2025-07-08 10:05:47.545636: Current learning rate: 0.00344 
2025-07-08 10:06:37.328529: train_loss -0.9255 
2025-07-08 10:06:37.329844: val_loss -0.9256 
2025-07-08 10:06:37.330081: Pseudo dice [np.float32(0.9459)] 
2025-07-08 10:06:37.330394: Epoch time: 49.78 s 
2025-07-08 10:06:37.330618: Yayy! New best EMA pseudo Dice: 0.944100022315979 
2025-07-08 10:06:39.653305:  
2025-07-08 10:06:39.653904: Epoch 695 
2025-07-08 10:06:39.654183: Current learning rate: 0.00343 
2025-07-08 10:07:28.242179: train_loss -0.9244 
2025-07-08 10:07:28.243232: val_loss -0.9346 
2025-07-08 10:07:28.243335: Pseudo dice [np.float32(0.9503)] 
2025-07-08 10:07:28.243503: Epoch time: 48.59 s 
2025-07-08 10:07:28.243604: Yayy! New best EMA pseudo Dice: 0.9447000026702881 
2025-07-08 10:07:30.501185:  
2025-07-08 10:07:30.501617: Epoch 696 
2025-07-08 10:07:30.501792: Current learning rate: 0.00342 
2025-07-08 10:08:20.101810: train_loss -0.9288 
2025-07-08 10:08:20.102314: val_loss -0.9314 
2025-07-08 10:08:20.102402: Pseudo dice [np.float32(0.942)] 
2025-07-08 10:08:20.102508: Epoch time: 49.6 s 
2025-07-08 10:08:21.256054:  
2025-07-08 10:08:21.256376: Epoch 697 
2025-07-08 10:08:21.256513: Current learning rate: 0.00341 
2025-07-08 10:09:11.299517: train_loss -0.9267 
2025-07-08 10:09:11.300126: val_loss -0.9264 
2025-07-08 10:09:11.300214: Pseudo dice [np.float32(0.9431)] 
2025-07-08 10:09:11.300333: Epoch time: 50.04 s 
2025-07-08 10:09:12.513810:  
2025-07-08 10:09:12.514419: Epoch 698 
2025-07-08 10:09:12.514748: Current learning rate: 0.0034 
2025-07-08 10:10:01.044151: train_loss -0.9264 
2025-07-08 10:10:01.044850: val_loss -0.9326 
2025-07-08 10:10:01.044931: Pseudo dice [np.float32(0.9471)] 
2025-07-08 10:10:01.045032: Epoch time: 48.53 s 
2025-07-08 10:10:02.260153:  
2025-07-08 10:10:02.260432: Epoch 699 
2025-07-08 10:10:02.260771: Current learning rate: 0.00339 
2025-07-08 10:10:50.794809: train_loss -0.9237 
2025-07-08 10:10:50.795715: val_loss -0.931 
2025-07-08 10:10:50.795804: Pseudo dice [np.float32(0.945)] 
2025-07-08 10:10:50.795918: Epoch time: 48.54 s 
2025-07-08 10:10:53.034324:  
2025-07-08 10:10:53.034813: Epoch 700 
2025-07-08 10:10:53.035195: Current learning rate: 0.00338 
2025-07-08 10:11:43.308392: train_loss -0.928 
2025-07-08 10:11:43.308861: val_loss -0.926 
2025-07-08 10:11:43.308946: Pseudo dice [np.float32(0.9385)] 
2025-07-08 10:11:43.309052: Epoch time: 50.28 s 
2025-07-08 10:11:44.536079:  
2025-07-08 10:11:44.536410: Epoch 701 
2025-07-08 10:11:44.536626: Current learning rate: 0.00337 
2025-07-08 10:12:32.430900: train_loss -0.9261 
2025-07-08 10:12:32.432793: val_loss -0.9217 
2025-07-08 10:12:32.432953: Pseudo dice [np.float32(0.9403)] 
2025-07-08 10:12:32.433236: Epoch time: 47.9 s 
2025-07-08 10:12:33.636470:  
2025-07-08 10:12:33.636908: Epoch 702 
2025-07-08 10:12:33.637076: Current learning rate: 0.00336 
2025-07-08 10:13:21.583532: train_loss -0.9215 
2025-07-08 10:13:21.584158: val_loss -0.9285 
2025-07-08 10:13:21.584267: Pseudo dice [np.float32(0.9443)] 
2025-07-08 10:13:21.584407: Epoch time: 47.95 s 
2025-07-08 10:13:22.849216:  
2025-07-08 10:13:22.849424: Epoch 703 
2025-07-08 10:13:22.849534: Current learning rate: 0.00335 
2025-07-08 10:14:11.603341: train_loss -0.9258 
2025-07-08 10:14:11.604017: val_loss -0.923 
2025-07-08 10:14:11.604140: Pseudo dice [np.float32(0.9406)] 
2025-07-08 10:14:11.604268: Epoch time: 48.76 s 
2025-07-08 10:14:12.785874:  
2025-07-08 10:14:12.786071: Epoch 704 
2025-07-08 10:14:12.786232: Current learning rate: 0.00334 
2025-07-08 10:15:01.623557: train_loss -0.9225 
2025-07-08 10:15:01.623981: val_loss -0.9297 
2025-07-08 10:15:01.624071: Pseudo dice [np.float32(0.9474)] 
2025-07-08 10:15:01.624192: Epoch time: 48.84 s 
2025-07-08 10:15:02.879634:  
2025-07-08 10:15:02.880451: Epoch 705 
2025-07-08 10:15:02.880732: Current learning rate: 0.00333 
2025-07-08 10:15:52.552552: train_loss -0.9239 
2025-07-08 10:15:52.553202: val_loss -0.9354 
2025-07-08 10:15:52.553310: Pseudo dice [np.float32(0.9483)] 
2025-07-08 10:15:52.553441: Epoch time: 49.67 s 
2025-07-08 10:15:54.768314:  
2025-07-08 10:15:54.768523: Epoch 706 
2025-07-08 10:15:54.768904: Current learning rate: 0.00332 
2025-07-08 10:16:45.399409: train_loss -0.9223 
2025-07-08 10:16:45.400067: val_loss -0.9287 
2025-07-08 10:16:45.403689: Pseudo dice [np.float32(0.9463)] 
2025-07-08 10:16:45.403962: Epoch time: 50.63 s 
2025-07-08 10:16:46.627878:  
2025-07-08 10:16:46.628289: Epoch 707 
2025-07-08 10:16:46.628404: Current learning rate: 0.00331 
2025-07-08 10:17:36.524002: train_loss -0.9295 
2025-07-08 10:17:36.525126: val_loss -0.9314 
2025-07-08 10:17:36.525234: Pseudo dice [np.float32(0.9435)] 
2025-07-08 10:17:36.525401: Epoch time: 49.9 s 
2025-07-08 10:17:37.799618:  
2025-07-08 10:17:37.799863: Epoch 708 
2025-07-08 10:17:37.800150: Current learning rate: 0.0033 
2025-07-08 10:18:27.344004: train_loss -0.9272 
2025-07-08 10:18:27.344483: val_loss -0.9248 
2025-07-08 10:18:27.344573: Pseudo dice [np.float32(0.9455)] 
2025-07-08 10:18:27.344678: Epoch time: 49.55 s 
2025-07-08 10:18:28.535841:  
2025-07-08 10:18:28.536496: Epoch 709 
2025-07-08 10:18:28.536680: Current learning rate: 0.00329 
2025-07-08 10:19:17.003410: train_loss -0.9287 
2025-07-08 10:19:17.004494: val_loss -0.9342 
2025-07-08 10:19:17.004879: Pseudo dice [np.float32(0.9508)] 
2025-07-08 10:19:17.005137: Epoch time: 48.47 s 
2025-07-08 10:19:17.005283: Yayy! New best EMA pseudo Dice: 0.9451000094413757 
2025-07-08 10:19:19.189207:  
2025-07-08 10:19:19.189478: Epoch 710 
2025-07-08 10:19:19.189613: Current learning rate: 0.00328 
2025-07-08 10:20:07.363928: train_loss -0.9274 
2025-07-08 10:20:07.364572: val_loss -0.9323 
2025-07-08 10:20:07.364675: Pseudo dice [np.float32(0.9473)] 
2025-07-08 10:20:07.364795: Epoch time: 48.18 s 
2025-07-08 10:20:07.364880: Yayy! New best EMA pseudo Dice: 0.9452999830245972 
2025-07-08 10:20:09.506595:  
2025-07-08 10:20:09.506805: Epoch 711 
2025-07-08 10:20:09.506968: Current learning rate: 0.00327 
2025-07-08 10:20:58.604193: train_loss -0.9299 
2025-07-08 10:20:58.604563: val_loss -0.9297 
2025-07-08 10:20:58.604656: Pseudo dice [np.float32(0.942)] 
2025-07-08 10:20:58.604765: Epoch time: 49.1 s 
2025-07-08 10:20:59.801796:  
2025-07-08 10:20:59.802225: Epoch 712 
2025-07-08 10:20:59.802404: Current learning rate: 0.00326 
2025-07-08 10:21:48.267932: train_loss -0.9275 
2025-07-08 10:21:48.268432: val_loss -0.9255 
2025-07-08 10:21:48.268533: Pseudo dice [np.float32(0.9454)] 
2025-07-08 10:21:48.268666: Epoch time: 48.47 s 
2025-07-08 10:21:49.475163:  
2025-07-08 10:21:49.475594: Epoch 713 
2025-07-08 10:21:49.475734: Current learning rate: 0.00325 
2025-07-08 10:22:38.040561: train_loss -0.9263 
2025-07-08 10:22:38.041096: val_loss -0.93 
2025-07-08 10:22:38.041186: Pseudo dice [np.float32(0.9476)] 
2025-07-08 10:22:38.041298: Epoch time: 48.57 s 
2025-07-08 10:22:39.207668:  
2025-07-08 10:22:39.208080: Epoch 714 
2025-07-08 10:22:39.208264: Current learning rate: 0.00324 
2025-07-08 10:23:29.464074: train_loss -0.9248 
2025-07-08 10:23:29.465666: val_loss -0.9323 
2025-07-08 10:23:29.465922: Pseudo dice [np.float32(0.9449)] 
2025-07-08 10:23:29.466108: Epoch time: 50.26 s 
2025-07-08 10:23:30.738596:  
2025-07-08 10:23:30.739033: Epoch 715 
2025-07-08 10:23:30.739379: Current learning rate: 0.00323 
2025-07-08 10:24:19.736741: train_loss -0.9251 
2025-07-08 10:24:19.737717: val_loss -0.932 
2025-07-08 10:24:19.737967: Pseudo dice [np.float32(0.9475)] 
2025-07-08 10:24:19.738358: Epoch time: 49.0 s 
2025-07-08 10:24:19.738835: Yayy! New best EMA pseudo Dice: 0.9455000162124634 
2025-07-08 10:24:21.952115:  
2025-07-08 10:24:21.952531: Epoch 716 
2025-07-08 10:24:21.952878: Current learning rate: 0.00322 
2025-07-08 10:25:11.803172: train_loss -0.9291 
2025-07-08 10:25:11.804080: val_loss -0.9262 
2025-07-08 10:25:11.804175: Pseudo dice [np.float32(0.9488)] 
2025-07-08 10:25:11.804312: Epoch time: 49.85 s 
2025-07-08 10:25:11.804392: Yayy! New best EMA pseudo Dice: 0.9458000063896179 
2025-07-08 10:25:14.129118:  
2025-07-08 10:25:14.129378: Epoch 717 
2025-07-08 10:25:14.129477: Current learning rate: 0.00321 
2025-07-08 10:26:03.215882: train_loss -0.9266 
2025-07-08 10:26:03.216404: val_loss -0.9316 
2025-07-08 10:26:03.216495: Pseudo dice [np.float32(0.9489)] 
2025-07-08 10:26:03.216633: Epoch time: 49.09 s 
2025-07-08 10:26:03.216711: Yayy! New best EMA pseudo Dice: 0.9460999965667725 
2025-07-08 10:26:05.349698:  
2025-07-08 10:26:05.350062: Epoch 718 
2025-07-08 10:26:05.350182: Current learning rate: 0.0032 
2025-07-08 10:26:55.320152: train_loss -0.9294 
2025-07-08 10:26:55.320500: val_loss -0.9269 
2025-07-08 10:26:55.320581: Pseudo dice [np.float32(0.9397)] 
2025-07-08 10:26:55.320675: Epoch time: 49.97 s 
2025-07-08 10:26:56.489068:  
2025-07-08 10:26:56.489262: Epoch 719 
2025-07-08 10:26:56.489394: Current learning rate: 0.00319 
2025-07-08 10:27:44.889799: train_loss -0.9263 
2025-07-08 10:27:44.891750: val_loss -0.933 
2025-07-08 10:27:44.892150: Pseudo dice [np.float32(0.9454)] 
2025-07-08 10:27:44.892364: Epoch time: 48.4 s 
2025-07-08 10:27:46.198756:  
2025-07-08 10:27:46.199051: Epoch 720 
2025-07-08 10:27:46.199259: Current learning rate: 0.00318 
2025-07-08 10:28:34.367905: train_loss -0.9289 
2025-07-08 10:28:34.368400: val_loss -0.9373 
2025-07-08 10:28:34.368478: Pseudo dice [np.float32(0.9516)] 
2025-07-08 10:28:34.368598: Epoch time: 48.17 s 
2025-07-08 10:28:36.447973:  
2025-07-08 10:28:36.448476: Epoch 721 
2025-07-08 10:28:36.448689: Current learning rate: 0.00317 
2025-07-08 10:29:24.768231: train_loss -0.9296 
2025-07-08 10:29:24.768608: val_loss -0.9423 
2025-07-08 10:29:24.768706: Pseudo dice [np.float32(0.9536)] 
2025-07-08 10:29:24.768820: Epoch time: 48.32 s 
2025-07-08 10:29:24.769030: Yayy! New best EMA pseudo Dice: 0.9467999935150146 
2025-07-08 10:29:26.946690:  
2025-07-08 10:29:26.947260: Epoch 722 
2025-07-08 10:29:26.947445: Current learning rate: 0.00316 
2025-07-08 10:30:14.707682: train_loss -0.9305 
2025-07-08 10:30:14.708108: val_loss -0.9339 
2025-07-08 10:30:14.708210: Pseudo dice [np.float32(0.9495)] 
2025-07-08 10:30:14.708322: Epoch time: 47.76 s 
2025-07-08 10:30:14.708398: Yayy! New best EMA pseudo Dice: 0.9470999836921692 
2025-07-08 10:30:16.748055:  
2025-07-08 10:30:16.748364: Epoch 723 
2025-07-08 10:30:16.748475: Current learning rate: 0.00315 
2025-07-08 10:31:05.292268: train_loss -0.9282 
2025-07-08 10:31:05.292743: val_loss -0.9293 
2025-07-08 10:31:05.292857: Pseudo dice [np.float32(0.9452)] 
2025-07-08 10:31:05.292981: Epoch time: 48.55 s 
2025-07-08 10:31:06.508137:  
2025-07-08 10:31:06.508614: Epoch 724 
2025-07-08 10:31:06.508775: Current learning rate: 0.00314 
2025-07-08 10:31:54.335469: train_loss -0.9262 
2025-07-08 10:31:54.336162: val_loss -0.9106 
2025-07-08 10:31:54.336262: Pseudo dice [np.float32(0.9344)] 
2025-07-08 10:31:54.336389: Epoch time: 47.83 s 
2025-07-08 10:31:55.526648:  
2025-07-08 10:31:55.527107: Epoch 725 
2025-07-08 10:31:55.527277: Current learning rate: 0.00313 
2025-07-08 10:32:45.217428: train_loss -0.9121 
2025-07-08 10:32:45.217954: val_loss -0.9163 
2025-07-08 10:32:45.218040: Pseudo dice [np.float32(0.9388)] 
2025-07-08 10:32:45.218148: Epoch time: 49.69 s 
2025-07-08 10:32:46.419557:  
2025-07-08 10:32:46.419899: Epoch 726 
2025-07-08 10:32:46.420048: Current learning rate: 0.00312 
2025-07-08 10:33:36.073865: train_loss -0.9178 
2025-07-08 10:33:36.074205: val_loss -0.9182 
2025-07-08 10:33:36.074285: Pseudo dice [np.float32(0.9447)] 
2025-07-08 10:33:36.074389: Epoch time: 49.66 s 
2025-07-08 10:33:37.336610:  
2025-07-08 10:33:37.337219: Epoch 727 
2025-07-08 10:33:37.337405: Current learning rate: 0.00311 
2025-07-08 10:34:28.070101: train_loss -0.9258 
2025-07-08 10:34:28.070861: val_loss -0.9311 
2025-07-08 10:34:28.070973: Pseudo dice [np.float32(0.9439)] 
2025-07-08 10:34:28.071115: Epoch time: 50.73 s 
2025-07-08 10:34:29.441094:  
2025-07-08 10:34:29.441831: Epoch 728 
2025-07-08 10:34:29.441975: Current learning rate: 0.0031 
2025-07-08 10:35:18.971396: train_loss -0.9254 
2025-07-08 10:35:18.971933: val_loss -0.9311 
2025-07-08 10:35:18.972022: Pseudo dice [np.float32(0.9472)] 
2025-07-08 10:35:18.972135: Epoch time: 49.53 s 
2025-07-08 10:35:20.213893:  
2025-07-08 10:35:20.214145: Epoch 729 
2025-07-08 10:35:20.214431: Current learning rate: 0.00309 
2025-07-08 10:36:11.505087: train_loss -0.9253 
2025-07-08 10:36:11.506686: val_loss -0.9299 
2025-07-08 10:36:11.506870: Pseudo dice [np.float32(0.9468)] 
2025-07-08 10:36:11.507053: Epoch time: 51.29 s 
2025-07-08 10:36:12.790861:  
2025-07-08 10:36:12.791234: Epoch 730 
2025-07-08 10:36:12.791420: Current learning rate: 0.00308 
2025-07-08 10:37:01.128740: train_loss -0.9186 
2025-07-08 10:37:01.130140: val_loss -0.9249 
2025-07-08 10:37:01.130313: Pseudo dice [np.float32(0.9411)] 
2025-07-08 10:37:01.130631: Epoch time: 48.34 s 
2025-07-08 10:37:02.421379:  
2025-07-08 10:37:02.421844: Epoch 731 
2025-07-08 10:37:02.421981: Current learning rate: 0.00307 
2025-07-08 10:37:51.911003: train_loss -0.9257 
2025-07-08 10:37:51.911833: val_loss -0.9226 
2025-07-08 10:37:51.911930: Pseudo dice [np.float32(0.9446)] 
2025-07-08 10:37:51.912053: Epoch time: 49.49 s 
2025-07-08 10:37:53.262041:  
2025-07-08 10:37:53.262324: Epoch 732 
2025-07-08 10:37:53.262638: Current learning rate: 0.00306 
2025-07-08 10:38:44.413546: train_loss -0.9219 
2025-07-08 10:38:44.414134: val_loss -0.9316 
2025-07-08 10:38:44.414248: Pseudo dice [np.float32(0.946)] 
2025-07-08 10:38:44.414393: Epoch time: 51.15 s 
2025-07-08 10:38:45.685695:  
2025-07-08 10:38:45.686098: Epoch 733 
2025-07-08 10:38:45.686216: Current learning rate: 0.00305 
2025-07-08 10:39:35.238668: train_loss -0.9253 
2025-07-08 10:39:35.239609: val_loss -0.9348 
2025-07-08 10:39:35.239725: Pseudo dice [np.float32(0.9499)] 
2025-07-08 10:39:35.239860: Epoch time: 49.55 s 
2025-07-08 10:39:36.507218:  
2025-07-08 10:39:36.507431: Epoch 734 
2025-07-08 10:39:36.507556: Current learning rate: 0.00304 
2025-07-08 10:40:26.277677: train_loss -0.9274 
2025-07-08 10:40:26.278084: val_loss -0.9194 
2025-07-08 10:40:26.278162: Pseudo dice [np.float32(0.9433)] 
2025-07-08 10:40:26.278256: Epoch time: 49.77 s 
2025-07-08 10:40:27.521959:  
2025-07-08 10:40:27.522267: Epoch 735 
2025-07-08 10:40:27.522371: Current learning rate: 0.00303 
2025-07-08 10:41:17.558129: train_loss -0.9245 
2025-07-08 10:41:17.558967: val_loss -0.9392 
2025-07-08 10:41:17.559072: Pseudo dice [np.float32(0.9532)] 
2025-07-08 10:41:17.559180: Epoch time: 50.04 s 
2025-07-08 10:41:18.813201:  
2025-07-08 10:41:18.813351: Epoch 736 
2025-07-08 10:41:18.813475: Current learning rate: 0.00302 
2025-07-08 10:42:09.676387: train_loss -0.9216 
2025-07-08 10:42:09.676914: val_loss -0.9325 
2025-07-08 10:42:09.677007: Pseudo dice [np.float32(0.9423)] 
2025-07-08 10:42:09.677122: Epoch time: 50.86 s 
2025-07-08 10:42:10.939325:  
2025-07-08 10:42:10.939610: Epoch 737 
2025-07-08 10:42:10.939831: Current learning rate: 0.00301 
2025-07-08 10:43:01.524722: train_loss -0.9238 
2025-07-08 10:43:01.525084: val_loss -0.9221 
2025-07-08 10:43:01.525161: Pseudo dice [np.float32(0.9399)] 
2025-07-08 10:43:01.525266: Epoch time: 50.59 s 
2025-07-08 10:43:02.710003:  
2025-07-08 10:43:02.710270: Epoch 738 
2025-07-08 10:43:02.710372: Current learning rate: 0.003 
2025-07-08 10:43:52.294551: train_loss -0.9282 
2025-07-08 10:43:52.295109: val_loss -0.9371 
2025-07-08 10:43:52.295217: Pseudo dice [np.float32(0.9532)] 
2025-07-08 10:43:52.295342: Epoch time: 49.59 s 
2025-07-08 10:43:53.525105:  
2025-07-08 10:43:53.525709: Epoch 739 
2025-07-08 10:43:53.525895: Current learning rate: 0.00299 
2025-07-08 10:44:43.328977: train_loss -0.9259 
2025-07-08 10:44:43.329574: val_loss -0.9234 
2025-07-08 10:44:43.329861: Pseudo dice [np.float32(0.9463)] 
2025-07-08 10:44:43.329992: Epoch time: 49.81 s 
2025-07-08 10:44:44.840564:  
2025-07-08 10:44:44.840800: Epoch 740 
2025-07-08 10:44:44.840916: Current learning rate: 0.00297 
2025-07-08 10:45:36.917928: train_loss -0.9284 
2025-07-08 10:45:36.918499: val_loss -0.9289 
2025-07-08 10:45:36.918614: Pseudo dice [np.float32(0.9469)] 
2025-07-08 10:45:36.918729: Epoch time: 52.08 s 
2025-07-08 10:45:38.100201:  
2025-07-08 10:45:38.100694: Epoch 741 
2025-07-08 10:45:38.100795: Current learning rate: 0.00296 
2025-07-08 10:46:26.988827: train_loss -0.9309 
2025-07-08 10:46:26.989355: val_loss -0.9274 
2025-07-08 10:46:26.989443: Pseudo dice [np.float32(0.9441)] 
2025-07-08 10:46:26.989574: Epoch time: 48.89 s 
2025-07-08 10:46:28.214223:  
2025-07-08 10:46:28.214415: Epoch 742 
2025-07-08 10:46:28.214596: Current learning rate: 0.00295 
2025-07-08 10:47:18.007606: train_loss -0.9302 
2025-07-08 10:47:18.008293: val_loss -0.935 
2025-07-08 10:47:18.008392: Pseudo dice [np.float32(0.949)] 
2025-07-08 10:47:18.008559: Epoch time: 49.79 s 
2025-07-08 10:47:19.263070:  
2025-07-08 10:47:19.263283: Epoch 743 
2025-07-08 10:47:19.263382: Current learning rate: 0.00294 
2025-07-08 10:48:09.414697: train_loss -0.9313 
2025-07-08 10:48:09.415220: val_loss -0.9275 
2025-07-08 10:48:09.415304: Pseudo dice [np.float32(0.9407)] 
2025-07-08 10:48:09.415412: Epoch time: 50.15 s 
2025-07-08 10:48:10.645816:  
2025-07-08 10:48:10.646231: Epoch 744 
2025-07-08 10:48:10.646333: Current learning rate: 0.00293 
2025-07-08 10:49:00.357692: train_loss -0.9248 
2025-07-08 10:49:00.358134: val_loss -0.9263 
2025-07-08 10:49:00.358214: Pseudo dice [np.float32(0.9429)] 
2025-07-08 10:49:00.358315: Epoch time: 49.71 s 
2025-07-08 10:49:01.594929:  
2025-07-08 10:49:01.595268: Epoch 745 
2025-07-08 10:49:01.595393: Current learning rate: 0.00292 
2025-07-08 10:49:50.729238: train_loss -0.9265 
2025-07-08 10:49:50.729809: val_loss -0.9338 
2025-07-08 10:49:50.729894: Pseudo dice [np.float32(0.9452)] 
2025-07-08 10:49:50.730000: Epoch time: 49.14 s 
2025-07-08 10:49:51.923464:  
2025-07-08 10:49:51.923617: Epoch 746 
2025-07-08 10:49:51.923792: Current learning rate: 0.00291 
2025-07-08 10:50:39.698596: train_loss -0.9274 
2025-07-08 10:50:39.699116: val_loss -0.9362 
2025-07-08 10:50:39.699207: Pseudo dice [np.float32(0.9496)] 
2025-07-08 10:50:39.699329: Epoch time: 47.78 s 
2025-07-08 10:50:40.932554:  
2025-07-08 10:50:40.932809: Epoch 747 
2025-07-08 10:50:40.932964: Current learning rate: 0.0029 
2025-07-08 10:51:30.318930: train_loss -0.9282 
2025-07-08 10:51:30.319573: val_loss -0.9292 
2025-07-08 10:51:30.319670: Pseudo dice [np.float32(0.9427)] 
2025-07-08 10:51:30.319823: Epoch time: 49.39 s 
2025-07-08 10:51:31.511889:  
2025-07-08 10:51:31.512359: Epoch 748 
2025-07-08 10:51:31.512519: Current learning rate: 0.00289 
2025-07-08 10:52:22.208801: train_loss -0.93 
2025-07-08 10:52:22.210130: val_loss -0.9358 
2025-07-08 10:52:22.210441: Pseudo dice [np.float32(0.951)] 
2025-07-08 10:52:22.210737: Epoch time: 50.7 s 
2025-07-08 10:52:23.530771:  
2025-07-08 10:52:23.531126: Epoch 749 
2025-07-08 10:52:23.531314: Current learning rate: 0.00288 
2025-07-08 10:53:12.416485: train_loss -0.9272 
2025-07-08 10:53:12.417006: val_loss -0.9337 
2025-07-08 10:53:12.417136: Pseudo dice [np.float32(0.95)] 
2025-07-08 10:53:12.417300: Epoch time: 48.89 s 
2025-07-08 10:53:14.520374:  
2025-07-08 10:53:14.520738: Epoch 750 
2025-07-08 10:53:14.520870: Current learning rate: 0.00287 
2025-07-08 10:54:06.225106: train_loss -0.9245 
2025-07-08 10:54:06.225606: val_loss -0.9253 
2025-07-08 10:54:06.225704: Pseudo dice [np.float32(0.9453)] 
2025-07-08 10:54:06.225830: Epoch time: 51.71 s 
2025-07-08 10:54:07.372684:  
2025-07-08 10:54:07.372883: Epoch 751 
2025-07-08 10:54:07.373157: Current learning rate: 0.00286 
2025-07-08 10:54:56.921723: train_loss -0.9297 
2025-07-08 10:54:56.922087: val_loss -0.9381 
2025-07-08 10:54:56.922164: Pseudo dice [np.float32(0.9503)] 
2025-07-08 10:54:56.922285: Epoch time: 49.55 s 
2025-07-08 10:54:58.895673:  
2025-07-08 10:54:58.895875: Epoch 752 
2025-07-08 10:54:58.895977: Current learning rate: 0.00285 
2025-07-08 10:55:48.824638: train_loss -0.9265 
2025-07-08 10:55:48.824955: val_loss -0.9217 
2025-07-08 10:55:48.825039: Pseudo dice [np.float32(0.9458)] 
2025-07-08 10:55:48.825125: Epoch time: 49.93 s 
2025-07-08 10:55:49.942570:  
2025-07-08 10:55:49.942897: Epoch 753 
2025-07-08 10:55:49.943053: Current learning rate: 0.00284 
2025-07-08 10:56:38.644139: train_loss -0.9267 
2025-07-08 10:56:38.644670: val_loss -0.9341 
2025-07-08 10:56:38.644775: Pseudo dice [np.float32(0.9482)] 
2025-07-08 10:56:38.644897: Epoch time: 48.7 s 
2025-07-08 10:56:39.924993:  
2025-07-08 10:56:39.926109: Epoch 754 
2025-07-08 10:56:39.926383: Current learning rate: 0.00283 
2025-07-08 10:57:28.232845: train_loss -0.9239 
2025-07-08 10:57:28.233322: val_loss -0.934 
2025-07-08 10:57:28.233417: Pseudo dice [np.float32(0.9452)] 
2025-07-08 10:57:28.233547: Epoch time: 48.31 s 
2025-07-08 10:57:29.459450:  
2025-07-08 10:57:29.459772: Epoch 755 
2025-07-08 10:57:29.460080: Current learning rate: 0.00282 
2025-07-08 10:58:20.870050: train_loss -0.9246 
2025-07-08 10:58:20.870686: val_loss -0.9339 
2025-07-08 10:58:20.870815: Pseudo dice [np.float32(0.9465)] 
2025-07-08 10:58:20.870980: Epoch time: 51.41 s 
2025-07-08 10:58:22.083887:  
2025-07-08 10:58:22.084311: Epoch 756 
2025-07-08 10:58:22.084563: Current learning rate: 0.00281 
2025-07-08 10:59:12.105719: train_loss -0.9298 
2025-07-08 10:59:12.106094: val_loss -0.9336 
2025-07-08 10:59:12.106175: Pseudo dice [np.float32(0.949)] 
2025-07-08 10:59:12.106287: Epoch time: 50.02 s 
2025-07-08 10:59:13.294250:  
2025-07-08 10:59:13.294533: Epoch 757 
2025-07-08 10:59:13.294677: Current learning rate: 0.0028 
2025-07-08 11:00:01.721329: train_loss -0.9283 
2025-07-08 11:00:01.722619: val_loss -0.9222 
2025-07-08 11:00:01.722826: Pseudo dice [np.float32(0.947)] 
2025-07-08 11:00:01.723053: Epoch time: 48.43 s 
2025-07-08 11:00:02.921857:  
2025-07-08 11:00:02.922399: Epoch 758 
2025-07-08 11:00:02.922529: Current learning rate: 0.00279 
2025-07-08 11:00:52.811974: train_loss -0.9282 
2025-07-08 11:00:52.812403: val_loss -0.935 
2025-07-08 11:00:52.812566: Pseudo dice [np.float32(0.9461)] 
2025-07-08 11:00:52.812680: Epoch time: 49.89 s 
2025-07-08 11:00:54.140495:  
2025-07-08 11:00:54.141150: Epoch 759 
2025-07-08 11:00:54.141278: Current learning rate: 0.00278 
2025-07-08 11:01:43.029781: train_loss -0.9319 
2025-07-08 11:01:43.030521: val_loss -0.9354 
2025-07-08 11:01:43.030629: Pseudo dice [np.float32(0.9479)] 
2025-07-08 11:01:43.030766: Epoch time: 48.89 s 
2025-07-08 11:01:44.292798:  
2025-07-08 11:01:44.293153: Epoch 760 
2025-07-08 11:01:44.293398: Current learning rate: 0.00277 
2025-07-08 11:02:33.754227: train_loss -0.9275 
2025-07-08 11:02:33.754842: val_loss -0.9331 
2025-07-08 11:02:33.758173: Pseudo dice [np.float32(0.9486)] 
2025-07-08 11:02:33.758340: Epoch time: 49.46 s 
2025-07-08 11:02:34.982082:  
2025-07-08 11:02:34.982268: Epoch 761 
2025-07-08 11:02:34.982398: Current learning rate: 0.00276 
2025-07-08 11:03:24.881385: train_loss -0.93 
2025-07-08 11:03:24.882468: val_loss -0.9395 
2025-07-08 11:03:24.882597: Pseudo dice [np.float32(0.9531)] 
2025-07-08 11:03:24.882750: Epoch time: 49.9 s 
2025-07-08 11:03:24.882846: Yayy! New best EMA pseudo Dice: 0.947700023651123 
2025-07-08 11:03:27.004670:  
2025-07-08 11:03:27.005058: Epoch 762 
2025-07-08 11:03:27.005324: Current learning rate: 0.00275 
2025-07-08 11:04:17.230178: train_loss -0.9047 
2025-07-08 11:04:17.231182: val_loss -0.898 
2025-07-08 11:04:17.231398: Pseudo dice [np.float32(0.923)] 
2025-07-08 11:04:17.231589: Epoch time: 50.23 s 
2025-07-08 11:04:18.403397:  
2025-07-08 11:04:18.403696: Epoch 763 
2025-07-08 11:04:18.403893: Current learning rate: 0.00274 
2025-07-08 11:05:07.099231: train_loss -0.8989 
2025-07-08 11:05:07.099774: val_loss -0.907 
2025-07-08 11:05:07.099866: Pseudo dice [np.float32(0.9249)] 
2025-07-08 11:05:07.100012: Epoch time: 48.7 s 
2025-07-08 11:05:08.303130:  
2025-07-08 11:05:08.303449: Epoch 764 
2025-07-08 11:05:08.303579: Current learning rate: 0.00273 
2025-07-08 11:05:58.281735: train_loss -0.9066 
2025-07-08 11:05:58.282326: val_loss -0.9209 
2025-07-08 11:05:58.282426: Pseudo dice [np.float32(0.9336)] 
2025-07-08 11:05:58.282555: Epoch time: 49.98 s 
2025-07-08 11:05:59.472515:  
2025-07-08 11:05:59.472998: Epoch 765 
2025-07-08 11:05:59.473224: Current learning rate: 0.00272 
2025-07-08 11:06:48.873322: train_loss -0.9176 
2025-07-08 11:06:48.874017: val_loss -0.9202 
2025-07-08 11:06:48.874102: Pseudo dice [np.float32(0.9371)] 
2025-07-08 11:06:48.874214: Epoch time: 49.4 s 
2025-07-08 11:06:50.082722:  
2025-07-08 11:06:50.083007: Epoch 766 
2025-07-08 11:06:50.083268: Current learning rate: 0.00271 
2025-07-08 11:07:39.214128: train_loss -0.9217 
2025-07-08 11:07:39.214440: val_loss -0.934 
2025-07-08 11:07:39.214528: Pseudo dice [np.float32(0.9451)] 
2025-07-08 11:07:39.214702: Epoch time: 49.13 s 
2025-07-08 11:07:41.680794:  
2025-07-08 11:07:41.681203: Epoch 767 
2025-07-08 11:07:41.681688: Current learning rate: 0.0027 
2025-07-08 11:08:30.907907: train_loss -0.9219 
2025-07-08 11:08:30.908713: val_loss -0.9296 
2025-07-08 11:08:30.908930: Pseudo dice [np.float32(0.9402)] 
2025-07-08 11:08:30.909066: Epoch time: 49.23 s 
2025-07-08 11:08:32.151392:  
2025-07-08 11:08:32.151898: Epoch 768 
2025-07-08 11:08:32.152106: Current learning rate: 0.00268 
2025-07-08 11:09:19.886651: train_loss -0.9266 
2025-07-08 11:09:19.887064: val_loss -0.937 
2025-07-08 11:09:19.887148: Pseudo dice [np.float32(0.9544)] 
2025-07-08 11:09:19.887249: Epoch time: 47.74 s 
2025-07-08 11:09:21.152580:  
2025-07-08 11:09:21.152874: Epoch 769 
2025-07-08 11:09:21.153038: Current learning rate: 0.00267 
2025-07-08 11:10:08.958699: train_loss -0.9274 
2025-07-08 11:10:08.959264: val_loss -0.9367 
2025-07-08 11:10:08.959359: Pseudo dice [np.float32(0.9504)] 
2025-07-08 11:10:08.959476: Epoch time: 47.81 s 
2025-07-08 11:10:10.245313:  
2025-07-08 11:10:10.245725: Epoch 770 
2025-07-08 11:10:10.245913: Current learning rate: 0.00266 
2025-07-08 11:10:59.492617: train_loss -0.9262 
2025-07-08 11:10:59.492968: val_loss -0.9259 
2025-07-08 11:10:59.493045: Pseudo dice [np.float32(0.9387)] 
2025-07-08 11:10:59.493147: Epoch time: 49.25 s 
2025-07-08 11:11:00.640665:  
2025-07-08 11:11:00.641191: Epoch 771 
2025-07-08 11:11:00.641314: Current learning rate: 0.00265 
2025-07-08 11:11:48.482440: train_loss -0.9261 
2025-07-08 11:11:48.483322: val_loss -0.9251 
2025-07-08 11:11:48.483686: Pseudo dice [np.float32(0.9456)] 
2025-07-08 11:11:48.483955: Epoch time: 47.84 s 
2025-07-08 11:11:49.749701:  
2025-07-08 11:11:49.750342: Epoch 772 
2025-07-08 11:11:49.750594: Current learning rate: 0.00264 
2025-07-08 11:12:38.877331: train_loss -0.9263 
2025-07-08 11:12:38.877813: val_loss -0.9362 
2025-07-08 11:12:38.877896: Pseudo dice [np.float32(0.9489)] 
2025-07-08 11:12:38.878006: Epoch time: 49.13 s 
2025-07-08 11:12:40.166385:  
2025-07-08 11:12:40.166603: Epoch 773 
2025-07-08 11:12:40.166757: Current learning rate: 0.00263 
2025-07-08 11:13:27.361776: train_loss -0.9246 
2025-07-08 11:13:27.362276: val_loss -0.9293 
2025-07-08 11:13:27.362359: Pseudo dice [np.float32(0.943)] 
2025-07-08 11:13:27.362463: Epoch time: 47.2 s 
2025-07-08 11:13:28.601981:  
2025-07-08 11:13:28.602268: Epoch 774 
2025-07-08 11:13:28.602531: Current learning rate: 0.00262 
2025-07-08 11:14:17.541572: train_loss -0.9261 
2025-07-08 11:14:17.542214: val_loss -0.9242 
2025-07-08 11:14:17.542316: Pseudo dice [np.float32(0.938)] 
2025-07-08 11:14:17.542455: Epoch time: 48.94 s 
2025-07-08 11:14:18.726659:  
2025-07-08 11:14:18.727006: Epoch 775 
2025-07-08 11:14:18.727126: Current learning rate: 0.00261 
2025-07-08 11:15:06.224372: train_loss -0.925 
2025-07-08 11:15:06.225035: val_loss -0.9257 
2025-07-08 11:15:06.225134: Pseudo dice [np.float32(0.9398)] 
2025-07-08 11:15:06.225280: Epoch time: 47.5 s 
2025-07-08 11:15:07.510769:  
2025-07-08 11:15:07.511160: Epoch 776 
2025-07-08 11:15:07.511347: Current learning rate: 0.0026 
2025-07-08 11:15:55.441824: train_loss -0.9239 
2025-07-08 11:15:55.442680: val_loss -0.9317 
2025-07-08 11:15:55.446340: Pseudo dice [np.float32(0.9475)] 
2025-07-08 11:15:55.446493: Epoch time: 47.93 s 
2025-07-08 11:15:56.686555:  
2025-07-08 11:15:56.686877: Epoch 777 
2025-07-08 11:15:56.687056: Current learning rate: 0.00259 
2025-07-08 11:16:43.768257: train_loss -0.931 
2025-07-08 11:16:43.768800: val_loss -0.9348 
2025-07-08 11:16:43.768913: Pseudo dice [np.float32(0.9472)] 
2025-07-08 11:16:43.769065: Epoch time: 47.08 s 
2025-07-08 11:16:44.948678:  
2025-07-08 11:16:44.949042: Epoch 778 
2025-07-08 11:16:44.949178: Current learning rate: 0.00258 
2025-07-08 11:17:34.992652: train_loss -0.9292 
2025-07-08 11:17:34.993165: val_loss -0.933 
2025-07-08 11:17:34.993276: Pseudo dice [np.float32(0.9488)] 
2025-07-08 11:17:34.993410: Epoch time: 50.05 s 
2025-07-08 11:17:36.295818:  
2025-07-08 11:17:36.296312: Epoch 779 
2025-07-08 11:17:36.296650: Current learning rate: 0.00257 
2025-07-08 11:18:25.291272: train_loss -0.9217 
2025-07-08 11:18:25.291778: val_loss -0.9273 
2025-07-08 11:18:25.291860: Pseudo dice [np.float32(0.9514)] 
2025-07-08 11:18:25.291959: Epoch time: 49.0 s 
2025-07-08 11:18:26.529509:  
2025-07-08 11:18:26.530103: Epoch 780 
2025-07-08 11:18:26.530273: Current learning rate: 0.00256 
2025-07-08 11:19:14.961921: train_loss -0.9269 
2025-07-08 11:19:14.962576: val_loss -0.9293 
2025-07-08 11:19:14.962708: Pseudo dice [np.float32(0.944)] 
2025-07-08 11:19:14.962841: Epoch time: 48.43 s 
2025-07-08 11:19:16.222267:  
2025-07-08 11:19:16.222787: Epoch 781 
2025-07-08 11:19:16.222932: Current learning rate: 0.00255 
2025-07-08 11:20:05.838742: train_loss -0.9284 
2025-07-08 11:20:05.839521: val_loss -0.9375 
2025-07-08 11:20:05.839789: Pseudo dice [np.float32(0.9481)] 
2025-07-08 11:20:05.839928: Epoch time: 49.62 s 
2025-07-08 11:20:07.927768:  
2025-07-08 11:20:07.927940: Epoch 782 
2025-07-08 11:20:07.928070: Current learning rate: 0.00254 
2025-07-08 11:20:56.197430: train_loss -0.9303 
2025-07-08 11:20:56.198086: val_loss -0.9315 
2025-07-08 11:20:56.198185: Pseudo dice [np.float32(0.9426)] 
2025-07-08 11:20:56.198318: Epoch time: 48.27 s 
2025-07-08 11:20:57.536961:  
2025-07-08 11:20:57.537407: Epoch 783 
2025-07-08 11:20:57.537517: Current learning rate: 0.00253 
2025-07-08 11:21:45.794872: train_loss -0.9284 
2025-07-08 11:21:45.795758: val_loss -0.9349 
2025-07-08 11:21:45.798993: Pseudo dice [np.float32(0.9494)] 
2025-07-08 11:21:45.799356: Epoch time: 48.26 s 
2025-07-08 11:21:46.975532:  
2025-07-08 11:21:46.975927: Epoch 784 
2025-07-08 11:21:46.976032: Current learning rate: 0.00252 
2025-07-08 11:22:35.979748: train_loss -0.9279 
2025-07-08 11:22:35.980325: val_loss -0.9357 
2025-07-08 11:22:35.980404: Pseudo dice [np.float32(0.95)] 
2025-07-08 11:22:35.980518: Epoch time: 49.01 s 
2025-07-08 11:22:37.181740:  
2025-07-08 11:22:37.182156: Epoch 785 
2025-07-08 11:22:37.182293: Current learning rate: 0.00251 
2025-07-08 11:23:27.205516: train_loss -0.9287 
2025-07-08 11:23:27.206485: val_loss -0.9342 
2025-07-08 11:23:27.206614: Pseudo dice [np.float32(0.9471)] 
2025-07-08 11:23:27.206750: Epoch time: 50.02 s 
2025-07-08 11:23:28.394137:  
2025-07-08 11:23:28.394628: Epoch 786 
2025-07-08 11:23:28.394888: Current learning rate: 0.0025 
2025-07-08 11:24:16.235262: train_loss -0.9267 
2025-07-08 11:24:16.235934: val_loss -0.9376 
2025-07-08 11:24:16.236042: Pseudo dice [np.float32(0.9495)] 
2025-07-08 11:24:16.236168: Epoch time: 47.84 s 
2025-07-08 11:24:17.501355:  
2025-07-08 11:24:17.501671: Epoch 787 
2025-07-08 11:24:17.501791: Current learning rate: 0.00249 
2025-07-08 11:25:05.971514: train_loss -0.9296 
2025-07-08 11:25:05.972301: val_loss -0.936 
2025-07-08 11:25:05.972382: Pseudo dice [np.float32(0.9509)] 
2025-07-08 11:25:05.972505: Epoch time: 48.47 s 
2025-07-08 11:25:07.183598:  
2025-07-08 11:25:07.184000: Epoch 788 
2025-07-08 11:25:07.184130: Current learning rate: 0.00248 
2025-07-08 11:25:56.976003: train_loss -0.9319 
2025-07-08 11:25:56.976571: val_loss -0.9335 
2025-07-08 11:25:56.976655: Pseudo dice [np.float32(0.948)] 
2025-07-08 11:25:56.976792: Epoch time: 49.79 s 
2025-07-08 11:25:58.316021:  
2025-07-08 11:25:58.316355: Epoch 789 
2025-07-08 11:25:58.316492: Current learning rate: 0.00247 
2025-07-08 11:26:48.159088: train_loss -0.9313 
2025-07-08 11:26:48.159714: val_loss -0.9373 
2025-07-08 11:26:48.159796: Pseudo dice [np.float32(0.9529)] 
2025-07-08 11:26:48.159909: Epoch time: 49.84 s 
2025-07-08 11:26:49.466567:  
2025-07-08 11:26:49.467016: Epoch 790 
2025-07-08 11:26:49.467246: Current learning rate: 0.00245 
2025-07-08 11:27:38.399111: train_loss -0.9327 
2025-07-08 11:27:38.399645: val_loss -0.933 
2025-07-08 11:27:38.399731: Pseudo dice [np.float32(0.9494)] 
2025-07-08 11:27:38.399839: Epoch time: 48.93 s 
2025-07-08 11:27:38.399922: Yayy! New best EMA pseudo Dice: 0.947700023651123 
2025-07-08 11:27:40.678537:  
2025-07-08 11:27:40.678873: Epoch 791 
2025-07-08 11:27:40.679108: Current learning rate: 0.00244 
2025-07-08 11:28:29.497307: train_loss -0.9294 
2025-07-08 11:28:29.498498: val_loss -0.9298 
2025-07-08 11:28:29.498663: Pseudo dice [np.float32(0.9457)] 
2025-07-08 11:28:29.498828: Epoch time: 48.82 s 
2025-07-08 11:28:30.704751:  
2025-07-08 11:28:30.705177: Epoch 792 
2025-07-08 11:28:30.705352: Current learning rate: 0.00243 
2025-07-08 11:29:19.888126: train_loss -0.9328 
2025-07-08 11:29:19.888885: val_loss -0.9399 
2025-07-08 11:29:19.889086: Pseudo dice [np.float32(0.9522)] 
2025-07-08 11:29:19.889265: Epoch time: 49.18 s 
2025-07-08 11:29:19.889354: Yayy! New best EMA pseudo Dice: 0.9480000138282776 
2025-07-08 11:29:22.147439:  
2025-07-08 11:29:22.148088: Epoch 793 
2025-07-08 11:29:22.148212: Current learning rate: 0.00242 
2025-07-08 11:30:12.473470: train_loss -0.9316 
2025-07-08 11:30:12.473959: val_loss -0.9355 
2025-07-08 11:30:12.474047: Pseudo dice [np.float32(0.9499)] 
2025-07-08 11:30:12.474160: Epoch time: 50.33 s 
2025-07-08 11:30:12.474235: Yayy! New best EMA pseudo Dice: 0.948199987411499 
2025-07-08 11:30:14.590688:  
2025-07-08 11:30:14.591017: Epoch 794 
2025-07-08 11:30:14.591125: Current learning rate: 0.00241 
2025-07-08 11:31:03.986081: train_loss -0.9305 
2025-07-08 11:31:03.986732: val_loss -0.9393 
2025-07-08 11:31:03.986817: Pseudo dice [np.float32(0.9481)] 
2025-07-08 11:31:03.986911: Epoch time: 49.4 s 
2025-07-08 11:31:05.171818:  
2025-07-08 11:31:05.172217: Epoch 795 
2025-07-08 11:31:05.172329: Current learning rate: 0.0024 
2025-07-08 11:31:53.952384: train_loss -0.9269 
2025-07-08 11:31:53.952871: val_loss -0.9344 
2025-07-08 11:31:53.953032: Pseudo dice [np.float32(0.9438)] 
2025-07-08 11:31:53.953132: Epoch time: 48.78 s 
2025-07-08 11:31:55.116167:  
2025-07-08 11:31:55.116623: Epoch 796 
2025-07-08 11:31:55.116850: Current learning rate: 0.00239 
2025-07-08 11:32:44.449665: train_loss -0.9246 
2025-07-08 11:32:44.450592: val_loss -0.9386 
2025-07-08 11:32:44.450711: Pseudo dice [np.float32(0.9507)] 
2025-07-08 11:32:44.450853: Epoch time: 49.33 s 
2025-07-08 11:32:46.528492:  
2025-07-08 11:32:46.528860: Epoch 797 
2025-07-08 11:32:46.529030: Current learning rate: 0.00238 
2025-07-08 11:33:35.149046: train_loss -0.931 
2025-07-08 11:33:35.149528: val_loss -0.9356 
2025-07-08 11:33:35.149632: Pseudo dice [np.float32(0.951)] 
2025-07-08 11:33:35.149749: Epoch time: 48.62 s 
2025-07-08 11:33:35.149830: Yayy! New best EMA pseudo Dice: 0.9483000040054321 
2025-07-08 11:33:37.315662:  
2025-07-08 11:33:37.315954: Epoch 798 
2025-07-08 11:33:37.316148: Current learning rate: 0.00237 
2025-07-08 11:34:26.461244: train_loss -0.9284 
2025-07-08 11:34:26.461907: val_loss -0.9372 
2025-07-08 11:34:26.462049: Pseudo dice [np.float32(0.9502)] 
2025-07-08 11:34:26.462198: Epoch time: 49.15 s 
2025-07-08 11:34:26.462301: Yayy! New best EMA pseudo Dice: 0.9484999775886536 
2025-07-08 11:34:28.697484:  
2025-07-08 11:34:28.698045: Epoch 799 
2025-07-08 11:34:28.698239: Current learning rate: 0.00236 
2025-07-08 11:35:17.873819: train_loss -0.9323 
2025-07-08 11:35:17.874396: val_loss -0.9341 
2025-07-08 11:35:17.874482: Pseudo dice [np.float32(0.9489)] 
2025-07-08 11:35:17.874614: Epoch time: 49.18 s 
2025-07-08 11:35:18.954075: Yayy! New best EMA pseudo Dice: 0.9485999941825867 
2025-07-08 11:35:20.966936:  
2025-07-08 11:35:20.967465: Epoch 800 
2025-07-08 11:35:20.967651: Current learning rate: 0.00235 
2025-07-08 11:36:10.853142: train_loss -0.93 
2025-07-08 11:36:10.853945: val_loss -0.935 
2025-07-08 11:36:10.854068: Pseudo dice [np.float32(0.9463)] 
2025-07-08 11:36:10.854216: Epoch time: 49.89 s 
2025-07-08 11:36:12.160021:  
2025-07-08 11:36:12.160707: Epoch 801 
2025-07-08 11:36:12.160907: Current learning rate: 0.00234 
2025-07-08 11:37:03.335574: train_loss -0.9311 
2025-07-08 11:37:03.337177: val_loss -0.9361 
2025-07-08 11:37:03.337300: Pseudo dice [np.float32(0.9502)] 
2025-07-08 11:37:03.337482: Epoch time: 51.18 s 
2025-07-08 11:37:04.696297:  
2025-07-08 11:37:04.697011: Epoch 802 
2025-07-08 11:37:04.697158: Current learning rate: 0.00233 
2025-07-08 11:37:55.214130: train_loss -0.9312 
2025-07-08 11:37:55.215114: val_loss -0.932 
2025-07-08 11:37:55.215240: Pseudo dice [np.float32(0.9489)] 
2025-07-08 11:37:55.215401: Epoch time: 50.52 s 
2025-07-08 11:37:56.484046:  
2025-07-08 11:37:56.484495: Epoch 803 
2025-07-08 11:37:56.484647: Current learning rate: 0.00232 
2025-07-08 11:38:45.057354: train_loss -0.9335 
2025-07-08 11:38:45.058268: val_loss -0.9248 
2025-07-08 11:38:45.058521: Pseudo dice [np.float32(0.9416)] 
2025-07-08 11:38:45.058673: Epoch time: 48.57 s 
2025-07-08 11:38:46.346518:  
2025-07-08 11:38:46.347164: Epoch 804 
2025-07-08 11:38:46.347556: Current learning rate: 0.00231 
2025-07-08 11:39:33.828146: train_loss -0.9322 
2025-07-08 11:39:33.829086: val_loss -0.9349 
2025-07-08 11:39:33.829187: Pseudo dice [np.float32(0.9481)] 
2025-07-08 11:39:33.829359: Epoch time: 47.48 s 
2025-07-08 11:39:35.037761:  
2025-07-08 11:39:35.038140: Epoch 805 
2025-07-08 11:39:35.038304: Current learning rate: 0.0023 
2025-07-08 11:40:25.332656: train_loss -0.9311 
2025-07-08 11:40:25.334831: val_loss -0.9312 
2025-07-08 11:40:25.335216: Pseudo dice [np.float32(0.9495)] 
2025-07-08 11:40:25.335475: Epoch time: 50.3 s 
2025-07-08 11:40:26.673987:  
2025-07-08 11:40:26.674204: Epoch 806 
2025-07-08 11:40:26.674335: Current learning rate: 0.00229 
2025-07-08 11:41:14.208861: train_loss -0.9328 
2025-07-08 11:41:14.209330: val_loss -0.9436 
2025-07-08 11:41:14.209713: Pseudo dice [np.float32(0.9554)] 
2025-07-08 11:41:14.209892: Epoch time: 47.54 s 
2025-07-08 11:41:14.210060: Yayy! New best EMA pseudo Dice: 0.9488000273704529 
2025-07-08 11:41:16.387627:  
2025-07-08 11:41:16.388043: Epoch 807 
2025-07-08 11:41:16.388281: Current learning rate: 0.00228 
2025-07-08 11:42:05.089384: train_loss -0.9337 
2025-07-08 11:42:05.090232: val_loss -0.9385 
2025-07-08 11:42:05.090435: Pseudo dice [np.float32(0.949)] 
2025-07-08 11:42:05.090728: Epoch time: 48.7 s 
2025-07-08 11:42:05.090935: Yayy! New best EMA pseudo Dice: 0.9488000273704529 
2025-07-08 11:42:07.354692:  
2025-07-08 11:42:07.355077: Epoch 808 
2025-07-08 11:42:07.355208: Current learning rate: 0.00226 
2025-07-08 11:42:57.316709: train_loss -0.9318 
2025-07-08 11:42:57.317125: val_loss -0.9318 
2025-07-08 11:42:57.317200: Pseudo dice [np.float32(0.9461)] 
2025-07-08 11:42:57.317303: Epoch time: 49.96 s 
2025-07-08 11:42:58.524146:  
2025-07-08 11:42:58.524513: Epoch 809 
2025-07-08 11:42:58.524664: Current learning rate: 0.00225 
2025-07-08 11:43:48.389859: train_loss -0.9311 
2025-07-08 11:43:48.390339: val_loss -0.9385 
2025-07-08 11:43:48.390425: Pseudo dice [np.float32(0.9504)] 
2025-07-08 11:43:48.390525: Epoch time: 49.87 s 
2025-07-08 11:43:49.848803:  
2025-07-08 11:43:49.848955: Epoch 810 
2025-07-08 11:43:49.849077: Current learning rate: 0.00224 
2025-07-08 11:44:40.405320: train_loss -0.9327 
2025-07-08 11:44:40.405909: val_loss -0.9296 
2025-07-08 11:44:40.405999: Pseudo dice [np.float32(0.9525)] 
2025-07-08 11:44:40.406122: Epoch time: 50.56 s 
2025-07-08 11:44:40.406204: Yayy! New best EMA pseudo Dice: 0.9491000175476074 
2025-07-08 11:44:43.727560:  
2025-07-08 11:44:43.727899: Epoch 811 
2025-07-08 11:44:43.728055: Current learning rate: 0.00223 
2025-07-08 11:45:33.532166: train_loss -0.9312 
2025-07-08 11:45:33.532950: val_loss -0.9381 
2025-07-08 11:45:33.533064: Pseudo dice [np.float32(0.955)] 
2025-07-08 11:45:33.533208: Epoch time: 49.81 s 
2025-07-08 11:45:33.533306: Yayy! New best EMA pseudo Dice: 0.9496999979019165 
2025-07-08 11:45:35.655910:  
2025-07-08 11:45:35.656223: Epoch 812 
2025-07-08 11:45:35.656531: Current learning rate: 0.00222 
2025-07-08 11:46:25.240578: train_loss -0.9347 
2025-07-08 11:46:25.241150: val_loss -0.9342 
2025-07-08 11:46:25.241237: Pseudo dice [np.float32(0.947)] 
2025-07-08 11:46:25.241378: Epoch time: 49.59 s 
2025-07-08 11:46:26.478764:  
2025-07-08 11:46:26.479019: Epoch 813 
2025-07-08 11:46:26.479185: Current learning rate: 0.00221 
2025-07-08 11:47:16.731315: train_loss -0.9347 
2025-07-08 11:47:16.731786: val_loss -0.9362 
2025-07-08 11:47:16.731867: Pseudo dice [np.float32(0.9561)] 
2025-07-08 11:47:16.731979: Epoch time: 50.25 s 
2025-07-08 11:47:16.732055: Yayy! New best EMA pseudo Dice: 0.9501000046730042 
2025-07-08 11:47:18.866597:  
2025-07-08 11:47:18.866927: Epoch 814 
2025-07-08 11:47:18.867095: Current learning rate: 0.0022 
2025-07-08 11:48:07.847349: train_loss -0.9361 
2025-07-08 11:48:07.848034: val_loss -0.9429 
2025-07-08 11:48:07.848126: Pseudo dice [np.float32(0.9516)] 
2025-07-08 11:48:07.848253: Epoch time: 48.98 s 
2025-07-08 11:48:07.848327: Yayy! New best EMA pseudo Dice: 0.9502000212669373 
2025-07-08 11:48:10.011865:  
2025-07-08 11:48:10.012363: Epoch 815 
2025-07-08 11:48:10.012488: Current learning rate: 0.00219 
2025-07-08 11:48:58.894395: train_loss -0.931 
2025-07-08 11:48:58.895269: val_loss -0.9341 
2025-07-08 11:48:58.895400: Pseudo dice [np.float32(0.9468)] 
2025-07-08 11:48:58.895587: Epoch time: 48.88 s 
2025-07-08 11:49:00.120507:  
2025-07-08 11:49:00.120795: Epoch 816 
2025-07-08 11:49:00.121078: Current learning rate: 0.00218 
2025-07-08 11:49:50.474591: train_loss -0.9359 
2025-07-08 11:49:50.475671: val_loss -0.9386 
2025-07-08 11:49:50.476073: Pseudo dice [np.float32(0.9499)] 
2025-07-08 11:49:50.476210: Epoch time: 50.36 s 
2025-07-08 11:49:51.798480:  
2025-07-08 11:49:51.798705: Epoch 817 
2025-07-08 11:49:51.798846: Current learning rate: 0.00217 
2025-07-08 11:50:41.567226: train_loss -0.9299 
2025-07-08 11:50:41.567572: val_loss -0.9385 
2025-07-08 11:50:41.567651: Pseudo dice [np.float32(0.9461)] 
2025-07-08 11:50:41.567752: Epoch time: 49.77 s 
2025-07-08 11:50:42.768563:  
2025-07-08 11:50:42.768844: Epoch 818 
2025-07-08 11:50:42.769100: Current learning rate: 0.00216 
2025-07-08 11:51:33.146717: train_loss -0.9297 
2025-07-08 11:51:33.147310: val_loss -0.9354 
2025-07-08 11:51:33.147415: Pseudo dice [np.float32(0.949)] 
2025-07-08 11:51:33.147531: Epoch time: 50.38 s 
2025-07-08 11:51:34.345695:  
2025-07-08 11:51:34.345993: Epoch 819 
2025-07-08 11:51:34.346136: Current learning rate: 0.00215 
2025-07-08 11:52:24.760935: train_loss -0.9276 
2025-07-08 11:52:24.762371: val_loss -0.9322 
2025-07-08 11:52:24.765760: Pseudo dice [np.float32(0.9475)] 
2025-07-08 11:52:24.766021: Epoch time: 50.42 s 
2025-07-08 11:52:25.981759:  
2025-07-08 11:52:25.982200: Epoch 820 
2025-07-08 11:52:25.982330: Current learning rate: 0.00214 
2025-07-08 11:53:15.207434: train_loss -0.931 
2025-07-08 11:53:15.207875: val_loss -0.9418 
2025-07-08 11:53:15.207953: Pseudo dice [np.float32(0.9517)] 
2025-07-08 11:53:15.208054: Epoch time: 49.23 s 
2025-07-08 11:53:16.364488:  
2025-07-08 11:53:16.364736: Epoch 821 
2025-07-08 11:53:16.364916: Current learning rate: 0.00213 
2025-07-08 11:54:06.645713: train_loss -0.9315 
2025-07-08 11:54:06.646412: val_loss -0.9404 
2025-07-08 11:54:06.646572: Pseudo dice [np.float32(0.9501)] 
2025-07-08 11:54:06.646728: Epoch time: 50.28 s 
2025-07-08 11:54:07.787928:  
2025-07-08 11:54:07.788164: Epoch 822 
2025-07-08 11:54:07.788284: Current learning rate: 0.00212 
2025-07-08 11:54:55.424675: train_loss -0.9335 
2025-07-08 11:54:55.425699: val_loss -0.9361 
2025-07-08 11:54:55.425848: Pseudo dice [np.float32(0.9526)] 
2025-07-08 11:54:55.426027: Epoch time: 47.64 s 
2025-07-08 11:54:56.727239:  
2025-07-08 11:54:56.727922: Epoch 823 
2025-07-08 11:54:56.728062: Current learning rate: 0.0021 
2025-07-08 11:55:47.330918: train_loss -0.9328 
2025-07-08 11:55:47.331208: val_loss -0.941 
2025-07-08 11:55:47.331419: Pseudo dice [np.float32(0.9526)] 
2025-07-08 11:55:47.331589: Epoch time: 50.6 s 
2025-07-08 11:55:48.496812:  
2025-07-08 11:55:48.497121: Epoch 824 
2025-07-08 11:55:48.497223: Current learning rate: 0.00209 
2025-07-08 11:56:38.963672: train_loss -0.9295 
2025-07-08 11:56:38.963995: val_loss -0.9392 
2025-07-08 11:56:38.964093: Pseudo dice [np.float32(0.9524)] 
2025-07-08 11:56:38.964203: Epoch time: 50.47 s 
2025-07-08 11:56:38.964344: Yayy! New best EMA pseudo Dice: 0.9503999948501587 
2025-07-08 11:56:41.000027:  
2025-07-08 11:56:41.000218: Epoch 825 
2025-07-08 11:56:41.000421: Current learning rate: 0.00208 
2025-07-08 11:57:29.645472: train_loss -0.9303 
2025-07-08 11:57:29.646030: val_loss -0.9342 
2025-07-08 11:57:29.646157: Pseudo dice [np.float32(0.9486)] 
2025-07-08 11:57:29.646317: Epoch time: 48.65 s 
2025-07-08 11:57:31.966516:  
2025-07-08 11:57:31.966864: Epoch 826 
2025-07-08 11:57:31.967091: Current learning rate: 0.00207 
2025-07-08 11:58:21.340290: train_loss -0.9319 
2025-07-08 11:58:21.340835: val_loss -0.9403 
2025-07-08 11:58:21.340931: Pseudo dice [np.float32(0.95)] 
2025-07-08 11:58:21.341048: Epoch time: 49.38 s 
2025-07-08 11:58:22.659230:  
2025-07-08 11:58:22.659622: Epoch 827 
2025-07-08 11:58:22.659773: Current learning rate: 0.00206 
2025-07-08 11:59:13.569415: train_loss -0.9329 
2025-07-08 11:59:13.569965: val_loss -0.9402 
2025-07-08 11:59:13.570299: Pseudo dice [np.float32(0.9542)] 
2025-07-08 11:59:13.571108: Epoch time: 50.91 s 
2025-07-08 11:59:13.571752: Yayy! New best EMA pseudo Dice: 0.9506000280380249 
2025-07-08 11:59:15.639695:  
2025-07-08 11:59:15.640131: Epoch 828 
2025-07-08 11:59:15.640237: Current learning rate: 0.00205 
2025-07-08 12:00:06.180077: train_loss -0.9313 
2025-07-08 12:00:06.180830: val_loss -0.9387 
2025-07-08 12:00:06.180972: Pseudo dice [np.float32(0.9506)] 
2025-07-08 12:00:06.181137: Epoch time: 50.54 s 
2025-07-08 12:00:06.181245: Yayy! New best EMA pseudo Dice: 0.9506000280380249 
2025-07-08 12:00:08.256650:  
2025-07-08 12:00:08.256786: Epoch 829 
2025-07-08 12:00:08.256898: Current learning rate: 0.00204 
2025-07-08 12:00:58.063878: train_loss -0.9323 
2025-07-08 12:00:58.064779: val_loss -0.9314 
2025-07-08 12:00:58.064898: Pseudo dice [np.float32(0.9544)] 
2025-07-08 12:00:58.065039: Epoch time: 49.81 s 
2025-07-08 12:00:58.065130: Yayy! New best EMA pseudo Dice: 0.9509999752044678 
2025-07-08 12:01:00.241936:  
2025-07-08 12:01:00.242194: Epoch 830 
2025-07-08 12:01:00.242321: Current learning rate: 0.00203 
2025-07-08 12:01:49.448022: train_loss -0.9352 
2025-07-08 12:01:49.448819: val_loss -0.9403 
2025-07-08 12:01:49.448941: Pseudo dice [np.float32(0.9524)] 
2025-07-08 12:01:49.449082: Epoch time: 49.21 s 
2025-07-08 12:01:49.449182: Yayy! New best EMA pseudo Dice: 0.9510999917984009 
2025-07-08 12:01:51.619209:  
2025-07-08 12:01:51.619460: Epoch 831 
2025-07-08 12:01:51.619662: Current learning rate: 0.00202 
2025-07-08 12:02:41.907390: train_loss -0.936 
2025-07-08 12:02:41.907845: val_loss -0.9401 
2025-07-08 12:02:41.907927: Pseudo dice [np.float32(0.9512)] 
2025-07-08 12:02:41.908038: Epoch time: 50.29 s 
2025-07-08 12:02:41.908112: Yayy! New best EMA pseudo Dice: 0.9510999917984009 
2025-07-08 12:02:44.053033:  
2025-07-08 12:02:44.053668: Epoch 832 
2025-07-08 12:02:44.053988: Current learning rate: 0.00201 
2025-07-08 12:03:34.494069: train_loss -0.9351 
2025-07-08 12:03:34.494979: val_loss -0.9442 
2025-07-08 12:03:34.495123: Pseudo dice [np.float32(0.9554)] 
2025-07-08 12:03:34.495253: Epoch time: 50.44 s 
2025-07-08 12:03:34.495333: Yayy! New best EMA pseudo Dice: 0.9514999985694885 
2025-07-08 12:03:36.702404:  
2025-07-08 12:03:36.702764: Epoch 833 
2025-07-08 12:03:36.702939: Current learning rate: 0.002 
2025-07-08 12:04:27.745306: train_loss -0.9318 
2025-07-08 12:04:27.745935: val_loss -0.9388 
2025-07-08 12:04:27.746030: Pseudo dice [np.float32(0.9553)] 
2025-07-08 12:04:27.746157: Epoch time: 51.04 s 
2025-07-08 12:04:27.746237: Yayy! New best EMA pseudo Dice: 0.9519000053405762 
2025-07-08 12:04:29.895469:  
2025-07-08 12:04:29.895802: Epoch 834 
2025-07-08 12:04:29.895994: Current learning rate: 0.00199 
2025-07-08 12:05:20.128580: train_loss -0.9332 
2025-07-08 12:05:20.128972: val_loss -0.9385 
2025-07-08 12:05:20.129062: Pseudo dice [np.float32(0.9525)] 
2025-07-08 12:05:20.129179: Epoch time: 50.23 s 
2025-07-08 12:05:20.129352: Yayy! New best EMA pseudo Dice: 0.9520000219345093 
2025-07-08 12:05:22.197014:  
2025-07-08 12:05:22.197186: Epoch 835 
2025-07-08 12:05:22.197285: Current learning rate: 0.00198 
2025-07-08 12:06:13.676334: train_loss -0.9321 
2025-07-08 12:06:13.676910: val_loss -0.9429 
2025-07-08 12:06:13.676997: Pseudo dice [np.float32(0.9548)] 
2025-07-08 12:06:13.677105: Epoch time: 51.48 s 
2025-07-08 12:06:13.677184: Yayy! New best EMA pseudo Dice: 0.9523000121116638 
2025-07-08 12:06:15.758428:  
2025-07-08 12:06:15.759009: Epoch 836 
2025-07-08 12:06:15.759161: Current learning rate: 0.00196 
2025-07-08 12:07:05.458602: train_loss -0.9352 
2025-07-08 12:07:05.459351: val_loss -0.941 
2025-07-08 12:07:05.459569: Pseudo dice [np.float32(0.9522)] 
2025-07-08 12:07:05.459715: Epoch time: 49.7 s 
2025-07-08 12:07:06.676606:  
2025-07-08 12:07:06.677105: Epoch 837 
2025-07-08 12:07:06.677305: Current learning rate: 0.00195 
2025-07-08 12:07:57.054187: train_loss -0.9335 
2025-07-08 12:07:57.054496: val_loss -0.9372 
2025-07-08 12:07:57.054584: Pseudo dice [np.float32(0.9548)] 
2025-07-08 12:07:57.054691: Epoch time: 50.38 s 
2025-07-08 12:07:57.054767: Yayy! New best EMA pseudo Dice: 0.9524999856948853 
2025-07-08 12:07:59.143695:  
2025-07-08 12:07:59.144239: Epoch 838 
2025-07-08 12:07:59.144471: Current learning rate: 0.00194 
2025-07-08 12:08:49.205133: train_loss -0.931 
2025-07-08 12:08:49.206235: val_loss -0.9341 
2025-07-08 12:08:49.206407: Pseudo dice [np.float32(0.9457)] 
2025-07-08 12:08:49.206625: Epoch time: 50.06 s 
2025-07-08 12:08:50.488415:  
2025-07-08 12:08:50.488603: Epoch 839 
2025-07-08 12:08:50.488803: Current learning rate: 0.00193 
2025-07-08 12:09:39.806179: train_loss -0.9285 
2025-07-08 12:09:39.806752: val_loss -0.9289 
2025-07-08 12:09:39.806833: Pseudo dice [np.float32(0.9418)] 
2025-07-08 12:09:39.806943: Epoch time: 49.32 s 
2025-07-08 12:09:40.954625:  
2025-07-08 12:09:40.955079: Epoch 840 
2025-07-08 12:09:40.955215: Current learning rate: 0.00192 
2025-07-08 12:10:30.452715: train_loss -0.9293 
2025-07-08 12:10:30.453300: val_loss -0.9349 
2025-07-08 12:10:30.453391: Pseudo dice [np.float32(0.9531)] 
2025-07-08 12:10:30.453512: Epoch time: 49.5 s 
2025-07-08 12:10:32.640673:  
2025-07-08 12:10:32.641286: Epoch 841 
2025-07-08 12:10:32.641416: Current learning rate: 0.00191 
2025-07-08 12:11:21.296364: train_loss -0.9335 
2025-07-08 12:11:21.297099: val_loss -0.935 
2025-07-08 12:11:21.297219: Pseudo dice [np.float32(0.9477)] 
2025-07-08 12:11:21.297358: Epoch time: 48.66 s 
2025-07-08 12:11:22.642027:  
2025-07-08 12:11:22.642912: Epoch 842 
2025-07-08 12:11:22.643055: Current learning rate: 0.0019 
2025-07-08 12:12:11.463031: train_loss -0.9293 
2025-07-08 12:12:11.463937: val_loss -0.9308 
2025-07-08 12:12:11.464066: Pseudo dice [np.float32(0.9486)] 
2025-07-08 12:12:11.464221: Epoch time: 48.82 s 
2025-07-08 12:12:12.703993:  
2025-07-08 12:12:12.704259: Epoch 843 
2025-07-08 12:12:12.704386: Current learning rate: 0.00189 
2025-07-08 12:13:01.392025: train_loss -0.9299 
2025-07-08 12:13:01.392855: val_loss -0.9428 
2025-07-08 12:13:01.393003: Pseudo dice [np.float32(0.9499)] 
2025-07-08 12:13:01.393158: Epoch time: 48.69 s 
2025-07-08 12:13:02.655763:  
2025-07-08 12:13:02.656090: Epoch 844 
2025-07-08 12:13:02.656310: Current learning rate: 0.00188 
2025-07-08 12:13:52.500487: train_loss -0.9316 
2025-07-08 12:13:52.501085: val_loss -0.9386 
2025-07-08 12:13:52.501184: Pseudo dice [np.float32(0.9488)] 
2025-07-08 12:13:52.501303: Epoch time: 49.85 s 
2025-07-08 12:13:53.724017:  
2025-07-08 12:13:53.724360: Epoch 845 
2025-07-08 12:13:53.724499: Current learning rate: 0.00187 
2025-07-08 12:14:44.296161: train_loss -0.9362 
2025-07-08 12:14:44.296732: val_loss -0.9445 
2025-07-08 12:14:44.296866: Pseudo dice [np.float32(0.958)] 
2025-07-08 12:14:44.297011: Epoch time: 50.57 s 
2025-07-08 12:14:45.466388:  
2025-07-08 12:14:45.466717: Epoch 846 
2025-07-08 12:14:45.467034: Current learning rate: 0.00186 
2025-07-08 12:15:34.976285: train_loss -0.9345 
2025-07-08 12:15:34.976803: val_loss -0.942 
2025-07-08 12:15:34.976894: Pseudo dice [np.float32(0.9541)] 
2025-07-08 12:15:34.977010: Epoch time: 49.51 s 
2025-07-08 12:15:36.135918:  
2025-07-08 12:15:36.136354: Epoch 847 
2025-07-08 12:15:36.136488: Current learning rate: 0.00185 
2025-07-08 12:16:26.212928: train_loss -0.935 
2025-07-08 12:16:26.213492: val_loss -0.9362 
2025-07-08 12:16:26.213776: Pseudo dice [np.float32(0.9509)] 
2025-07-08 12:16:26.214240: Epoch time: 50.08 s 
2025-07-08 12:16:27.482518:  
2025-07-08 12:16:27.482745: Epoch 848 
2025-07-08 12:16:27.482957: Current learning rate: 0.00184 
2025-07-08 12:17:17.203925: train_loss -0.9337 
2025-07-08 12:17:17.204982: val_loss -0.9414 
2025-07-08 12:17:17.205127: Pseudo dice [np.float32(0.953)] 
2025-07-08 12:17:17.205311: Epoch time: 49.72 s 
2025-07-08 12:17:18.353067:  
2025-07-08 12:17:18.353358: Epoch 849 
2025-07-08 12:17:18.353477: Current learning rate: 0.00182 
2025-07-08 12:18:10.195405: train_loss -0.935 
2025-07-08 12:18:10.196042: val_loss -0.9406 
2025-07-08 12:18:10.196135: Pseudo dice [np.float32(0.9492)] 
2025-07-08 12:18:10.196243: Epoch time: 51.84 s 
2025-07-08 12:18:12.327003:  
2025-07-08 12:18:12.327464: Epoch 850 
2025-07-08 12:18:12.327806: Current learning rate: 0.00181 
2025-07-08 12:19:01.986968: train_loss -0.9354 
2025-07-08 12:19:01.987555: val_loss -0.9382 
2025-07-08 12:19:01.991327: Pseudo dice [np.float32(0.9514)] 
2025-07-08 12:19:01.991945: Epoch time: 49.66 s 
2025-07-08 12:19:03.178794:  
2025-07-08 12:19:03.179166: Epoch 851 
2025-07-08 12:19:03.179419: Current learning rate: 0.0018 
2025-07-08 12:19:52.729077: train_loss -0.9348 
2025-07-08 12:19:52.729913: val_loss -0.9387 
2025-07-08 12:19:52.730084: Pseudo dice [np.float32(0.9518)] 
2025-07-08 12:19:52.730325: Epoch time: 49.55 s 
2025-07-08 12:19:53.927498:  
2025-07-08 12:19:53.927881: Epoch 852 
2025-07-08 12:19:53.928012: Current learning rate: 0.00179 
2025-07-08 12:20:44.023152: train_loss -0.9329 
2025-07-08 12:20:44.023724: val_loss -0.9433 
2025-07-08 12:20:44.023813: Pseudo dice [np.float32(0.9548)] 
2025-07-08 12:20:44.023926: Epoch time: 50.1 s 
2025-07-08 12:20:45.172868:  
2025-07-08 12:20:45.173366: Epoch 853 
2025-07-08 12:20:45.173603: Current learning rate: 0.00178 
2025-07-08 12:21:34.504123: train_loss -0.9348 
2025-07-08 12:21:34.504784: val_loss -0.9413 
2025-07-08 12:21:34.504878: Pseudo dice [np.float32(0.9517)] 
2025-07-08 12:21:34.505002: Epoch time: 49.33 s 
2025-07-08 12:21:35.647479:  
2025-07-08 12:21:35.647830: Epoch 854 
2025-07-08 12:21:35.647969: Current learning rate: 0.00177 
2025-07-08 12:22:25.903159: train_loss -0.9347 
2025-07-08 12:22:25.903521: val_loss -0.9423 
2025-07-08 12:22:25.903688: Pseudo dice [np.float32(0.9548)] 
2025-07-08 12:22:25.903867: Epoch time: 50.26 s 
2025-07-08 12:22:27.077252:  
2025-07-08 12:22:27.077477: Epoch 855 
2025-07-08 12:22:27.077611: Current learning rate: 0.00176 
2025-07-08 12:23:18.342350: train_loss -0.9344 
2025-07-08 12:23:18.343092: val_loss -0.9449 
2025-07-08 12:23:18.343199: Pseudo dice [np.float32(0.9547)] 
2025-07-08 12:23:18.343335: Epoch time: 51.27 s 
2025-07-08 12:23:19.516357:  
2025-07-08 12:23:19.516831: Epoch 856 
2025-07-08 12:23:19.516969: Current learning rate: 0.00175 
2025-07-08 12:24:09.691461: train_loss -0.9351 
2025-07-08 12:24:09.691773: val_loss -0.9377 
2025-07-08 12:24:09.691854: Pseudo dice [np.float32(0.9533)] 
2025-07-08 12:24:09.691945: Epoch time: 50.18 s 
2025-07-08 12:24:10.794317:  
2025-07-08 12:24:10.794500: Epoch 857 
2025-07-08 12:24:10.794621: Current learning rate: 0.00174 
2025-07-08 12:25:01.672590: train_loss -0.9353 
2025-07-08 12:25:01.673251: val_loss -0.9408 
2025-07-08 12:25:01.673343: Pseudo dice [np.float32(0.9509)] 
2025-07-08 12:25:01.673487: Epoch time: 50.88 s 
2025-07-08 12:25:04.055199:  
2025-07-08 12:25:04.055664: Epoch 858 
2025-07-08 12:25:04.055839: Current learning rate: 0.00173 
2025-07-08 12:25:53.304739: train_loss -0.9366 
2025-07-08 12:25:53.305300: val_loss -0.9384 
2025-07-08 12:25:53.305398: Pseudo dice [np.float32(0.9519)] 
2025-07-08 12:25:53.305515: Epoch time: 49.25 s 
2025-07-08 12:25:54.571193:  
2025-07-08 12:25:54.571664: Epoch 859 
2025-07-08 12:25:54.571860: Current learning rate: 0.00172 
2025-07-08 12:26:43.042893: train_loss -0.9384 
2025-07-08 12:26:43.044070: val_loss -0.938 
2025-07-08 12:26:43.044413: Pseudo dice [np.float32(0.9514)] 
2025-07-08 12:26:43.044657: Epoch time: 48.47 s 
2025-07-08 12:26:44.316578:  
2025-07-08 12:26:44.317176: Epoch 860 
2025-07-08 12:26:44.317400: Current learning rate: 0.0017 
2025-07-08 12:27:32.714629: train_loss -0.9345 
2025-07-08 12:27:32.715245: val_loss -0.9387 
2025-07-08 12:27:32.715384: Pseudo dice [np.float32(0.9507)] 
2025-07-08 12:27:32.715555: Epoch time: 48.4 s 
2025-07-08 12:27:33.872983:  
2025-07-08 12:27:33.873435: Epoch 861 
2025-07-08 12:27:33.873794: Current learning rate: 0.00169 
2025-07-08 12:28:22.787501: train_loss -0.9311 
2025-07-08 12:28:22.787957: val_loss -0.9359 
2025-07-08 12:28:22.788081: Pseudo dice [np.float32(0.9509)] 
2025-07-08 12:28:22.788193: Epoch time: 48.92 s 
2025-07-08 12:28:24.054308:  
2025-07-08 12:28:24.054925: Epoch 862 
2025-07-08 12:28:24.055047: Current learning rate: 0.00168 
2025-07-08 12:29:12.394197: train_loss -0.9353 
2025-07-08 12:29:12.395061: val_loss -0.942 
2025-07-08 12:29:12.395170: Pseudo dice [np.float32(0.9519)] 
2025-07-08 12:29:12.395329: Epoch time: 48.34 s 
2025-07-08 12:29:13.622008:  
2025-07-08 12:29:13.622440: Epoch 863 
2025-07-08 12:29:13.622701: Current learning rate: 0.00167 
2025-07-08 12:30:04.355575: train_loss -0.9365 
2025-07-08 12:30:04.356699: val_loss -0.9333 
2025-07-08 12:30:04.356858: Pseudo dice [np.float32(0.9495)] 
2025-07-08 12:30:04.357152: Epoch time: 50.73 s 
2025-07-08 12:30:05.561438:  
2025-07-08 12:30:05.561946: Epoch 864 
2025-07-08 12:30:05.562090: Current learning rate: 0.00166 
2025-07-08 12:30:54.730403: train_loss -0.9332 
2025-07-08 12:30:54.731061: val_loss -0.9383 
2025-07-08 12:30:54.731163: Pseudo dice [np.float32(0.952)] 
2025-07-08 12:30:54.731311: Epoch time: 49.17 s 
2025-07-08 12:30:55.954263:  
2025-07-08 12:30:55.954656: Epoch 865 
2025-07-08 12:30:55.954778: Current learning rate: 0.00165 
2025-07-08 12:31:45.972772: train_loss -0.9366 
2025-07-08 12:31:45.973336: val_loss -0.9378 
2025-07-08 12:31:45.973424: Pseudo dice [np.float32(0.9536)] 
2025-07-08 12:31:45.973562: Epoch time: 50.02 s 
2025-07-08 12:31:47.122701:  
2025-07-08 12:31:47.122875: Epoch 866 
2025-07-08 12:31:47.122997: Current learning rate: 0.00164 
2025-07-08 12:32:36.294889: train_loss -0.9359 
2025-07-08 12:32:36.295738: val_loss -0.9416 
2025-07-08 12:32:36.295842: Pseudo dice [np.float32(0.9527)] 
2025-07-08 12:32:36.295990: Epoch time: 49.17 s 
2025-07-08 12:32:37.495284:  
2025-07-08 12:32:37.495960: Epoch 867 
2025-07-08 12:32:37.496114: Current learning rate: 0.00163 
2025-07-08 12:33:25.079785: train_loss -0.9395 
2025-07-08 12:33:25.080355: val_loss -0.9386 
2025-07-08 12:33:25.080446: Pseudo dice [np.float32(0.9484)] 
2025-07-08 12:33:25.080583: Epoch time: 47.59 s 
2025-07-08 12:33:26.226250:  
2025-07-08 12:33:26.226441: Epoch 868 
2025-07-08 12:33:26.226822: Current learning rate: 0.00162 
2025-07-08 12:34:14.148302: train_loss -0.9358 
2025-07-08 12:34:14.148776: val_loss -0.9337 
2025-07-08 12:34:14.148864: Pseudo dice [np.float32(0.9528)] 
2025-07-08 12:34:14.148986: Epoch time: 47.92 s 
2025-07-08 12:34:15.362216:  
2025-07-08 12:34:15.362679: Epoch 869 
2025-07-08 12:34:15.362959: Current learning rate: 0.00161 
2025-07-08 12:35:04.424598: train_loss -0.9348 
2025-07-08 12:35:04.426262: val_loss -0.941 
2025-07-08 12:35:04.426634: Pseudo dice [np.float32(0.9556)] 
2025-07-08 12:35:04.426940: Epoch time: 49.06 s 
2025-07-08 12:35:05.806183:  
2025-07-08 12:35:05.806742: Epoch 870 
2025-07-08 12:35:05.806886: Current learning rate: 0.00159 
2025-07-08 12:35:54.478567: train_loss -0.9381 
2025-07-08 12:35:54.479070: val_loss -0.9389 
2025-07-08 12:35:54.479154: Pseudo dice [np.float32(0.9508)] 
2025-07-08 12:35:54.479264: Epoch time: 48.67 s 
2025-07-08 12:35:55.664531:  
2025-07-08 12:35:55.664865: Epoch 871 
2025-07-08 12:35:55.665095: Current learning rate: 0.00158 
2025-07-08 12:36:44.815705: train_loss -0.932 
2025-07-08 12:36:44.816103: val_loss -0.9454 
2025-07-08 12:36:44.816188: Pseudo dice [np.float32(0.9583)] 
2025-07-08 12:36:44.816291: Epoch time: 49.15 s 
2025-07-08 12:36:44.816363: Yayy! New best EMA pseudo Dice: 0.9526000022888184 
2025-07-08 12:36:46.803155:  
2025-07-08 12:36:46.803515: Epoch 872 
2025-07-08 12:36:46.803653: Current learning rate: 0.00157 
2025-07-08 12:37:36.388165: train_loss -0.9357 
2025-07-08 12:37:36.388602: val_loss -0.9374 
2025-07-08 12:37:36.388680: Pseudo dice [np.float32(0.9522)] 
2025-07-08 12:37:36.388785: Epoch time: 49.59 s 
2025-07-08 12:37:37.548593:  
2025-07-08 12:37:37.549051: Epoch 873 
2025-07-08 12:37:37.549216: Current learning rate: 0.00156 
2025-07-08 12:38:25.713040: train_loss -0.9307 
2025-07-08 12:38:25.713519: val_loss -0.9319 
2025-07-08 12:38:25.713622: Pseudo dice [np.float32(0.9508)] 
2025-07-08 12:38:25.713747: Epoch time: 48.17 s 
2025-07-08 12:38:26.891068:  
2025-07-08 12:38:26.891364: Epoch 874 
2025-07-08 12:38:26.891587: Current learning rate: 0.00155 
2025-07-08 12:39:16.983384: train_loss -0.9284 
2025-07-08 12:39:16.984039: val_loss -0.9352 
2025-07-08 12:39:16.984153: Pseudo dice [np.float32(0.9537)] 
2025-07-08 12:39:16.984306: Epoch time: 50.09 s 
2025-07-08 12:39:19.226891:  
2025-07-08 12:39:19.227379: Epoch 875 
2025-07-08 12:39:19.227670: Current learning rate: 0.00154 
2025-07-08 12:40:08.194933: train_loss -0.9353 
2025-07-08 12:40:08.196088: val_loss -0.9417 
2025-07-08 12:40:08.196219: Pseudo dice [np.float32(0.954)] 
2025-07-08 12:40:08.196450: Epoch time: 48.97 s 
2025-07-08 12:40:08.196618: Yayy! New best EMA pseudo Dice: 0.9527000188827515 
2025-07-08 12:40:10.314984:  
2025-07-08 12:40:10.315551: Epoch 876 
2025-07-08 12:40:10.315707: Current learning rate: 0.00153 
2025-07-08 12:41:00.862866: train_loss -0.9362 
2025-07-08 12:41:00.863401: val_loss -0.9424 
2025-07-08 12:41:00.863500: Pseudo dice [np.float32(0.9532)] 
2025-07-08 12:41:00.863638: Epoch time: 50.55 s 
2025-07-08 12:41:00.863720: Yayy! New best EMA pseudo Dice: 0.9527000188827515 
2025-07-08 12:41:03.030525:  
2025-07-08 12:41:03.030928: Epoch 877 
2025-07-08 12:41:03.031065: Current learning rate: 0.00152 
2025-07-08 12:41:51.558087: train_loss -0.9384 
2025-07-08 12:41:51.558480: val_loss -0.9381 
2025-07-08 12:41:51.558578: Pseudo dice [np.float32(0.9507)] 
2025-07-08 12:41:51.558693: Epoch time: 48.53 s 
2025-07-08 12:41:52.805231:  
2025-07-08 12:41:52.805772: Epoch 878 
2025-07-08 12:41:52.806015: Current learning rate: 0.00151 
2025-07-08 12:42:42.043404: train_loss -0.9357 
2025-07-08 12:42:42.044176: val_loss -0.9468 
2025-07-08 12:42:42.044279: Pseudo dice [np.float32(0.9575)] 
2025-07-08 12:42:42.044395: Epoch time: 49.24 s 
2025-07-08 12:42:42.044473: Yayy! New best EMA pseudo Dice: 0.953000009059906 
2025-07-08 12:42:44.258128:  
2025-07-08 12:42:44.258734: Epoch 879 
2025-07-08 12:42:44.258906: Current learning rate: 0.00149 
2025-07-08 12:43:33.925167: train_loss -0.9373 
2025-07-08 12:43:33.925791: val_loss -0.9382 
2025-07-08 12:43:33.925888: Pseudo dice [np.float32(0.9517)] 
2025-07-08 12:43:33.925993: Epoch time: 49.67 s 
2025-07-08 12:43:35.222906:  
2025-07-08 12:43:35.223120: Epoch 880 
2025-07-08 12:43:35.223244: Current learning rate: 0.00148 
2025-07-08 12:44:23.186027: train_loss -0.9306 
2025-07-08 12:44:23.186493: val_loss -0.9404 
2025-07-08 12:44:23.186615: Pseudo dice [np.float32(0.9518)] 
2025-07-08 12:44:23.186736: Epoch time: 47.96 s 
2025-07-08 12:44:24.365206:  
2025-07-08 12:44:24.365554: Epoch 881 
2025-07-08 12:44:24.365757: Current learning rate: 0.00147 
2025-07-08 12:45:13.326233: train_loss -0.9356 
2025-07-08 12:45:13.327157: val_loss -0.9401 
2025-07-08 12:45:13.327344: Pseudo dice [np.float32(0.949)] 
2025-07-08 12:45:13.327525: Epoch time: 48.96 s 
2025-07-08 12:45:14.598165:  
2025-07-08 12:45:14.598561: Epoch 882 
2025-07-08 12:45:14.598747: Current learning rate: 0.00146 
2025-07-08 12:46:02.710664: train_loss -0.9364 
2025-07-08 12:46:02.711432: val_loss -0.9396 
2025-07-08 12:46:02.711573: Pseudo dice [np.float32(0.9526)] 
2025-07-08 12:46:02.711744: Epoch time: 48.11 s 
2025-07-08 12:46:03.904638:  
2025-07-08 12:46:03.905115: Epoch 883 
2025-07-08 12:46:03.905254: Current learning rate: 0.00145 
2025-07-08 12:46:53.735928: train_loss -0.9362 
2025-07-08 12:46:53.737192: val_loss -0.9393 
2025-07-08 12:46:53.737507: Pseudo dice [np.float32(0.9527)] 
2025-07-08 12:46:53.737772: Epoch time: 49.83 s 
2025-07-08 12:46:54.966491:  
2025-07-08 12:46:54.966847: Epoch 884 
2025-07-08 12:46:54.966976: Current learning rate: 0.00144 
2025-07-08 12:47:44.632441: train_loss -0.9356 
2025-07-08 12:47:44.633015: val_loss -0.9448 
2025-07-08 12:47:44.633106: Pseudo dice [np.float32(0.957)] 
2025-07-08 12:47:44.633227: Epoch time: 49.67 s 
2025-07-08 12:47:45.790629:  
2025-07-08 12:47:45.790998: Epoch 885 
2025-07-08 12:47:45.791217: Current learning rate: 0.00143 
2025-07-08 12:48:35.231922: train_loss -0.9381 
2025-07-08 12:48:35.232527: val_loss -0.9382 
2025-07-08 12:48:35.232641: Pseudo dice [np.float32(0.954)] 
2025-07-08 12:48:35.232776: Epoch time: 49.44 s 
2025-07-08 12:48:36.416270:  
2025-07-08 12:48:36.416508: Epoch 886 
2025-07-08 12:48:36.416661: Current learning rate: 0.00142 
2025-07-08 12:49:25.933864: train_loss -0.9392 
2025-07-08 12:49:25.934432: val_loss -0.9361 
2025-07-08 12:49:25.934530: Pseudo dice [np.float32(0.9507)] 
2025-07-08 12:49:25.934672: Epoch time: 49.52 s 
2025-07-08 12:49:27.117133:  
2025-07-08 12:49:27.117715: Epoch 887 
2025-07-08 12:49:27.117896: Current learning rate: 0.00141 
2025-07-08 12:50:17.429905: train_loss -0.9341 
2025-07-08 12:50:17.430640: val_loss -0.9421 
2025-07-08 12:50:17.430756: Pseudo dice [np.float32(0.9554)] 
2025-07-08 12:50:17.430887: Epoch time: 50.31 s 
2025-07-08 12:50:17.430985: Yayy! New best EMA pseudo Dice: 0.953000009059906 
2025-07-08 12:50:19.697809:  
2025-07-08 12:50:19.698231: Epoch 888 
2025-07-08 12:50:19.698409: Current learning rate: 0.00139 
2025-07-08 12:51:10.972421: train_loss -0.9378 
2025-07-08 12:51:10.972893: val_loss -0.9431 
2025-07-08 12:51:10.972981: Pseudo dice [np.float32(0.9531)] 
2025-07-08 12:51:10.973101: Epoch time: 51.28 s 
2025-07-08 12:51:10.973182: Yayy! New best EMA pseudo Dice: 0.9531000256538391 
2025-07-08 12:51:13.112042:  
2025-07-08 12:51:13.112509: Epoch 889 
2025-07-08 12:51:13.112709: Current learning rate: 0.00138 
2025-07-08 12:52:02.310642: train_loss -0.9367 
2025-07-08 12:52:02.311736: val_loss -0.9451 
2025-07-08 12:52:02.311870: Pseudo dice [np.float32(0.956)] 
2025-07-08 12:52:02.312066: Epoch time: 49.21 s 
2025-07-08 12:52:02.312201: Yayy! New best EMA pseudo Dice: 0.9532999992370605 
2025-07-08 12:52:05.397087:  
2025-07-08 12:52:05.397507: Epoch 890 
2025-07-08 12:52:05.397748: Current learning rate: 0.00137 
2025-07-08 12:52:54.365745: train_loss -0.9419 
2025-07-08 12:52:54.366096: val_loss -0.94 
2025-07-08 12:52:54.366177: Pseudo dice [np.float32(0.9507)] 
2025-07-08 12:52:54.366282: Epoch time: 48.97 s 
2025-07-08 12:52:55.609009:  
2025-07-08 12:52:55.609306: Epoch 891 
2025-07-08 12:52:55.609437: Current learning rate: 0.00136 
2025-07-08 12:53:46.123463: train_loss -0.9359 
2025-07-08 12:53:46.123843: val_loss -0.9352 
2025-07-08 12:53:46.123961: Pseudo dice [np.float32(0.9484)] 
2025-07-08 12:53:46.124230: Epoch time: 50.52 s 
2025-07-08 12:53:47.270703:  
2025-07-08 12:53:47.271084: Epoch 892 
2025-07-08 12:53:47.271447: Current learning rate: 0.00135 
2025-07-08 12:54:37.761311: train_loss -0.9319 
2025-07-08 12:54:37.761721: val_loss -0.9407 
2025-07-08 12:54:37.761799: Pseudo dice [np.float32(0.953)] 
2025-07-08 12:54:37.761912: Epoch time: 50.49 s 
2025-07-08 12:54:38.909961:  
2025-07-08 12:54:38.910321: Epoch 893 
2025-07-08 12:54:38.910449: Current learning rate: 0.00134 
2025-07-08 12:55:29.299336: train_loss -0.9388 
2025-07-08 12:55:29.299843: val_loss -0.9398 
2025-07-08 12:55:29.299940: Pseudo dice [np.float32(0.95)] 
2025-07-08 12:55:29.300060: Epoch time: 50.39 s 
2025-07-08 12:55:30.429297:  
2025-07-08 12:55:30.429496: Epoch 894 
2025-07-08 12:55:30.429766: Current learning rate: 0.00133 
2025-07-08 12:56:20.493514: train_loss -0.9358 
2025-07-08 12:56:20.494081: val_loss -0.9275 
2025-07-08 12:56:20.494175: Pseudo dice [np.float32(0.9477)] 
2025-07-08 12:56:20.494302: Epoch time: 50.07 s 
2025-07-08 12:56:21.670183:  
2025-07-08 12:56:21.670665: Epoch 895 
2025-07-08 12:56:21.670879: Current learning rate: 0.00132 
2025-07-08 12:57:11.155185: train_loss -0.9349 
2025-07-08 12:57:11.155972: val_loss -0.9379 
2025-07-08 12:57:11.156050: Pseudo dice [np.float32(0.9519)] 
2025-07-08 12:57:11.156178: Epoch time: 49.49 s 
2025-07-08 12:57:12.325312:  
2025-07-08 12:57:12.325711: Epoch 896 
2025-07-08 12:57:12.325996: Current learning rate: 0.0013 
2025-07-08 12:58:01.098229: train_loss -0.9388 
2025-07-08 12:58:01.099000: val_loss -0.9465 
2025-07-08 12:58:01.099117: Pseudo dice [np.float32(0.9575)] 
2025-07-08 12:58:01.099327: Epoch time: 48.77 s 
2025-07-08 12:58:02.411944:  
2025-07-08 12:58:02.412371: Epoch 897 
2025-07-08 12:58:02.412502: Current learning rate: 0.00129 
2025-07-08 12:58:53.366491: train_loss -0.9391 
2025-07-08 12:58:53.367054: val_loss -0.94 
2025-07-08 12:58:53.367141: Pseudo dice [np.float32(0.9568)] 
2025-07-08 12:58:53.367242: Epoch time: 50.96 s 
2025-07-08 12:58:54.509120:  
2025-07-08 12:58:54.509548: Epoch 898 
2025-07-08 12:58:54.509839: Current learning rate: 0.00128 
2025-07-08 12:59:43.773178: train_loss -0.9374 
2025-07-08 12:59:43.773832: val_loss -0.9389 
2025-07-08 12:59:43.773919: Pseudo dice [np.float32(0.951)] 
2025-07-08 12:59:43.774040: Epoch time: 49.27 s 
2025-07-08 12:59:45.010745:  
2025-07-08 12:59:45.011009: Epoch 899 
2025-07-08 12:59:45.011134: Current learning rate: 0.00127 
2025-07-08 13:00:36.396860: train_loss -0.9368 
2025-07-08 13:00:36.397316: val_loss -0.9437 
2025-07-08 13:00:36.397400: Pseudo dice [np.float32(0.9591)] 
2025-07-08 13:00:36.397516: Epoch time: 51.39 s 
2025-07-08 13:00:37.491583: Yayy! New best EMA pseudo Dice: 0.9534000158309937 
2025-07-08 13:00:39.488239:  
2025-07-08 13:00:39.488521: Epoch 900 
2025-07-08 13:00:39.488718: Current learning rate: 0.00126 
2025-07-08 13:01:30.689657: train_loss -0.9402 
2025-07-08 13:01:30.690246: val_loss -0.9395 
2025-07-08 13:01:30.690336: Pseudo dice [np.float32(0.9568)] 
2025-07-08 13:01:30.690491: Epoch time: 51.2 s 
2025-07-08 13:01:30.690583: Yayy! New best EMA pseudo Dice: 0.9537000060081482 
2025-07-08 13:01:32.813518:  
2025-07-08 13:01:32.814013: Epoch 901 
2025-07-08 13:01:32.814352: Current learning rate: 0.00125 
2025-07-08 13:02:22.203805: train_loss -0.9383 
2025-07-08 13:02:22.204402: val_loss -0.9427 
2025-07-08 13:02:22.204499: Pseudo dice [np.float32(0.9556)] 
2025-07-08 13:02:22.204656: Epoch time: 49.39 s 
2025-07-08 13:02:22.204745: Yayy! New best EMA pseudo Dice: 0.9538999795913696 
2025-07-08 13:02:24.346386:  
2025-07-08 13:02:24.346706: Epoch 902 
2025-07-08 13:02:24.346882: Current learning rate: 0.00124 
2025-07-08 13:03:14.931473: train_loss -0.9376 
2025-07-08 13:03:14.934402: val_loss -0.9392 
2025-07-08 13:03:14.934748: Pseudo dice [np.float32(0.9544)] 
2025-07-08 13:03:14.934898: Epoch time: 50.59 s 
2025-07-08 13:03:14.934989: Yayy! New best EMA pseudo Dice: 0.9538999795913696 
2025-07-08 13:03:17.206887:  
2025-07-08 13:03:17.207395: Epoch 903 
2025-07-08 13:03:17.207695: Current learning rate: 0.00122 
2025-07-08 13:04:06.169248: train_loss -0.9396 
2025-07-08 13:04:06.170476: val_loss -0.9398 
2025-07-08 13:04:06.170706: Pseudo dice [np.float32(0.9527)] 
2025-07-08 13:04:06.170944: Epoch time: 48.96 s 
2025-07-08 13:04:07.445169:  
2025-07-08 13:04:07.445708: Epoch 904 
2025-07-08 13:04:07.445983: Current learning rate: 0.00121 
2025-07-08 13:04:55.790517: train_loss -0.9378 
2025-07-08 13:04:55.791235: val_loss -0.9408 
2025-07-08 13:04:55.791332: Pseudo dice [np.float32(0.9521)] 
2025-07-08 13:04:55.791461: Epoch time: 48.35 s 
2025-07-08 13:04:57.042638:  
2025-07-08 13:04:57.043180: Epoch 905 
2025-07-08 13:04:57.043323: Current learning rate: 0.0012 
2025-07-08 13:05:47.261605: train_loss -0.937 
2025-07-08 13:05:47.262320: val_loss -0.9438 
2025-07-08 13:05:47.262413: Pseudo dice [np.float32(0.9566)] 
2025-07-08 13:05:47.262524: Epoch time: 50.22 s 
2025-07-08 13:05:47.262617: Yayy! New best EMA pseudo Dice: 0.9538999795913696 
2025-07-08 13:05:49.361840:  
2025-07-08 13:05:49.362034: Epoch 906 
2025-07-08 13:05:49.362185: Current learning rate: 0.00119 
2025-07-08 13:06:39.334006: train_loss -0.9395 
2025-07-08 13:06:39.334501: val_loss -0.9455 
2025-07-08 13:06:39.334604: Pseudo dice [np.float32(0.9555)] 
2025-07-08 13:06:39.334728: Epoch time: 49.97 s 
2025-07-08 13:06:39.334807: Yayy! New best EMA pseudo Dice: 0.9541000127792358 
2025-07-08 13:06:42.583979:  
2025-07-08 13:06:42.584331: Epoch 907 
2025-07-08 13:06:42.584626: Current learning rate: 0.00118 
2025-07-08 13:07:34.271382: train_loss -0.9386 
2025-07-08 13:07:34.271954: val_loss -0.9437 
2025-07-08 13:07:34.272105: Pseudo dice [np.float32(0.9591)] 
2025-07-08 13:07:34.272255: Epoch time: 51.69 s 
2025-07-08 13:07:34.272348: Yayy! New best EMA pseudo Dice: 0.9545999765396118 
2025-07-08 13:07:36.600186:  
2025-07-08 13:07:36.600721: Epoch 908 
2025-07-08 13:07:36.600893: Current learning rate: 0.00117 
2025-07-08 13:08:27.482048: train_loss -0.9331 
2025-07-08 13:08:27.482519: val_loss -0.9402 
2025-07-08 13:08:27.482616: Pseudo dice [np.float32(0.9541)] 
2025-07-08 13:08:27.482719: Epoch time: 50.88 s 
2025-07-08 13:08:28.631016:  
2025-07-08 13:08:28.631485: Epoch 909 
2025-07-08 13:08:28.631634: Current learning rate: 0.00116 
2025-07-08 13:09:19.528126: train_loss -0.9358 
2025-07-08 13:09:19.529211: val_loss -0.9446 
2025-07-08 13:09:19.529447: Pseudo dice [np.float32(0.9551)] 
2025-07-08 13:09:19.529738: Epoch time: 50.9 s 
2025-07-08 13:09:19.529955: Yayy! New best EMA pseudo Dice: 0.9545999765396118 
2025-07-08 13:09:21.663991:  
2025-07-08 13:09:21.664426: Epoch 910 
2025-07-08 13:09:21.664574: Current learning rate: 0.00115 
2025-07-08 13:10:10.344183: train_loss -0.9411 
2025-07-08 13:10:10.344929: val_loss -0.9435 
2025-07-08 13:10:10.345010: Pseudo dice [np.float32(0.9544)] 
2025-07-08 13:10:10.345171: Epoch time: 48.68 s 
2025-07-08 13:10:11.489790:  
2025-07-08 13:10:11.490247: Epoch 911 
2025-07-08 13:10:11.490438: Current learning rate: 0.00113 
2025-07-08 13:11:01.423535: train_loss -0.9378 
2025-07-08 13:11:01.424176: val_loss -0.9387 
2025-07-08 13:11:01.424268: Pseudo dice [np.float32(0.9527)] 
2025-07-08 13:11:01.424393: Epoch time: 49.93 s 
2025-07-08 13:11:02.657799:  
2025-07-08 13:11:02.658325: Epoch 912 
2025-07-08 13:11:02.658501: Current learning rate: 0.00112 
2025-07-08 13:11:51.859712: train_loss -0.9392 
2025-07-08 13:11:51.860234: val_loss -0.9433 
2025-07-08 13:11:51.860327: Pseudo dice [np.float32(0.9558)] 
2025-07-08 13:11:51.860439: Epoch time: 49.2 s 
2025-07-08 13:11:53.071675:  
2025-07-08 13:11:53.072249: Epoch 913 
2025-07-08 13:11:53.072420: Current learning rate: 0.00111 
2025-07-08 13:12:43.476469: train_loss -0.9354 
2025-07-08 13:12:43.476986: val_loss -0.9448 
2025-07-08 13:12:43.477066: Pseudo dice [np.float32(0.9542)] 
2025-07-08 13:12:43.477170: Epoch time: 50.41 s 
2025-07-08 13:12:44.675719:  
2025-07-08 13:12:44.676294: Epoch 914 
2025-07-08 13:12:44.676442: Current learning rate: 0.0011 
2025-07-08 13:13:34.580779: train_loss -0.9388 
2025-07-08 13:13:34.581314: val_loss -0.9434 
2025-07-08 13:13:34.581581: Pseudo dice [np.float32(0.9581)] 
2025-07-08 13:13:34.581699: Epoch time: 49.91 s 
2025-07-08 13:13:34.581782: Yayy! New best EMA pseudo Dice: 0.9549000263214111 
2025-07-08 13:13:36.789503:  
2025-07-08 13:13:36.789969: Epoch 915 
2025-07-08 13:13:36.790187: Current learning rate: 0.00109 
2025-07-08 13:14:26.135140: train_loss -0.9388 
2025-07-08 13:14:26.135781: val_loss -0.9425 
2025-07-08 13:14:26.135870: Pseudo dice [np.float32(0.9538)] 
2025-07-08 13:14:26.135986: Epoch time: 49.35 s 
2025-07-08 13:14:27.304952:  
2025-07-08 13:14:27.305128: Epoch 916 
2025-07-08 13:14:27.305245: Current learning rate: 0.00108 
2025-07-08 13:15:18.002896: train_loss -0.9399 
2025-07-08 13:15:18.003603: val_loss -0.939 
2025-07-08 13:15:18.003727: Pseudo dice [np.float32(0.9524)] 
2025-07-08 13:15:18.003874: Epoch time: 50.7 s 
2025-07-08 13:15:19.141101:  
2025-07-08 13:15:19.141729: Epoch 917 
2025-07-08 13:15:19.141915: Current learning rate: 0.00106 
2025-07-08 13:16:09.704729: train_loss -0.9408 
2025-07-08 13:16:09.705854: val_loss -0.941 
2025-07-08 13:16:09.705997: Pseudo dice [np.float32(0.9554)] 
2025-07-08 13:16:09.706228: Epoch time: 50.56 s 
2025-07-08 13:16:10.924600:  
2025-07-08 13:16:10.924728: Epoch 918 
2025-07-08 13:16:10.924829: Current learning rate: 0.00105 
2025-07-08 13:17:02.074968: train_loss -0.939 
2025-07-08 13:17:02.075461: val_loss -0.9405 
2025-07-08 13:17:02.075696: Pseudo dice [np.float32(0.9562)] 
2025-07-08 13:17:02.075838: Epoch time: 51.15 s 
2025-07-08 13:17:03.222923:  
2025-07-08 13:17:03.223122: Epoch 919 
2025-07-08 13:17:03.223243: Current learning rate: 0.00104 
2025-07-08 13:17:53.068111: train_loss -0.9405 
2025-07-08 13:17:53.069247: val_loss -0.9483 
2025-07-08 13:17:53.069380: Pseudo dice [np.float32(0.9579)] 
2025-07-08 13:17:53.069596: Epoch time: 49.85 s 
2025-07-08 13:17:53.069687: Yayy! New best EMA pseudo Dice: 0.9550999999046326 
2025-07-08 13:17:55.205723:  
2025-07-08 13:17:55.206278: Epoch 920 
2025-07-08 13:17:55.206496: Current learning rate: 0.00103 
2025-07-08 13:18:45.833231: train_loss -0.9399 
2025-07-08 13:18:45.833936: val_loss -0.9456 
2025-07-08 13:18:45.834054: Pseudo dice [np.float32(0.9557)] 
2025-07-08 13:18:45.834188: Epoch time: 50.63 s 
2025-07-08 13:18:45.834272: Yayy! New best EMA pseudo Dice: 0.9552000164985657 
2025-07-08 13:18:47.996890:  
2025-07-08 13:18:47.997093: Epoch 921 
2025-07-08 13:18:47.997234: Current learning rate: 0.00102 
2025-07-08 13:19:38.322558: train_loss -0.9389 
2025-07-08 13:19:38.323171: val_loss -0.9402 
2025-07-08 13:19:38.323260: Pseudo dice [np.float32(0.9561)] 
2025-07-08 13:19:38.323378: Epoch time: 50.33 s 
2025-07-08 13:19:38.323452: Yayy! New best EMA pseudo Dice: 0.955299973487854 
2025-07-08 13:19:40.524259:  
2025-07-08 13:19:40.524787: Epoch 922 
2025-07-08 13:19:40.524913: Current learning rate: 0.00101 
2025-07-08 13:20:30.440593: train_loss -0.9372 
2025-07-08 13:20:30.441024: val_loss -0.9437 
2025-07-08 13:20:30.441113: Pseudo dice [np.float32(0.9562)] 
2025-07-08 13:20:30.441226: Epoch time: 49.92 s 
2025-07-08 13:20:30.441314: Yayy! New best EMA pseudo Dice: 0.955299973487854 
2025-07-08 13:20:33.470383:  
2025-07-08 13:20:33.471024: Epoch 923 
2025-07-08 13:20:33.471149: Current learning rate: 0.001 
2025-07-08 13:21:23.294435: train_loss -0.9395 
2025-07-08 13:21:23.295534: val_loss -0.9421 
2025-07-08 13:21:23.295701: Pseudo dice [np.float32(0.9543)] 
2025-07-08 13:21:23.295883: Epoch time: 49.83 s 
2025-07-08 13:21:24.519293:  
2025-07-08 13:21:24.519532: Epoch 924 
2025-07-08 13:21:24.519799: Current learning rate: 0.00098 
2025-07-08 13:22:13.630415: train_loss -0.9399 
2025-07-08 13:22:13.631013: val_loss -0.9475 
2025-07-08 13:22:13.631150: Pseudo dice [np.float32(0.9578)] 
2025-07-08 13:22:13.631310: Epoch time: 49.11 s 
2025-07-08 13:22:13.631437: Yayy! New best EMA pseudo Dice: 0.9555000066757202 
2025-07-08 13:22:15.690686:  
2025-07-08 13:22:15.691205: Epoch 925 
2025-07-08 13:22:15.691532: Current learning rate: 0.00097 
2025-07-08 13:23:04.807751: train_loss -0.9372 
2025-07-08 13:23:04.808530: val_loss -0.9427 
2025-07-08 13:23:04.808659: Pseudo dice [np.float32(0.9551)] 
2025-07-08 13:23:04.808771: Epoch time: 49.12 s 
2025-07-08 13:23:06.010664:  
2025-07-08 13:23:06.010944: Epoch 926 
2025-07-08 13:23:06.011111: Current learning rate: 0.00096 
2025-07-08 13:23:56.736262: train_loss -0.9372 
2025-07-08 13:23:56.736765: val_loss -0.9432 
2025-07-08 13:23:56.737353: Pseudo dice [np.float32(0.9551)] 
2025-07-08 13:23:56.737603: Epoch time: 50.73 s 
2025-07-08 13:23:57.930674:  
2025-07-08 13:23:57.931159: Epoch 927 
2025-07-08 13:23:57.931340: Current learning rate: 0.00095 
2025-07-08 13:24:46.335671: train_loss -0.9393 
2025-07-08 13:24:46.336434: val_loss -0.9432 
2025-07-08 13:24:46.336607: Pseudo dice [np.float32(0.9542)] 
2025-07-08 13:24:46.336806: Epoch time: 48.41 s 
2025-07-08 13:24:47.591658:  
2025-07-08 13:24:47.591809: Epoch 928 
2025-07-08 13:24:47.592108: Current learning rate: 0.00094 
2025-07-08 13:25:37.253752: train_loss -0.9389 
2025-07-08 13:25:37.255020: val_loss -0.9406 
2025-07-08 13:25:37.255270: Pseudo dice [np.float32(0.9539)] 
2025-07-08 13:25:37.255564: Epoch time: 49.66 s 
2025-07-08 13:25:38.516572:  
2025-07-08 13:25:38.516908: Epoch 929 
2025-07-08 13:25:38.517136: Current learning rate: 0.00092 
2025-07-08 13:26:28.368062: train_loss -0.9383 
2025-07-08 13:26:28.368689: val_loss -0.9439 
2025-07-08 13:26:28.368777: Pseudo dice [np.float32(0.9538)] 
2025-07-08 13:26:28.368901: Epoch time: 49.85 s 
2025-07-08 13:26:29.707178:  
2025-07-08 13:26:29.707573: Epoch 930 
2025-07-08 13:26:29.707708: Current learning rate: 0.00091 
2025-07-08 13:27:19.133307: train_loss -0.9365 
2025-07-08 13:27:19.134422: val_loss -0.9392 
2025-07-08 13:27:19.134530: Pseudo dice [np.float32(0.9564)] 
2025-07-08 13:27:19.134712: Epoch time: 49.43 s 
2025-07-08 13:27:20.347135:  
2025-07-08 13:27:20.347285: Epoch 931 
2025-07-08 13:27:20.347400: Current learning rate: 0.0009 
2025-07-08 13:28:10.387162: train_loss -0.9389 
2025-07-08 13:28:10.387654: val_loss -0.9413 
2025-07-08 13:28:10.387737: Pseudo dice [np.float32(0.9559)] 
2025-07-08 13:28:10.387851: Epoch time: 50.04 s 
2025-07-08 13:28:11.606708:  
2025-07-08 13:28:11.607122: Epoch 932 
2025-07-08 13:28:11.607378: Current learning rate: 0.00089 
2025-07-08 13:29:02.027076: train_loss -0.938 
2025-07-08 13:29:02.027761: val_loss -0.944 
2025-07-08 13:29:02.027895: Pseudo dice [np.float32(0.9543)] 
2025-07-08 13:29:02.029068: Epoch time: 50.42 s 
2025-07-08 13:29:03.301389:  
2025-07-08 13:29:03.301658: Epoch 933 
2025-07-08 13:29:03.301882: Current learning rate: 0.00088 
2025-07-08 13:29:54.076324: train_loss -0.9391 
2025-07-08 13:29:54.076899: val_loss -0.941 
2025-07-08 13:29:54.076993: Pseudo dice [np.float32(0.9573)] 
2025-07-08 13:29:54.077113: Epoch time: 50.78 s 
2025-07-08 13:29:55.272054:  
2025-07-08 13:29:55.272258: Epoch 934 
2025-07-08 13:29:55.272593: Current learning rate: 0.00087 
2025-07-08 13:30:44.699743: train_loss -0.9402 
2025-07-08 13:30:44.700364: val_loss -0.9479 
2025-07-08 13:30:44.700557: Pseudo dice [np.float32(0.9587)] 
2025-07-08 13:30:44.700840: Epoch time: 49.43 s 
2025-07-08 13:30:44.700934: Yayy! New best EMA pseudo Dice: 0.9556999802589417 
2025-07-08 13:30:47.065634:  
2025-07-08 13:30:47.066261: Epoch 935 
2025-07-08 13:30:47.066546: Current learning rate: 0.00085 
2025-07-08 13:31:36.251578: train_loss -0.9412 
2025-07-08 13:31:36.252392: val_loss -0.9451 
2025-07-08 13:31:36.252486: Pseudo dice [np.float32(0.9564)] 
2025-07-08 13:31:36.252653: Epoch time: 49.19 s 
2025-07-08 13:31:36.252735: Yayy! New best EMA pseudo Dice: 0.9557999968528748 
2025-07-08 13:31:38.329292:  
2025-07-08 13:31:38.329477: Epoch 936 
2025-07-08 13:31:38.329630: Current learning rate: 0.00084 
2025-07-08 13:32:27.385319: train_loss -0.941 
2025-07-08 13:32:27.386064: val_loss -0.9451 
2025-07-08 13:32:27.386154: Pseudo dice [np.float32(0.9576)] 
2025-07-08 13:32:27.386273: Epoch time: 49.06 s 
2025-07-08 13:32:27.386358: Yayy! New best EMA pseudo Dice: 0.9559000134468079 
2025-07-08 13:32:29.627762:  
2025-07-08 13:32:29.628176: Epoch 937 
2025-07-08 13:32:29.628312: Current learning rate: 0.00083 
2025-07-08 13:33:17.661203: train_loss -0.9368 
2025-07-08 13:33:17.662829: val_loss -0.9461 
2025-07-08 13:33:17.663116: Pseudo dice [np.float32(0.9582)] 
2025-07-08 13:33:17.663615: Epoch time: 48.03 s 
2025-07-08 13:33:17.663856: Yayy! New best EMA pseudo Dice: 0.9562000036239624 
2025-07-08 13:33:20.907944:  
2025-07-08 13:33:20.908409: Epoch 938 
2025-07-08 13:33:20.908639: Current learning rate: 0.00082 
2025-07-08 13:34:10.663254: train_loss -0.9423 
2025-07-08 13:34:10.664184: val_loss -0.9463 
2025-07-08 13:34:10.664318: Pseudo dice [np.float32(0.9568)] 
2025-07-08 13:34:10.664517: Epoch time: 49.76 s 
2025-07-08 13:34:10.664649: Yayy! New best EMA pseudo Dice: 0.9562000036239624 
2025-07-08 13:34:12.828821:  
2025-07-08 13:34:12.829024: Epoch 939 
2025-07-08 13:34:12.829165: Current learning rate: 0.00081 
2025-07-08 13:35:03.332684: train_loss -0.9331 
2025-07-08 13:35:03.333407: val_loss -0.9463 
2025-07-08 13:35:03.333500: Pseudo dice [np.float32(0.9578)] 
2025-07-08 13:35:03.333637: Epoch time: 50.51 s 
2025-07-08 13:35:03.333719: Yayy! New best EMA pseudo Dice: 0.9563999772071838 
2025-07-08 13:35:05.606436:  
2025-07-08 13:35:05.606718: Epoch 940 
2025-07-08 13:35:05.606848: Current learning rate: 0.00079 
2025-07-08 13:35:55.890502: train_loss -0.9379 
2025-07-08 13:35:55.890945: val_loss -0.9475 
2025-07-08 13:35:55.891027: Pseudo dice [np.float32(0.9579)] 
2025-07-08 13:35:55.891183: Epoch time: 50.29 s 
2025-07-08 13:35:55.891258: Yayy! New best EMA pseudo Dice: 0.9564999938011169 
2025-07-08 13:35:57.943859:  
2025-07-08 13:35:57.944112: Epoch 941 
2025-07-08 13:35:57.944231: Current learning rate: 0.00078 
2025-07-08 13:36:46.255748: train_loss -0.9391 
2025-07-08 13:36:46.256844: val_loss -0.9449 
2025-07-08 13:36:46.256992: Pseudo dice [np.float32(0.9566)] 
2025-07-08 13:36:46.257212: Epoch time: 48.31 s 
2025-07-08 13:36:46.257394: Yayy! New best EMA pseudo Dice: 0.9564999938011169 
2025-07-08 13:36:48.426599:  
2025-07-08 13:36:48.426939: Epoch 942 
2025-07-08 13:36:48.427112: Current learning rate: 0.00077 
2025-07-08 13:37:41.040995: train_loss -0.9417 
2025-07-08 13:37:41.041511: val_loss -0.9489 
2025-07-08 13:37:41.041620: Pseudo dice [np.float32(0.9586)] 
2025-07-08 13:37:41.041742: Epoch time: 52.62 s 
2025-07-08 13:37:41.041823: Yayy! New best EMA pseudo Dice: 0.9567999839782715 
2025-07-08 13:37:43.195532:  
2025-07-08 13:37:43.195728: Epoch 943 
2025-07-08 13:37:43.195848: Current learning rate: 0.00076 
2025-07-08 13:38:30.458368: train_loss -0.9414 
2025-07-08 13:38:30.458753: val_loss -0.9492 
2025-07-08 13:38:30.458852: Pseudo dice [np.float32(0.96)] 
2025-07-08 13:38:30.458952: Epoch time: 47.26 s 
2025-07-08 13:38:30.459023: Yayy! New best EMA pseudo Dice: 0.957099974155426 
2025-07-08 13:38:32.535073:  
2025-07-08 13:38:32.535317: Epoch 944 
2025-07-08 13:38:32.535438: Current learning rate: 0.00075 
2025-07-08 13:39:22.375460: train_loss -0.9345 
2025-07-08 13:39:22.376032: val_loss -0.9435 
2025-07-08 13:39:22.376148: Pseudo dice [np.float32(0.9547)] 
2025-07-08 13:39:22.376261: Epoch time: 49.84 s 
2025-07-08 13:39:23.565053:  
2025-07-08 13:39:23.565492: Epoch 945 
2025-07-08 13:39:23.565650: Current learning rate: 0.00074 
2025-07-08 13:40:12.906884: train_loss -0.9379 
2025-07-08 13:40:12.907607: val_loss -0.9444 
2025-07-08 13:40:12.907727: Pseudo dice [np.float32(0.9564)] 
2025-07-08 13:40:12.907866: Epoch time: 49.34 s 
2025-07-08 13:40:14.041942:  
2025-07-08 13:40:14.042343: Epoch 946 
2025-07-08 13:40:14.042636: Current learning rate: 0.00072 
2025-07-08 13:41:03.393386: train_loss -0.9397 
2025-07-08 13:41:03.393982: val_loss -0.9458 
2025-07-08 13:41:03.394081: Pseudo dice [np.float32(0.9593)] 
2025-07-08 13:41:03.394211: Epoch time: 49.35 s 
2025-07-08 13:41:04.597475:  
2025-07-08 13:41:04.597734: Epoch 947 
2025-07-08 13:41:04.597918: Current learning rate: 0.00071 
2025-07-08 13:41:54.203104: train_loss -0.9423 
2025-07-08 13:41:54.203913: val_loss -0.9389 
2025-07-08 13:41:54.204004: Pseudo dice [np.float32(0.9544)] 
2025-07-08 13:41:54.204129: Epoch time: 49.61 s 
2025-07-08 13:41:55.500094:  
2025-07-08 13:41:55.500243: Epoch 948 
2025-07-08 13:41:55.500353: Current learning rate: 0.0007 
2025-07-08 13:42:46.341676: train_loss -0.9414 
2025-07-08 13:42:46.342150: val_loss -0.9429 
2025-07-08 13:42:46.342243: Pseudo dice [np.float32(0.9578)] 
2025-07-08 13:42:46.342370: Epoch time: 50.84 s 
2025-07-08 13:42:47.486785:  
2025-07-08 13:42:47.487411: Epoch 949 
2025-07-08 13:42:47.487537: Current learning rate: 0.00069 
2025-07-08 13:43:35.979862: train_loss -0.9429 
2025-07-08 13:43:35.980462: val_loss -0.9526 
2025-07-08 13:43:35.980558: Pseudo dice [np.float32(0.9588)] 
2025-07-08 13:43:35.980696: Epoch time: 48.49 s 
2025-07-08 13:43:38.072990:  
2025-07-08 13:43:38.073515: Epoch 950 
2025-07-08 13:43:38.073709: Current learning rate: 0.00067 
2025-07-08 13:44:27.873269: train_loss -0.9425 
2025-07-08 13:44:27.874738: val_loss -0.9405 
2025-07-08 13:44:27.875039: Pseudo dice [np.float32(0.9522)] 
2025-07-08 13:44:27.875357: Epoch time: 49.8 s 
2025-07-08 13:44:29.046696:  
2025-07-08 13:44:29.047012: Epoch 951 
2025-07-08 13:44:29.047141: Current learning rate: 0.00066 
2025-07-08 13:45:18.384362: train_loss -0.9427 
2025-07-08 13:45:18.385012: val_loss -0.9445 
2025-07-08 13:45:18.385094: Pseudo dice [np.float32(0.9558)] 
2025-07-08 13:45:18.385230: Epoch time: 49.34 s 
2025-07-08 13:45:19.612776:  
2025-07-08 13:45:19.613115: Epoch 952 
2025-07-08 13:45:19.613237: Current learning rate: 0.00065 
2025-07-08 13:46:08.477914: train_loss -0.945 
2025-07-08 13:46:08.478336: val_loss -0.9433 
2025-07-08 13:46:08.478451: Pseudo dice [np.float32(0.9547)] 
2025-07-08 13:46:08.478621: Epoch time: 48.87 s 
2025-07-08 13:46:09.558962:  
2025-07-08 13:46:09.559301: Epoch 953 
2025-07-08 13:46:09.559453: Current learning rate: 0.00064 
2025-07-08 13:46:58.873399: train_loss -0.9395 
2025-07-08 13:46:58.874176: val_loss -0.9464 
2025-07-08 13:46:58.874302: Pseudo dice [np.float32(0.9564)] 
2025-07-08 13:46:58.874449: Epoch time: 49.32 s 
2025-07-08 13:47:00.945742:  
2025-07-08 13:47:00.946014: Epoch 954 
2025-07-08 13:47:00.946179: Current learning rate: 0.00063 
2025-07-08 13:47:49.957911: train_loss -0.9414 
2025-07-08 13:47:49.958477: val_loss -0.9443 
2025-07-08 13:47:49.958581: Pseudo dice [np.float32(0.9544)] 
2025-07-08 13:47:49.958705: Epoch time: 49.01 s 
2025-07-08 13:47:51.172623:  
2025-07-08 13:47:51.172939: Epoch 955 
2025-07-08 13:47:51.173283: Current learning rate: 0.00061 
2025-07-08 13:48:40.490573: train_loss -0.9406 
2025-07-08 13:48:40.490956: val_loss -0.9428 
2025-07-08 13:48:40.491037: Pseudo dice [np.float32(0.9541)] 
2025-07-08 13:48:40.491131: Epoch time: 49.32 s 
2025-07-08 13:48:41.592179:  
2025-07-08 13:48:41.592629: Epoch 956 
2025-07-08 13:48:41.592940: Current learning rate: 0.0006 
2025-07-08 13:49:31.365643: train_loss -0.9362 
2025-07-08 13:49:31.366144: val_loss -0.9427 
2025-07-08 13:49:31.366227: Pseudo dice [np.float32(0.9573)] 
2025-07-08 13:49:31.366335: Epoch time: 49.77 s 
2025-07-08 13:49:32.549311:  
2025-07-08 13:49:32.549669: Epoch 957 
2025-07-08 13:49:32.549895: Current learning rate: 0.00059 
2025-07-08 13:50:22.124014: train_loss -0.9399 
2025-07-08 13:50:22.124590: val_loss -0.9452 
2025-07-08 13:50:22.124797: Pseudo dice [np.float32(0.9549)] 
2025-07-08 13:50:22.125023: Epoch time: 49.58 s 
2025-07-08 13:50:23.283388:  
2025-07-08 13:50:23.283942: Epoch 958 
2025-07-08 13:50:23.284135: Current learning rate: 0.00058 
2025-07-08 13:51:12.997664: train_loss -0.9431 
2025-07-08 13:51:12.998233: val_loss -0.9455 
2025-07-08 13:51:12.998317: Pseudo dice [np.float32(0.9557)] 
2025-07-08 13:51:12.998416: Epoch time: 49.72 s 
2025-07-08 13:51:14.155171:  
2025-07-08 13:51:14.155576: Epoch 959 
2025-07-08 13:51:14.155744: Current learning rate: 0.00056 
2025-07-08 13:52:03.118309: train_loss -0.9418 
2025-07-08 13:52:03.118844: val_loss -0.9477 
2025-07-08 13:52:03.118981: Pseudo dice [np.float32(0.957)] 
2025-07-08 13:52:03.119143: Epoch time: 48.96 s 
2025-07-08 13:52:04.272086:  
2025-07-08 13:52:04.272624: Epoch 960 
2025-07-08 13:52:04.272806: Current learning rate: 0.00055 
2025-07-08 13:52:53.292881: train_loss -0.9426 
2025-07-08 13:52:53.293468: val_loss -0.9462 
2025-07-08 13:52:53.293601: Pseudo dice [np.float32(0.9614)] 
2025-07-08 13:52:53.293754: Epoch time: 49.02 s 
2025-07-08 13:52:54.507329:  
2025-07-08 13:52:54.507984: Epoch 961 
2025-07-08 13:52:54.508095: Current learning rate: 0.00054 
2025-07-08 13:53:41.951977: train_loss -0.9424 
2025-07-08 13:53:41.953260: val_loss -0.948 
2025-07-08 13:53:41.953459: Pseudo dice [np.float32(0.9598)] 
2025-07-08 13:53:41.953679: Epoch time: 47.45 s 
2025-07-08 13:53:43.191291:  
2025-07-08 13:53:43.191823: Epoch 962 
2025-07-08 13:53:43.192173: Current learning rate: 0.00053 
2025-07-08 13:54:33.003530: train_loss -0.9389 
2025-07-08 13:54:33.003967: val_loss -0.9432 
2025-07-08 13:54:33.004050: Pseudo dice [np.float32(0.9539)] 
2025-07-08 13:54:33.004155: Epoch time: 49.81 s 
2025-07-08 13:54:34.177922:  
2025-07-08 13:54:34.178506: Epoch 963 
2025-07-08 13:54:34.178654: Current learning rate: 0.00051 
2025-07-08 13:55:23.495566: train_loss -0.9443 
2025-07-08 13:55:23.496248: val_loss -0.94 
2025-07-08 13:55:23.496356: Pseudo dice [np.float32(0.954)] 
2025-07-08 13:55:23.496480: Epoch time: 49.32 s 
2025-07-08 13:55:24.706391:  
2025-07-08 13:55:24.706785: Epoch 964 
2025-07-08 13:55:24.706984: Current learning rate: 0.0005 
2025-07-08 13:56:13.246672: train_loss -0.9419 
2025-07-08 13:56:13.247236: val_loss -0.9407 
2025-07-08 13:56:13.247367: Pseudo dice [np.float32(0.9549)] 
2025-07-08 13:56:13.247556: Epoch time: 48.54 s 
2025-07-08 13:56:14.381682:  
2025-07-08 13:56:14.381890: Epoch 965 
2025-07-08 13:56:14.382007: Current learning rate: 0.00049 
2025-07-08 13:57:03.154976: train_loss -0.9395 
2025-07-08 13:57:03.155509: val_loss -0.9433 
2025-07-08 13:57:03.155602: Pseudo dice [np.float32(0.9533)] 
2025-07-08 13:57:03.155710: Epoch time: 48.77 s 
2025-07-08 13:57:04.301665:  
2025-07-08 13:57:04.302137: Epoch 966 
2025-07-08 13:57:04.302440: Current learning rate: 0.00048 
2025-07-08 13:57:54.086464: train_loss -0.9439 
2025-07-08 13:57:54.086938: val_loss -0.944 
2025-07-08 13:57:54.087017: Pseudo dice [np.float32(0.9576)] 
2025-07-08 13:57:54.087126: Epoch time: 49.79 s 
2025-07-08 13:57:55.205375:  
2025-07-08 13:57:55.205691: Epoch 967 
2025-07-08 13:57:55.205830: Current learning rate: 0.00046 
2025-07-08 13:58:43.772668: train_loss -0.9426 
2025-07-08 13:58:43.773097: val_loss -0.9513 
2025-07-08 13:58:43.773184: Pseudo dice [np.float32(0.9614)] 
2025-07-08 13:58:43.773299: Epoch time: 48.57 s 
2025-07-08 13:58:45.003901:  
2025-07-08 13:58:45.004488: Epoch 968 
2025-07-08 13:58:45.004640: Current learning rate: 0.00045 
2025-07-08 13:59:33.629065: train_loss -0.9401 
2025-07-08 13:59:33.629699: val_loss -0.9405 
2025-07-08 13:59:33.629815: Pseudo dice [np.float32(0.9564)] 
2025-07-08 13:59:33.629940: Epoch time: 48.63 s 
2025-07-08 13:59:34.807321:  
2025-07-08 13:59:34.807597: Epoch 969 
2025-07-08 13:59:34.807873: Current learning rate: 0.00044 
2025-07-08 14:00:23.003045: train_loss -0.944 
2025-07-08 14:00:23.003743: val_loss -0.9458 
2025-07-08 14:00:23.003842: Pseudo dice [np.float32(0.9568)] 
2025-07-08 14:00:23.003975: Epoch time: 48.2 s 
2025-07-08 14:00:24.254289:  
2025-07-08 14:00:24.254782: Epoch 970 
2025-07-08 14:00:24.254928: Current learning rate: 0.00043 
2025-07-08 14:01:12.601304: train_loss -0.9416 
2025-07-08 14:01:12.601676: val_loss -0.9487 
2025-07-08 14:01:12.601761: Pseudo dice [np.float32(0.957)] 
2025-07-08 14:01:12.601866: Epoch time: 48.35 s 
2025-07-08 14:01:14.899790:  
2025-07-08 14:01:14.900254: Epoch 971 
2025-07-08 14:01:14.900855: Current learning rate: 0.00041 
2025-07-08 14:02:05.087022: train_loss -0.9395 
2025-07-08 14:02:05.087669: val_loss -0.9469 
2025-07-08 14:02:05.087785: Pseudo dice [np.float32(0.9573)] 
2025-07-08 14:02:05.087936: Epoch time: 50.19 s 
2025-07-08 14:02:06.295033:  
2025-07-08 14:02:06.295897: Epoch 972 
2025-07-08 14:02:06.296025: Current learning rate: 0.0004 
2025-07-08 14:02:54.368291: train_loss -0.9399 
2025-07-08 14:02:54.368774: val_loss -0.9459 
2025-07-08 14:02:54.368862: Pseudo dice [np.float32(0.9554)] 
2025-07-08 14:02:54.368969: Epoch time: 48.07 s 
2025-07-08 14:02:55.526946:  
2025-07-08 14:02:55.527334: Epoch 973 
2025-07-08 14:02:55.527699: Current learning rate: 0.00039 
2025-07-08 14:03:44.726854: train_loss -0.9412 
2025-07-08 14:03:44.727725: val_loss -0.9512 
2025-07-08 14:03:44.727821: Pseudo dice [np.float32(0.9601)] 
2025-07-08 14:03:44.727947: Epoch time: 49.2 s 
2025-07-08 14:03:45.928416:  
2025-07-08 14:03:45.929253: Epoch 974 
2025-07-08 14:03:45.929678: Current learning rate: 0.00037 
2025-07-08 14:04:36.037903: train_loss -0.9377 
2025-07-08 14:04:36.038834: val_loss -0.9417 
2025-07-08 14:04:36.038942: Pseudo dice [np.float32(0.9574)] 
2025-07-08 14:04:36.039058: Epoch time: 50.11 s 
2025-07-08 14:04:37.263342:  
2025-07-08 14:04:37.263769: Epoch 975 
2025-07-08 14:04:37.263977: Current learning rate: 0.00036 
2025-07-08 14:05:28.121506: train_loss -0.9407 
2025-07-08 14:05:28.123291: val_loss -0.9524 
2025-07-08 14:05:28.123442: Pseudo dice [np.float32(0.9623)] 
2025-07-08 14:05:28.123661: Epoch time: 50.86 s 
2025-07-08 14:05:28.123802: Yayy! New best EMA pseudo Dice: 0.9574999809265137 
2025-07-08 14:05:30.238895:  
2025-07-08 14:05:30.239320: Epoch 976 
2025-07-08 14:05:30.239457: Current learning rate: 0.00035 
2025-07-08 14:06:20.521003: train_loss -0.9396 
2025-07-08 14:06:20.521606: val_loss -0.9463 
2025-07-08 14:06:20.521690: Pseudo dice [np.float32(0.9617)] 
2025-07-08 14:06:20.521815: Epoch time: 50.28 s 
2025-07-08 14:06:20.521886: Yayy! New best EMA pseudo Dice: 0.9578999876976013 
2025-07-08 14:06:22.745469:  
2025-07-08 14:06:22.745716: Epoch 977 
2025-07-08 14:06:22.745839: Current learning rate: 0.00034 
2025-07-08 14:07:12.745172: train_loss -0.9385 
2025-07-08 14:07:12.745838: val_loss -0.9428 
2025-07-08 14:07:12.745931: Pseudo dice [np.float32(0.9558)] 
2025-07-08 14:07:12.746057: Epoch time: 50.0 s 
2025-07-08 14:07:13.916575:  
2025-07-08 14:07:13.917089: Epoch 978 
2025-07-08 14:07:13.917323: Current learning rate: 0.00032 
2025-07-08 14:08:03.572924: train_loss -0.9424 
2025-07-08 14:08:03.573828: val_loss -0.9461 
2025-07-08 14:08:03.573952: Pseudo dice [np.float32(0.9567)] 
2025-07-08 14:08:03.574104: Epoch time: 49.66 s 
2025-07-08 14:08:04.885995:  
2025-07-08 14:08:04.886700: Epoch 979 
2025-07-08 14:08:04.887061: Current learning rate: 0.00031 
2025-07-08 14:08:54.178585: train_loss -0.9407 
2025-07-08 14:08:54.179046: val_loss -0.9474 
2025-07-08 14:08:54.179144: Pseudo dice [np.float32(0.9579)] 
2025-07-08 14:08:54.179271: Epoch time: 49.3 s 
2025-07-08 14:08:55.357338:  
2025-07-08 14:08:55.357853: Epoch 980 
2025-07-08 14:08:55.358090: Current learning rate: 0.0003 
2025-07-08 14:09:44.361335: train_loss -0.9427 
2025-07-08 14:09:44.361983: val_loss -0.9432 
2025-07-08 14:09:44.362079: Pseudo dice [np.float32(0.9576)] 
2025-07-08 14:09:44.362223: Epoch time: 49.01 s 
2025-07-08 14:09:45.683333:  
2025-07-08 14:09:45.683636: Epoch 981 
2025-07-08 14:09:45.683839: Current learning rate: 0.00028 
2025-07-08 14:10:34.195075: train_loss -0.9391 
2025-07-08 14:10:34.196360: val_loss -0.9471 
2025-07-08 14:10:34.196579: Pseudo dice [np.float32(0.9591)] 
2025-07-08 14:10:34.196876: Epoch time: 48.51 s 
2025-07-08 14:10:35.397062:  
2025-07-08 14:10:35.397320: Epoch 982 
2025-07-08 14:10:35.397505: Current learning rate: 0.00027 
2025-07-08 14:11:24.226342: train_loss -0.9451 
2025-07-08 14:11:24.227046: val_loss -0.9453 
2025-07-08 14:11:24.227135: Pseudo dice [np.float32(0.9572)] 
2025-07-08 14:11:24.227260: Epoch time: 48.83 s 
2025-07-08 14:11:25.450796:  
2025-07-08 14:11:25.451349: Epoch 983 
2025-07-08 14:11:25.451528: Current learning rate: 0.00026 
2025-07-08 14:12:14.248804: train_loss -0.9395 
2025-07-08 14:12:14.249537: val_loss -0.9431 
2025-07-08 14:12:14.249675: Pseudo dice [np.float32(0.9527)] 
2025-07-08 14:12:14.249841: Epoch time: 48.8 s 
2025-07-08 14:12:15.406161:  
2025-07-08 14:12:15.406650: Epoch 984 
2025-07-08 14:12:15.406774: Current learning rate: 0.00024 
2025-07-08 14:13:04.825408: train_loss -0.9421 
2025-07-08 14:13:04.826238: val_loss -0.9466 
2025-07-08 14:13:04.826334: Pseudo dice [np.float32(0.9575)] 
2025-07-08 14:13:04.826532: Epoch time: 49.42 s 
2025-07-08 14:13:06.161761:  
2025-07-08 14:13:06.161903: Epoch 985 
2025-07-08 14:13:06.162060: Current learning rate: 0.00023 
2025-07-08 14:13:54.959285: train_loss -0.9415 
2025-07-08 14:13:54.960171: val_loss -0.945 
2025-07-08 14:13:54.964443: Pseudo dice [np.float32(0.957)] 
2025-07-08 14:13:54.965010: Epoch time: 48.8 s 
2025-07-08 14:13:56.208689:  
2025-07-08 14:13:56.209024: Epoch 986 
2025-07-08 14:13:56.209155: Current learning rate: 0.00021 
2025-07-08 14:14:44.645817: train_loss -0.9369 
2025-07-08 14:14:44.646475: val_loss -0.9419 
2025-07-08 14:14:44.646596: Pseudo dice [np.float32(0.952)] 
2025-07-08 14:14:44.646766: Epoch time: 48.44 s 
2025-07-08 14:14:46.868159:  
2025-07-08 14:14:46.868524: Epoch 987 
2025-07-08 14:14:46.868738: Current learning rate: 0.0002 
2025-07-08 14:15:35.999045: train_loss -0.9386 
2025-07-08 14:15:35.999875: val_loss -0.9483 
2025-07-08 14:15:35.999981: Pseudo dice [np.float32(0.9616)] 
2025-07-08 14:15:36.000124: Epoch time: 49.13 s 
2025-07-08 14:15:37.292337:  
2025-07-08 14:15:37.292834: Epoch 988 
2025-07-08 14:15:37.292998: Current learning rate: 0.00019 
2025-07-08 14:16:26.978735: train_loss -0.9417 
2025-07-08 14:16:26.979167: val_loss -0.9446 
2025-07-08 14:16:26.979244: Pseudo dice [np.float32(0.9563)] 
2025-07-08 14:16:26.979364: Epoch time: 49.69 s 
2025-07-08 14:16:28.107562:  
2025-07-08 14:16:28.108103: Epoch 989 
2025-07-08 14:16:28.108477: Current learning rate: 0.00017 
2025-07-08 14:17:16.139027: train_loss -0.9409 
2025-07-08 14:17:16.139876: val_loss -0.9532 
2025-07-08 14:17:16.139993: Pseudo dice [np.float32(0.9608)] 
2025-07-08 14:17:16.140125: Epoch time: 48.03 s 
2025-07-08 14:17:17.402123:  
2025-07-08 14:17:17.402656: Epoch 990 
2025-07-08 14:17:17.402809: Current learning rate: 0.00016 
2025-07-08 14:18:08.011528: train_loss -0.9415 
2025-07-08 14:18:08.012341: val_loss -0.9447 
2025-07-08 14:18:08.012434: Pseudo dice [np.float32(0.9604)] 
2025-07-08 14:18:08.012576: Epoch time: 50.61 s 
2025-07-08 14:18:09.247168:  
2025-07-08 14:18:09.247839: Epoch 991 
2025-07-08 14:18:09.247981: Current learning rate: 0.00014 
2025-07-08 14:18:55.693828: train_loss -0.9458 
2025-07-08 14:18:55.695453: val_loss -0.9496 
2025-07-08 14:18:55.695668: Pseudo dice [np.float32(0.9607)] 
2025-07-08 14:18:55.695888: Epoch time: 46.45 s 
2025-07-08 14:18:55.696023: Yayy! New best EMA pseudo Dice: 0.9580000042915344 
2025-07-08 14:18:57.775570:  
2025-07-08 14:18:57.776041: Epoch 992 
2025-07-08 14:18:57.776200: Current learning rate: 0.00013 
2025-07-08 14:19:46.537317: train_loss -0.9414 
2025-07-08 14:19:46.538854: val_loss -0.9468 
2025-07-08 14:19:46.539045: Pseudo dice [np.float32(0.9606)] 
2025-07-08 14:19:46.539297: Epoch time: 48.76 s 
2025-07-08 14:19:46.539441: Yayy! New best EMA pseudo Dice: 0.958299994468689 
2025-07-08 14:19:48.840845:  
2025-07-08 14:19:48.841327: Epoch 993 
2025-07-08 14:19:48.841513: Current learning rate: 0.00011 
2025-07-08 14:20:37.609603: train_loss -0.9452 
2025-07-08 14:20:37.610208: val_loss -0.9435 
2025-07-08 14:20:37.610296: Pseudo dice [np.float32(0.9567)] 
2025-07-08 14:20:37.610416: Epoch time: 48.77 s 
2025-07-08 14:20:38.866017:  
2025-07-08 14:20:38.866457: Epoch 994 
2025-07-08 14:20:38.866591: Current learning rate: 0.0001 
2025-07-08 14:21:27.446757: train_loss -0.9427 
2025-07-08 14:21:27.447125: val_loss -0.9472 
2025-07-08 14:21:27.447206: Pseudo dice [np.float32(0.9572)] 
2025-07-08 14:21:27.447313: Epoch time: 48.58 s 
2025-07-08 14:21:28.633672:  
2025-07-08 14:21:28.633950: Epoch 995 
2025-07-08 14:21:28.634087: Current learning rate: 8e-05 
2025-07-08 14:22:16.720444: train_loss -0.9455 
2025-07-08 14:22:16.720986: val_loss -0.945 
2025-07-08 14:22:16.721118: Pseudo dice [np.float32(0.956)] 
2025-07-08 14:22:16.721256: Epoch time: 48.09 s 
2025-07-08 14:22:17.932445:  
2025-07-08 14:22:17.932864: Epoch 996 
2025-07-08 14:22:17.933060: Current learning rate: 7e-05 
2025-07-08 14:23:06.919230: train_loss -0.9401 
2025-07-08 14:23:06.919880: val_loss -0.9481 
2025-07-08 14:23:06.920043: Pseudo dice [np.float32(0.9592)] 
2025-07-08 14:23:06.920187: Epoch time: 48.99 s 
2025-07-08 14:23:08.161141:  
2025-07-08 14:23:08.161304: Epoch 997 
2025-07-08 14:23:08.161406: Current learning rate: 5e-05 
2025-07-08 14:23:58.339152: train_loss -0.9408 
2025-07-08 14:23:58.339706: val_loss -0.9458 
2025-07-08 14:23:58.339795: Pseudo dice [np.float32(0.9563)] 
2025-07-08 14:23:58.339911: Epoch time: 50.18 s 
2025-07-08 14:23:59.653426:  
2025-07-08 14:23:59.653965: Epoch 998 
2025-07-08 14:23:59.654163: Current learning rate: 4e-05 
2025-07-08 14:24:49.576660: train_loss -0.942 
2025-07-08 14:24:49.577556: val_loss -0.9472 
2025-07-08 14:24:49.577668: Pseudo dice [np.float32(0.9586)] 
2025-07-08 14:24:49.577808: Epoch time: 49.92 s 
2025-07-08 14:24:50.864423:  
2025-07-08 14:24:50.864727: Epoch 999 
2025-07-08 14:24:50.864856: Current learning rate: 2e-05 
2025-07-08 14:25:43.258609: train_loss -0.9406 
2025-07-08 14:25:43.259057: val_loss -0.9486 
2025-07-08 14:25:43.259134: Pseudo dice [np.float32(0.9596)] 
2025-07-08 14:25:43.259236: Epoch time: 52.4 s 
2025-07-08 14:25:44.899485: Training done. 
2025-07-08 14:25:44.926295: predicting BraTS-PED-00001-000 
2025-07-08 14:25:45.044199: BraTS-PED-00001-000, shape torch.Size([4, 149, 177, 136]), rank 0 
2025-07-08 14:25:55.693966: predicting BraTS-PED-00002-000 
2025-07-08 14:25:55.739270: BraTS-PED-00002-000, shape torch.Size([4, 135, 156, 128]), rank 0 
2025-07-08 14:25:56.082912: predicting BraTS-PED-00003-000 
2025-07-08 14:25:56.125054: BraTS-PED-00003-000, shape torch.Size([4, 133, 148, 133]), rank 0 
2025-07-08 14:25:56.782618: predicting BraTS-PED-00004-000 
2025-07-08 14:25:56.829622: BraTS-PED-00004-000, shape torch.Size([4, 141, 160, 130]), rank 0 
2025-07-08 14:25:57.488788: predicting BraTS-PED-00005-000 
2025-07-08 14:25:57.552087: BraTS-PED-00005-000, shape torch.Size([4, 144, 185, 152]), rank 0 
2025-07-08 14:25:58.214608: predicting BraTS-PED-00006-000 
2025-07-08 14:25:58.264534: BraTS-PED-00006-000, shape torch.Size([4, 145, 158, 137]), rank 0 
2025-07-08 14:25:58.926906: predicting BraTS-PED-00008-000 
2025-07-08 14:25:58.976476: BraTS-PED-00008-000, shape torch.Size([4, 142, 162, 135]), rank 0 
2025-07-08 14:25:59.636300: predicting BraTS-PED-00009-000 
2025-07-08 14:25:59.689513: BraTS-PED-00009-000, shape torch.Size([4, 144, 164, 140]), rank 0 
2025-07-08 14:26:00.350645: predicting BraTS-PED-00010-000 
2025-07-08 14:26:00.416780: BraTS-PED-00010-000, shape torch.Size([4, 148, 191, 147]), rank 0 
2025-07-08 14:26:01.079872: predicting BraTS-PED-00013-000 
2025-07-08 14:26:01.138722: BraTS-PED-00013-000, shape torch.Size([4, 143, 173, 152]), rank 0 
2025-07-08 14:26:01.801322: predicting BraTS-PED-00014-000 
2025-07-08 14:26:01.847495: BraTS-PED-00014-000, shape torch.Size([4, 135, 163, 131]), rank 0 
2025-07-08 14:26:02.508417: predicting BraTS-PED-00015-000 
2025-07-08 14:26:02.564483: BraTS-PED-00015-000, shape torch.Size([4, 144, 177, 140]), rank 0 
2025-07-08 14:26:03.225214: predicting BraTS-PED-00016-000 
2025-07-08 14:26:03.280554: BraTS-PED-00016-000, shape torch.Size([4, 145, 171, 142]), rank 0 
2025-07-08 14:26:03.946679: predicting BraTS-PED-00017-000 
2025-07-08 14:26:04.005794: BraTS-PED-00017-000, shape torch.Size([4, 146, 174, 138]), rank 0 
2025-07-08 14:26:04.668832: predicting BraTS-PED-00018-000 
2025-07-08 14:26:04.723819: BraTS-PED-00018-000, shape torch.Size([4, 145, 170, 135]), rank 0 
2025-07-08 14:26:05.389107: predicting BraTS-PED-00019-000 
2025-07-08 14:26:05.445209: BraTS-PED-00019-000, shape torch.Size([4, 146, 170, 138]), rank 0 
2025-07-08 14:26:06.111434: predicting BraTS-PED-00020-000 
2025-07-08 14:26:06.167150: BraTS-PED-00020-000, shape torch.Size([4, 143, 175, 132]), rank 0 
2025-07-08 14:26:06.830441: predicting BraTS-PED-00021-000 
2025-07-08 14:26:06.884108: BraTS-PED-00021-000, shape torch.Size([4, 148, 160, 144]), rank 0 
2025-07-08 14:26:07.547772: predicting BraTS-PED-00022-000 
2025-07-08 14:26:07.604722: BraTS-PED-00022-000, shape torch.Size([4, 145, 172, 143]), rank 0 
2025-07-08 14:26:08.267753: predicting BraTS-PED-00023-000 
2025-07-08 14:26:08.313966: BraTS-PED-00023-000, shape torch.Size([4, 130, 158, 137]), rank 0 
2025-07-08 14:26:08.977581: predicting BraTS-PED-00024-000 
2025-07-08 14:26:09.027180: BraTS-PED-00024-000, shape torch.Size([4, 137, 164, 135]), rank 0 
2025-07-08 14:26:09.689642: predicting BraTS-PED-00025-000 
2025-07-08 14:26:09.742160: BraTS-PED-00025-000, shape torch.Size([4, 145, 165, 144]), rank 0 
2025-07-08 14:26:10.406592: predicting BraTS-PED-00026-000 
2025-07-08 14:26:10.457141: BraTS-PED-00026-000, shape torch.Size([4, 136, 165, 134]), rank 0 
2025-07-08 14:26:11.119620: predicting BraTS-PED-00027-000 
2025-07-08 14:26:11.174402: BraTS-PED-00027-000, shape torch.Size([4, 140, 168, 145]), rank 0 
2025-07-08 14:26:11.837519: predicting BraTS-PED-00028-000 
2025-07-08 14:26:11.890070: BraTS-PED-00028-000, shape torch.Size([4, 139, 174, 135]), rank 0 
2025-07-08 14:26:12.553126: predicting BraTS-PED-00029-000 
2025-07-08 14:26:12.604750: BraTS-PED-00029-000, shape torch.Size([4, 140, 169, 132]), rank 0 
2025-07-08 14:26:13.267065: predicting BraTS-PED-00030-000 
2025-07-08 14:26:13.324827: BraTS-PED-00030-000, shape torch.Size([4, 145, 171, 147]), rank 0 
2025-07-08 14:26:13.989429: predicting BraTS-PED-00031-000 
2025-07-08 14:26:14.042445: BraTS-PED-00031-000, shape torch.Size([4, 147, 161, 136]), rank 0 
2025-07-08 14:26:14.706153: predicting BraTS-PED-00032-000 
2025-07-08 14:26:14.757860: BraTS-PED-00032-000, shape torch.Size([4, 134, 167, 133]), rank 0 
2025-07-08 14:26:15.420448: predicting BraTS-PED-00033-000 
2025-07-08 14:26:15.470497: BraTS-PED-00033-000, shape torch.Size([4, 139, 158, 134]), rank 0 
2025-07-08 14:26:16.133110: predicting BraTS-PED-00034-000 
2025-07-08 14:26:16.189118: BraTS-PED-00034-000, shape torch.Size([4, 145, 172, 136]), rank 0 
2025-07-08 14:26:16.855874: predicting BraTS-PED-00035-000 
2025-07-08 14:26:16.918238: BraTS-PED-00035-000, shape torch.Size([4, 144, 183, 141]), rank 0 
2025-07-08 14:26:17.585293: predicting BraTS-PED-00036-000 
2025-07-08 14:26:17.641715: BraTS-PED-00036-000, shape torch.Size([4, 147, 174, 135]), rank 0 
2025-07-08 14:26:18.307733: predicting BraTS-PED-00037-000 
2025-07-08 14:26:18.364485: BraTS-PED-00037-000, shape torch.Size([4, 144, 172, 142]), rank 0 
2025-07-08 14:26:19.032734: predicting BraTS-PED-00038-000 
2025-07-08 14:26:19.087561: BraTS-PED-00038-000, shape torch.Size([4, 144, 169, 139]), rank 0 
2025-07-08 14:26:19.751877: predicting BraTS-PED-00039-000 
2025-07-08 14:26:19.795654: BraTS-PED-00039-000, shape torch.Size([4, 135, 156, 126]), rank 0 
2025-07-08 14:26:20.167472: predicting BraTS-PED-00040-000 
2025-07-08 14:26:20.228082: BraTS-PED-00040-000, shape torch.Size([4, 147, 183, 144]), rank 0 
2025-07-08 14:26:20.893141: predicting BraTS-PED-00041-000 
2025-07-08 14:26:20.942005: BraTS-PED-00041-000, shape torch.Size([4, 127, 158, 133]), rank 0 
2025-07-08 14:26:21.315736: predicting BraTS-PED-00042-000 
2025-07-08 14:26:21.353732: BraTS-PED-00042-000, shape torch.Size([4, 138, 141, 120]), rank 0 
2025-07-08 14:26:21.722447: predicting BraTS-PED-00043-000 
2025-07-08 14:26:21.780925: BraTS-PED-00043-000, shape torch.Size([4, 141, 174, 140]), rank 0 
2025-07-08 14:26:22.445229: predicting BraTS-PED-00044-000 
2025-07-08 14:26:22.503142: BraTS-PED-00044-000, shape torch.Size([4, 142, 176, 142]), rank 0 
2025-07-08 14:26:23.170313: predicting BraTS-PED-00045-000 
2025-07-08 14:26:23.223490: BraTS-PED-00045-000, shape torch.Size([4, 142, 159, 137]), rank 0 
2025-07-08 14:26:23.888833: predicting BraTS-PED-00046-000 
2025-07-08 14:26:23.935175: BraTS-PED-00046-000, shape torch.Size([4, 137, 163, 129]), rank 0 
2025-07-08 14:26:24.599336: predicting BraTS-PED-00047-000 
2025-07-08 14:26:24.651774: BraTS-PED-00047-000, shape torch.Size([4, 147, 159, 135]), rank 0 
2025-07-08 14:26:25.315233: predicting BraTS-PED-00048-000 
2025-07-08 14:26:25.365009: BraTS-PED-00048-000, shape torch.Size([4, 137, 156, 130]), rank 0 
2025-07-08 14:26:26.027952: predicting BraTS-PED-00049-000 
2025-07-08 14:26:26.074223: BraTS-PED-00049-000, shape torch.Size([4, 131, 167, 126]), rank 0 
2025-07-08 14:26:26.448519: predicting BraTS-PED-00050-000 
2025-07-08 14:26:26.503753: BraTS-PED-00050-000, shape torch.Size([4, 141, 168, 137]), rank 0 
2025-07-08 14:26:27.167249: predicting BraTS-PED-00051-000 
2025-07-08 14:26:27.221382: BraTS-PED-00051-000, shape torch.Size([4, 143, 162, 141]), rank 0 
2025-07-08 14:26:27.886139: predicting BraTS-PED-00052-000 
2025-07-08 14:26:27.935302: BraTS-PED-00052-000, shape torch.Size([4, 139, 155, 139]), rank 0 
2025-07-08 14:26:28.598747: predicting BraTS-PED-00053-000 
2025-07-08 14:26:28.647809: BraTS-PED-00053-000, shape torch.Size([4, 141, 163, 126]), rank 0 
2025-07-08 14:26:29.022813: predicting BraTS-PED-00054-000 
2025-07-08 14:26:29.078731: BraTS-PED-00054-000, shape torch.Size([4, 146, 171, 141]), rank 0 
2025-07-08 14:26:29.742912: predicting BraTS-PED-00055-000 
2025-07-08 14:26:29.796586: BraTS-PED-00055-000, shape torch.Size([4, 141, 156, 151]), rank 0 
2025-07-08 14:26:30.461271: predicting BraTS-PED-00056-000 
2025-07-08 14:26:30.512265: BraTS-PED-00056-000, shape torch.Size([4, 136, 165, 138]), rank 0 
2025-07-08 14:26:31.177437: predicting BraTS-PED-00057-000 
2025-07-08 14:26:31.221740: BraTS-PED-00057-000, shape torch.Size([4, 136, 157, 131]), rank 0 
2025-07-08 14:26:31.885686: predicting BraTS-PED-00058-000 
2025-07-08 14:26:31.935891: BraTS-PED-00058-000, shape torch.Size([4, 138, 164, 133]), rank 0 
2025-07-08 14:26:32.599717: predicting BraTS-PED-00059-000 
2025-07-08 14:26:32.652179: BraTS-PED-00059-000, shape torch.Size([4, 139, 166, 126]), rank 0 
2025-07-08 14:26:33.029098: predicting BraTS-PED-00060-000 
2025-07-08 14:26:33.085530: BraTS-PED-00060-000, shape torch.Size([4, 144, 164, 141]), rank 0 
2025-07-08 14:26:33.755037: predicting BraTS-PED-00061-000 
2025-07-08 14:26:33.809835: BraTS-PED-00061-000, shape torch.Size([4, 141, 161, 132]), rank 0 
2025-07-08 14:26:34.476480: predicting BraTS-PED-00062-000 
2025-07-08 14:26:34.531800: BraTS-PED-00062-000, shape torch.Size([4, 144, 176, 133]), rank 0 
2025-07-08 14:26:35.198082: predicting BraTS-PED-00063-000 
2025-07-08 14:26:35.255403: BraTS-PED-00063-000, shape torch.Size([4, 146, 174, 129]), rank 0 
2025-07-08 14:26:35.920925: predicting BraTS-PED-00064-000 
2025-07-08 14:26:35.982769: BraTS-PED-00064-000, shape torch.Size([4, 145, 172, 139]), rank 0 
2025-07-08 14:26:36.651906: predicting BraTS-PED-00065-000 
2025-07-08 14:26:36.702562: BraTS-PED-00065-000, shape torch.Size([4, 134, 163, 133]), rank 0 
2025-07-08 14:26:37.368167: predicting BraTS-PED-00066-000 
2025-07-08 14:26:37.424949: BraTS-PED-00066-000, shape torch.Size([4, 141, 172, 141]), rank 0 
2025-07-08 14:26:38.091074: predicting BraTS-PED-00067-000 
2025-07-08 14:26:38.137107: BraTS-PED-00067-000, shape torch.Size([4, 138, 145, 132]), rank 0 
2025-07-08 14:26:38.801798: predicting BraTS-PED-00068-000 
2025-07-08 14:26:38.849104: BraTS-PED-00068-000, shape torch.Size([4, 138, 159, 134]), rank 0 
2025-07-08 14:26:39.513563: predicting BraTS-PED-00069-000 
2025-07-08 14:26:39.563043: BraTS-PED-00069-000, shape torch.Size([4, 142, 161, 134]), rank 0 
2025-07-08 14:26:40.228354: predicting BraTS-PED-00070-000 
2025-07-08 14:26:40.280080: BraTS-PED-00070-000, shape torch.Size([4, 146, 147, 145]), rank 0 
2025-07-08 14:26:40.946012: predicting BraTS-PED-00071-000 
2025-07-08 14:26:41.003619: BraTS-PED-00071-000, shape torch.Size([4, 143, 171, 142]), rank 0 
2025-07-08 14:26:41.671183: predicting BraTS-PED-00072-000 
2025-07-08 14:26:41.717463: BraTS-PED-00072-000, shape torch.Size([4, 138, 161, 129]), rank 0 
2025-07-08 14:26:42.383035: predicting BraTS-PED-00073-000 
2025-07-08 14:26:42.437853: BraTS-PED-00073-000, shape torch.Size([4, 141, 161, 139]), rank 0 
2025-07-08 14:26:43.103783: predicting BraTS-PED-00074-000 
2025-07-08 14:26:43.151141: BraTS-PED-00074-000, shape torch.Size([4, 140, 162, 131]), rank 0 
2025-07-08 14:26:43.817125: predicting BraTS-PED-00075-000 
2025-07-08 14:26:43.868062: BraTS-PED-00075-000, shape torch.Size([4, 140, 153, 139]), rank 0 
2025-07-08 14:26:44.532733: predicting BraTS-PED-00076-000 
2025-07-08 14:26:44.594571: BraTS-PED-00076-000, shape torch.Size([4, 143, 172, 146]), rank 0 
2025-07-08 14:26:45.261134: predicting BraTS-PED-00077-000 
2025-07-08 14:26:45.312748: BraTS-PED-00077-000, shape torch.Size([4, 142, 166, 130]), rank 0 
2025-07-08 14:26:45.978985: predicting BraTS-PED-00078-000 
2025-07-08 14:26:46.033326: BraTS-PED-00078-000, shape torch.Size([4, 137, 172, 132]), rank 0 
2025-07-08 14:26:46.700074: predicting BraTS-PED-00079-000 
2025-07-08 14:26:46.758723: BraTS-PED-00079-000, shape torch.Size([4, 143, 169, 145]), rank 0 
2025-07-08 14:26:47.424359: predicting BraTS-PED-00080-000 
2025-07-08 14:26:47.479102: BraTS-PED-00080-000, shape torch.Size([4, 148, 163, 143]), rank 0 
2025-07-08 14:26:48.146278: predicting BraTS-PED-00081-000 
2025-07-08 14:26:48.200944: BraTS-PED-00081-000, shape torch.Size([4, 143, 172, 137]), rank 0 
2025-07-08 14:26:48.867760: predicting BraTS-PED-00082-000 
2025-07-08 14:26:48.923586: BraTS-PED-00082-000, shape torch.Size([4, 148, 174, 135]), rank 0 
2025-07-08 14:26:49.591083: predicting BraTS-PED-00083-000 
2025-07-08 14:26:49.647368: BraTS-PED-00083-000, shape torch.Size([4, 148, 170, 139]), rank 0 
2025-07-08 14:26:50.314478: predicting BraTS-PED-00084-000 
2025-07-08 14:26:50.373498: BraTS-PED-00084-000, shape torch.Size([4, 150, 171, 142]), rank 0 
2025-07-08 14:26:51.041509: predicting BraTS-PED-00085-000 
2025-07-08 14:26:51.099855: BraTS-PED-00085-000, shape torch.Size([4, 145, 181, 138]), rank 0 
2025-07-08 14:26:51.767217: predicting BraTS-PED-00086-000 
2025-07-08 14:26:51.811951: BraTS-PED-00086-000, shape torch.Size([4, 133, 152, 134]), rank 0 
2025-07-08 14:26:52.477412: predicting BraTS-PED-00087-000 
2025-07-08 14:26:52.530658: BraTS-PED-00087-000, shape torch.Size([4, 143, 158, 133]), rank 0 
2025-07-08 14:26:53.195196: predicting BraTS-PED-00088-000 
2025-07-08 14:26:53.259422: BraTS-PED-00088-000, shape torch.Size([4, 149, 175, 148]), rank 0 
2025-07-08 14:26:53.927937: predicting BraTS-PED-00089-000 
2025-07-08 14:26:53.983500: BraTS-PED-00089-000, shape torch.Size([4, 144, 174, 134]), rank 0 
2025-07-08 14:26:54.650948: predicting BraTS-PED-00091-000 
2025-07-08 14:26:54.705180: BraTS-PED-00091-000, shape torch.Size([4, 143, 173, 137]), rank 0 
2025-07-08 14:26:55.372149: predicting BraTS-PED-00092-000 
2025-07-08 14:26:55.428246: BraTS-PED-00092-000, shape torch.Size([4, 145, 163, 145]), rank 0 
2025-07-08 14:26:56.094948: predicting BraTS-PED-00093-000 
2025-07-08 14:26:56.153587: BraTS-PED-00093-000, shape torch.Size([4, 144, 183, 143]), rank 0 
2025-07-08 14:26:56.821775: predicting BraTS-PED-00094-000 
2025-07-08 14:26:56.881284: BraTS-PED-00094-000, shape torch.Size([4, 141, 183, 142]), rank 0 
2025-07-08 14:26:57.550209: predicting BraTS-PED-00095-000 
2025-07-08 14:26:57.583112: BraTS-PED-00095-000, shape torch.Size([4, 109, 134, 120]), rank 0 
2025-07-08 14:26:57.790986: predicting BraTS-PED-00096-000 
2025-07-08 14:26:57.839741: BraTS-PED-00096-000, shape torch.Size([4, 139, 148, 136]), rank 0 
2025-07-08 14:26:58.503273: predicting BraTS-PED-00097-000 
2025-07-08 14:26:58.559292: BraTS-PED-00097-000, shape torch.Size([4, 145, 180, 134]), rank 0 
2025-07-08 14:26:59.226586: predicting BraTS-PED-00098-000 
2025-07-08 14:26:59.275028: BraTS-PED-00098-000, shape torch.Size([4, 144, 156, 128]), rank 0 
2025-07-08 14:26:59.617911: predicting BraTS-PED-00099-000 
2025-07-08 14:26:59.672577: BraTS-PED-00099-000, shape torch.Size([4, 146, 174, 133]), rank 0 
2025-07-08 14:27:00.339920: predicting BraTS-PED-00100-000 
2025-07-08 14:27:00.404163: BraTS-PED-00100-000, shape torch.Size([4, 145, 187, 147]), rank 0 
2025-07-08 14:27:01.073203: predicting BraTS-PED-00101-000 
2025-07-08 14:27:01.145554: BraTS-PED-00101-000, shape torch.Size([4, 146, 188, 155]), rank 0 
2025-07-08 14:27:01.817028: predicting BraTS-PED-00102-000 
2025-07-08 14:27:01.868802: BraTS-PED-00102-000, shape torch.Size([4, 147, 155, 132]), rank 0 
2025-07-08 14:27:02.536364: predicting BraTS-PED-00103-000 
2025-07-08 14:27:02.605283: BraTS-PED-00103-000, shape torch.Size([4, 142, 177, 156]), rank 0 
2025-07-08 14:27:03.274323: predicting BraTS-PED-00104-000 
2025-07-08 14:27:03.322398: BraTS-PED-00104-000, shape torch.Size([4, 140, 162, 134]), rank 0 
2025-07-08 14:27:03.989674: predicting BraTS-PED-00105-000 
2025-07-08 14:27:04.048838: BraTS-PED-00105-000, shape torch.Size([4, 147, 181, 137]), rank 0 
2025-07-08 14:27:04.717216: predicting BraTS-PED-00106-000 
2025-07-08 14:27:04.771373: BraTS-PED-00106-000, shape torch.Size([4, 144, 164, 140]), rank 0 
2025-07-08 14:27:05.439835: predicting BraTS-PED-00107-000 
2025-07-08 14:27:05.494032: BraTS-PED-00107-000, shape torch.Size([4, 150, 174, 144]), rank 0 
2025-07-08 14:27:06.164392: predicting BraTS-PED-00108-000 
2025-07-08 14:27:06.223386: BraTS-PED-00108-000, shape torch.Size([4, 145, 166, 147]), rank 0 
2025-07-08 14:27:06.893172: predicting BraTS-PED-00109-000 
2025-07-08 14:27:06.959426: BraTS-PED-00109-000, shape torch.Size([4, 151, 183, 147]), rank 0 
2025-07-08 14:27:07.628834: predicting BraTS-PED-00110-000 
2025-07-08 14:27:07.679662: BraTS-PED-00110-000, shape torch.Size([4, 143, 167, 136]), rank 0 
2025-07-08 14:27:08.348728: predicting BraTS-PED-00112-000 
2025-07-08 14:27:08.401323: BraTS-PED-00112-000, shape torch.Size([4, 140, 164, 133]), rank 0 
2025-07-08 14:27:09.068135: predicting BraTS-PED-00113-000 
2025-07-08 14:27:09.130642: BraTS-PED-00113-000, shape torch.Size([4, 145, 178, 146]), rank 0 
2025-07-08 14:27:09.799401: predicting BraTS-PED-00114-000 
2025-07-08 14:27:09.850644: BraTS-PED-00114-000, shape torch.Size([4, 140, 166, 129]), rank 0 
2025-07-08 14:27:10.517513: predicting BraTS-PED-00115-000 
2025-07-08 14:27:10.573244: BraTS-PED-00115-000, shape torch.Size([4, 144, 173, 138]), rank 0 
2025-07-08 14:27:11.242053: predicting BraTS-PED-00116-000 
2025-07-08 14:27:11.298094: BraTS-PED-00116-000, shape torch.Size([4, 142, 178, 132]), rank 0 
2025-07-08 14:27:11.967205: predicting BraTS-PED-00117-000 
2025-07-08 14:27:12.016447: BraTS-PED-00117-000, shape torch.Size([4, 144, 154, 137]), rank 0 
2025-07-08 14:27:12.683868: predicting BraTS-PED-00118-000 
2025-07-08 14:27:12.746458: BraTS-PED-00118-000, shape torch.Size([4, 143, 191, 149]), rank 0 
2025-07-08 14:27:13.416173: predicting BraTS-PED-00119-000 
2025-07-08 14:27:13.463416: BraTS-PED-00119-000, shape torch.Size([4, 130, 158, 137]), rank 0 
2025-07-08 14:27:14.132703: predicting BraTS-PED-00120-000 
2025-07-08 14:27:14.186926: BraTS-PED-00120-000, shape torch.Size([4, 142, 174, 133]), rank 0 
2025-07-08 14:27:14.854267: predicting BraTS-PED-00121-000 
2025-07-08 14:27:14.909582: BraTS-PED-00121-000, shape torch.Size([4, 151, 161, 136]), rank 0 
2025-07-08 14:27:15.577678: predicting BraTS-PED-00122-000 
2025-07-08 14:27:15.630973: BraTS-PED-00122-000, shape torch.Size([4, 142, 170, 132]), rank 0 
2025-07-08 14:27:16.299190: predicting BraTS-PED-00123-000 
2025-07-08 14:27:16.352122: BraTS-PED-00123-000, shape torch.Size([4, 144, 165, 136]), rank 0 
2025-07-08 14:27:17.020510: predicting BraTS-PED-00124-000 
2025-07-08 14:27:17.075643: BraTS-PED-00124-000, shape torch.Size([4, 142, 171, 141]), rank 0 
2025-07-08 14:27:17.745522: predicting BraTS-PED-00125-000 
2025-07-08 14:27:17.797022: BraTS-PED-00125-000, shape torch.Size([4, 144, 171, 135]), rank 0 
2025-07-08 14:27:18.465084: predicting BraTS-PED-00126-000 
2025-07-08 14:27:18.524313: BraTS-PED-00126-000, shape torch.Size([4, 148, 180, 136]), rank 0 
2025-07-08 14:27:19.193377: predicting BraTS-PED-00127-000 
2025-07-08 14:27:19.247769: BraTS-PED-00127-000, shape torch.Size([4, 139, 173, 136]), rank 0 
2025-07-08 14:27:19.916979: predicting BraTS-PED-00128-000 
2025-07-08 14:27:19.974284: BraTS-PED-00128-000, shape torch.Size([4, 147, 175, 132]), rank 0 
2025-07-08 14:27:20.643200: predicting BraTS-PED-00129-000 
2025-07-08 14:27:20.698154: BraTS-PED-00129-000, shape torch.Size([4, 144, 169, 137]), rank 0 
2025-07-08 14:27:21.367965: predicting BraTS-PED-00130-000 
2025-07-08 14:27:21.423007: BraTS-PED-00130-000, shape torch.Size([4, 143, 175, 138]), rank 0 
2025-07-08 14:27:22.091235: predicting BraTS-PED-00131-000 
2025-07-08 14:27:22.154283: BraTS-PED-00131-000, shape torch.Size([4, 145, 179, 140]), rank 0 
2025-07-08 14:27:22.824416: predicting BraTS-PED-00132-000 
2025-07-08 14:27:22.876718: BraTS-PED-00132-000, shape torch.Size([4, 142, 172, 135]), rank 0 
2025-07-08 14:27:23.546469: predicting BraTS-PED-00133-000 
2025-07-08 14:27:23.606696: BraTS-PED-00133-000, shape torch.Size([4, 145, 178, 141]), rank 0 
2025-07-08 14:27:24.276824: predicting BraTS-PED-00134-000 
2025-07-08 14:27:24.332462: BraTS-PED-00134-000, shape torch.Size([4, 143, 172, 142]), rank 0 
2025-07-08 14:27:25.002894: predicting BraTS-PED-00135-000 
2025-07-08 14:27:25.056094: BraTS-PED-00135-000, shape torch.Size([4, 141, 164, 138]), rank 0 
2025-07-08 14:27:25.724932: predicting BraTS-PED-00136-000 
2025-07-08 14:27:25.783509: BraTS-PED-00136-000, shape torch.Size([4, 138, 179, 142]), rank 0 
2025-07-08 14:27:26.453231: predicting BraTS-PED-00137-000 
2025-07-08 14:27:26.507480: BraTS-PED-00137-000, shape torch.Size([4, 144, 175, 135]), rank 0 
2025-07-08 14:27:27.176899: predicting BraTS-PED-00138-000 
2025-07-08 14:27:27.230263: BraTS-PED-00138-000, shape torch.Size([4, 145, 167, 143]), rank 0 
2025-07-08 14:27:27.899400: predicting BraTS-PED-00139-000 
2025-07-08 14:27:27.957487: BraTS-PED-00139-000, shape torch.Size([4, 144, 180, 143]), rank 0 
2025-07-08 14:27:28.627907: predicting BraTS-PED-00140-000 
2025-07-08 14:27:28.683744: BraTS-PED-00140-000, shape torch.Size([4, 143, 178, 139]), rank 0 
2025-07-08 14:27:29.354156: predicting BraTS-PED-00141-000 
2025-07-08 14:27:29.402900: BraTS-PED-00141-000, shape torch.Size([4, 141, 166, 133]), rank 0 
2025-07-08 14:27:30.074810: predicting BraTS-PED-00142-000 
2025-07-08 14:27:30.126548: BraTS-PED-00142-000, shape torch.Size([4, 143, 171, 136]), rank 0 
2025-07-08 14:27:30.795496: predicting BraTS-PED-00143-000 
2025-07-08 14:27:30.854018: BraTS-PED-00143-000, shape torch.Size([4, 141, 180, 140]), rank 0 
2025-07-08 14:27:31.523971: predicting BraTS-PED-00144-000 
2025-07-08 14:27:31.574468: BraTS-PED-00144-000, shape torch.Size([4, 139, 171, 134]), rank 0 
2025-07-08 14:27:32.245453: predicting BraTS-PED-00145-000 
2025-07-08 14:27:32.304313: BraTS-PED-00145-000, shape torch.Size([4, 143, 166, 151]), rank 0 
2025-07-08 14:27:32.974088: predicting BraTS-PED-00146-000 
2025-07-08 14:27:33.032631: BraTS-PED-00146-000, shape torch.Size([4, 143, 189, 129]), rank 0 
2025-07-08 14:27:33.703019: predicting BraTS-PED-00147-000 
2025-07-08 14:27:33.758655: BraTS-PED-00147-000, shape torch.Size([4, 145, 166, 141]), rank 0 
2025-07-08 14:27:34.428566: predicting BraTS-PED-00148-000 
2025-07-08 14:27:34.482012: BraTS-PED-00148-000, shape torch.Size([4, 138, 174, 139]), rank 0 
2025-07-08 14:27:35.152297: predicting BraTS-PED-00149-000 
2025-07-08 14:27:35.209380: BraTS-PED-00149-000, shape torch.Size([4, 143, 174, 138]), rank 0 
2025-07-08 14:27:35.878883: predicting BraTS-PED-00150-000 
2025-07-08 14:27:35.932953: BraTS-PED-00150-000, shape torch.Size([4, 138, 163, 134]), rank 0 
2025-07-08 14:27:36.601843: predicting BraTS-PED-00151-000 
2025-07-08 14:27:36.665532: BraTS-PED-00151-000, shape torch.Size([4, 138, 179, 148]), rank 0 
2025-07-08 14:27:37.338042: predicting BraTS-PED-00152-000 
2025-07-08 14:27:37.393154: BraTS-PED-00152-000, shape torch.Size([4, 145, 169, 144]), rank 0 
2025-07-08 14:27:38.066033: predicting BraTS-PED-00153-000 
2025-07-08 14:27:38.125587: BraTS-PED-00153-000, shape torch.Size([4, 145, 182, 143]), rank 0 
2025-07-08 14:27:38.797224: predicting BraTS-PED-00154-000 
2025-07-08 14:27:38.853202: BraTS-PED-00154-000, shape torch.Size([4, 145, 174, 141]), rank 0 
2025-07-08 14:27:39.524012: predicting BraTS-PED-00155-000 
2025-07-08 14:27:39.575297: BraTS-PED-00155-000, shape torch.Size([4, 144, 175, 129]), rank 0 
2025-07-08 14:27:40.248895: predicting BraTS-PED-00156-000 
2025-07-08 14:27:40.306348: BraTS-PED-00156-000, shape torch.Size([4, 146, 160, 147]), rank 0 
2025-07-08 14:27:40.976572: predicting BraTS-PED-00157-000 
2025-07-08 14:27:41.034409: BraTS-PED-00157-000, shape torch.Size([4, 142, 167, 142]), rank 0 
2025-07-08 14:27:41.704209: predicting BraTS-PED-00158-000 
2025-07-08 14:27:41.755833: BraTS-PED-00158-000, shape torch.Size([4, 137, 162, 138]), rank 0 
2025-07-08 14:27:42.425849: predicting BraTS-PED-00159-000 
2025-07-08 14:27:42.491212: BraTS-PED-00159-000, shape torch.Size([4, 147, 178, 154]), rank 0 
2025-07-08 14:27:43.164177: predicting BraTS-PED-00160-000 
2025-07-08 14:27:43.218445: BraTS-PED-00160-000, shape torch.Size([4, 144, 161, 140]), rank 0 
2025-07-08 14:27:43.889220: predicting BraTS-PED-00161-000 
2025-07-08 14:27:43.948007: BraTS-PED-00161-000, shape torch.Size([4, 148, 178, 142]), rank 0 
2025-07-08 14:27:44.617908: predicting BraTS-PED-00162-000 
2025-07-08 14:27:44.671427: BraTS-PED-00162-000, shape torch.Size([4, 140, 161, 146]), rank 0 
2025-07-08 14:27:45.341289: predicting BraTS-PED-00163-000 
2025-07-08 14:27:45.395929: BraTS-PED-00163-000, shape torch.Size([4, 140, 162, 139]), rank 0 
2025-07-08 14:27:46.065531: predicting BraTS-PED-00164-000 
2025-07-08 14:27:46.119126: BraTS-PED-00164-000, shape torch.Size([4, 144, 171, 133]), rank 0 
2025-07-08 14:27:46.788698: predicting BraTS-PED-00165-000 
2025-07-08 14:27:46.840215: BraTS-PED-00165-000, shape torch.Size([4, 142, 160, 138]), rank 0 
2025-07-08 14:27:47.509765: predicting BraTS-PED-00166-000 
2025-07-08 14:27:47.567566: BraTS-PED-00166-000, shape torch.Size([4, 145, 174, 138]), rank 0 
2025-07-08 14:27:48.237901: predicting BraTS-PED-00167-000 
2025-07-08 14:27:48.295489: BraTS-PED-00167-000, shape torch.Size([4, 139, 175, 139]), rank 0 
2025-07-08 14:27:48.967123: predicting BraTS-PED-00168-000 
2025-07-08 14:27:49.025054: BraTS-PED-00168-000, shape torch.Size([4, 144, 172, 142]), rank 0 
2025-07-08 14:27:49.696918: predicting BraTS-PED-00169-000 
2025-07-08 14:27:49.747789: BraTS-PED-00169-000, shape torch.Size([4, 139, 163, 134]), rank 0 
2025-07-08 14:27:50.419302: predicting BraTS-PED-00170-000 
2025-07-08 14:27:50.476102: BraTS-PED-00170-000, shape torch.Size([4, 147, 176, 133]), rank 0 
2025-07-08 14:27:51.146210: predicting BraTS-PED-00171-000 
2025-07-08 14:27:51.194064: BraTS-PED-00171-000, shape torch.Size([4, 141, 151, 132]), rank 0 
2025-07-08 14:27:51.862876: predicting BraTS-PED-00172-000 
2025-07-08 14:27:51.927525: BraTS-PED-00172-000, shape torch.Size([4, 143, 183, 145]), rank 0 
2025-07-08 14:27:52.597537: predicting BraTS-PED-00173-000 
2025-07-08 14:27:52.655318: BraTS-PED-00173-000, shape torch.Size([4, 148, 168, 145]), rank 0 
2025-07-08 14:27:53.325865: predicting BraTS-PED-00174-000 
2025-07-08 14:27:53.389343: BraTS-PED-00174-000, shape torch.Size([4, 146, 185, 139]), rank 0 
2025-07-08 14:27:54.061128: predicting BraTS-PED-00175-000 
2025-07-08 14:27:54.112239: BraTS-PED-00175-000, shape torch.Size([4, 137, 174, 132]), rank 0 
2025-07-08 14:27:54.783926: predicting BraTS-PED-00176-000 
2025-07-08 14:27:54.837670: BraTS-PED-00176-000, shape torch.Size([4, 144, 162, 140]), rank 0 
2025-07-08 14:27:55.507530: predicting BraTS-PED-00177-000 
2025-07-08 14:27:55.565248: BraTS-PED-00177-000, shape torch.Size([4, 146, 176, 138]), rank 0 
2025-07-08 14:27:56.236801: predicting BraTS-PED-00178-000 
2025-07-08 14:27:56.285964: BraTS-PED-00178-000, shape torch.Size([4, 140, 154, 131]), rank 0 
2025-07-08 14:27:56.956237: predicting BraTS-PED-00179-000 
2025-07-08 14:27:57.013483: BraTS-PED-00179-000, shape torch.Size([4, 143, 172, 143]), rank 0 
2025-07-08 14:27:57.684565: predicting BraTS-PED-00180-000 
2025-07-08 14:27:57.732124: BraTS-PED-00180-000, shape torch.Size([4, 137, 151, 133]), rank 0 
2025-07-08 14:27:58.400695: predicting BraTS-PED-00181-000 
2025-07-08 14:27:58.452155: BraTS-PED-00181-000, shape torch.Size([4, 138, 168, 136]), rank 0 
2025-07-08 14:27:59.121079: predicting BraTS-PED-00182-000 
2025-07-08 14:27:59.177355: BraTS-PED-00182-000, shape torch.Size([4, 140, 163, 146]), rank 0 
2025-07-08 14:27:59.848226: predicting BraTS-PED-00183-000 
2025-07-08 14:27:59.895469: BraTS-PED-00183-000, shape torch.Size([4, 139, 166, 129]), rank 0 
2025-07-08 14:28:00.564864: predicting BraTS-PED-00184-000 
2025-07-08 14:28:00.617966: BraTS-PED-00184-000, shape torch.Size([4, 145, 166, 134]), rank 0 
2025-07-08 14:28:01.288253: predicting BraTS-PED-00185-000 
2025-07-08 14:28:01.340378: BraTS-PED-00185-000, shape torch.Size([4, 144, 163, 139]), rank 0 
2025-07-08 14:28:02.010211: predicting BraTS-PED-00186-000 
2025-07-08 14:28:02.069476: BraTS-PED-00186-000, shape torch.Size([4, 144, 171, 139]), rank 0 
2025-07-08 14:28:02.741230: predicting BraTS-PED-00187-000 
2025-07-08 14:28:02.792910: BraTS-PED-00187-000, shape torch.Size([4, 143, 169, 138]), rank 0 
2025-07-08 14:28:03.466927: predicting BraTS-PED-00188-000 
2025-07-08 14:28:03.518648: BraTS-PED-00188-000, shape torch.Size([4, 144, 161, 142]), rank 0 
2025-07-08 14:28:04.189822: predicting BraTS-PED-00189-000 
2025-07-08 14:28:04.240118: BraTS-PED-00189-000, shape torch.Size([4, 140, 167, 135]), rank 0 
2025-07-08 14:28:04.909954: predicting BraTS-PED-00190-000 
2025-07-08 14:28:04.952882: BraTS-PED-00190-000, shape torch.Size([4, 131, 151, 133]), rank 0 
2025-07-08 14:28:05.624966: predicting BraTS-PED-00191-000 
2025-07-08 14:28:05.676732: BraTS-PED-00191-000, shape torch.Size([4, 146, 161, 144]), rank 0 
2025-07-08 14:28:06.348335: predicting BraTS-PED-00192-000 
2025-07-08 14:28:06.398784: BraTS-PED-00192-000, shape torch.Size([4, 139, 163, 136]), rank 0 
2025-07-08 14:28:07.068160: predicting BraTS-PED-00193-000 
2025-07-08 14:28:07.118777: BraTS-PED-00193-000, shape torch.Size([4, 137, 170, 134]), rank 0 
2025-07-08 14:28:07.789467: predicting BraTS-PED-00194-000 
2025-07-08 14:28:07.829077: BraTS-PED-00194-000, shape torch.Size([4, 139, 139, 127]), rank 0 
2025-07-08 14:28:08.200411: predicting BraTS-PED-00195-000 
2025-07-08 14:28:08.245771: BraTS-PED-00195-000, shape torch.Size([4, 140, 154, 134]), rank 0 
2025-07-08 14:28:08.914184: predicting BraTS-PED-00196-000 
2025-07-08 14:28:08.964279: BraTS-PED-00196-000, shape torch.Size([4, 142, 159, 138]), rank 0 
2025-07-08 14:28:09.635193: predicting BraTS-PED-00197-000 
2025-07-08 14:28:09.690457: BraTS-PED-00197-000, shape torch.Size([4, 142, 175, 143]), rank 0 
2025-07-08 14:28:10.362470: predicting BraTS-PED-00198-000 
2025-07-08 14:28:10.414083: BraTS-PED-00198-000, shape torch.Size([4, 146, 160, 130]), rank 0 
2025-07-08 14:28:11.084649: predicting BraTS-PED-00199-000 
2025-07-08 14:28:11.142418: BraTS-PED-00199-000, shape torch.Size([4, 147, 173, 134]), rank 0 
2025-07-08 14:28:11.812920: predicting BraTS-PED-00200-000 
2025-07-08 14:28:11.860674: BraTS-PED-00200-000, shape torch.Size([4, 134, 161, 125]), rank 0 
2025-07-08 14:28:12.237779: predicting BraTS-PED-00201-000 
2025-07-08 14:28:12.296557: BraTS-PED-00201-000, shape torch.Size([4, 142, 173, 133]), rank 0 
2025-07-08 14:28:12.966299: predicting BraTS-PED-00202-000 
2025-07-08 14:28:13.024252: BraTS-PED-00202-000, shape torch.Size([4, 144, 178, 141]), rank 0 
2025-07-08 14:28:13.696265: predicting BraTS-PED-00203-000 
2025-07-08 14:28:13.753968: BraTS-PED-00203-000, shape torch.Size([4, 144, 169, 148]), rank 0 
2025-07-08 14:28:14.430172: predicting BraTS-PED-00204-000 
2025-07-08 14:28:14.472857: BraTS-PED-00204-000, shape torch.Size([4, 131, 144, 125]), rank 0 
2025-07-08 14:28:14.844087: predicting BraTS-PED-00205-000 
2025-07-08 14:28:14.896190: BraTS-PED-00205-000, shape torch.Size([4, 147, 171, 136]), rank 0 
2025-07-08 14:28:15.565552: predicting BraTS-PED-00206-000 
2025-07-08 14:28:15.621702: BraTS-PED-00206-000, shape torch.Size([4, 148, 176, 135]), rank 0 
2025-07-08 14:28:16.293478: predicting BraTS-PED-00207-000 
2025-07-08 14:28:16.345505: BraTS-PED-00207-000, shape torch.Size([4, 145, 169, 127]), rank 0 
2025-07-08 14:28:16.727399: predicting BraTS-PED-00208-000 
2025-07-08 14:28:16.789852: BraTS-PED-00208-000, shape torch.Size([4, 140, 182, 148]), rank 0 
2025-07-08 14:28:17.463046: predicting BraTS-PED-00209-000 
2025-07-08 14:28:17.508436: BraTS-PED-00209-000, shape torch.Size([4, 129, 166, 126]), rank 0 
2025-07-08 14:28:17.884797: predicting BraTS-PED-00210-000 
2025-07-08 14:28:18.000150: BraTS-PED-00210-000, shape torch.Size([4, 155, 240, 240]), rank 0 
2025-07-08 14:28:19.511705: predicting BraTS-PED-00211-000 
2025-07-08 14:28:19.629017: BraTS-PED-00211-000, shape torch.Size([4, 155, 240, 240]), rank 0 
2025-07-08 14:28:21.146524: predicting BraTS-PED-00212-000 
2025-07-08 14:28:21.195550: BraTS-PED-00212-000, shape torch.Size([4, 139, 163, 127]), rank 0 
2025-07-08 14:28:21.586796: predicting BraTS-PED-00213-000 
2025-07-08 14:28:21.638458: BraTS-PED-00213-000, shape torch.Size([4, 139, 166, 132]), rank 0 
2025-07-08 14:28:22.308785: predicting BraTS-PED-00214-000 
2025-07-08 14:28:22.362947: BraTS-PED-00214-000, shape torch.Size([4, 141, 172, 138]), rank 0 
2025-07-08 14:28:23.033988: predicting BraTS-PED-00215-000 
2025-07-08 14:28:23.086577: BraTS-PED-00215-000, shape torch.Size([4, 138, 171, 138]), rank 0 
2025-07-08 14:28:23.759146: predicting BraTS-PED-00216-000 
2025-07-08 14:28:23.813988: BraTS-PED-00216-000, shape torch.Size([4, 148, 163, 143]), rank 0 
2025-07-08 14:28:24.484485: predicting BraTS-PED-00217-000 
2025-07-08 14:28:24.543329: BraTS-PED-00217-000, shape torch.Size([4, 135, 181, 140]), rank 0 
2025-07-08 14:28:25.215384: predicting BraTS-PED-00218-000 
2025-07-08 14:28:25.327459: BraTS-PED-00218-000, shape torch.Size([4, 155, 240, 240]), rank 0 
2025-07-08 14:28:26.837427: predicting BraTS-PED-00219-000 
2025-07-08 14:28:26.959954: BraTS-PED-00219-000, shape torch.Size([4, 155, 240, 240]), rank 0 
2025-07-08 14:28:28.478139: predicting BraTS-PED-00220-000 
2025-07-08 14:28:28.543748: BraTS-PED-00220-000, shape torch.Size([4, 148, 171, 134]), rank 0 
2025-07-08 14:28:29.222999: predicting BraTS-PED-00221-000 
2025-07-08 14:28:29.290568: BraTS-PED-00221-000, shape torch.Size([4, 140, 177, 139]), rank 0 
2025-07-08 14:28:29.963093: predicting BraTS-PED-00222-000 
2025-07-08 14:28:30.078097: BraTS-PED-00222-000, shape torch.Size([4, 155, 240, 240]), rank 0 
2025-07-08 14:28:31.591251: predicting BraTS-PED-00223-000 
2025-07-08 14:28:31.651897: BraTS-PED-00223-000, shape torch.Size([4, 144, 167, 136]), rank 0 
2025-07-08 14:28:32.328522: predicting BraTS-PED-00224-000 
2025-07-08 14:28:32.384335: BraTS-PED-00224-000, shape torch.Size([4, 144, 167, 140]), rank 0 
2025-07-08 14:28:33.055859: predicting BraTS-PED-00225-000 
2025-07-08 14:28:33.109125: BraTS-PED-00225-000, shape torch.Size([4, 143, 171, 144]), rank 0 
2025-07-08 14:28:33.781134: predicting BraTS-PED-00226-000 
2025-07-08 14:28:33.893790: BraTS-PED-00226-000, shape torch.Size([4, 155, 240, 240]), rank 0 
2025-07-08 14:28:35.407185: predicting BraTS-PED-00227-000 
2025-07-08 14:28:35.530965: BraTS-PED-00227-000, shape torch.Size([4, 155, 240, 240]), rank 0 
2025-07-08 14:28:37.049682: predicting BraTS-PED-00228-000 
2025-07-08 14:28:37.164506: BraTS-PED-00228-000, shape torch.Size([4, 155, 240, 240]), rank 0 
2025-07-08 14:28:38.679739: predicting BraTS-PED-00229-000 
2025-07-08 14:28:38.801989: BraTS-PED-00229-000, shape torch.Size([4, 155, 240, 240]), rank 0 
2025-07-08 14:28:40.320952: predicting BraTS-PED-00230-000 
2025-07-08 14:28:40.384973: BraTS-PED-00230-000, shape torch.Size([4, 143, 173, 148]), rank 0 
2025-07-08 14:28:41.062759: predicting BraTS-PED-00231-000 
2025-07-08 14:28:41.118131: BraTS-PED-00231-000, shape torch.Size([4, 145, 165, 134]), rank 0 
2025-07-08 14:28:41.790699: predicting BraTS-PED-00232-000 
2025-07-08 14:28:41.908201: BraTS-PED-00232-000, shape torch.Size([4, 155, 240, 240]), rank 0 
2025-07-08 14:28:43.420574: predicting BraTS-PED-00233-000 
2025-07-08 14:28:43.470298: BraTS-PED-00233-000, shape torch.Size([4, 138, 166, 130]), rank 0 
2025-07-08 14:28:44.154172: predicting BraTS-PED-00234-000 
2025-07-08 14:28:44.205398: BraTS-PED-00234-000, shape torch.Size([4, 139, 169, 131]), rank 0 
2025-07-08 14:28:44.876247: predicting BraTS-PED-00235-000 
2025-07-08 14:28:44.927408: BraTS-PED-00235-000, shape torch.Size([4, 136, 157, 129]), rank 0 
2025-07-08 14:28:45.598110: predicting BraTS-PED-00236-000 
2025-07-08 14:28:45.652951: BraTS-PED-00236-000, shape torch.Size([4, 147, 165, 137]), rank 0 
2025-07-08 14:28:46.323381: predicting BraTS-PED-00237-000 
2025-07-08 14:28:46.375950: BraTS-PED-00237-000, shape torch.Size([4, 145, 168, 133]), rank 0 
2025-07-08 14:28:47.048126: predicting BraTS-PED-00238-000 
2025-07-08 14:28:47.159317: BraTS-PED-00238-000, shape torch.Size([4, 155, 240, 240]), rank 0 
2025-07-08 14:28:48.673419: predicting BraTS-PED-00239-000 
2025-07-08 14:28:48.737564: BraTS-PED-00239-000, shape torch.Size([4, 143, 167, 149]), rank 0 
2025-07-08 14:28:49.415760: predicting BraTS-PED-00240-000 
2025-07-08 14:28:49.524965: BraTS-PED-00240-000, shape torch.Size([4, 155, 240, 240]), rank 0 
2025-07-08 14:28:51.038867: predicting BraTS-PED-00241-000 
2025-07-08 14:28:51.090580: BraTS-PED-00241-000, shape torch.Size([4, 139, 161, 138]), rank 0 
2025-07-08 14:28:51.773632: predicting BraTS-PED-00242-000 
2025-07-08 14:28:51.830104: BraTS-PED-00242-000, shape torch.Size([4, 144, 178, 143]), rank 0 
2025-07-08 14:28:52.503063: predicting BraTS-PED-00243-000 
2025-07-08 14:28:52.611333: BraTS-PED-00243-000, shape torch.Size([4, 155, 240, 240]), rank 0 
2025-07-08 14:28:54.128863: predicting BraTS-PED-00244-000 
2025-07-08 14:28:54.249352: BraTS-PED-00244-000, shape torch.Size([4, 155, 240, 240]), rank 0 
2025-07-08 14:28:55.769966: predicting BraTS-PED-00245-000 
2025-07-08 14:28:55.823040: BraTS-PED-00245-000, shape torch.Size([4, 142, 171, 136]), rank 0 
2025-07-08 14:28:56.504673: predicting BraTS-PED-00246-000 
2025-07-08 14:28:56.613809: BraTS-PED-00246-000, shape torch.Size([4, 155, 240, 240]), rank 0 
2025-07-08 14:28:58.130018: predicting BraTS-PED-00247-000 
2025-07-08 14:28:58.249820: BraTS-PED-00247-000, shape torch.Size([4, 155, 240, 240]), rank 0 
2025-07-08 14:28:59.770715: predicting BraTS-PED-00248-000 
2025-07-08 14:28:59.815145: BraTS-PED-00248-000, shape torch.Size([4, 134, 159, 125]), rank 0 
2025-07-08 14:29:00.200568: predicting BraTS-PED-00249-000 
2025-07-08 14:29:00.316166: BraTS-PED-00249-000, shape torch.Size([4, 155, 240, 240]), rank 0 
2025-07-08 14:29:01.830429: predicting BraTS-PED-00250-000 
2025-07-08 14:29:01.875639: BraTS-PED-00250-000, shape torch.Size([4, 144, 158, 121]), rank 0 
2025-07-08 14:29:02.262779: predicting BraTS-PED-00251-000 
2025-07-08 14:29:02.378419: BraTS-PED-00251-000, shape torch.Size([4, 155, 240, 240]), rank 0 
2025-07-08 14:29:03.891639: predicting BraTS-PED-00252-000 
2025-07-08 14:29:03.945284: BraTS-PED-00252-000, shape torch.Size([4, 142, 163, 139]), rank 0 
2025-07-08 14:29:04.627828: predicting BraTS-PED-00253-000 
2025-07-08 14:29:04.740927: BraTS-PED-00253-000, shape torch.Size([4, 155, 240, 240]), rank 0 
2025-07-08 14:29:06.255271: predicting BraTS-PED-00254-000 
2025-07-08 14:29:06.314147: BraTS-PED-00254-000, shape torch.Size([4, 139, 156, 140]), rank 0 
2025-07-08 14:29:06.990648: predicting BraTS-PED-00255-000 
2025-07-08 14:29:07.047127: BraTS-PED-00255-000, shape torch.Size([4, 143, 172, 146]), rank 0 
2025-07-08 14:29:07.719132: predicting BraTS-PED-00256-000 
2025-07-08 14:29:07.760424: BraTS-PED-00256-000, shape torch.Size([4, 138, 140, 130]), rank 0 
2025-07-08 14:29:08.430672: predicting BraTS-PED-00257-000 
2025-07-08 14:29:08.486326: BraTS-PED-00257-000, shape torch.Size([4, 145, 171, 139]), rank 0 
2025-07-08 14:29:09.157185: predicting BraTS-PED-00258-000 
2025-07-08 14:29:09.205712: BraTS-PED-00258-000, shape torch.Size([4, 133, 168, 136]), rank 0 
2025-07-08 14:29:09.876974: predicting BraTS-PED-00259-000 
2025-07-08 14:29:09.926957: BraTS-PED-00259-000, shape torch.Size([4, 139, 166, 135]), rank 0 
2025-07-08 14:29:10.598620: predicting BraTS-PED-00260-000 
2025-07-08 14:29:10.652381: BraTS-PED-00260-000, shape torch.Size([4, 143, 177, 134]), rank 0 
2025-07-08 14:29:11.324103: predicting BraTS-PED-00261-000 
2025-07-08 14:29:11.374734: BraTS-PED-00261-000, shape torch.Size([4, 138, 164, 138]), rank 0 
2025-07-08 14:29:12.046935: predicting BraTS-PED-00262-000 
2025-07-08 14:29:12.160153: BraTS-PED-00262-000, shape torch.Size([4, 155, 240, 240]), rank 0 
2025-07-08 14:29:13.677076: predicting BraTS-PED-00263-000 
2025-07-08 14:29:13.740875: BraTS-PED-00263-000, shape torch.Size([4, 146, 168, 152]), rank 0 
2025-07-08 14:29:14.418017: predicting BraTS-PED-00264-000 
2025-07-08 14:29:14.528159: BraTS-PED-00264-000, shape torch.Size([4, 155, 240, 240]), rank 0 
2025-07-08 14:29:16.043176: predicting BraTS-PED-00265-000 
2025-07-08 14:29:16.167646: BraTS-PED-00265-000, shape torch.Size([4, 155, 240, 240]), rank 0 
2025-07-08 14:29:17.686654: predicting BraTS-PED-00266-000 
2025-07-08 14:29:17.808079: BraTS-PED-00266-000, shape torch.Size([4, 155, 240, 240]), rank 0 
2025-07-08 14:29:29.261712: Validation complete 
2025-07-08 14:29:29.261810: Mean Validation Dice:  0.9608889990365018 
