
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-07-08 16:14:46.614329: Using torch.compile... 
2025-07-08 16:14:47.966113: do_dummy_2d_data_aug: False 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 10, 'patch_size': [80, 80, 80], 'median_image_size_in_voxels': [73.0, 73.0, 73.0], 'spacing': [1.0, 1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization'], 'use_mask_for_norm': [False, False, False, False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 5, 'features_per_stage': [32, 64, 128, 256, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': False} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset007_BraTS2025_PedCropped', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.0, 1.0, 1.0], 'original_median_shape_after_transp': [73, 73, 73], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 9167.501953125, 'mean': 582.2219020773033, 'median': 338.1693420410156, 'min': 0.0, 'percentile_00_5': 39.72725296020508, 'percentile_99_5': 3340.2822265625, 'std': 630.4747836838144}, '1': {'max': 13502.4140625, 'mean': 802.727592007679, 'median': 427.1595458984375, 'min': 0.0, 'percentile_00_5': 75.78582763671875, 'percentile_99_5': 11524.0380859375, 'std': 1324.343744021567}, '2': {'max': 11522.162109375, 'mean': 946.0190134638801, 'median': 726.2399291992188, 'min': 0.0, 'percentile_00_5': 70.09772491455078, 'percentile_99_5': 11522.162109375, 'std': 1022.7432677825359}, '3': {'max': 20274.908203125, 'mean': 681.1038662609585, 'median': 452.2572937011719, 'min': 0.0, 'percentile_00_5': 47.44221496582031, 'percentile_99_5': 12898.986328125, 'std': 1233.3159468540975}}} 
 
2025-07-08 16:14:52.782420: Unable to plot network architecture: nnUNet_compile is enabled! 
2025-07-08 16:14:52.795651:  
2025-07-08 16:14:52.796253: Epoch 0 
2025-07-08 16:14:52.796758: Current learning rate: 0.01 
2025-07-08 16:16:17.395184: train_loss -0.2077 
2025-07-08 16:16:17.395807: val_loss -0.3029 
2025-07-08 16:16:17.395901: Pseudo dice [np.float32(0.5816)] 
2025-07-08 16:16:17.396008: Epoch time: 84.6 s 
2025-07-08 16:16:17.396088: Yayy! New best EMA pseudo Dice: 0.58160001039505 
2025-07-08 16:16:18.585681:  
2025-07-08 16:16:18.586171: Epoch 1 
2025-07-08 16:16:18.586469: Current learning rate: 0.00999 
2025-07-08 16:17:07.097410: train_loss -0.3348 
2025-07-08 16:17:07.098094: val_loss -0.3597 
2025-07-08 16:17:07.098202: Pseudo dice [np.float32(0.6558)] 
2025-07-08 16:17:07.098341: Epoch time: 48.51 s 
2025-07-08 16:17:07.098428: Yayy! New best EMA pseudo Dice: 0.5891000032424927 
2025-07-08 16:17:08.651718:  
2025-07-08 16:17:08.652162: Epoch 2 
2025-07-08 16:17:08.652294: Current learning rate: 0.00998 
2025-07-08 16:17:57.322062: train_loss -0.3576 
2025-07-08 16:17:57.322719: val_loss -0.3789 
2025-07-08 16:17:57.322830: Pseudo dice [np.float32(0.7552)] 
2025-07-08 16:17:57.322953: Epoch time: 48.67 s 
2025-07-08 16:17:57.323036: Yayy! New best EMA pseudo Dice: 0.6057000160217285 
2025-07-08 16:17:59.013649:  
2025-07-08 16:17:59.013931: Epoch 3 
2025-07-08 16:17:59.014281: Current learning rate: 0.00997 
2025-07-08 16:18:47.701479: train_loss -0.3636 
2025-07-08 16:18:47.701899: val_loss -0.3737 
2025-07-08 16:18:47.702038: Pseudo dice [np.float32(0.7079)] 
2025-07-08 16:18:47.702142: Epoch time: 48.69 s 
2025-07-08 16:18:47.702218: Yayy! New best EMA pseudo Dice: 0.6158999800682068 
2025-07-08 16:18:49.289908:  
2025-07-08 16:18:49.290136: Epoch 4 
2025-07-08 16:18:49.290260: Current learning rate: 0.00996 
2025-07-08 16:19:37.449609: train_loss -0.3847 
2025-07-08 16:19:37.450083: val_loss -0.4061 
2025-07-08 16:19:37.450186: Pseudo dice [np.float32(0.7544)] 
2025-07-08 16:19:37.450320: Epoch time: 48.16 s 
2025-07-08 16:19:37.450403: Yayy! New best EMA pseudo Dice: 0.629800021648407 
2025-07-08 16:19:39.139619:  
2025-07-08 16:19:39.140265: Epoch 5 
2025-07-08 16:19:39.140397: Current learning rate: 0.00995 
2025-07-08 16:20:26.486958: train_loss -0.394 
2025-07-08 16:20:26.487512: val_loss -0.4349 
2025-07-08 16:20:26.487643: Pseudo dice [np.float32(0.7512)] 
2025-07-08 16:20:26.487798: Epoch time: 47.35 s 
2025-07-08 16:20:26.487898: Yayy! New best EMA pseudo Dice: 0.6419000029563904 
2025-07-08 16:20:28.234740:  
2025-07-08 16:20:28.234970: Epoch 6 
2025-07-08 16:20:28.235222: Current learning rate: 0.00995 
2025-07-08 16:21:15.069262: train_loss -0.4064 
2025-07-08 16:21:15.069671: val_loss -0.3814 
2025-07-08 16:21:15.069757: Pseudo dice [np.float32(0.7611)] 
2025-07-08 16:21:15.069857: Epoch time: 46.84 s 
2025-07-08 16:21:15.069928: Yayy! New best EMA pseudo Dice: 0.6538000106811523 
2025-07-08 16:21:17.630267:  
2025-07-08 16:21:17.630907: Epoch 7 
2025-07-08 16:21:17.631420: Current learning rate: 0.00994 
2025-07-08 16:22:04.503922: train_loss -0.4254 
2025-07-08 16:22:04.504425: val_loss -0.4098 
2025-07-08 16:22:04.504510: Pseudo dice [np.float32(0.7675)] 
2025-07-08 16:22:04.504644: Epoch time: 46.88 s 
2025-07-08 16:22:04.504726: Yayy! New best EMA pseudo Dice: 0.6651999950408936 
2025-07-08 16:22:06.219588:  
2025-07-08 16:22:06.219962: Epoch 8 
2025-07-08 16:22:06.220114: Current learning rate: 0.00993 
2025-07-08 16:22:54.977241: train_loss -0.4182 
2025-07-08 16:22:54.978219: val_loss -0.3937 
2025-07-08 16:22:54.978379: Pseudo dice [np.float32(0.7695)] 
2025-07-08 16:22:54.978549: Epoch time: 48.76 s 
2025-07-08 16:22:54.978651: Yayy! New best EMA pseudo Dice: 0.675599992275238 
2025-07-08 16:22:56.634138:  
2025-07-08 16:22:56.634576: Epoch 9 
2025-07-08 16:22:56.634912: Current learning rate: 0.00992 
2025-07-08 16:23:45.107982: train_loss -0.4242 
2025-07-08 16:23:45.109217: val_loss -0.4543 
2025-07-08 16:23:45.109490: Pseudo dice [np.float32(0.7752)] 
2025-07-08 16:23:45.109972: Epoch time: 48.47 s 
2025-07-08 16:23:45.110088: Yayy! New best EMA pseudo Dice: 0.6855999827384949 
2025-07-08 16:23:46.693883:  
2025-07-08 16:23:46.694277: Epoch 10 
2025-07-08 16:23:46.694488: Current learning rate: 0.00991 
2025-07-08 16:24:36.191998: train_loss -0.4317 
2025-07-08 16:24:36.192350: val_loss -0.4345 
2025-07-08 16:24:36.192430: Pseudo dice [np.float32(0.7617)] 
2025-07-08 16:24:36.192522: Epoch time: 49.5 s 
2025-07-08 16:24:36.192603: Yayy! New best EMA pseudo Dice: 0.6931999921798706 
2025-07-08 16:24:37.775826:  
2025-07-08 16:24:37.776026: Epoch 11 
2025-07-08 16:24:37.776306: Current learning rate: 0.0099 
2025-07-08 16:25:27.762845: train_loss -0.423 
2025-07-08 16:25:27.763344: val_loss -0.411 
2025-07-08 16:25:27.763443: Pseudo dice [np.float32(0.7641)] 
2025-07-08 16:25:27.763570: Epoch time: 49.99 s 
2025-07-08 16:25:27.763746: Yayy! New best EMA pseudo Dice: 0.7002999782562256 
2025-07-08 16:25:29.351862:  
2025-07-08 16:25:29.352155: Epoch 12 
2025-07-08 16:25:29.352264: Current learning rate: 0.00989 
2025-07-08 16:26:16.832494: train_loss -0.4359 
2025-07-08 16:26:16.832965: val_loss -0.4642 
2025-07-08 16:26:16.833174: Pseudo dice [np.float32(0.8042)] 
2025-07-08 16:26:16.833322: Epoch time: 47.48 s 
2025-07-08 16:26:16.833408: Yayy! New best EMA pseudo Dice: 0.7106999754905701 
2025-07-08 16:26:18.509017:  
2025-07-08 16:26:18.509318: Epoch 13 
2025-07-08 16:26:18.509464: Current learning rate: 0.00988 
2025-07-08 16:27:06.216282: train_loss -0.4389 
2025-07-08 16:27:06.216686: val_loss -0.4619 
2025-07-08 16:27:06.216769: Pseudo dice [np.float32(0.7856)] 
2025-07-08 16:27:06.216868: Epoch time: 47.71 s 
2025-07-08 16:27:06.216946: Yayy! New best EMA pseudo Dice: 0.7182000279426575 
2025-07-08 16:27:07.822806:  
2025-07-08 16:27:07.823055: Epoch 14 
2025-07-08 16:27:07.823235: Current learning rate: 0.00987 
2025-07-08 16:27:55.317458: train_loss -0.4375 
2025-07-08 16:27:55.318270: val_loss -0.4251 
2025-07-08 16:27:55.318364: Pseudo dice [np.float32(0.7781)] 
2025-07-08 16:27:55.318483: Epoch time: 47.5 s 
2025-07-08 16:27:55.318582: Yayy! New best EMA pseudo Dice: 0.7242000102996826 
2025-07-08 16:27:57.005331:  
2025-07-08 16:27:57.005520: Epoch 15 
2025-07-08 16:27:57.005720: Current learning rate: 0.00986 
2025-07-08 16:28:43.388798: train_loss -0.4471 
2025-07-08 16:28:43.389743: val_loss -0.4494 
2025-07-08 16:28:43.389874: Pseudo dice [np.float32(0.7749)] 
2025-07-08 16:28:43.390035: Epoch time: 46.38 s 
2025-07-08 16:28:43.390193: Yayy! New best EMA pseudo Dice: 0.729200005531311 
2025-07-08 16:28:45.051677:  
2025-07-08 16:28:45.052052: Epoch 16 
2025-07-08 16:28:45.052179: Current learning rate: 0.00986 
2025-07-08 16:29:31.962448: train_loss -0.4457 
2025-07-08 16:29:31.962826: val_loss -0.4652 
2025-07-08 16:29:31.962906: Pseudo dice [np.float32(0.7946)] 
2025-07-08 16:29:31.963007: Epoch time: 46.91 s 
2025-07-08 16:29:31.963088: Yayy! New best EMA pseudo Dice: 0.73580002784729 
2025-07-08 16:29:33.619733:  
2025-07-08 16:29:33.620040: Epoch 17 
2025-07-08 16:29:33.620170: Current learning rate: 0.00985 
2025-07-08 16:30:20.893191: train_loss -0.4534 
2025-07-08 16:30:20.893815: val_loss -0.4741 
2025-07-08 16:30:20.894108: Pseudo dice [np.float32(0.8083)] 
2025-07-08 16:30:20.894231: Epoch time: 47.27 s 
2025-07-08 16:30:20.894314: Yayy! New best EMA pseudo Dice: 0.7429999709129333 
2025-07-08 16:30:22.524417:  
2025-07-08 16:30:22.524847: Epoch 18 
2025-07-08 16:30:22.524947: Current learning rate: 0.00984 
2025-07-08 16:31:10.005739: train_loss -0.4595 
2025-07-08 16:31:10.006779: val_loss -0.4437 
2025-07-08 16:31:10.006938: Pseudo dice [np.float32(0.8165)] 
2025-07-08 16:31:10.007088: Epoch time: 47.48 s 
2025-07-08 16:31:10.007174: Yayy! New best EMA pseudo Dice: 0.7504000067710876 
2025-07-08 16:31:11.610028:  
2025-07-08 16:31:11.610437: Epoch 19 
2025-07-08 16:31:11.610615: Current learning rate: 0.00983 
2025-07-08 16:31:58.792063: train_loss -0.4757 
2025-07-08 16:31:58.792933: val_loss -0.5005 
2025-07-08 16:31:58.793055: Pseudo dice [np.float32(0.7722)] 
2025-07-08 16:31:58.793291: Epoch time: 47.18 s 
2025-07-08 16:31:58.793409: Yayy! New best EMA pseudo Dice: 0.7526000142097473 
2025-07-08 16:32:01.372917:  
2025-07-08 16:32:01.373467: Epoch 20 
2025-07-08 16:32:01.373836: Current learning rate: 0.00982 
2025-07-08 16:32:47.923272: train_loss -0.4783 
2025-07-08 16:32:47.923788: val_loss -0.478 
2025-07-08 16:32:47.923875: Pseudo dice [np.float32(0.8275)] 
2025-07-08 16:32:47.923985: Epoch time: 46.55 s 
2025-07-08 16:32:47.924063: Yayy! New best EMA pseudo Dice: 0.7601000070571899 
2025-07-08 16:32:49.571767:  
2025-07-08 16:32:49.572136: Epoch 21 
2025-07-08 16:32:49.572278: Current learning rate: 0.00981 
2025-07-08 16:33:37.463573: train_loss -0.4818 
2025-07-08 16:33:37.464718: val_loss -0.454 
2025-07-08 16:33:37.464829: Pseudo dice [np.float32(0.768)] 
2025-07-08 16:33:37.465031: Epoch time: 47.89 s 
2025-07-08 16:33:37.465108: Yayy! New best EMA pseudo Dice: 0.7608000040054321 
2025-07-08 16:33:39.134062:  
2025-07-08 16:33:39.134517: Epoch 22 
2025-07-08 16:33:39.134973: Current learning rate: 0.0098 
2025-07-08 16:34:26.477224: train_loss -0.4722 
2025-07-08 16:34:26.477891: val_loss -0.4792 
2025-07-08 16:34:26.477983: Pseudo dice [np.float32(0.7599)] 
2025-07-08 16:34:26.478102: Epoch time: 47.34 s 
2025-07-08 16:34:27.669424:  
2025-07-08 16:34:27.669834: Epoch 23 
2025-07-08 16:34:27.670027: Current learning rate: 0.00979 
2025-07-08 16:35:14.974363: train_loss -0.4718 
2025-07-08 16:35:14.974788: val_loss -0.4903 
2025-07-08 16:35:14.974878: Pseudo dice [np.float32(0.7711)] 
2025-07-08 16:35:14.974999: Epoch time: 47.31 s 
2025-07-08 16:35:14.975081: Yayy! New best EMA pseudo Dice: 0.7617999911308289 
2025-07-08 16:35:16.657498:  
2025-07-08 16:35:16.658005: Epoch 24 
2025-07-08 16:35:16.658210: Current learning rate: 0.00978 
2025-07-08 16:36:03.459996: train_loss -0.4747 
2025-07-08 16:36:03.460569: val_loss -0.4995 
2025-07-08 16:36:03.460673: Pseudo dice [np.float32(0.7934)] 
2025-07-08 16:36:03.460801: Epoch time: 46.8 s 
2025-07-08 16:36:03.460891: Yayy! New best EMA pseudo Dice: 0.7649999856948853 
2025-07-08 16:36:05.106190:  
2025-07-08 16:36:05.106585: Epoch 25 
2025-07-08 16:36:05.106745: Current learning rate: 0.00977 
2025-07-08 16:36:52.484117: train_loss -0.4837 
2025-07-08 16:36:52.484670: val_loss -0.4895 
2025-07-08 16:36:52.484758: Pseudo dice [np.float32(0.7927)] 
2025-07-08 16:36:52.484874: Epoch time: 47.38 s 
2025-07-08 16:36:52.484954: Yayy! New best EMA pseudo Dice: 0.7677000164985657 
2025-07-08 16:36:54.106045:  
2025-07-08 16:36:54.106207: Epoch 26 
2025-07-08 16:36:54.106330: Current learning rate: 0.00977 
2025-07-08 16:37:42.619755: train_loss -0.4832 
2025-07-08 16:37:42.620272: val_loss -0.4787 
2025-07-08 16:37:42.620371: Pseudo dice [np.float32(0.7911)] 
2025-07-08 16:37:42.620482: Epoch time: 48.51 s 
2025-07-08 16:37:42.620585: Yayy! New best EMA pseudo Dice: 0.7700999975204468 
2025-07-08 16:37:44.256293:  
2025-07-08 16:37:44.256638: Epoch 27 
2025-07-08 16:37:44.256763: Current learning rate: 0.00976 
2025-07-08 16:38:32.153250: train_loss -0.4929 
2025-07-08 16:38:32.154257: val_loss -0.5067 
2025-07-08 16:38:32.154378: Pseudo dice [np.float32(0.7782)] 
2025-07-08 16:38:32.154556: Epoch time: 47.9 s 
2025-07-08 16:38:32.154651: Yayy! New best EMA pseudo Dice: 0.7709000110626221 
2025-07-08 16:38:33.711812:  
2025-07-08 16:38:33.712218: Epoch 28 
2025-07-08 16:38:33.712383: Current learning rate: 0.00975 
2025-07-08 16:39:20.314428: train_loss -0.497 
2025-07-08 16:39:20.314921: val_loss -0.4959 
2025-07-08 16:39:20.315028: Pseudo dice [np.float32(0.7878)] 
2025-07-08 16:39:20.315164: Epoch time: 46.6 s 
2025-07-08 16:39:20.315237: Yayy! New best EMA pseudo Dice: 0.772599995136261 
2025-07-08 16:39:21.866783:  
2025-07-08 16:39:21.867121: Epoch 29 
2025-07-08 16:39:21.867275: Current learning rate: 0.00974 
2025-07-08 16:40:09.177982: train_loss -0.485 
2025-07-08 16:40:09.178280: val_loss -0.5047 
2025-07-08 16:40:09.181782: Pseudo dice [np.float32(0.7991)] 
2025-07-08 16:40:09.181908: Epoch time: 47.31 s 
2025-07-08 16:40:09.181989: Yayy! New best EMA pseudo Dice: 0.7752000093460083 
2025-07-08 16:40:10.736040:  
2025-07-08 16:40:10.736584: Epoch 30 
2025-07-08 16:40:10.736716: Current learning rate: 0.00973 
2025-07-08 16:40:58.668883: train_loss -0.4989 
2025-07-08 16:40:58.669304: val_loss -0.5186 
2025-07-08 16:40:58.669396: Pseudo dice [np.float32(0.8022)] 
2025-07-08 16:40:58.669503: Epoch time: 47.93 s 
2025-07-08 16:40:58.669603: Yayy! New best EMA pseudo Dice: 0.777899980545044 
2025-07-08 16:41:00.262106:  
2025-07-08 16:41:00.262559: Epoch 31 
2025-07-08 16:41:00.262693: Current learning rate: 0.00972 
2025-07-08 16:41:47.969115: train_loss -0.5104 
2025-07-08 16:41:47.969722: val_loss -0.5107 
2025-07-08 16:41:47.969832: Pseudo dice [np.float32(0.8083)] 
2025-07-08 16:41:47.969974: Epoch time: 47.71 s 
2025-07-08 16:41:47.970070: Yayy! New best EMA pseudo Dice: 0.781000018119812 
2025-07-08 16:41:49.668964:  
2025-07-08 16:41:49.669487: Epoch 32 
2025-07-08 16:41:49.669631: Current learning rate: 0.00971 
2025-07-08 16:42:36.986200: train_loss -0.5141 
2025-07-08 16:42:36.986685: val_loss -0.5175 
2025-07-08 16:42:36.986769: Pseudo dice [np.float32(0.8115)] 
2025-07-08 16:42:36.986964: Epoch time: 47.32 s 
2025-07-08 16:42:36.987041: Yayy! New best EMA pseudo Dice: 0.7839999794960022 
2025-07-08 16:42:38.577342:  
2025-07-08 16:42:38.577911: Epoch 33 
2025-07-08 16:42:38.578105: Current learning rate: 0.0097 
2025-07-08 16:43:25.245111: train_loss -0.5027 
2025-07-08 16:43:25.245526: val_loss -0.5147 
2025-07-08 16:43:25.245633: Pseudo dice [np.float32(0.8022)] 
2025-07-08 16:43:25.245755: Epoch time: 46.67 s 
2025-07-08 16:43:25.245838: Yayy! New best EMA pseudo Dice: 0.7857999801635742 
2025-07-08 16:43:26.812864:  
2025-07-08 16:43:26.813223: Epoch 34 
2025-07-08 16:43:26.813411: Current learning rate: 0.00969 
2025-07-08 16:44:13.607394: train_loss -0.5032 
2025-07-08 16:44:13.607932: val_loss -0.5026 
2025-07-08 16:44:13.608036: Pseudo dice [np.float32(0.7755)] 
2025-07-08 16:44:13.608149: Epoch time: 46.8 s 
2025-07-08 16:44:15.068100:  
2025-07-08 16:44:15.068483: Epoch 35 
2025-07-08 16:44:15.068742: Current learning rate: 0.00968 
2025-07-08 16:45:02.830736: train_loss -0.5113 
2025-07-08 16:45:02.831460: val_loss -0.536 
2025-07-08 16:45:02.831592: Pseudo dice [np.float32(0.801)] 
2025-07-08 16:45:02.831713: Epoch time: 47.76 s 
2025-07-08 16:45:02.831794: Yayy! New best EMA pseudo Dice: 0.7864000201225281 
2025-07-08 16:45:04.442433:  
2025-07-08 16:45:04.442742: Epoch 36 
2025-07-08 16:45:04.443053: Current learning rate: 0.00968 
2025-07-08 16:45:51.842422: train_loss -0.5065 
2025-07-08 16:45:51.842994: val_loss -0.5103 
2025-07-08 16:45:51.843216: Pseudo dice [np.float32(0.8062)] 
2025-07-08 16:45:51.843330: Epoch time: 47.4 s 
2025-07-08 16:45:51.843417: Yayy! New best EMA pseudo Dice: 0.7883999943733215 
2025-07-08 16:45:53.457948:  
2025-07-08 16:45:53.458220: Epoch 37 
2025-07-08 16:45:53.458445: Current learning rate: 0.00967 
2025-07-08 16:46:40.673959: train_loss -0.4974 
2025-07-08 16:46:40.674281: val_loss -0.5368 
2025-07-08 16:46:40.674359: Pseudo dice [np.float32(0.816)] 
2025-07-08 16:46:40.674447: Epoch time: 47.22 s 
2025-07-08 16:46:40.674517: Yayy! New best EMA pseudo Dice: 0.7911999821662903 
2025-07-08 16:46:42.287533:  
2025-07-08 16:46:42.287744: Epoch 38 
2025-07-08 16:46:42.287853: Current learning rate: 0.00966 
2025-07-08 16:47:29.722537: train_loss -0.5122 
2025-07-08 16:47:29.723205: val_loss -0.5266 
2025-07-08 16:47:29.723338: Pseudo dice [np.float32(0.8102)] 
2025-07-08 16:47:29.723492: Epoch time: 47.44 s 
2025-07-08 16:47:29.723629: Yayy! New best EMA pseudo Dice: 0.7930999994277954 
2025-07-08 16:47:31.441815:  
2025-07-08 16:47:31.442155: Epoch 39 
2025-07-08 16:47:31.442281: Current learning rate: 0.00965 
2025-07-08 16:48:18.184115: train_loss -0.5189 
2025-07-08 16:48:18.184566: val_loss -0.5266 
2025-07-08 16:48:18.184657: Pseudo dice [np.float32(0.7988)] 
2025-07-08 16:48:18.184764: Epoch time: 46.74 s 
2025-07-08 16:48:18.184846: Yayy! New best EMA pseudo Dice: 0.7936000227928162 
2025-07-08 16:48:19.846642:  
2025-07-08 16:48:19.847056: Epoch 40 
2025-07-08 16:48:19.847182: Current learning rate: 0.00964 
2025-07-08 16:49:07.159225: train_loss -0.5004 
2025-07-08 16:49:07.159577: val_loss -0.5053 
2025-07-08 16:49:07.159655: Pseudo dice [np.float32(0.8164)] 
2025-07-08 16:49:07.159747: Epoch time: 47.31 s 
2025-07-08 16:49:07.159818: Yayy! New best EMA pseudo Dice: 0.7958999872207642 
2025-07-08 16:49:08.822779:  
2025-07-08 16:49:08.822968: Epoch 41 
2025-07-08 16:49:08.823242: Current learning rate: 0.00963 
2025-07-08 16:49:56.239236: train_loss -0.5275 
2025-07-08 16:49:56.239622: val_loss -0.5615 
2025-07-08 16:49:56.239699: Pseudo dice [np.float32(0.8169)] 
2025-07-08 16:49:56.239792: Epoch time: 47.42 s 
2025-07-08 16:49:56.240038: Yayy! New best EMA pseudo Dice: 0.7979999780654907 
2025-07-08 16:49:57.870990:  
2025-07-08 16:49:57.871424: Epoch 42 
2025-07-08 16:49:57.871562: Current learning rate: 0.00962 
2025-07-08 16:50:43.830173: train_loss -0.4947 
2025-07-08 16:50:43.830890: val_loss -0.5279 
2025-07-08 16:50:43.831039: Pseudo dice [np.float32(0.7943)] 
2025-07-08 16:50:43.831228: Epoch time: 45.96 s 
2025-07-08 16:50:45.026888:  
2025-07-08 16:50:45.027236: Epoch 43 
2025-07-08 16:50:45.027458: Current learning rate: 0.00961 
2025-07-08 16:51:31.898203: train_loss -0.5238 
2025-07-08 16:51:31.898735: val_loss -0.532 
2025-07-08 16:51:31.898831: Pseudo dice [np.float32(0.8063)] 
2025-07-08 16:51:31.898955: Epoch time: 46.87 s 
2025-07-08 16:51:31.899044: Yayy! New best EMA pseudo Dice: 0.7985000014305115 
2025-07-08 16:51:33.638713:  
2025-07-08 16:51:33.639157: Epoch 44 
2025-07-08 16:51:33.639298: Current learning rate: 0.0096 
2025-07-08 16:52:20.385946: train_loss -0.5123 
2025-07-08 16:52:20.386703: val_loss -0.5213 
2025-07-08 16:52:20.386842: Pseudo dice [np.float32(0.8229)] 
2025-07-08 16:52:20.386992: Epoch time: 46.75 s 
2025-07-08 16:52:20.387096: Yayy! New best EMA pseudo Dice: 0.8008999824523926 
2025-07-08 16:52:22.045828:  
2025-07-08 16:52:22.045994: Epoch 45 
2025-07-08 16:52:22.046131: Current learning rate: 0.00959 
2025-07-08 16:53:08.013104: train_loss -0.5084 
2025-07-08 16:53:08.013678: val_loss -0.4887 
2025-07-08 16:53:08.013769: Pseudo dice [np.float32(0.8095)] 
2025-07-08 16:53:08.013874: Epoch time: 45.97 s 
2025-07-08 16:53:08.013950: Yayy! New best EMA pseudo Dice: 0.801800012588501 
2025-07-08 16:53:09.673030:  
2025-07-08 16:53:09.673321: Epoch 46 
2025-07-08 16:53:09.673604: Current learning rate: 0.00959 
2025-07-08 16:53:57.294868: train_loss -0.5081 
2025-07-08 16:53:57.295356: val_loss -0.5189 
2025-07-08 16:53:57.295444: Pseudo dice [np.float32(0.7889)] 
2025-07-08 16:53:57.295559: Epoch time: 47.62 s 
2025-07-08 16:53:58.412389:  
2025-07-08 16:53:58.412680: Epoch 47 
2025-07-08 16:53:58.412791: Current learning rate: 0.00958 
2025-07-08 16:54:45.535805: train_loss -0.5245 
2025-07-08 16:54:45.536205: val_loss -0.5152 
2025-07-08 16:54:45.536295: Pseudo dice [np.float32(0.8078)] 
2025-07-08 16:54:45.536413: Epoch time: 47.12 s 
2025-07-08 16:54:47.238509:  
2025-07-08 16:54:47.238814: Epoch 48 
2025-07-08 16:54:47.238951: Current learning rate: 0.00957 
2025-07-08 16:55:35.155221: train_loss -0.526 
2025-07-08 16:55:35.155874: val_loss -0.4941 
2025-07-08 16:55:35.155975: Pseudo dice [np.float32(0.8149)] 
2025-07-08 16:55:35.156099: Epoch time: 47.92 s 
2025-07-08 16:55:35.156193: Yayy! New best EMA pseudo Dice: 0.8026000261306763 
2025-07-08 16:55:36.785689:  
2025-07-08 16:55:36.785904: Epoch 49 
2025-07-08 16:55:36.786048: Current learning rate: 0.00956 
2025-07-08 16:56:24.650851: train_loss -0.5094 
2025-07-08 16:56:24.651237: val_loss -0.5122 
2025-07-08 16:56:24.651324: Pseudo dice [np.float32(0.8084)] 
2025-07-08 16:56:24.651427: Epoch time: 47.87 s 
2025-07-08 16:56:24.916054: Yayy! New best EMA pseudo Dice: 0.8032000064849854 
2025-07-08 16:56:26.426577:  
2025-07-08 16:56:26.426850: Epoch 50 
2025-07-08 16:56:26.426995: Current learning rate: 0.00955 
2025-07-08 16:57:13.539101: train_loss -0.5213 
2025-07-08 16:57:13.539632: val_loss -0.5355 
2025-07-08 16:57:13.539715: Pseudo dice [np.float32(0.836)] 
2025-07-08 16:57:13.539814: Epoch time: 47.11 s 
2025-07-08 16:57:13.539893: Yayy! New best EMA pseudo Dice: 0.8065000176429749 
2025-07-08 16:57:15.128104:  
2025-07-08 16:57:15.128438: Epoch 51 
2025-07-08 16:57:15.128661: Current learning rate: 0.00954 
2025-07-08 16:58:01.805143: train_loss -0.528 
2025-07-08 16:58:01.805747: val_loss -0.5532 
2025-07-08 16:58:01.805842: Pseudo dice [np.float32(0.8295)] 
2025-07-08 16:58:01.805952: Epoch time: 46.68 s 
2025-07-08 16:58:01.806031: Yayy! New best EMA pseudo Dice: 0.8087999820709229 
2025-07-08 16:58:03.440197:  
2025-07-08 16:58:03.440595: Epoch 52 
2025-07-08 16:58:03.440794: Current learning rate: 0.00953 
2025-07-08 16:58:50.217010: train_loss -0.5291 
2025-07-08 16:58:50.217481: val_loss -0.5208 
2025-07-08 16:58:50.217589: Pseudo dice [np.float32(0.8196)] 
2025-07-08 16:58:50.217703: Epoch time: 46.78 s 
2025-07-08 16:58:50.217794: Yayy! New best EMA pseudo Dice: 0.8098999857902527 
2025-07-08 16:58:51.775944:  
2025-07-08 16:58:51.776275: Epoch 53 
2025-07-08 16:58:51.776376: Current learning rate: 0.00952 
2025-07-08 16:59:38.901165: train_loss -0.5235 
2025-07-08 16:59:38.901515: val_loss -0.5318 
2025-07-08 16:59:38.901603: Pseudo dice [np.float32(0.808)] 
2025-07-08 16:59:38.901698: Epoch time: 47.13 s 
2025-07-08 16:59:40.014934:  
2025-07-08 16:59:40.015214: Epoch 54 
2025-07-08 16:59:40.015313: Current learning rate: 0.00951 
2025-07-08 17:00:27.100866: train_loss -0.5267 
2025-07-08 17:00:27.101167: val_loss -0.537 
2025-07-08 17:00:27.101301: Pseudo dice [np.float32(0.8283)] 
2025-07-08 17:00:27.101465: Epoch time: 47.09 s 
2025-07-08 17:00:27.101553: Yayy! New best EMA pseudo Dice: 0.8115000128746033 
2025-07-08 17:00:28.750120:  
2025-07-08 17:00:28.750806: Epoch 55 
2025-07-08 17:00:28.751152: Current learning rate: 0.0095 
2025-07-08 17:01:16.455177: train_loss -0.5169 
2025-07-08 17:01:16.455835: val_loss -0.5559 
2025-07-08 17:01:16.455918: Pseudo dice [np.float32(0.8175)] 
2025-07-08 17:01:16.456014: Epoch time: 47.71 s 
2025-07-08 17:01:16.456091: Yayy! New best EMA pseudo Dice: 0.8120999932289124 
2025-07-08 17:01:18.108562:  
2025-07-08 17:01:18.108922: Epoch 56 
2025-07-08 17:01:18.109031: Current learning rate: 0.00949 
2025-07-08 17:02:05.080036: train_loss -0.5089 
2025-07-08 17:02:05.080587: val_loss -0.5444 
2025-07-08 17:02:05.080687: Pseudo dice [np.float32(0.8051)] 
2025-07-08 17:02:05.080806: Epoch time: 46.97 s 
2025-07-08 17:02:06.311677:  
2025-07-08 17:02:06.311872: Epoch 57 
2025-07-08 17:02:06.312059: Current learning rate: 0.00949 
2025-07-08 17:02:53.462468: train_loss -0.5189 
2025-07-08 17:02:53.462853: val_loss -0.5273 
2025-07-08 17:02:53.462941: Pseudo dice [np.float32(0.8185)] 
2025-07-08 17:02:53.463064: Epoch time: 47.15 s 
2025-07-08 17:02:54.557668:  
2025-07-08 17:02:54.557899: Epoch 58 
2025-07-08 17:02:54.558173: Current learning rate: 0.00948 
2025-07-08 17:03:41.377941: train_loss -0.5252 
2025-07-08 17:03:41.378620: val_loss -0.5427 
2025-07-08 17:03:41.378707: Pseudo dice [np.float32(0.8393)] 
2025-07-08 17:03:41.378816: Epoch time: 46.82 s 
2025-07-08 17:03:41.378895: Yayy! New best EMA pseudo Dice: 0.8148000240325928 
2025-07-08 17:03:43.133405:  
2025-07-08 17:03:43.133806: Epoch 59 
2025-07-08 17:03:43.133920: Current learning rate: 0.00947 
2025-07-08 17:04:30.632616: train_loss -0.53 
2025-07-08 17:04:30.633037: val_loss -0.5294 
2025-07-08 17:04:30.633117: Pseudo dice [np.float32(0.8224)] 
2025-07-08 17:04:30.633231: Epoch time: 47.5 s 
2025-07-08 17:04:30.633309: Yayy! New best EMA pseudo Dice: 0.8155999779701233 
2025-07-08 17:04:32.253504:  
2025-07-08 17:04:32.254200: Epoch 60 
2025-07-08 17:04:32.254377: Current learning rate: 0.00946 
2025-07-08 17:05:19.734990: train_loss -0.5281 
2025-07-08 17:05:19.735459: val_loss -0.5345 
2025-07-08 17:05:19.735556: Pseudo dice [np.float32(0.8236)] 
2025-07-08 17:05:19.735671: Epoch time: 47.48 s 
2025-07-08 17:05:19.735751: Yayy! New best EMA pseudo Dice: 0.8163999915122986 
2025-07-08 17:05:21.385332:  
2025-07-08 17:05:21.385844: Epoch 61 
2025-07-08 17:05:21.386017: Current learning rate: 0.00945 
2025-07-08 17:06:09.220227: train_loss -0.5256 
2025-07-08 17:06:09.221072: val_loss -0.5388 
2025-07-08 17:06:09.221178: Pseudo dice [np.float32(0.8292)] 
2025-07-08 17:06:09.221337: Epoch time: 47.84 s 
2025-07-08 17:06:09.221432: Yayy! New best EMA pseudo Dice: 0.8177000284194946 
2025-07-08 17:06:10.863574:  
2025-07-08 17:06:10.863817: Epoch 62 
2025-07-08 17:06:10.863944: Current learning rate: 0.00944 
2025-07-08 17:06:59.085443: train_loss -0.5247 
2025-07-08 17:06:59.085970: val_loss -0.548 
2025-07-08 17:06:59.086051: Pseudo dice [np.float32(0.8206)] 
2025-07-08 17:06:59.086154: Epoch time: 48.22 s 
2025-07-08 17:06:59.086227: Yayy! New best EMA pseudo Dice: 0.8180000185966492 
2025-07-08 17:07:01.276931:  
2025-07-08 17:07:01.277156: Epoch 63 
2025-07-08 17:07:01.277332: Current learning rate: 0.00943 
2025-07-08 17:07:48.331177: train_loss -0.5273 
2025-07-08 17:07:48.331635: val_loss -0.5405 
2025-07-08 17:07:48.331730: Pseudo dice [np.float32(0.8235)] 
2025-07-08 17:07:48.331846: Epoch time: 47.06 s 
2025-07-08 17:07:48.331922: Yayy! New best EMA pseudo Dice: 0.8184999823570251 
2025-07-08 17:07:49.939899:  
2025-07-08 17:07:49.940075: Epoch 64 
2025-07-08 17:07:49.940278: Current learning rate: 0.00942 
2025-07-08 17:08:37.140474: train_loss -0.5325 
2025-07-08 17:08:37.140836: val_loss -0.5197 
2025-07-08 17:08:37.140911: Pseudo dice [np.float32(0.8316)] 
2025-07-08 17:08:37.140995: Epoch time: 47.2 s 
2025-07-08 17:08:37.141063: Yayy! New best EMA pseudo Dice: 0.8198000192642212 
2025-07-08 17:08:38.794615:  
2025-07-08 17:08:38.794807: Epoch 65 
2025-07-08 17:08:38.795088: Current learning rate: 0.00941 
2025-07-08 17:09:26.018877: train_loss -0.5382 
2025-07-08 17:09:26.019292: val_loss -0.5444 
2025-07-08 17:09:26.019377: Pseudo dice [np.float32(0.8239)] 
2025-07-08 17:09:26.019487: Epoch time: 47.23 s 
2025-07-08 17:09:26.019580: Yayy! New best EMA pseudo Dice: 0.8202000260353088 
2025-07-08 17:09:27.663091:  
2025-07-08 17:09:27.663504: Epoch 66 
2025-07-08 17:09:27.663642: Current learning rate: 0.0094 
2025-07-08 17:10:14.963662: train_loss -0.5342 
2025-07-08 17:10:14.964246: val_loss -0.5476 
2025-07-08 17:10:14.964349: Pseudo dice [np.float32(0.8227)] 
2025-07-08 17:10:14.964478: Epoch time: 47.3 s 
2025-07-08 17:10:14.964581: Yayy! New best EMA pseudo Dice: 0.8205000162124634 
2025-07-08 17:10:16.642608:  
2025-07-08 17:10:16.642955: Epoch 67 
2025-07-08 17:10:16.643205: Current learning rate: 0.00939 
2025-07-08 17:11:03.758645: train_loss -0.5337 
2025-07-08 17:11:03.759135: val_loss -0.5361 
2025-07-08 17:11:03.759227: Pseudo dice [np.float32(0.8252)] 
2025-07-08 17:11:03.759344: Epoch time: 47.12 s 
2025-07-08 17:11:03.759428: Yayy! New best EMA pseudo Dice: 0.8209999799728394 
2025-07-08 17:11:05.451205:  
2025-07-08 17:11:05.451398: Epoch 68 
2025-07-08 17:11:05.451624: Current learning rate: 0.00939 
2025-07-08 17:11:53.680950: train_loss -0.5294 
2025-07-08 17:11:53.681606: val_loss -0.5426 
2025-07-08 17:11:53.681721: Pseudo dice [np.float32(0.8447)] 
2025-07-08 17:11:53.681851: Epoch time: 48.23 s 
2025-07-08 17:11:53.681950: Yayy! New best EMA pseudo Dice: 0.8233000040054321 
2025-07-08 17:11:55.349922:  
2025-07-08 17:11:55.350356: Epoch 69 
2025-07-08 17:11:55.350491: Current learning rate: 0.00938 
2025-07-08 17:12:42.269500: train_loss -0.5223 
2025-07-08 17:12:42.270088: val_loss -0.5463 
2025-07-08 17:12:42.270173: Pseudo dice [np.float32(0.8374)] 
2025-07-08 17:12:42.270326: Epoch time: 46.92 s 
2025-07-08 17:12:42.270409: Yayy! New best EMA pseudo Dice: 0.8246999979019165 
2025-07-08 17:12:43.928458:  
2025-07-08 17:12:43.928785: Epoch 70 
2025-07-08 17:12:43.929022: Current learning rate: 0.00937 
2025-07-08 17:13:30.999064: train_loss -0.5158 
2025-07-08 17:13:30.999479: val_loss -0.5228 
2025-07-08 17:13:30.999575: Pseudo dice [np.float32(0.8307)] 
2025-07-08 17:13:30.999684: Epoch time: 47.07 s 
2025-07-08 17:13:30.999850: Yayy! New best EMA pseudo Dice: 0.8252999782562256 
2025-07-08 17:13:32.688998:  
2025-07-08 17:13:32.689525: Epoch 71 
2025-07-08 17:13:32.689680: Current learning rate: 0.00936 
2025-07-08 17:14:20.774737: train_loss -0.5253 
2025-07-08 17:14:20.775450: val_loss -0.5615 
2025-07-08 17:14:20.775558: Pseudo dice [np.float32(0.8134)] 
2025-07-08 17:14:20.775687: Epoch time: 48.09 s 
2025-07-08 17:14:22.040990:  
2025-07-08 17:14:22.041582: Epoch 72 
2025-07-08 17:14:22.041761: Current learning rate: 0.00935 
2025-07-08 17:15:11.013841: train_loss -0.53 
2025-07-08 17:15:11.014481: val_loss -0.547 
2025-07-08 17:15:11.014628: Pseudo dice [np.float32(0.8298)] 
2025-07-08 17:15:11.014748: Epoch time: 48.97 s 
2025-07-08 17:15:12.263357:  
2025-07-08 17:15:12.263592: Epoch 73 
2025-07-08 17:15:12.263987: Current learning rate: 0.00934 
2025-07-08 17:16:00.558117: train_loss -0.5175 
2025-07-08 17:16:00.558501: val_loss -0.5286 
2025-07-08 17:16:00.558609: Pseudo dice [np.float32(0.8253)] 
2025-07-08 17:16:00.558718: Epoch time: 48.3 s 
2025-07-08 17:16:01.713557:  
2025-07-08 17:16:01.713995: Epoch 74 
2025-07-08 17:16:01.714132: Current learning rate: 0.00933 
2025-07-08 17:16:49.709594: train_loss -0.5302 
2025-07-08 17:16:49.709997: val_loss -0.5666 
2025-07-08 17:16:49.710083: Pseudo dice [np.float32(0.8332)] 
2025-07-08 17:16:49.710182: Epoch time: 48.0 s 
2025-07-08 17:16:49.710256: Yayy! New best EMA pseudo Dice: 0.8256000280380249 
2025-07-08 17:16:51.321121:  
2025-07-08 17:16:51.321369: Epoch 75 
2025-07-08 17:16:51.321562: Current learning rate: 0.00932 
2025-07-08 17:17:39.563461: train_loss -0.5399 
2025-07-08 17:17:39.563850: val_loss -0.537 
2025-07-08 17:17:39.563978: Pseudo dice [np.float32(0.8297)] 
2025-07-08 17:17:39.564074: Epoch time: 48.24 s 
2025-07-08 17:17:39.564154: Yayy! New best EMA pseudo Dice: 0.8259999752044678 
2025-07-08 17:17:41.196671:  
2025-07-08 17:17:41.197061: Epoch 76 
2025-07-08 17:17:41.197171: Current learning rate: 0.00931 
2025-07-08 17:18:29.793019: train_loss -0.535 
2025-07-08 17:18:29.793298: val_loss -0.5295 
2025-07-08 17:18:29.793374: Pseudo dice [np.float32(0.8381)] 
2025-07-08 17:18:29.793462: Epoch time: 48.6 s 
2025-07-08 17:18:29.793532: Yayy! New best EMA pseudo Dice: 0.8271999955177307 
2025-07-08 17:18:31.365600:  
2025-07-08 17:18:31.365987: Epoch 77 
2025-07-08 17:18:31.366135: Current learning rate: 0.0093 
2025-07-08 17:19:20.349022: train_loss -0.5357 
2025-07-08 17:19:20.349388: val_loss -0.5428 
2025-07-08 17:19:20.349475: Pseudo dice [np.float32(0.8222)] 
2025-07-08 17:19:20.349590: Epoch time: 48.98 s 
2025-07-08 17:19:21.564271:  
2025-07-08 17:19:21.564635: Epoch 78 
2025-07-08 17:19:21.564753: Current learning rate: 0.0093 
2025-07-08 17:20:08.743225: train_loss -0.5454 
2025-07-08 17:20:08.743584: val_loss -0.5403 
2025-07-08 17:20:08.743701: Pseudo dice [np.float32(0.8306)] 
2025-07-08 17:20:08.743887: Epoch time: 47.18 s 
2025-07-08 17:20:09.939581:  
2025-07-08 17:20:09.939857: Epoch 79 
2025-07-08 17:20:09.939991: Current learning rate: 0.00929 
2025-07-08 17:20:57.898276: train_loss -0.5351 
2025-07-08 17:20:57.898972: val_loss -0.5352 
2025-07-08 17:20:57.899147: Pseudo dice [np.float32(0.8365)] 
2025-07-08 17:20:57.899356: Epoch time: 47.96 s 
2025-07-08 17:20:57.899480: Yayy! New best EMA pseudo Dice: 0.8281000256538391 
2025-07-08 17:20:59.561336:  
2025-07-08 17:20:59.561959: Epoch 80 
2025-07-08 17:20:59.562092: Current learning rate: 0.00928 
2025-07-08 17:21:46.488429: train_loss -0.5465 
2025-07-08 17:21:46.488895: val_loss -0.5716 
2025-07-08 17:21:46.488991: Pseudo dice [np.float32(0.8502)] 
2025-07-08 17:21:46.489111: Epoch time: 46.93 s 
2025-07-08 17:21:46.489194: Yayy! New best EMA pseudo Dice: 0.830299973487854 
2025-07-08 17:21:48.131268:  
2025-07-08 17:21:48.131869: Epoch 81 
2025-07-08 17:21:48.132061: Current learning rate: 0.00927 
2025-07-08 17:22:36.743846: train_loss -0.5515 
2025-07-08 17:22:36.744321: val_loss -0.5373 
2025-07-08 17:22:36.744417: Pseudo dice [np.float32(0.8383)] 
2025-07-08 17:22:36.744537: Epoch time: 48.61 s 
2025-07-08 17:22:36.744644: Yayy! New best EMA pseudo Dice: 0.8310999870300293 
2025-07-08 17:22:38.405943:  
2025-07-08 17:22:38.406334: Epoch 82 
2025-07-08 17:22:38.406610: Current learning rate: 0.00926 
2025-07-08 17:23:26.205001: train_loss -0.5288 
2025-07-08 17:23:26.205448: val_loss -0.5471 
2025-07-08 17:23:26.205530: Pseudo dice [np.float32(0.8333)] 
2025-07-08 17:23:26.205673: Epoch time: 47.8 s 
2025-07-08 17:23:26.205749: Yayy! New best EMA pseudo Dice: 0.8313000202178955 
2025-07-08 17:23:27.820584:  
2025-07-08 17:23:27.820912: Epoch 83 
2025-07-08 17:23:27.821037: Current learning rate: 0.00925 
2025-07-08 17:24:15.757653: train_loss -0.5319 
2025-07-08 17:24:15.758226: val_loss -0.5292 
2025-07-08 17:24:15.758308: Pseudo dice [np.float32(0.8194)] 
2025-07-08 17:24:15.758442: Epoch time: 47.94 s 
2025-07-08 17:24:16.911219:  
2025-07-08 17:24:16.911657: Epoch 84 
2025-07-08 17:24:16.912019: Current learning rate: 0.00924 
2025-07-08 17:25:05.796971: train_loss -0.5458 
2025-07-08 17:25:05.797349: val_loss -0.5613 
2025-07-08 17:25:05.797427: Pseudo dice [np.float32(0.844)] 
2025-07-08 17:25:05.797529: Epoch time: 48.89 s 
2025-07-08 17:25:05.797619: Yayy! New best EMA pseudo Dice: 0.8314999938011169 
2025-07-08 17:25:07.412194:  
2025-07-08 17:25:07.412611: Epoch 85 
2025-07-08 17:25:07.412740: Current learning rate: 0.00923 
2025-07-08 17:25:55.087815: train_loss -0.5253 
2025-07-08 17:25:55.088216: val_loss -0.5421 
2025-07-08 17:25:55.088299: Pseudo dice [np.float32(0.8289)] 
2025-07-08 17:25:55.088407: Epoch time: 47.68 s 
2025-07-08 17:25:56.201937:  
2025-07-08 17:25:56.202188: Epoch 86 
2025-07-08 17:25:56.202519: Current learning rate: 0.00922 
2025-07-08 17:26:44.498582: train_loss -0.5351 
2025-07-08 17:26:44.499037: val_loss -0.5462 
2025-07-08 17:26:44.499122: Pseudo dice [np.float32(0.8295)] 
2025-07-08 17:26:44.499233: Epoch time: 48.3 s 
2025-07-08 17:26:45.659604:  
2025-07-08 17:26:45.660120: Epoch 87 
2025-07-08 17:26:45.660282: Current learning rate: 0.00921 
2025-07-08 17:27:34.730712: train_loss -0.5349 
2025-07-08 17:27:34.731683: val_loss -0.5484 
2025-07-08 17:27:34.731820: Pseudo dice [np.float32(0.8328)] 
2025-07-08 17:27:34.732025: Epoch time: 49.07 s 
2025-07-08 17:27:36.023813:  
2025-07-08 17:27:36.024136: Epoch 88 
2025-07-08 17:27:36.024360: Current learning rate: 0.0092 
2025-07-08 17:28:24.459749: train_loss -0.5477 
2025-07-08 17:28:24.460126: val_loss -0.5237 
2025-07-08 17:28:24.460226: Pseudo dice [np.float32(0.8401)] 
2025-07-08 17:28:24.460331: Epoch time: 48.44 s 
2025-07-08 17:28:24.460410: Yayy! New best EMA pseudo Dice: 0.832099974155426 
2025-07-08 17:28:26.217763:  
2025-07-08 17:28:26.218123: Epoch 89 
2025-07-08 17:28:26.218354: Current learning rate: 0.0092 
2025-07-08 17:29:14.943340: train_loss -0.5402 
2025-07-08 17:29:14.943945: val_loss -0.5392 
2025-07-08 17:29:14.944028: Pseudo dice [np.float32(0.8271)] 
2025-07-08 17:29:14.944139: Epoch time: 48.73 s 
2025-07-08 17:29:16.995538:  
2025-07-08 17:29:16.995813: Epoch 90 
2025-07-08 17:29:16.995951: Current learning rate: 0.00919 
2025-07-08 17:30:05.254350: train_loss -0.548 
2025-07-08 17:30:05.254804: val_loss -0.5719 
2025-07-08 17:30:05.254897: Pseudo dice [np.float32(0.8375)] 
2025-07-08 17:30:05.255140: Epoch time: 48.26 s 
2025-07-08 17:30:05.255328: Yayy! New best EMA pseudo Dice: 0.8321999907493591 
2025-07-08 17:30:06.888351:  
2025-07-08 17:30:06.888679: Epoch 91 
2025-07-08 17:30:06.888921: Current learning rate: 0.00918 
2025-07-08 17:30:55.052825: train_loss -0.5392 
2025-07-08 17:30:55.053501: val_loss -0.5395 
2025-07-08 17:30:55.053623: Pseudo dice [np.float32(0.8358)] 
2025-07-08 17:30:55.053746: Epoch time: 48.17 s 
2025-07-08 17:30:55.053833: Yayy! New best EMA pseudo Dice: 0.8325999975204468 
2025-07-08 17:30:56.723428:  
2025-07-08 17:30:56.724128: Epoch 92 
2025-07-08 17:30:56.724309: Current learning rate: 0.00917 
2025-07-08 17:31:42.399985: train_loss -0.5329 
2025-07-08 17:31:42.400466: val_loss -0.5277 
2025-07-08 17:31:42.400571: Pseudo dice [np.float32(0.8364)] 
2025-07-08 17:31:42.400688: Epoch time: 45.68 s 
2025-07-08 17:31:42.400921: Yayy! New best EMA pseudo Dice: 0.8330000042915344 
2025-07-08 17:31:44.023193:  
2025-07-08 17:31:44.023457: Epoch 93 
2025-07-08 17:31:44.023822: Current learning rate: 0.00916 
2025-07-08 17:32:30.536425: train_loss -0.5379 
2025-07-08 17:32:30.536874: val_loss -0.5488 
2025-07-08 17:32:30.536954: Pseudo dice [np.float32(0.8258)] 
2025-07-08 17:32:30.537056: Epoch time: 46.51 s 
2025-07-08 17:32:31.756271:  
2025-07-08 17:32:31.756716: Epoch 94 
2025-07-08 17:32:31.756885: Current learning rate: 0.00915 
2025-07-08 17:33:18.337096: train_loss -0.5342 
2025-07-08 17:33:18.337756: val_loss -0.5414 
2025-07-08 17:33:18.337871: Pseudo dice [np.float32(0.8419)] 
2025-07-08 17:33:18.338011: Epoch time: 46.58 s 
2025-07-08 17:33:18.338102: Yayy! New best EMA pseudo Dice: 0.8331999778747559 
2025-07-08 17:33:19.947452:  
2025-07-08 17:33:19.947790: Epoch 95 
2025-07-08 17:33:19.948097: Current learning rate: 0.00914 
2025-07-08 17:34:06.638809: train_loss -0.5452 
2025-07-08 17:34:06.639138: val_loss -0.5497 
2025-07-08 17:34:06.639217: Pseudo dice [np.float32(0.8398)] 
2025-07-08 17:34:06.639314: Epoch time: 46.69 s 
2025-07-08 17:34:06.639390: Yayy! New best EMA pseudo Dice: 0.833899974822998 
2025-07-08 17:34:08.223725:  
2025-07-08 17:34:08.224267: Epoch 96 
2025-07-08 17:34:08.224392: Current learning rate: 0.00913 
2025-07-08 17:34:55.104494: train_loss -0.5424 
2025-07-08 17:34:55.105241: val_loss -0.5642 
2025-07-08 17:34:55.105352: Pseudo dice [np.float32(0.8616)] 
2025-07-08 17:34:55.105495: Epoch time: 46.88 s 
2025-07-08 17:34:55.105604: Yayy! New best EMA pseudo Dice: 0.8366000056266785 
2025-07-08 17:34:56.763057:  
2025-07-08 17:34:56.763667: Epoch 97 
2025-07-08 17:34:56.764180: Current learning rate: 0.00912 
2025-07-08 17:35:43.329635: train_loss -0.5395 
2025-07-08 17:35:43.330102: val_loss -0.5109 
2025-07-08 17:35:43.330194: Pseudo dice [np.float32(0.8296)] 
2025-07-08 17:35:43.330361: Epoch time: 46.57 s 
2025-07-08 17:35:44.480356:  
2025-07-08 17:35:44.480643: Epoch 98 
2025-07-08 17:35:44.480764: Current learning rate: 0.00911 
2025-07-08 17:36:30.912555: train_loss -0.5425 
2025-07-08 17:36:30.913151: val_loss -0.5449 
2025-07-08 17:36:30.913241: Pseudo dice [np.float32(0.8346)] 
2025-07-08 17:36:30.913349: Epoch time: 46.43 s 
2025-07-08 17:36:32.134170:  
2025-07-08 17:36:32.134561: Epoch 99 
2025-07-08 17:36:32.134769: Current learning rate: 0.0091 
2025-07-08 17:37:19.289609: train_loss -0.5402 
2025-07-08 17:37:19.290177: val_loss -0.5315 
2025-07-08 17:37:19.290404: Pseudo dice [np.float32(0.8455)] 
2025-07-08 17:37:19.290592: Epoch time: 47.16 s 
2025-07-08 17:37:19.890795: Yayy! New best EMA pseudo Dice: 0.8367999792098999 
2025-07-08 17:37:21.431451:  
2025-07-08 17:37:21.431752: Epoch 100 
2025-07-08 17:37:21.432050: Current learning rate: 0.0091 
2025-07-08 17:38:08.417089: train_loss -0.53 
2025-07-08 17:38:08.418210: val_loss -0.5671 
2025-07-08 17:38:08.418381: Pseudo dice [np.float32(0.8194)] 
2025-07-08 17:38:08.418518: Epoch time: 46.99 s 
2025-07-08 17:38:09.653474:  
2025-07-08 17:38:09.654362: Epoch 101 
2025-07-08 17:38:09.654597: Current learning rate: 0.00909 
2025-07-08 17:38:56.806660: train_loss -0.5577 
2025-07-08 17:38:56.807425: val_loss -0.5599 
2025-07-08 17:38:56.807607: Pseudo dice [np.float32(0.8385)] 
2025-07-08 17:38:56.807728: Epoch time: 47.16 s 
2025-07-08 17:38:58.016835:  
2025-07-08 17:38:58.017279: Epoch 102 
2025-07-08 17:38:58.017414: Current learning rate: 0.00908 
2025-07-08 17:39:45.026931: train_loss -0.5459 
2025-07-08 17:39:45.027423: val_loss -0.5528 
2025-07-08 17:39:45.027506: Pseudo dice [np.float32(0.8452)] 
2025-07-08 17:39:45.027622: Epoch time: 47.01 s 
2025-07-08 17:39:46.180357:  
2025-07-08 17:39:46.180730: Epoch 103 
2025-07-08 17:39:46.181120: Current learning rate: 0.00907 
2025-07-08 17:40:32.630328: train_loss -0.5397 
2025-07-08 17:40:32.631941: val_loss -0.5405 
2025-07-08 17:40:32.632155: Pseudo dice [np.float32(0.8297)] 
2025-07-08 17:40:32.632352: Epoch time: 46.45 s 
2025-07-08 17:40:33.879418:  
2025-07-08 17:40:33.879793: Epoch 104 
2025-07-08 17:40:33.879921: Current learning rate: 0.00906 
2025-07-08 17:41:21.010483: train_loss -0.542 
2025-07-08 17:41:21.010872: val_loss -0.56 
2025-07-08 17:41:21.010954: Pseudo dice [np.float32(0.8305)] 
2025-07-08 17:41:21.011055: Epoch time: 47.13 s 
2025-07-08 17:41:22.902342:  
2025-07-08 17:41:22.902682: Epoch 105 
2025-07-08 17:41:22.902850: Current learning rate: 0.00905 
2025-07-08 17:42:10.042120: train_loss -0.5538 
2025-07-08 17:42:10.042522: val_loss -0.5296 
2025-07-08 17:42:10.042609: Pseudo dice [np.float32(0.8335)] 
2025-07-08 17:42:10.042719: Epoch time: 47.14 s 
2025-07-08 17:42:11.166913:  
2025-07-08 17:42:11.167466: Epoch 106 
2025-07-08 17:42:11.167647: Current learning rate: 0.00904 
2025-07-08 17:42:58.270705: train_loss -0.5421 
2025-07-08 17:42:58.271176: val_loss -0.5812 
2025-07-08 17:42:58.271265: Pseudo dice [np.float32(0.8484)] 
2025-07-08 17:42:58.271383: Epoch time: 47.1 s 
2025-07-08 17:42:59.469448:  
2025-07-08 17:42:59.469949: Epoch 107 
2025-07-08 17:42:59.470146: Current learning rate: 0.00903 
2025-07-08 17:43:46.170121: train_loss -0.5506 
2025-07-08 17:43:46.170743: val_loss -0.5531 
2025-07-08 17:43:46.170838: Pseudo dice [np.float32(0.8454)] 
2025-07-08 17:43:46.170964: Epoch time: 46.7 s 
2025-07-08 17:43:46.171067: Yayy! New best EMA pseudo Dice: 0.8373000025749207 
2025-07-08 17:43:47.904564:  
2025-07-08 17:43:47.905196: Epoch 108 
2025-07-08 17:43:47.905533: Current learning rate: 0.00902 
2025-07-08 17:44:34.816508: train_loss -0.5476 
2025-07-08 17:44:34.817146: val_loss -0.5483 
2025-07-08 17:44:34.817292: Pseudo dice [np.float32(0.8368)] 
2025-07-08 17:44:34.817450: Epoch time: 46.91 s 
2025-07-08 17:44:35.977346:  
2025-07-08 17:44:35.977817: Epoch 109 
2025-07-08 17:44:35.978011: Current learning rate: 0.00901 
2025-07-08 17:45:24.002310: train_loss -0.5279 
2025-07-08 17:45:24.002941: val_loss -0.5571 
2025-07-08 17:45:24.003030: Pseudo dice [np.float32(0.8215)] 
2025-07-08 17:45:24.003142: Epoch time: 48.03 s 
2025-07-08 17:45:25.145807:  
2025-07-08 17:45:25.146340: Epoch 110 
2025-07-08 17:45:25.146477: Current learning rate: 0.009 
2025-07-08 17:46:12.466802: train_loss -0.5288 
2025-07-08 17:46:12.467340: val_loss -0.5602 
2025-07-08 17:46:12.467438: Pseudo dice [np.float32(0.844)] 
2025-07-08 17:46:12.467567: Epoch time: 47.32 s 
2025-07-08 17:46:13.684194:  
2025-07-08 17:46:13.684601: Epoch 111 
2025-07-08 17:46:13.684780: Current learning rate: 0.009 
2025-07-08 17:47:01.147930: train_loss -0.548 
2025-07-08 17:47:01.148857: val_loss -0.5603 
2025-07-08 17:47:01.148964: Pseudo dice [np.float32(0.8412)] 
2025-07-08 17:47:01.149089: Epoch time: 47.46 s 
2025-07-08 17:47:02.389236:  
2025-07-08 17:47:02.389596: Epoch 112 
2025-07-08 17:47:02.389743: Current learning rate: 0.00899 
2025-07-08 17:47:51.208687: train_loss -0.5274 
2025-07-08 17:47:51.209418: val_loss -0.5543 
2025-07-08 17:47:51.209526: Pseudo dice [np.float32(0.8314)] 
2025-07-08 17:47:51.209646: Epoch time: 48.82 s 
2025-07-08 17:47:52.362282:  
2025-07-08 17:47:52.362446: Epoch 113 
2025-07-08 17:47:52.362584: Current learning rate: 0.00898 
2025-07-08 17:48:40.512718: train_loss -0.5263 
2025-07-08 17:48:40.513086: val_loss -0.5326 
2025-07-08 17:48:40.517003: Pseudo dice [np.float32(0.8322)] 
2025-07-08 17:48:40.517416: Epoch time: 48.15 s 
2025-07-08 17:48:41.723268:  
2025-07-08 17:48:41.723561: Epoch 114 
2025-07-08 17:48:41.723722: Current learning rate: 0.00897 
2025-07-08 17:49:29.930993: train_loss -0.5297 
2025-07-08 17:49:29.931514: val_loss -0.542 
2025-07-08 17:49:29.931612: Pseudo dice [np.float32(0.8518)] 
2025-07-08 17:49:29.931733: Epoch time: 48.21 s 
2025-07-08 17:49:29.931811: Yayy! New best EMA pseudo Dice: 0.8375999927520752 
2025-07-08 17:49:31.624854:  
2025-07-08 17:49:31.625049: Epoch 115 
2025-07-08 17:49:31.625214: Current learning rate: 0.00896 
2025-07-08 17:50:20.673712: train_loss -0.5402 
2025-07-08 17:50:20.674773: val_loss -0.5579 
2025-07-08 17:50:20.674944: Pseudo dice [np.float32(0.8366)] 
2025-07-08 17:50:20.675148: Epoch time: 49.05 s 
2025-07-08 17:50:21.895352:  
2025-07-08 17:50:21.895588: Epoch 116 
2025-07-08 17:50:21.895738: Current learning rate: 0.00895 
2025-07-08 17:51:10.060107: train_loss -0.5352 
2025-07-08 17:51:10.060559: val_loss -0.5601 
2025-07-08 17:51:10.060654: Pseudo dice [np.float32(0.836)] 
2025-07-08 17:51:10.060769: Epoch time: 48.17 s 
2025-07-08 17:51:11.227757:  
2025-07-08 17:51:11.228191: Epoch 117 
2025-07-08 17:51:11.228327: Current learning rate: 0.00894 
2025-07-08 17:51:59.416423: train_loss -0.5512 
2025-07-08 17:51:59.416842: val_loss -0.5678 
2025-07-08 17:51:59.416948: Pseudo dice [np.float32(0.8451)] 
2025-07-08 17:51:59.417066: Epoch time: 48.19 s 
2025-07-08 17:51:59.417286: Yayy! New best EMA pseudo Dice: 0.838100016117096 
2025-07-08 17:52:01.060685:  
2025-07-08 17:52:01.060972: Epoch 118 
2025-07-08 17:52:01.061114: Current learning rate: 0.00893 
2025-07-08 17:52:49.852235: train_loss -0.5465 
2025-07-08 17:52:49.853153: val_loss -0.5575 
2025-07-08 17:52:49.853275: Pseudo dice [np.float32(0.843)] 
2025-07-08 17:52:49.853425: Epoch time: 48.79 s 
2025-07-08 17:52:49.853527: Yayy! New best EMA pseudo Dice: 0.8385999798774719 
2025-07-08 17:52:52.105341:  
2025-07-08 17:52:52.105785: Epoch 119 
2025-07-08 17:52:52.106020: Current learning rate: 0.00892 
2025-07-08 17:53:39.858379: train_loss -0.558 
2025-07-08 17:53:39.858928: val_loss -0.5728 
2025-07-08 17:53:39.859027: Pseudo dice [np.float32(0.8487)] 
2025-07-08 17:53:39.859153: Epoch time: 47.75 s 
2025-07-08 17:53:39.859237: Yayy! New best EMA pseudo Dice: 0.8396000266075134 
2025-07-08 17:53:41.497907:  
2025-07-08 17:53:41.498251: Epoch 120 
2025-07-08 17:53:41.498559: Current learning rate: 0.00891 
2025-07-08 17:54:29.083724: train_loss -0.5403 
2025-07-08 17:54:29.084097: val_loss -0.5612 
2025-07-08 17:54:29.084169: Pseudo dice [np.float32(0.8452)] 
2025-07-08 17:54:29.084266: Epoch time: 47.59 s 
2025-07-08 17:54:29.084340: Yayy! New best EMA pseudo Dice: 0.8402000069618225 
2025-07-08 17:54:30.870585:  
2025-07-08 17:54:30.871006: Epoch 121 
2025-07-08 17:54:30.871185: Current learning rate: 0.0089 
2025-07-08 17:55:18.396668: train_loss -0.5393 
2025-07-08 17:55:18.397000: val_loss -0.5619 
2025-07-08 17:55:18.397081: Pseudo dice [np.float32(0.848)] 
2025-07-08 17:55:18.397183: Epoch time: 47.53 s 
2025-07-08 17:55:18.397388: Yayy! New best EMA pseudo Dice: 0.8409000039100647 
2025-07-08 17:55:19.999960:  
2025-07-08 17:55:20.000414: Epoch 122 
2025-07-08 17:55:20.000642: Current learning rate: 0.00889 
2025-07-08 17:56:08.047789: train_loss -0.5461 
2025-07-08 17:56:08.048256: val_loss -0.5778 
2025-07-08 17:56:08.048466: Pseudo dice [np.float32(0.8461)] 
2025-07-08 17:56:08.048707: Epoch time: 48.05 s 
2025-07-08 17:56:08.048886: Yayy! New best EMA pseudo Dice: 0.8414999842643738 
2025-07-08 17:56:09.705233:  
2025-07-08 17:56:09.705634: Epoch 123 
2025-07-08 17:56:09.705761: Current learning rate: 0.00889 
2025-07-08 17:56:57.627200: train_loss -0.5569 
2025-07-08 17:56:57.627662: val_loss -0.5629 
2025-07-08 17:56:57.627741: Pseudo dice [np.float32(0.8455)] 
2025-07-08 17:56:57.627855: Epoch time: 47.92 s 
2025-07-08 17:56:57.627934: Yayy! New best EMA pseudo Dice: 0.8418999910354614 
2025-07-08 17:56:59.217747:  
2025-07-08 17:56:59.218161: Epoch 124 
2025-07-08 17:56:59.218282: Current learning rate: 0.00888 
2025-07-08 17:57:48.077547: train_loss -0.5542 
2025-07-08 17:57:48.078091: val_loss -0.5572 
2025-07-08 17:57:48.078430: Pseudo dice [np.float32(0.8423)] 
2025-07-08 17:57:48.078696: Epoch time: 48.86 s 
2025-07-08 17:57:48.078900: Yayy! New best EMA pseudo Dice: 0.8418999910354614 
2025-07-08 17:57:49.777305:  
2025-07-08 17:57:49.777522: Epoch 125 
2025-07-08 17:57:49.777670: Current learning rate: 0.00887 
2025-07-08 17:58:37.023442: train_loss -0.559 
2025-07-08 17:58:37.024375: val_loss -0.5868 
2025-07-08 17:58:37.024750: Pseudo dice [np.float32(0.8496)] 
2025-07-08 17:58:37.024937: Epoch time: 47.25 s 
2025-07-08 17:58:37.025051: Yayy! New best EMA pseudo Dice: 0.8427000045776367 
2025-07-08 17:58:38.758071:  
2025-07-08 17:58:38.758430: Epoch 126 
2025-07-08 17:58:38.758567: Current learning rate: 0.00886 
2025-07-08 17:59:26.299186: train_loss -0.5476 
2025-07-08 17:59:26.299737: val_loss -0.542 
2025-07-08 17:59:26.299867: Pseudo dice [np.float32(0.8489)] 
2025-07-08 17:59:26.299966: Epoch time: 47.54 s 
2025-07-08 17:59:26.300047: Yayy! New best EMA pseudo Dice: 0.8432999849319458 
2025-07-08 17:59:27.914531:  
2025-07-08 17:59:27.914938: Epoch 127 
2025-07-08 17:59:27.915148: Current learning rate: 0.00885 
2025-07-08 18:00:14.384454: train_loss -0.5524 
2025-07-08 18:00:14.385011: val_loss -0.5629 
2025-07-08 18:00:14.385094: Pseudo dice [np.float32(0.8401)] 
2025-07-08 18:00:14.385200: Epoch time: 46.47 s 
2025-07-08 18:00:15.557442:  
2025-07-08 18:00:15.558168: Epoch 128 
2025-07-08 18:00:15.558398: Current learning rate: 0.00884 
2025-07-08 18:01:02.578089: train_loss -0.5519 
2025-07-08 18:01:02.578910: val_loss -0.5696 
2025-07-08 18:01:02.579120: Pseudo dice [np.float32(0.857)] 
2025-07-08 18:01:02.579373: Epoch time: 47.02 s 
2025-07-08 18:01:02.579630: Yayy! New best EMA pseudo Dice: 0.8443999886512756 
2025-07-08 18:01:04.297752:  
2025-07-08 18:01:04.298136: Epoch 129 
2025-07-08 18:01:04.298360: Current learning rate: 0.00883 
2025-07-08 18:01:51.609478: train_loss -0.5518 
2025-07-08 18:01:51.610177: val_loss -0.5833 
2025-07-08 18:01:51.610263: Pseudo dice [np.float32(0.8451)] 
2025-07-08 18:01:51.610371: Epoch time: 47.31 s 
2025-07-08 18:01:51.610463: Yayy! New best EMA pseudo Dice: 0.8443999886512756 
2025-07-08 18:01:53.276068:  
2025-07-08 18:01:53.276478: Epoch 130 
2025-07-08 18:01:53.276727: Current learning rate: 0.00882 
2025-07-08 18:02:40.806953: train_loss -0.5644 
2025-07-08 18:02:40.807497: val_loss -0.5637 
2025-07-08 18:02:40.807600: Pseudo dice [np.float32(0.8486)] 
2025-07-08 18:02:40.807705: Epoch time: 47.53 s 
2025-07-08 18:02:40.807786: Yayy! New best EMA pseudo Dice: 0.8449000120162964 
2025-07-08 18:02:42.488593:  
2025-07-08 18:02:42.489213: Epoch 131 
2025-07-08 18:02:42.489670: Current learning rate: 0.00881 
2025-07-08 18:03:29.723877: train_loss -0.5551 
2025-07-08 18:03:29.724844: val_loss -0.5688 
2025-07-08 18:03:29.724940: Pseudo dice [np.float32(0.8475)] 
2025-07-08 18:03:29.725086: Epoch time: 47.24 s 
2025-07-08 18:03:29.725178: Yayy! New best EMA pseudo Dice: 0.8450999855995178 
2025-07-08 18:03:31.461203:  
2025-07-08 18:03:31.461729: Epoch 132 
2025-07-08 18:03:31.461969: Current learning rate: 0.0088 
2025-07-08 18:04:18.454220: train_loss -0.5614 
2025-07-08 18:04:18.454882: val_loss -0.5641 
2025-07-08 18:04:18.454987: Pseudo dice [np.float32(0.8545)] 
2025-07-08 18:04:18.455121: Epoch time: 46.99 s 
2025-07-08 18:04:18.455218: Yayy! New best EMA pseudo Dice: 0.8460999727249146 
2025-07-08 18:04:21.028857:  
2025-07-08 18:04:21.029291: Epoch 133 
2025-07-08 18:04:21.029558: Current learning rate: 0.00879 
2025-07-08 18:05:08.331975: train_loss -0.5534 
2025-07-08 18:05:08.332406: val_loss -0.557 
2025-07-08 18:05:08.332564: Pseudo dice [np.float32(0.8566)] 
2025-07-08 18:05:08.332678: Epoch time: 47.3 s 
2025-07-08 18:05:08.332762: Yayy! New best EMA pseudo Dice: 0.847100019454956 
2025-07-08 18:05:09.948400:  
2025-07-08 18:05:09.948823: Epoch 134 
2025-07-08 18:05:09.949075: Current learning rate: 0.00879 
2025-07-08 18:05:57.873627: train_loss -0.5598 
2025-07-08 18:05:57.874398: val_loss -0.5948 
2025-07-08 18:05:57.874496: Pseudo dice [np.float32(0.857)] 
2025-07-08 18:05:57.874634: Epoch time: 47.93 s 
2025-07-08 18:05:57.874714: Yayy! New best EMA pseudo Dice: 0.8481000065803528 
2025-07-08 18:05:59.523299:  
2025-07-08 18:05:59.523640: Epoch 135 
2025-07-08 18:05:59.523943: Current learning rate: 0.00878 
2025-07-08 18:06:46.799139: train_loss -0.563 
2025-07-08 18:06:46.799645: val_loss -0.5553 
2025-07-08 18:06:46.799730: Pseudo dice [np.float32(0.8425)] 
2025-07-08 18:06:46.799833: Epoch time: 47.28 s 
2025-07-08 18:06:48.009703:  
2025-07-08 18:06:48.010158: Epoch 136 
2025-07-08 18:06:48.010289: Current learning rate: 0.00877 
2025-07-08 18:07:34.317467: train_loss -0.5424 
2025-07-08 18:07:34.317840: val_loss -0.549 
2025-07-08 18:07:34.317922: Pseudo dice [np.float32(0.8407)] 
2025-07-08 18:07:34.318019: Epoch time: 46.31 s 
2025-07-08 18:07:35.502972:  
2025-07-08 18:07:35.503517: Epoch 137 
2025-07-08 18:07:35.503667: Current learning rate: 0.00876 
2025-07-08 18:08:23.021527: train_loss -0.5503 
2025-07-08 18:08:23.021945: val_loss -0.5793 
2025-07-08 18:08:23.022030: Pseudo dice [np.float32(0.8537)] 
2025-07-08 18:08:23.022150: Epoch time: 47.52 s 
2025-07-08 18:08:24.367367:  
2025-07-08 18:08:24.367642: Epoch 138 
2025-07-08 18:08:24.367767: Current learning rate: 0.00875 
2025-07-08 18:09:11.937758: train_loss -0.5572 
2025-07-08 18:09:11.938339: val_loss -0.557 
2025-07-08 18:09:11.938428: Pseudo dice [np.float32(0.8525)] 
2025-07-08 18:09:11.938554: Epoch time: 47.57 s 
2025-07-08 18:09:13.140860:  
2025-07-08 18:09:13.141501: Epoch 139 
2025-07-08 18:09:13.141650: Current learning rate: 0.00874 
2025-07-08 18:09:59.194951: train_loss -0.5718 
2025-07-08 18:09:59.195275: val_loss -0.5905 
2025-07-08 18:09:59.195352: Pseudo dice [np.float32(0.8566)] 
2025-07-08 18:09:59.195453: Epoch time: 46.06 s 
2025-07-08 18:09:59.195592: Yayy! New best EMA pseudo Dice: 0.8489000201225281 
2025-07-08 18:10:00.873522:  
2025-07-08 18:10:00.873892: Epoch 140 
2025-07-08 18:10:00.874100: Current learning rate: 0.00873 
2025-07-08 18:10:47.575154: train_loss -0.5586 
2025-07-08 18:10:47.575628: val_loss -0.5549 
2025-07-08 18:10:47.575709: Pseudo dice [np.float32(0.8491)] 
2025-07-08 18:10:47.575812: Epoch time: 46.7 s 
2025-07-08 18:10:47.575886: Yayy! New best EMA pseudo Dice: 0.8489000201225281 
2025-07-08 18:10:49.278244:  
2025-07-08 18:10:49.278718: Epoch 141 
2025-07-08 18:10:49.278973: Current learning rate: 0.00872 
2025-07-08 18:11:35.655831: train_loss -0.5534 
2025-07-08 18:11:35.656308: val_loss -0.5535 
2025-07-08 18:11:35.656388: Pseudo dice [np.float32(0.8423)] 
2025-07-08 18:11:35.656496: Epoch time: 46.38 s 
2025-07-08 18:11:36.827713:  
2025-07-08 18:11:36.828199: Epoch 142 
2025-07-08 18:11:36.828513: Current learning rate: 0.00871 
2025-07-08 18:12:22.601838: train_loss -0.5366 
2025-07-08 18:12:22.602223: val_loss -0.5646 
2025-07-08 18:12:22.602306: Pseudo dice [np.float32(0.8469)] 
2025-07-08 18:12:22.602409: Epoch time: 45.78 s 
2025-07-08 18:12:23.780076:  
2025-07-08 18:12:23.780365: Epoch 143 
2025-07-08 18:12:23.780667: Current learning rate: 0.0087 
2025-07-08 18:13:09.701339: train_loss -0.5408 
2025-07-08 18:13:09.701950: val_loss -0.5484 
2025-07-08 18:13:09.702041: Pseudo dice [np.float32(0.8415)] 
2025-07-08 18:13:09.702151: Epoch time: 45.92 s 
2025-07-08 18:13:10.897282:  
2025-07-08 18:13:10.897516: Epoch 144 
2025-07-08 18:13:10.897654: Current learning rate: 0.00869 
2025-07-08 18:13:57.783041: train_loss -0.5424 
2025-07-08 18:13:57.783519: val_loss -0.5715 
2025-07-08 18:13:57.784971: Pseudo dice [np.float32(0.8481)] 
2025-07-08 18:13:57.785113: Epoch time: 46.89 s 
2025-07-08 18:13:58.993306:  
2025-07-08 18:13:58.994043: Epoch 145 
2025-07-08 18:13:58.994303: Current learning rate: 0.00868 
2025-07-08 18:14:46.439750: train_loss -0.5581 
2025-07-08 18:14:46.440231: val_loss -0.5745 
2025-07-08 18:14:46.440381: Pseudo dice [np.float32(0.848)] 
2025-07-08 18:14:46.440528: Epoch time: 47.45 s 
2025-07-08 18:14:47.661303:  
2025-07-08 18:14:47.661758: Epoch 146 
2025-07-08 18:14:47.662050: Current learning rate: 0.00868 
2025-07-08 18:15:34.952593: train_loss -0.5517 
2025-07-08 18:15:34.953398: val_loss -0.5415 
2025-07-08 18:15:34.953494: Pseudo dice [np.float32(0.8494)] 
2025-07-08 18:15:34.953660: Epoch time: 47.29 s 
2025-07-08 18:15:36.853270:  
2025-07-08 18:15:36.853881: Epoch 147 
2025-07-08 18:15:36.854281: Current learning rate: 0.00867 
2025-07-08 18:16:23.459259: train_loss -0.5636 
2025-07-08 18:16:23.460337: val_loss -0.5686 
2025-07-08 18:16:23.460509: Pseudo dice [np.float32(0.8424)] 
2025-07-08 18:16:23.460806: Epoch time: 46.61 s 
2025-07-08 18:16:24.675445:  
2025-07-08 18:16:24.675624: Epoch 148 
2025-07-08 18:16:24.675762: Current learning rate: 0.00866 
2025-07-08 18:17:11.311257: train_loss -0.552 
2025-07-08 18:17:11.312034: val_loss -0.5611 
2025-07-08 18:17:11.312128: Pseudo dice [np.float32(0.8404)] 
2025-07-08 18:17:11.312245: Epoch time: 46.64 s 
2025-07-08 18:17:12.509620:  
2025-07-08 18:17:12.509904: Epoch 149 
2025-07-08 18:17:12.510020: Current learning rate: 0.00865 
2025-07-08 18:17:58.548064: train_loss -0.5523 
2025-07-08 18:17:58.548564: val_loss -0.5691 
2025-07-08 18:17:58.548650: Pseudo dice [np.float32(0.8456)] 
2025-07-08 18:17:58.548759: Epoch time: 46.04 s 
2025-07-08 18:18:00.260021:  
2025-07-08 18:18:00.260219: Epoch 150 
2025-07-08 18:18:00.260341: Current learning rate: 0.00864 
2025-07-08 18:18:46.902829: train_loss -0.5571 
2025-07-08 18:18:46.903377: val_loss -0.5723 
2025-07-08 18:18:46.903472: Pseudo dice [np.float32(0.8539)] 
2025-07-08 18:18:46.903612: Epoch time: 46.64 s 
2025-07-08 18:18:48.183332:  
2025-07-08 18:18:48.183765: Epoch 151 
2025-07-08 18:18:48.183900: Current learning rate: 0.00863 
2025-07-08 18:19:34.743612: train_loss -0.5494 
2025-07-08 18:19:34.744139: val_loss -0.5623 
2025-07-08 18:19:34.744287: Pseudo dice [np.float32(0.8519)] 
2025-07-08 18:19:34.744469: Epoch time: 46.56 s 
2025-07-08 18:19:35.964461:  
2025-07-08 18:19:35.964847: Epoch 152 
2025-07-08 18:19:35.965045: Current learning rate: 0.00862 
2025-07-08 18:20:23.141954: train_loss -0.5505 
2025-07-08 18:20:23.142552: val_loss -0.5561 
2025-07-08 18:20:23.142643: Pseudo dice [np.float32(0.8604)] 
2025-07-08 18:20:23.142771: Epoch time: 47.18 s 
2025-07-08 18:20:23.142856: Yayy! New best EMA pseudo Dice: 0.8489000201225281 
2025-07-08 18:20:24.867082:  
2025-07-08 18:20:24.867477: Epoch 153 
2025-07-08 18:20:24.867864: Current learning rate: 0.00861 
2025-07-08 18:21:11.761087: train_loss -0.5603 
2025-07-08 18:21:11.761940: val_loss -0.5552 
2025-07-08 18:21:11.765822: Pseudo dice [np.float32(0.843)] 
2025-07-08 18:21:11.766204: Epoch time: 46.9 s 
2025-07-08 18:21:12.998286:  
2025-07-08 18:21:12.998479: Epoch 154 
2025-07-08 18:21:12.998621: Current learning rate: 0.0086 
2025-07-08 18:21:59.793015: train_loss -0.5518 
2025-07-08 18:21:59.793705: val_loss -0.561 
2025-07-08 18:21:59.793788: Pseudo dice [np.float32(0.8482)] 
2025-07-08 18:21:59.793933: Epoch time: 46.8 s 
2025-07-08 18:22:00.977487:  
2025-07-08 18:22:00.977894: Epoch 155 
2025-07-08 18:22:00.978016: Current learning rate: 0.00859 
2025-07-08 18:22:47.806982: train_loss -0.5517 
2025-07-08 18:22:47.807435: val_loss -0.5491 
2025-07-08 18:22:47.807516: Pseudo dice [np.float32(0.8439)] 
2025-07-08 18:22:47.807629: Epoch time: 46.83 s 
2025-07-08 18:22:49.052531:  
2025-07-08 18:22:49.053104: Epoch 156 
2025-07-08 18:22:49.053305: Current learning rate: 0.00858 
2025-07-08 18:23:34.638095: train_loss -0.5592 
2025-07-08 18:23:34.638836: val_loss -0.569 
2025-07-08 18:23:34.638926: Pseudo dice [np.float32(0.856)] 
2025-07-08 18:23:34.639042: Epoch time: 45.59 s 
2025-07-08 18:23:35.860848:  
2025-07-08 18:23:35.861400: Epoch 157 
2025-07-08 18:23:35.861586: Current learning rate: 0.00858 
2025-07-08 18:24:22.228243: train_loss -0.5546 
2025-07-08 18:24:22.228966: val_loss -0.5619 
2025-07-08 18:24:22.229054: Pseudo dice [np.float32(0.8621)] 
2025-07-08 18:24:22.229154: Epoch time: 46.37 s 
2025-07-08 18:24:22.229271: Yayy! New best EMA pseudo Dice: 0.8500000238418579 
2025-07-08 18:24:23.879321:  
2025-07-08 18:24:23.879531: Epoch 158 
2025-07-08 18:24:23.879813: Current learning rate: 0.00857 
2025-07-08 18:25:09.526163: train_loss -0.5638 
2025-07-08 18:25:09.527617: val_loss -0.5615 
2025-07-08 18:25:09.531062: Pseudo dice [np.float32(0.8481)] 
2025-07-08 18:25:09.531288: Epoch time: 45.65 s 
2025-07-08 18:25:10.773835:  
2025-07-08 18:25:10.774019: Epoch 159 
2025-07-08 18:25:10.774132: Current learning rate: 0.00856 
2025-07-08 18:25:57.171465: train_loss -0.5467 
2025-07-08 18:25:57.172173: val_loss -0.5928 
2025-07-08 18:25:57.172319: Pseudo dice [np.float32(0.8507)] 
2025-07-08 18:25:57.172426: Epoch time: 46.4 s 
2025-07-08 18:25:59.273676:  
2025-07-08 18:25:59.274060: Epoch 160 
2025-07-08 18:25:59.274180: Current learning rate: 0.00855 
2025-07-08 18:26:45.736181: train_loss -0.5616 
2025-07-08 18:26:45.736528: val_loss -0.5625 
2025-07-08 18:26:45.736618: Pseudo dice [np.float32(0.8533)] 
2025-07-08 18:26:45.736722: Epoch time: 46.46 s 
2025-07-08 18:26:45.736799: Yayy! New best EMA pseudo Dice: 0.8503000140190125 
2025-07-08 18:26:47.417310:  
2025-07-08 18:26:47.417699: Epoch 161 
2025-07-08 18:26:47.417855: Current learning rate: 0.00854 
2025-07-08 18:27:33.525584: train_loss -0.5645 
2025-07-08 18:27:33.526165: val_loss -0.5798 
2025-07-08 18:27:33.526248: Pseudo dice [np.float32(0.8505)] 
2025-07-08 18:27:33.526354: Epoch time: 46.11 s 
2025-07-08 18:27:33.526436: Yayy! New best EMA pseudo Dice: 0.8503000140190125 
2025-07-08 18:27:35.243412:  
2025-07-08 18:27:35.243959: Epoch 162 
2025-07-08 18:27:35.244215: Current learning rate: 0.00853 
2025-07-08 18:28:21.702620: train_loss -0.5626 
2025-07-08 18:28:21.702937: val_loss -0.5396 
2025-07-08 18:28:21.703015: Pseudo dice [np.float32(0.838)] 
2025-07-08 18:28:21.703113: Epoch time: 46.46 s 
2025-07-08 18:28:22.909529:  
2025-07-08 18:28:22.910104: Epoch 163 
2025-07-08 18:28:22.910283: Current learning rate: 0.00852 
2025-07-08 18:29:09.754527: train_loss -0.5546 
2025-07-08 18:29:09.755249: val_loss -0.5714 
2025-07-08 18:29:09.755348: Pseudo dice [np.float32(0.8466)] 
2025-07-08 18:29:09.755487: Epoch time: 46.85 s 
2025-07-08 18:29:10.906206:  
2025-07-08 18:29:10.906397: Epoch 164 
2025-07-08 18:29:10.906621: Current learning rate: 0.00851 
2025-07-08 18:29:57.965093: train_loss -0.5531 
2025-07-08 18:29:57.965425: val_loss -0.5815 
2025-07-08 18:29:57.965506: Pseudo dice [np.float32(0.8496)] 
2025-07-08 18:29:57.965629: Epoch time: 47.06 s 
2025-07-08 18:29:59.133456:  
2025-07-08 18:29:59.133804: Epoch 165 
2025-07-08 18:29:59.133902: Current learning rate: 0.0085 
2025-07-08 18:30:47.130007: train_loss -0.5612 
2025-07-08 18:30:47.130347: val_loss -0.5864 
2025-07-08 18:30:47.130454: Pseudo dice [np.float32(0.8553)] 
2025-07-08 18:30:47.130564: Epoch time: 48.0 s 
2025-07-08 18:30:48.335419:  
2025-07-08 18:30:48.335603: Epoch 166 
2025-07-08 18:30:48.335711: Current learning rate: 0.00849 
2025-07-08 18:31:35.300839: train_loss -0.5544 
2025-07-08 18:31:35.301336: val_loss -0.5405 
2025-07-08 18:31:35.301422: Pseudo dice [np.float32(0.8467)] 
2025-07-08 18:31:35.301529: Epoch time: 46.97 s 
2025-07-08 18:31:36.460676:  
2025-07-08 18:31:36.460908: Epoch 167 
2025-07-08 18:31:36.461009: Current learning rate: 0.00848 
2025-07-08 18:32:23.641385: train_loss -0.5553 
2025-07-08 18:32:23.642090: val_loss -0.571 
2025-07-08 18:32:23.645965: Pseudo dice [np.float32(0.8457)] 
2025-07-08 18:32:23.646343: Epoch time: 47.18 s 
2025-07-08 18:32:24.942968:  
2025-07-08 18:32:24.943183: Epoch 168 
2025-07-08 18:32:24.943425: Current learning rate: 0.00847 
2025-07-08 18:33:12.749943: train_loss -0.5552 
2025-07-08 18:33:12.750279: val_loss -0.5805 
2025-07-08 18:33:12.750354: Pseudo dice [np.float32(0.8527)] 
2025-07-08 18:33:12.750446: Epoch time: 47.81 s 
2025-07-08 18:33:13.951458:  
2025-07-08 18:33:13.951729: Epoch 169 
2025-07-08 18:33:13.951904: Current learning rate: 0.00847 
2025-07-08 18:34:01.310611: train_loss -0.559 
2025-07-08 18:34:01.311161: val_loss -0.6087 
2025-07-08 18:34:01.311257: Pseudo dice [np.float32(0.8574)] 
2025-07-08 18:34:01.311374: Epoch time: 47.36 s 
2025-07-08 18:34:02.466264:  
2025-07-08 18:34:02.466525: Epoch 170 
2025-07-08 18:34:02.466739: Current learning rate: 0.00846 
2025-07-08 18:34:48.459786: train_loss -0.5571 
2025-07-08 18:34:48.460267: val_loss -0.5767 
2025-07-08 18:34:48.460370: Pseudo dice [np.float32(0.8519)] 
2025-07-08 18:34:48.460499: Epoch time: 45.99 s 
2025-07-08 18:34:49.649009:  
2025-07-08 18:34:49.649576: Epoch 171 
2025-07-08 18:34:49.649776: Current learning rate: 0.00845 
2025-07-08 18:35:35.699887: train_loss -0.5744 
2025-07-08 18:35:35.700500: val_loss -0.5882 
2025-07-08 18:35:35.700706: Pseudo dice [np.float32(0.8572)] 
2025-07-08 18:35:35.700831: Epoch time: 46.05 s 
2025-07-08 18:35:35.700920: Yayy! New best EMA pseudo Dice: 0.8510000109672546 
2025-07-08 18:35:37.480097:  
2025-07-08 18:35:37.480596: Epoch 172 
2025-07-08 18:35:37.480736: Current learning rate: 0.00844 
2025-07-08 18:36:24.574492: train_loss -0.5703 
2025-07-08 18:36:24.574942: val_loss -0.5736 
2025-07-08 18:36:24.578395: Pseudo dice [np.float32(0.8579)] 
2025-07-08 18:36:24.578530: Epoch time: 47.1 s 
2025-07-08 18:36:24.578639: Yayy! New best EMA pseudo Dice: 0.8517000079154968 
2025-07-08 18:36:26.255943:  
2025-07-08 18:36:26.256117: Epoch 173 
2025-07-08 18:36:26.256401: Current learning rate: 0.00843 
2025-07-08 18:37:12.062960: train_loss -0.5579 
2025-07-08 18:37:12.064337: val_loss -0.572 
2025-07-08 18:37:12.064497: Pseudo dice [np.float32(0.8545)] 
2025-07-08 18:37:12.064705: Epoch time: 45.81 s 
2025-07-08 18:37:12.064821: Yayy! New best EMA pseudo Dice: 0.8518999814987183 
2025-07-08 18:37:14.737062:  
2025-07-08 18:37:14.737417: Epoch 174 
2025-07-08 18:37:14.737573: Current learning rate: 0.00842 
2025-07-08 18:38:00.948998: train_loss -0.5585 
2025-07-08 18:38:00.949673: val_loss -0.5488 
2025-07-08 18:38:00.949775: Pseudo dice [np.float32(0.8484)] 
2025-07-08 18:38:00.949902: Epoch time: 46.21 s 
2025-07-08 18:38:02.160116:  
2025-07-08 18:38:02.160303: Epoch 175 
2025-07-08 18:38:02.160405: Current learning rate: 0.00841 
2025-07-08 18:38:47.938532: train_loss -0.5605 
2025-07-08 18:38:47.939236: val_loss -0.5818 
2025-07-08 18:38:47.939335: Pseudo dice [np.float32(0.8645)] 
2025-07-08 18:38:47.939455: Epoch time: 45.78 s 
2025-07-08 18:38:47.939537: Yayy! New best EMA pseudo Dice: 0.8529000282287598 
2025-07-08 18:38:49.559502:  
2025-07-08 18:38:49.560115: Epoch 176 
2025-07-08 18:38:49.560451: Current learning rate: 0.0084 
2025-07-08 18:39:35.400009: train_loss -0.5538 
2025-07-08 18:39:35.401957: val_loss -0.5749 
2025-07-08 18:39:35.402282: Pseudo dice [np.float32(0.8409)] 
2025-07-08 18:39:35.402671: Epoch time: 45.84 s 
2025-07-08 18:39:36.649195:  
2025-07-08 18:39:36.649565: Epoch 177 
2025-07-08 18:39:36.649701: Current learning rate: 0.00839 
2025-07-08 18:40:22.237957: train_loss -0.5497 
2025-07-08 18:40:22.238607: val_loss -0.5911 
2025-07-08 18:40:22.238722: Pseudo dice [np.float32(0.8492)] 
2025-07-08 18:40:22.238864: Epoch time: 45.59 s 
2025-07-08 18:40:23.522625:  
2025-07-08 18:40:23.523054: Epoch 178 
2025-07-08 18:40:23.523322: Current learning rate: 0.00838 
2025-07-08 18:41:09.174095: train_loss -0.5533 
2025-07-08 18:41:09.175262: val_loss -0.5633 
2025-07-08 18:41:09.175503: Pseudo dice [np.float32(0.8606)] 
2025-07-08 18:41:09.175959: Epoch time: 45.65 s 
2025-07-08 18:41:10.425779:  
2025-07-08 18:41:10.426211: Epoch 179 
2025-07-08 18:41:10.426427: Current learning rate: 0.00837 
2025-07-08 18:41:56.839559: train_loss -0.565 
2025-07-08 18:41:56.840023: val_loss -0.5912 
2025-07-08 18:41:56.840106: Pseudo dice [np.float32(0.8517)] 
2025-07-08 18:41:56.840224: Epoch time: 46.42 s 
2025-07-08 18:41:58.136828:  
2025-07-08 18:41:58.137230: Epoch 180 
2025-07-08 18:41:58.137465: Current learning rate: 0.00836 
2025-07-08 18:42:45.090802: train_loss -0.562 
2025-07-08 18:42:45.091143: val_loss -0.5889 
2025-07-08 18:42:45.091231: Pseudo dice [np.float32(0.8582)] 
2025-07-08 18:42:45.091339: Epoch time: 46.95 s 
2025-07-08 18:42:46.250263:  
2025-07-08 18:42:46.250627: Epoch 181 
2025-07-08 18:42:46.250767: Current learning rate: 0.00836 
2025-07-08 18:43:32.838928: train_loss -0.5556 
2025-07-08 18:43:32.839354: val_loss -0.5562 
2025-07-08 18:43:32.839586: Pseudo dice [np.float32(0.8464)] 
2025-07-08 18:43:32.839770: Epoch time: 46.59 s 
2025-07-08 18:43:34.014844:  
2025-07-08 18:43:34.015124: Epoch 182 
2025-07-08 18:43:34.015305: Current learning rate: 0.00835 
2025-07-08 18:44:20.452853: train_loss -0.5618 
2025-07-08 18:44:20.453725: val_loss -0.5697 
2025-07-08 18:44:20.453852: Pseudo dice [np.float32(0.8607)] 
2025-07-08 18:44:20.453985: Epoch time: 46.44 s 
2025-07-08 18:44:20.454081: Yayy! New best EMA pseudo Dice: 0.8531000018119812 
2025-07-08 18:44:22.130404:  
2025-07-08 18:44:22.131042: Epoch 183 
2025-07-08 18:44:22.131292: Current learning rate: 0.00834 
2025-07-08 18:45:08.321597: train_loss -0.5674 
2025-07-08 18:45:08.322532: val_loss -0.5978 
2025-07-08 18:45:08.322679: Pseudo dice [np.float32(0.8542)] 
2025-07-08 18:45:08.322818: Epoch time: 46.19 s 
2025-07-08 18:45:08.322928: Yayy! New best EMA pseudo Dice: 0.8532000184059143 
2025-07-08 18:45:10.104285:  
2025-07-08 18:45:10.104558: Epoch 184 
2025-07-08 18:45:10.104721: Current learning rate: 0.00833 
2025-07-08 18:45:55.866517: train_loss -0.5515 
2025-07-08 18:45:55.867321: val_loss -0.5715 
2025-07-08 18:45:55.867460: Pseudo dice [np.float32(0.8476)] 
2025-07-08 18:45:55.867664: Epoch time: 45.76 s 
2025-07-08 18:45:57.099457:  
2025-07-08 18:45:57.099774: Epoch 185 
2025-07-08 18:45:57.100035: Current learning rate: 0.00832 
2025-07-08 18:46:43.938002: train_loss -0.5616 
2025-07-08 18:46:43.938567: val_loss -0.5617 
2025-07-08 18:46:43.938674: Pseudo dice [np.float32(0.8507)] 
2025-07-08 18:46:43.938804: Epoch time: 46.84 s 
2025-07-08 18:46:45.102026:  
2025-07-08 18:46:45.102281: Epoch 186 
2025-07-08 18:46:45.102401: Current learning rate: 0.00831 
2025-07-08 18:47:31.818742: train_loss -0.5444 
2025-07-08 18:47:31.819087: val_loss -0.5567 
2025-07-08 18:47:31.819165: Pseudo dice [np.float32(0.8442)] 
2025-07-08 18:47:31.819359: Epoch time: 46.72 s 
2025-07-08 18:47:34.040995:  
2025-07-08 18:47:34.041441: Epoch 187 
2025-07-08 18:47:34.041676: Current learning rate: 0.0083 
2025-07-08 18:48:20.344825: train_loss -0.5515 
2025-07-08 18:48:20.345569: val_loss -0.5685 
2025-07-08 18:48:20.345752: Pseudo dice [np.float32(0.8434)] 
2025-07-08 18:48:20.345901: Epoch time: 46.3 s 
2025-07-08 18:48:21.624230:  
2025-07-08 18:48:21.624681: Epoch 188 
2025-07-08 18:48:21.624816: Current learning rate: 0.00829 
2025-07-08 18:49:07.607855: train_loss -0.5579 
2025-07-08 18:49:07.608171: val_loss -0.5641 
2025-07-08 18:49:07.608244: Pseudo dice [np.float32(0.8398)] 
2025-07-08 18:49:07.608340: Epoch time: 45.98 s 
2025-07-08 18:49:08.754171:  
2025-07-08 18:49:08.754463: Epoch 189 
2025-07-08 18:49:08.754606: Current learning rate: 0.00828 
2025-07-08 18:49:56.286623: train_loss -0.5476 
2025-07-08 18:49:56.287401: val_loss -0.5887 
2025-07-08 18:49:56.287523: Pseudo dice [np.float32(0.8515)] 
2025-07-08 18:49:56.287696: Epoch time: 47.53 s 
2025-07-08 18:49:57.602647:  
2025-07-08 18:49:57.602974: Epoch 190 
2025-07-08 18:49:57.603276: Current learning rate: 0.00827 
2025-07-08 18:50:44.106882: train_loss -0.5565 
2025-07-08 18:50:44.107417: val_loss -0.5655 
2025-07-08 18:50:44.107501: Pseudo dice [np.float32(0.8461)] 
2025-07-08 18:50:44.107622: Epoch time: 46.51 s 
2025-07-08 18:50:45.349274:  
2025-07-08 18:50:45.349630: Epoch 191 
2025-07-08 18:50:45.349982: Current learning rate: 0.00826 
2025-07-08 18:51:32.054077: train_loss -0.5526 
2025-07-08 18:51:32.055008: val_loss -0.5742 
2025-07-08 18:51:32.055133: Pseudo dice [np.float32(0.8554)] 
2025-07-08 18:51:32.055307: Epoch time: 46.71 s 
2025-07-08 18:51:33.355808:  
2025-07-08 18:51:33.356219: Epoch 192 
2025-07-08 18:51:33.356387: Current learning rate: 0.00825 
2025-07-08 18:52:20.786989: train_loss -0.5512 
2025-07-08 18:52:20.787481: val_loss -0.5554 
2025-07-08 18:52:20.787589: Pseudo dice [np.float32(0.863)] 
2025-07-08 18:52:20.787712: Epoch time: 47.43 s 
2025-07-08 18:52:22.016406:  
2025-07-08 18:52:22.016958: Epoch 193 
2025-07-08 18:52:22.017337: Current learning rate: 0.00824 
2025-07-08 18:53:09.664422: train_loss -0.5489 
2025-07-08 18:53:09.665935: val_loss -0.566 
2025-07-08 18:53:09.666184: Pseudo dice [np.float32(0.8517)] 
2025-07-08 18:53:09.666478: Epoch time: 47.65 s 
2025-07-08 18:53:10.875491:  
2025-07-08 18:53:10.875863: Epoch 194 
2025-07-08 18:53:10.876019: Current learning rate: 0.00824 
2025-07-08 18:53:57.060912: train_loss -0.5669 
2025-07-08 18:53:57.061273: val_loss -0.565 
2025-07-08 18:53:57.061353: Pseudo dice [np.float32(0.8547)] 
2025-07-08 18:53:57.061456: Epoch time: 46.19 s 
2025-07-08 18:53:58.310664:  
2025-07-08 18:53:58.310821: Epoch 195 
2025-07-08 18:53:58.310932: Current learning rate: 0.00823 
2025-07-08 18:54:45.514585: train_loss -0.5646 
2025-07-08 18:54:45.515564: val_loss -0.5949 
2025-07-08 18:54:45.515716: Pseudo dice [np.float32(0.8742)] 
2025-07-08 18:54:45.515897: Epoch time: 47.2 s 
2025-07-08 18:54:45.516003: Yayy! New best EMA pseudo Dice: 0.8539999723434448 
2025-07-08 18:54:47.194154:  
2025-07-08 18:54:47.194632: Epoch 196 
2025-07-08 18:54:47.194827: Current learning rate: 0.00822 
2025-07-08 18:55:33.810479: train_loss -0.5529 
2025-07-08 18:55:33.811031: val_loss -0.5822 
2025-07-08 18:55:33.811118: Pseudo dice [np.float32(0.8679)] 
2025-07-08 18:55:33.811223: Epoch time: 46.62 s 
2025-07-08 18:55:33.811304: Yayy! New best EMA pseudo Dice: 0.855400025844574 
2025-07-08 18:55:35.497998:  
2025-07-08 18:55:35.498576: Epoch 197 
2025-07-08 18:55:35.498747: Current learning rate: 0.00821 
2025-07-08 18:56:23.251754: train_loss -0.5515 
2025-07-08 18:56:23.252386: val_loss -0.5629 
2025-07-08 18:56:23.252496: Pseudo dice [np.float32(0.8611)] 
2025-07-08 18:56:23.252625: Epoch time: 47.75 s 
2025-07-08 18:56:23.252705: Yayy! New best EMA pseudo Dice: 0.8560000061988831 
2025-07-08 18:56:24.967495:  
2025-07-08 18:56:24.967723: Epoch 198 
2025-07-08 18:56:24.967955: Current learning rate: 0.0082 
2025-07-08 18:57:12.623585: train_loss -0.5535 
2025-07-08 18:57:12.624233: val_loss -0.552 
2025-07-08 18:57:12.624323: Pseudo dice [np.float32(0.8525)] 
2025-07-08 18:57:12.624427: Epoch time: 47.66 s 
2025-07-08 18:57:13.814215:  
2025-07-08 18:57:13.814659: Epoch 199 
2025-07-08 18:57:13.814874: Current learning rate: 0.00819 
2025-07-08 18:58:01.029986: train_loss -0.5515 
2025-07-08 18:58:01.030511: val_loss -0.5426 
2025-07-08 18:58:01.030696: Pseudo dice [np.float32(0.8442)] 
2025-07-08 18:58:01.030804: Epoch time: 47.22 s 
2025-07-08 18:58:03.530085:  
2025-07-08 18:58:03.530511: Epoch 200 
2025-07-08 18:58:03.530657: Current learning rate: 0.00818 
2025-07-08 18:58:50.941234: train_loss -0.5538 
2025-07-08 18:58:50.941992: val_loss -0.5668 
2025-07-08 18:58:50.942102: Pseudo dice [np.float32(0.8452)] 
2025-07-08 18:58:50.942230: Epoch time: 47.41 s 
2025-07-08 18:58:52.201307:  
2025-07-08 18:58:52.201765: Epoch 201 
2025-07-08 18:58:52.201937: Current learning rate: 0.00817 
2025-07-08 18:59:38.209838: train_loss -0.5551 
2025-07-08 18:59:38.210226: val_loss -0.5461 
2025-07-08 18:59:38.210308: Pseudo dice [np.float32(0.8623)] 
2025-07-08 18:59:38.210514: Epoch time: 46.01 s 
2025-07-08 18:59:39.456129:  
2025-07-08 18:59:39.456577: Epoch 202 
2025-07-08 18:59:39.456831: Current learning rate: 0.00816 
2025-07-08 19:00:27.022302: train_loss -0.561 
2025-07-08 19:00:27.022847: val_loss -0.5776 
2025-07-08 19:00:27.022928: Pseudo dice [np.float32(0.8562)] 
2025-07-08 19:00:27.023039: Epoch time: 47.57 s 
2025-07-08 19:00:28.197398:  
2025-07-08 19:00:28.197862: Epoch 203 
2025-07-08 19:00:28.197991: Current learning rate: 0.00815 
2025-07-08 19:01:15.092499: train_loss -0.5771 
2025-07-08 19:01:15.093204: val_loss -0.5895 
2025-07-08 19:01:15.093305: Pseudo dice [np.float32(0.8624)] 
2025-07-08 19:01:15.093409: Epoch time: 46.9 s 
2025-07-08 19:01:16.274551:  
2025-07-08 19:01:16.274813: Epoch 204 
2025-07-08 19:01:16.275054: Current learning rate: 0.00814 
2025-07-08 19:02:03.714363: train_loss -0.5706 
2025-07-08 19:02:03.714992: val_loss -0.5759 
2025-07-08 19:02:03.715102: Pseudo dice [np.float32(0.8549)] 
2025-07-08 19:02:03.715236: Epoch time: 47.44 s 
2025-07-08 19:02:05.021875:  
2025-07-08 19:02:05.022412: Epoch 205 
2025-07-08 19:02:05.022557: Current learning rate: 0.00813 
2025-07-08 19:02:51.258866: train_loss -0.5604 
2025-07-08 19:02:51.259429: val_loss -0.5448 
2025-07-08 19:02:51.259514: Pseudo dice [np.float32(0.8557)] 
2025-07-08 19:02:51.259655: Epoch time: 46.24 s 
2025-07-08 19:02:52.441722:  
2025-07-08 19:02:52.442136: Epoch 206 
2025-07-08 19:02:52.442399: Current learning rate: 0.00813 
2025-07-08 19:03:38.718897: train_loss -0.5469 
2025-07-08 19:03:38.719333: val_loss -0.5379 
2025-07-08 19:03:38.719414: Pseudo dice [np.float32(0.8403)] 
2025-07-08 19:03:38.719522: Epoch time: 46.28 s 
2025-07-08 19:03:39.912672:  
2025-07-08 19:03:39.913208: Epoch 207 
2025-07-08 19:03:39.913342: Current learning rate: 0.00812 
2025-07-08 19:04:27.109067: train_loss -0.5493 
2025-07-08 19:04:27.109638: val_loss -0.5642 
2025-07-08 19:04:27.109736: Pseudo dice [np.float32(0.8467)] 
2025-07-08 19:04:27.109861: Epoch time: 47.2 s 
2025-07-08 19:04:28.251647:  
2025-07-08 19:04:28.251839: Epoch 208 
2025-07-08 19:04:28.252137: Current learning rate: 0.00811 
2025-07-08 19:05:15.336001: train_loss -0.5508 
2025-07-08 19:05:15.336330: val_loss -0.5846 
2025-07-08 19:05:15.336421: Pseudo dice [np.float32(0.8523)] 
2025-07-08 19:05:15.336533: Epoch time: 47.09 s 
2025-07-08 19:05:16.499389:  
2025-07-08 19:05:16.499937: Epoch 209 
2025-07-08 19:05:16.500189: Current learning rate: 0.0081 
2025-07-08 19:06:05.005233: train_loss -0.5602 
2025-07-08 19:06:05.005714: val_loss -0.5616 
2025-07-08 19:06:05.005811: Pseudo dice [np.float32(0.8436)] 
2025-07-08 19:06:05.005954: Epoch time: 48.51 s 
2025-07-08 19:06:06.145620:  
2025-07-08 19:06:06.145967: Epoch 210 
2025-07-08 19:06:06.146095: Current learning rate: 0.00809 
2025-07-08 19:06:54.492043: train_loss -0.5655 
2025-07-08 19:06:54.492623: val_loss -0.5493 
2025-07-08 19:06:54.492709: Pseudo dice [np.float32(0.8577)] 
2025-07-08 19:06:54.492830: Epoch time: 48.35 s 
2025-07-08 19:06:55.723400:  
2025-07-08 19:06:55.723800: Epoch 211 
2025-07-08 19:06:55.723949: Current learning rate: 0.00808 
2025-07-08 19:07:44.703015: train_loss -0.5626 
2025-07-08 19:07:44.703630: val_loss -0.5607 
2025-07-08 19:07:44.703719: Pseudo dice [np.float32(0.8512)] 
2025-07-08 19:07:44.703821: Epoch time: 48.98 s 
2025-07-08 19:07:45.829669:  
2025-07-08 19:07:45.830019: Epoch 212 
2025-07-08 19:07:45.830297: Current learning rate: 0.00807 
2025-07-08 19:08:34.976871: train_loss -0.5684 
2025-07-08 19:08:34.977250: val_loss -0.5711 
2025-07-08 19:08:34.977335: Pseudo dice [np.float32(0.8581)] 
2025-07-08 19:08:34.977434: Epoch time: 49.15 s 
2025-07-08 19:08:36.193193:  
2025-07-08 19:08:36.193706: Epoch 213 
2025-07-08 19:08:36.193846: Current learning rate: 0.00806 
2025-07-08 19:09:24.994928: train_loss -0.5612 
2025-07-08 19:09:24.995342: val_loss -0.5754 
2025-07-08 19:09:24.995518: Pseudo dice [np.float32(0.8629)] 
2025-07-08 19:09:24.995654: Epoch time: 48.8 s 
2025-07-08 19:09:26.911497:  
2025-07-08 19:09:26.911856: Epoch 214 
2025-07-08 19:09:26.911989: Current learning rate: 0.00805 
2025-07-08 19:10:16.178505: train_loss -0.5647 
2025-07-08 19:10:16.179047: val_loss -0.5775 
2025-07-08 19:10:16.179141: Pseudo dice [np.float32(0.8657)] 
2025-07-08 19:10:16.179267: Epoch time: 49.27 s 
2025-07-08 19:10:17.378912:  
2025-07-08 19:10:17.379260: Epoch 215 
2025-07-08 19:10:17.379385: Current learning rate: 0.00804 
2025-07-08 19:11:06.284725: train_loss -0.554 
2025-07-08 19:11:06.285417: val_loss -0.5762 
2025-07-08 19:11:06.285518: Pseudo dice [np.float32(0.8717)] 
2025-07-08 19:11:06.285677: Epoch time: 48.91 s 
2025-07-08 19:11:06.285780: Yayy! New best EMA pseudo Dice: 0.8568999767303467 
2025-07-08 19:11:07.930906:  
2025-07-08 19:11:07.931349: Epoch 216 
2025-07-08 19:11:07.931472: Current learning rate: 0.00803 
2025-07-08 19:11:55.886372: train_loss -0.6158 
2025-07-08 19:11:55.886939: val_loss -0.6198 
2025-07-08 19:11:55.887035: Pseudo dice [np.float32(0.8381)] 
2025-07-08 19:11:55.887153: Epoch time: 47.96 s 
2025-07-08 19:11:57.045864:  
2025-07-08 19:11:57.046131: Epoch 217 
2025-07-08 19:11:57.046283: Current learning rate: 0.00802 
2025-07-08 19:12:45.972090: train_loss -0.5222 
2025-07-08 19:12:45.972596: val_loss -0.5579 
2025-07-08 19:12:45.976169: Pseudo dice [np.float32(0.7855)] 
2025-07-08 19:12:45.976557: Epoch time: 48.93 s 
2025-07-08 19:12:47.113934:  
2025-07-08 19:12:47.114238: Epoch 218 
2025-07-08 19:12:47.114425: Current learning rate: 0.00801 
2025-07-08 19:13:34.861087: train_loss -0.4873 
2025-07-08 19:13:34.861498: val_loss -0.5272 
2025-07-08 19:13:34.861593: Pseudo dice [np.float32(0.7572)] 
2025-07-08 19:13:34.861693: Epoch time: 47.75 s 
2025-07-08 19:13:36.154192:  
2025-07-08 19:13:36.154617: Epoch 219 
2025-07-08 19:13:36.154839: Current learning rate: 0.00801 
2025-07-08 19:14:23.963676: train_loss -0.5214 
2025-07-08 19:14:23.964129: val_loss -0.5562 
2025-07-08 19:14:23.964208: Pseudo dice [np.float32(0.7576)] 
2025-07-08 19:14:23.964314: Epoch time: 47.81 s 
2025-07-08 19:14:25.086151:  
2025-07-08 19:14:25.086655: Epoch 220 
2025-07-08 19:14:25.086799: Current learning rate: 0.008 
2025-07-08 19:15:12.717015: train_loss -0.5448 
2025-07-08 19:15:12.717472: val_loss -0.5651 
2025-07-08 19:15:12.717571: Pseudo dice [np.float32(0.7631)] 
2025-07-08 19:15:12.717705: Epoch time: 47.63 s 
2025-07-08 19:15:13.871740:  
2025-07-08 19:15:13.872232: Epoch 221 
2025-07-08 19:15:13.872602: Current learning rate: 0.00799 
2025-07-08 19:16:01.662310: train_loss -0.4871 
2025-07-08 19:16:01.662872: val_loss -0.5059 
2025-07-08 19:16:01.662967: Pseudo dice [np.float32(0.7336)] 
2025-07-08 19:16:01.663082: Epoch time: 47.79 s 
2025-07-08 19:16:02.798338:  
2025-07-08 19:16:02.798594: Epoch 222 
2025-07-08 19:16:02.798779: Current learning rate: 0.00798 
2025-07-08 19:16:50.414345: train_loss -0.5106 
2025-07-08 19:16:50.414985: val_loss -0.5141 
2025-07-08 19:16:50.415079: Pseudo dice [np.float32(0.7327)] 
2025-07-08 19:16:50.415214: Epoch time: 47.62 s 
2025-07-08 19:16:51.565055:  
2025-07-08 19:16:51.565395: Epoch 223 
2025-07-08 19:16:51.565809: Current learning rate: 0.00797 
2025-07-08 19:17:37.691656: train_loss -0.5367 
2025-07-08 19:17:37.692207: val_loss -0.5364 
2025-07-08 19:17:37.692312: Pseudo dice [np.float32(0.7719)] 
2025-07-08 19:17:37.692444: Epoch time: 46.13 s 
2025-07-08 19:17:38.875995:  
2025-07-08 19:17:38.876373: Epoch 224 
2025-07-08 19:17:38.876568: Current learning rate: 0.00796 
2025-07-08 19:18:25.637525: train_loss -0.4864 
2025-07-08 19:18:25.638193: val_loss -0.558 
2025-07-08 19:18:25.638292: Pseudo dice [np.float32(0.7559)] 
2025-07-08 19:18:25.638423: Epoch time: 46.76 s 
2025-07-08 19:18:26.826860:  
2025-07-08 19:18:26.827312: Epoch 225 
2025-07-08 19:18:26.827504: Current learning rate: 0.00795 
2025-07-08 19:19:12.960160: train_loss -0.5231 
2025-07-08 19:19:12.960712: val_loss -0.5571 
2025-07-08 19:19:12.960802: Pseudo dice [np.float32(0.766)] 
2025-07-08 19:19:12.960912: Epoch time: 46.13 s 
2025-07-08 19:19:14.137235:  
2025-07-08 19:19:14.137629: Epoch 226 
2025-07-08 19:19:14.137821: Current learning rate: 0.00794 
2025-07-08 19:20:01.194625: train_loss -0.559 
2025-07-08 19:20:01.195020: val_loss -0.564 
2025-07-08 19:20:01.195098: Pseudo dice [np.float32(0.8048)] 
2025-07-08 19:20:01.195192: Epoch time: 47.06 s 
2025-07-08 19:20:02.472591:  
2025-07-08 19:20:02.472821: Epoch 227 
2025-07-08 19:20:02.473041: Current learning rate: 0.00793 
2025-07-08 19:20:49.583254: train_loss -0.536 
2025-07-08 19:20:49.583984: val_loss -0.5551 
2025-07-08 19:20:49.584093: Pseudo dice [np.float32(0.7609)] 
2025-07-08 19:20:49.584237: Epoch time: 47.11 s 
2025-07-08 19:20:50.747554:  
2025-07-08 19:20:50.747816: Epoch 228 
2025-07-08 19:20:50.748017: Current learning rate: 0.00792 
2025-07-08 19:21:38.100341: train_loss -0.5644 
2025-07-08 19:21:38.100697: val_loss -0.544 
2025-07-08 19:21:38.100788: Pseudo dice [np.float32(0.7748)] 
2025-07-08 19:21:38.100909: Epoch time: 47.35 s 
2025-07-08 19:21:39.836326:  
2025-07-08 19:21:39.836531: Epoch 229 
2025-07-08 19:21:39.836807: Current learning rate: 0.00791 
2025-07-08 19:22:27.491915: train_loss -0.4896 
2025-07-08 19:22:27.492247: val_loss -0.4967 
2025-07-08 19:22:27.492328: Pseudo dice [np.float32(0.7156)] 
2025-07-08 19:22:27.492432: Epoch time: 47.66 s 
2025-07-08 19:22:28.589261:  
2025-07-08 19:22:28.589785: Epoch 230 
2025-07-08 19:22:28.589908: Current learning rate: 0.0079 
2025-07-08 19:23:15.845536: train_loss -0.5308 
2025-07-08 19:23:15.846140: val_loss -0.5541 
2025-07-08 19:23:15.846233: Pseudo dice [np.float32(0.7664)] 
2025-07-08 19:23:15.846343: Epoch time: 47.26 s 
2025-07-08 19:23:17.037471:  
2025-07-08 19:23:17.037786: Epoch 231 
2025-07-08 19:23:17.037930: Current learning rate: 0.00789 
2025-07-08 19:24:04.617038: train_loss -0.5275 
2025-07-08 19:24:04.617609: val_loss -0.5423 
2025-07-08 19:24:04.617761: Pseudo dice [np.float32(0.7602)] 
2025-07-08 19:24:04.617874: Epoch time: 47.58 s 
2025-07-08 19:24:05.730923:  
2025-07-08 19:24:05.731199: Epoch 232 
2025-07-08 19:24:05.731412: Current learning rate: 0.00789 
2025-07-08 19:24:53.388314: train_loss -0.5509 
2025-07-08 19:24:53.388914: val_loss -0.56 
2025-07-08 19:24:53.389004: Pseudo dice [np.float32(0.757)] 
2025-07-08 19:24:53.389129: Epoch time: 47.66 s 
2025-07-08 19:24:54.496070:  
2025-07-08 19:24:54.496522: Epoch 233 
2025-07-08 19:24:54.496664: Current learning rate: 0.00788 
2025-07-08 19:25:42.411308: train_loss -0.5496 
2025-07-08 19:25:42.411691: val_loss -0.5901 
2025-07-08 19:25:42.411798: Pseudo dice [np.float32(0.7811)] 
2025-07-08 19:25:42.411898: Epoch time: 47.92 s 
2025-07-08 19:25:43.536369:  
2025-07-08 19:25:43.536701: Epoch 234 
2025-07-08 19:25:43.536866: Current learning rate: 0.00787 
2025-07-08 19:26:30.667027: train_loss -0.5751 
2025-07-08 19:26:30.667972: val_loss -0.5774 
2025-07-08 19:26:30.668062: Pseudo dice [np.float32(0.7728)] 
2025-07-08 19:26:30.668175: Epoch time: 47.13 s 
2025-07-08 19:26:31.805161:  
2025-07-08 19:26:31.805621: Epoch 235 
2025-07-08 19:26:31.805797: Current learning rate: 0.00786 
2025-07-08 19:27:18.888043: train_loss -0.5782 
2025-07-08 19:27:18.888561: val_loss -0.5909 
2025-07-08 19:27:18.888666: Pseudo dice [np.float32(0.7934)] 
2025-07-08 19:27:18.888783: Epoch time: 47.08 s 
2025-07-08 19:27:19.992557:  
2025-07-08 19:27:19.992896: Epoch 236 
2025-07-08 19:27:19.993023: Current learning rate: 0.00785 
2025-07-08 19:28:08.282992: train_loss -0.5783 
2025-07-08 19:28:08.283516: val_loss -0.6012 
2025-07-08 19:28:08.283622: Pseudo dice [np.float32(0.7946)] 
2025-07-08 19:28:08.283736: Epoch time: 48.29 s 
2025-07-08 19:28:09.417302:  
2025-07-08 19:28:09.417790: Epoch 237 
2025-07-08 19:28:09.418065: Current learning rate: 0.00784 
2025-07-08 19:28:58.748843: train_loss -0.5612 
2025-07-08 19:28:58.749245: val_loss -0.4969 
2025-07-08 19:28:58.749329: Pseudo dice [np.float32(0.7605)] 
2025-07-08 19:28:58.749424: Epoch time: 49.33 s 
2025-07-08 19:28:59.905430:  
2025-07-08 19:28:59.905630: Epoch 238 
2025-07-08 19:28:59.905838: Current learning rate: 0.00783 
2025-07-08 19:29:48.056113: train_loss -0.5419 
2025-07-08 19:29:48.056356: val_loss -0.5687 
2025-07-08 19:29:48.056433: Pseudo dice [np.float32(0.7769)] 
2025-07-08 19:29:48.056525: Epoch time: 48.15 s 
2025-07-08 19:29:49.176442:  
2025-07-08 19:29:49.176627: Epoch 239 
2025-07-08 19:29:49.176747: Current learning rate: 0.00782 
2025-07-08 19:30:37.181831: train_loss -0.5726 
2025-07-08 19:30:37.182401: val_loss -0.586 
2025-07-08 19:30:37.182505: Pseudo dice [np.float32(0.7786)] 
2025-07-08 19:30:37.182662: Epoch time: 48.01 s 
2025-07-08 19:30:38.425471:  
2025-07-08 19:30:38.425958: Epoch 240 
2025-07-08 19:30:38.426086: Current learning rate: 0.00781 
2025-07-08 19:31:26.318877: train_loss -0.5178 
2025-07-08 19:31:26.319227: val_loss -0.5395 
2025-07-08 19:31:26.319308: Pseudo dice [np.float32(0.775)] 
2025-07-08 19:31:26.319411: Epoch time: 47.89 s 
2025-07-08 19:31:27.442976:  
2025-07-08 19:31:27.443213: Epoch 241 
2025-07-08 19:31:27.443531: Current learning rate: 0.0078 
2025-07-08 19:32:16.499054: train_loss -0.5526 
2025-07-08 19:32:16.500689: val_loss -0.5743 
2025-07-08 19:32:16.500999: Pseudo dice [np.float32(0.7967)] 
2025-07-08 19:32:16.501372: Epoch time: 49.06 s 
2025-07-08 19:32:17.769516:  
2025-07-08 19:32:17.769841: Epoch 242 
2025-07-08 19:32:17.770042: Current learning rate: 0.00779 
2025-07-08 19:33:05.296664: train_loss -0.5656 
2025-07-08 19:33:05.297125: val_loss -0.5701 
2025-07-08 19:33:05.297212: Pseudo dice [np.float32(0.7938)] 
2025-07-08 19:33:05.297322: Epoch time: 47.53 s 
2025-07-08 19:33:06.427490:  
2025-07-08 19:33:06.427708: Epoch 243 
2025-07-08 19:33:06.427990: Current learning rate: 0.00778 
2025-07-08 19:33:54.422171: train_loss -0.5435 
2025-07-08 19:33:54.422746: val_loss -0.576 
2025-07-08 19:33:54.422949: Pseudo dice [np.float32(0.7793)] 
2025-07-08 19:33:54.423108: Epoch time: 48.0 s 
2025-07-08 19:33:55.556058:  
2025-07-08 19:33:55.556368: Epoch 244 
2025-07-08 19:33:55.556493: Current learning rate: 0.00777 
2025-07-08 19:34:43.470304: train_loss -0.588 
2025-07-08 19:34:43.471029: val_loss -0.6213 
2025-07-08 19:34:43.471150: Pseudo dice [np.float32(0.8078)] 
2025-07-08 19:34:43.471329: Epoch time: 47.92 s 
2025-07-08 19:34:45.344738:  
2025-07-08 19:34:45.345087: Epoch 245 
2025-07-08 19:34:45.345218: Current learning rate: 0.00777 
2025-07-08 19:35:33.037111: train_loss -0.5958 
2025-07-08 19:35:33.037608: val_loss -0.5902 
2025-07-08 19:35:33.037694: Pseudo dice [np.float32(0.788)] 
2025-07-08 19:35:33.037794: Epoch time: 47.69 s 
2025-07-08 19:35:34.159249:  
2025-07-08 19:35:34.159636: Epoch 246 
2025-07-08 19:35:34.159784: Current learning rate: 0.00776 
2025-07-08 19:36:21.555034: train_loss -0.5957 
2025-07-08 19:36:21.555618: val_loss -0.6184 
2025-07-08 19:36:21.555706: Pseudo dice [np.float32(0.8112)] 
2025-07-08 19:36:21.555808: Epoch time: 47.4 s 
2025-07-08 19:36:22.740521:  
2025-07-08 19:36:22.740883: Epoch 247 
2025-07-08 19:36:22.741140: Current learning rate: 0.00775 
2025-07-08 19:37:10.172182: train_loss -0.5981 
2025-07-08 19:37:10.173220: val_loss -0.6109 
2025-07-08 19:37:10.173368: Pseudo dice [np.float32(0.7929)] 
2025-07-08 19:37:10.173558: Epoch time: 47.43 s 
2025-07-08 19:37:11.322360:  
2025-07-08 19:37:11.322691: Epoch 248 
2025-07-08 19:37:11.322802: Current learning rate: 0.00774 
2025-07-08 19:37:58.825911: train_loss -0.6013 
2025-07-08 19:37:58.826849: val_loss -0.6174 
2025-07-08 19:37:58.827061: Pseudo dice [np.float32(0.8214)] 
2025-07-08 19:37:58.827188: Epoch time: 47.5 s 
2025-07-08 19:38:00.009644:  
2025-07-08 19:38:00.009807: Epoch 249 
2025-07-08 19:38:00.009911: Current learning rate: 0.00773 
2025-07-08 19:38:46.570333: train_loss -0.6055 
2025-07-08 19:38:46.570982: val_loss -0.6005 
2025-07-08 19:38:46.571066: Pseudo dice [np.float32(0.7763)] 
2025-07-08 19:38:46.571175: Epoch time: 46.56 s 
2025-07-08 19:38:48.162091:  
2025-07-08 19:38:48.162330: Epoch 250 
2025-07-08 19:38:48.162549: Current learning rate: 0.00772 
2025-07-08 19:39:34.076176: train_loss -0.5898 
2025-07-08 19:39:34.077078: val_loss -0.5879 
2025-07-08 19:39:34.077186: Pseudo dice [np.float32(0.8025)] 
2025-07-08 19:39:34.077325: Epoch time: 45.91 s 
2025-07-08 19:39:35.257398:  
2025-07-08 19:39:35.257982: Epoch 251 
2025-07-08 19:39:35.258162: Current learning rate: 0.00771 
2025-07-08 19:40:21.863879: train_loss -0.5882 
2025-07-08 19:40:21.864353: val_loss -0.6321 
2025-07-08 19:40:21.864438: Pseudo dice [np.float32(0.8175)] 
2025-07-08 19:40:21.864556: Epoch time: 46.61 s 
2025-07-08 19:40:23.044446:  
2025-07-08 19:40:23.044896: Epoch 252 
2025-07-08 19:40:23.045085: Current learning rate: 0.0077 
2025-07-08 19:41:09.447509: train_loss -0.5758 
2025-07-08 19:41:09.448149: val_loss -0.5807 
2025-07-08 19:41:09.448261: Pseudo dice [np.float32(0.7689)] 
2025-07-08 19:41:09.448373: Epoch time: 46.4 s 
2025-07-08 19:41:10.694383:  
2025-07-08 19:41:10.694755: Epoch 253 
2025-07-08 19:41:10.694886: Current learning rate: 0.00769 
2025-07-08 19:41:58.167047: train_loss -0.5914 
2025-07-08 19:41:58.168225: val_loss -0.6258 
2025-07-08 19:41:58.168344: Pseudo dice [np.float32(0.7945)] 
2025-07-08 19:41:58.168548: Epoch time: 47.47 s 
2025-07-08 19:41:59.314103:  
2025-07-08 19:41:59.314466: Epoch 254 
2025-07-08 19:41:59.314604: Current learning rate: 0.00768 
2025-07-08 19:42:45.641181: train_loss -0.604 
2025-07-08 19:42:45.641599: val_loss -0.6119 
2025-07-08 19:42:45.641702: Pseudo dice [np.float32(0.8274)] 
2025-07-08 19:42:45.641801: Epoch time: 46.33 s 
2025-07-08 19:42:46.826334:  
2025-07-08 19:42:46.826684: Epoch 255 
2025-07-08 19:42:46.827021: Current learning rate: 0.00767 
2025-07-08 19:43:32.595829: train_loss -0.5495 
2025-07-08 19:43:32.596555: val_loss -0.561 
2025-07-08 19:43:32.596724: Pseudo dice [np.float32(0.7493)] 
2025-07-08 19:43:32.596873: Epoch time: 45.77 s 
2025-07-08 19:43:33.754568:  
2025-07-08 19:43:33.754809: Epoch 256 
2025-07-08 19:43:33.755047: Current learning rate: 0.00766 
2025-07-08 19:44:20.787702: train_loss -0.5673 
2025-07-08 19:44:20.788705: val_loss -0.5618 
2025-07-08 19:44:20.788832: Pseudo dice [np.float32(0.7674)] 
2025-07-08 19:44:20.788977: Epoch time: 47.03 s 
2025-07-08 19:44:21.923414:  
2025-07-08 19:44:21.923651: Epoch 257 
2025-07-08 19:44:21.923892: Current learning rate: 0.00765 
2025-07-08 19:45:08.193042: train_loss -0.5735 
2025-07-08 19:45:08.193749: val_loss -0.5866 
2025-07-08 19:45:08.193894: Pseudo dice [np.float32(0.7874)] 
2025-07-08 19:45:08.194036: Epoch time: 46.27 s 
2025-07-08 19:45:09.354503:  
2025-07-08 19:45:09.354785: Epoch 258 
2025-07-08 19:45:09.354886: Current learning rate: 0.00764 
2025-07-08 19:45:56.208681: train_loss -0.5875 
2025-07-08 19:45:56.209277: val_loss -0.6231 
2025-07-08 19:45:56.209363: Pseudo dice [np.float32(0.8189)] 
2025-07-08 19:45:56.209471: Epoch time: 46.86 s 
2025-07-08 19:45:57.346633:  
2025-07-08 19:45:57.347040: Epoch 259 
2025-07-08 19:45:57.347320: Current learning rate: 0.00764 
2025-07-08 19:46:44.454011: train_loss -0.592 
2025-07-08 19:46:44.454806: val_loss -0.6169 
2025-07-08 19:46:44.454909: Pseudo dice [np.float32(0.809)] 
2025-07-08 19:46:44.455046: Epoch time: 47.11 s 
2025-07-08 19:46:46.521115:  
2025-07-08 19:46:46.521280: Epoch 260 
2025-07-08 19:46:46.521381: Current learning rate: 0.00763 
2025-07-08 19:47:33.381398: train_loss -0.5987 
2025-07-08 19:47:33.382422: val_loss -0.6139 
2025-07-08 19:47:33.382536: Pseudo dice [np.float32(0.811)] 
2025-07-08 19:47:33.382733: Epoch time: 46.86 s 
2025-07-08 19:47:34.522837:  
2025-07-08 19:47:34.523179: Epoch 261 
2025-07-08 19:47:34.523403: Current learning rate: 0.00762 
2025-07-08 19:48:22.975878: train_loss -0.6082 
2025-07-08 19:48:22.976456: val_loss -0.6183 
2025-07-08 19:48:22.976565: Pseudo dice [np.float32(0.8262)] 
2025-07-08 19:48:22.976699: Epoch time: 48.45 s 
2025-07-08 19:48:24.123849:  
2025-07-08 19:48:24.124252: Epoch 262 
2025-07-08 19:48:24.124378: Current learning rate: 0.00761 
2025-07-08 19:49:13.082345: train_loss -0.5996 
2025-07-08 19:49:13.082799: val_loss -0.6208 
2025-07-08 19:49:13.082918: Pseudo dice [np.float32(0.8184)] 
2025-07-08 19:49:13.083102: Epoch time: 48.96 s 
2025-07-08 19:49:14.225141:  
2025-07-08 19:49:14.225356: Epoch 263 
2025-07-08 19:49:14.225511: Current learning rate: 0.0076 
2025-07-08 19:50:02.218659: train_loss -0.6126 
2025-07-08 19:50:02.219080: val_loss -0.6286 
2025-07-08 19:50:02.219166: Pseudo dice [np.float32(0.8233)] 
2025-07-08 19:50:02.219268: Epoch time: 47.99 s 
2025-07-08 19:50:03.359910:  
2025-07-08 19:50:03.360467: Epoch 264 
2025-07-08 19:50:03.360824: Current learning rate: 0.00759 
2025-07-08 19:50:51.348375: train_loss -0.6081 
2025-07-08 19:50:51.348901: val_loss -0.6439 
2025-07-08 19:50:51.348986: Pseudo dice [np.float32(0.8224)] 
2025-07-08 19:50:51.349089: Epoch time: 47.99 s 
2025-07-08 19:50:52.502432:  
2025-07-08 19:50:52.502801: Epoch 265 
2025-07-08 19:50:52.503209: Current learning rate: 0.00758 
2025-07-08 19:51:39.439631: train_loss -0.6221 
2025-07-08 19:51:39.440625: val_loss -0.6125 
2025-07-08 19:51:39.444312: Pseudo dice [np.float32(0.8199)] 
2025-07-08 19:51:39.444620: Epoch time: 46.94 s 
2025-07-08 19:51:40.588988:  
2025-07-08 19:51:40.589398: Epoch 266 
2025-07-08 19:51:40.589507: Current learning rate: 0.00757 
2025-07-08 19:52:27.552932: train_loss -0.6113 
2025-07-08 19:52:27.553581: val_loss -0.6308 
2025-07-08 19:52:27.553670: Pseudo dice [np.float32(0.831)] 
2025-07-08 19:52:27.553777: Epoch time: 46.96 s 
2025-07-08 19:52:28.708726:  
2025-07-08 19:52:28.709027: Epoch 267 
2025-07-08 19:52:28.709275: Current learning rate: 0.00756 
2025-07-08 19:53:15.967205: train_loss -0.6279 
2025-07-08 19:53:15.967774: val_loss -0.6316 
2025-07-08 19:53:15.967983: Pseudo dice [np.float32(0.8361)] 
2025-07-08 19:53:15.968112: Epoch time: 47.26 s 
2025-07-08 19:53:17.162526:  
2025-07-08 19:53:17.162842: Epoch 268 
2025-07-08 19:53:17.163027: Current learning rate: 0.00755 
2025-07-08 19:54:04.108356: train_loss -0.6096 
2025-07-08 19:54:04.108965: val_loss -0.6404 
2025-07-08 19:54:04.109092: Pseudo dice [np.float32(0.8184)] 
2025-07-08 19:54:04.109204: Epoch time: 46.95 s 
2025-07-08 19:54:05.315958:  
2025-07-08 19:54:05.316233: Epoch 269 
2025-07-08 19:54:05.316452: Current learning rate: 0.00754 
2025-07-08 19:54:52.238326: train_loss -0.6069 
2025-07-08 19:54:52.239213: val_loss -0.5776 
2025-07-08 19:54:52.239330: Pseudo dice [np.float32(0.8037)] 
2025-07-08 19:54:52.239467: Epoch time: 46.92 s 
2025-07-08 19:54:53.444782:  
2025-07-08 19:54:53.445063: Epoch 270 
2025-07-08 19:54:53.445252: Current learning rate: 0.00753 
2025-07-08 19:55:39.598835: train_loss -0.5582 
2025-07-08 19:55:39.599449: val_loss -0.5826 
2025-07-08 19:55:39.599560: Pseudo dice [np.float32(0.7826)] 
2025-07-08 19:55:39.599686: Epoch time: 46.16 s 
2025-07-08 19:55:40.785928:  
2025-07-08 19:55:40.786358: Epoch 271 
2025-07-08 19:55:40.786638: Current learning rate: 0.00752 
2025-07-08 19:56:27.531755: train_loss -0.5645 
2025-07-08 19:56:27.532631: val_loss -0.5616 
2025-07-08 19:56:27.532730: Pseudo dice [np.float32(0.7755)] 
2025-07-08 19:56:27.532866: Epoch time: 46.75 s 
2025-07-08 19:56:28.753493:  
2025-07-08 19:56:28.753824: Epoch 272 
2025-07-08 19:56:28.754001: Current learning rate: 0.00751 
2025-07-08 19:57:17.404804: train_loss -0.5688 
2025-07-08 19:57:17.405681: val_loss -0.5847 
2025-07-08 19:57:17.405821: Pseudo dice [np.float32(0.7889)] 
2025-07-08 19:57:17.406110: Epoch time: 48.65 s 
2025-07-08 19:57:18.585769:  
2025-07-08 19:57:18.586228: Epoch 273 
2025-07-08 19:57:18.586442: Current learning rate: 0.00751 
2025-07-08 19:58:07.442821: train_loss -0.5353 
2025-07-08 19:58:07.443762: val_loss -0.5294 
2025-07-08 19:58:07.443869: Pseudo dice [np.float32(0.7195)] 
2025-07-08 19:58:07.444014: Epoch time: 48.86 s 
2025-07-08 19:58:09.293797:  
2025-07-08 19:58:09.294347: Epoch 274 
2025-07-08 19:58:09.294476: Current learning rate: 0.0075 
2025-07-08 19:58:56.905070: train_loss -0.566 
2025-07-08 19:58:56.905763: val_loss -0.6174 
2025-07-08 19:58:56.905859: Pseudo dice [np.float32(0.8084)] 
2025-07-08 19:58:56.905972: Epoch time: 47.61 s 
2025-07-08 19:58:58.018055:  
2025-07-08 19:58:58.018742: Epoch 275 
2025-07-08 19:58:58.018883: Current learning rate: 0.00749 
2025-07-08 19:59:45.062230: train_loss -0.5859 
2025-07-08 19:59:45.062698: val_loss -0.5883 
2025-07-08 19:59:45.062787: Pseudo dice [np.float32(0.8063)] 
2025-07-08 19:59:45.062916: Epoch time: 47.05 s 
2025-07-08 19:59:46.224892:  
2025-07-08 19:59:46.225108: Epoch 276 
2025-07-08 19:59:46.225236: Current learning rate: 0.00748 
2025-07-08 20:00:34.126137: train_loss -0.5904 
2025-07-08 20:00:34.127261: val_loss -0.6018 
2025-07-08 20:00:34.127381: Pseudo dice [np.float32(0.8003)] 
2025-07-08 20:00:34.127529: Epoch time: 47.9 s 
2025-07-08 20:00:35.377278:  
2025-07-08 20:00:35.377578: Epoch 277 
2025-07-08 20:00:35.377852: Current learning rate: 0.00747 
2025-07-08 20:01:22.452195: train_loss -0.6084 
2025-07-08 20:01:22.452652: val_loss -0.6184 
2025-07-08 20:01:22.452779: Pseudo dice [np.float32(0.8132)] 
2025-07-08 20:01:22.452893: Epoch time: 47.08 s 
2025-07-08 20:01:23.661165:  
2025-07-08 20:01:23.661596: Epoch 278 
2025-07-08 20:01:23.661820: Current learning rate: 0.00746 
2025-07-08 20:02:09.774797: train_loss -0.6074 
2025-07-08 20:02:09.775305: val_loss -0.5992 
2025-07-08 20:02:09.775391: Pseudo dice [np.float32(0.8178)] 
2025-07-08 20:02:09.775498: Epoch time: 46.11 s 
2025-07-08 20:02:10.961627:  
2025-07-08 20:02:10.961858: Epoch 279 
2025-07-08 20:02:10.962053: Current learning rate: 0.00745 
2025-07-08 20:02:57.931963: train_loss -0.6085 
2025-07-08 20:02:57.932896: val_loss -0.6202 
2025-07-08 20:02:57.932996: Pseudo dice [np.float32(0.8217)] 
2025-07-08 20:02:57.933152: Epoch time: 46.97 s 
2025-07-08 20:02:59.216708:  
2025-07-08 20:02:59.216975: Epoch 280 
2025-07-08 20:02:59.217167: Current learning rate: 0.00744 
2025-07-08 20:03:45.911791: train_loss -0.5817 
2025-07-08 20:03:45.912323: val_loss -0.6132 
2025-07-08 20:03:45.912469: Pseudo dice [np.float32(0.818)] 
2025-07-08 20:03:45.912599: Epoch time: 46.7 s 
2025-07-08 20:03:47.090569:  
2025-07-08 20:03:47.091039: Epoch 281 
2025-07-08 20:03:47.091249: Current learning rate: 0.00743 
2025-07-08 20:04:33.908533: train_loss -0.5988 
2025-07-08 20:04:33.909148: val_loss -0.6251 
2025-07-08 20:04:33.909273: Pseudo dice [np.float32(0.821)] 
2025-07-08 20:04:33.909394: Epoch time: 46.82 s 
2025-07-08 20:04:35.116604:  
2025-07-08 20:04:35.116916: Epoch 282 
2025-07-08 20:04:35.117225: Current learning rate: 0.00742 
2025-07-08 20:05:21.588414: train_loss -0.5656 
2025-07-08 20:05:21.588901: val_loss -0.6145 
2025-07-08 20:05:21.589001: Pseudo dice [np.float32(0.8048)] 
2025-07-08 20:05:21.589128: Epoch time: 46.47 s 
2025-07-08 20:05:22.734894:  
2025-07-08 20:05:22.735197: Epoch 283 
2025-07-08 20:05:22.735327: Current learning rate: 0.00741 
2025-07-08 20:06:08.562653: train_loss -0.5991 
2025-07-08 20:06:08.563217: val_loss -0.5887 
2025-07-08 20:06:08.563314: Pseudo dice [np.float32(0.8078)] 
2025-07-08 20:06:08.563447: Epoch time: 45.83 s 
2025-07-08 20:06:09.757039:  
2025-07-08 20:06:09.757545: Epoch 284 
2025-07-08 20:06:09.757680: Current learning rate: 0.0074 
2025-07-08 20:06:55.876297: train_loss -0.5936 
2025-07-08 20:06:55.876748: val_loss -0.611 
2025-07-08 20:06:55.876845: Pseudo dice [np.float32(0.7963)] 
2025-07-08 20:06:55.876950: Epoch time: 46.12 s 
2025-07-08 20:06:57.129774:  
2025-07-08 20:06:57.130322: Epoch 285 
2025-07-08 20:06:57.130503: Current learning rate: 0.00739 
2025-07-08 20:07:43.103133: train_loss -0.5898 
2025-07-08 20:07:43.103551: val_loss -0.5878 
2025-07-08 20:07:43.103633: Pseudo dice [np.float32(0.793)] 
2025-07-08 20:07:43.103725: Epoch time: 45.97 s 
2025-07-08 20:07:44.340686:  
2025-07-08 20:07:44.340913: Epoch 286 
2025-07-08 20:07:44.341043: Current learning rate: 0.00738 
2025-07-08 20:08:30.584870: train_loss -0.5798 
2025-07-08 20:08:30.585419: val_loss -0.6248 
2025-07-08 20:08:30.585505: Pseudo dice [np.float32(0.8091)] 
2025-07-08 20:08:30.585630: Epoch time: 46.25 s 
2025-07-08 20:08:31.755479:  
2025-07-08 20:08:31.755657: Epoch 287 
2025-07-08 20:08:31.755783: Current learning rate: 0.00738 
2025-07-08 20:09:18.478154: train_loss -0.5818 
2025-07-08 20:09:18.478621: val_loss -0.5462 
2025-07-08 20:09:18.478718: Pseudo dice [np.float32(0.7806)] 
2025-07-08 20:09:18.478827: Epoch time: 46.72 s 
2025-07-08 20:09:19.632247:  
2025-07-08 20:09:19.632583: Epoch 288 
2025-07-08 20:09:19.632708: Current learning rate: 0.00737 
2025-07-08 20:10:06.327378: train_loss -0.5871 
2025-07-08 20:10:06.327792: val_loss -0.624 
2025-07-08 20:10:06.327869: Pseudo dice [np.float32(0.8181)] 
2025-07-08 20:10:06.327970: Epoch time: 46.7 s 
2025-07-08 20:10:07.491447:  
2025-07-08 20:10:07.492085: Epoch 289 
2025-07-08 20:10:07.492224: Current learning rate: 0.00736 
2025-07-08 20:10:53.769856: train_loss -0.6012 
2025-07-08 20:10:53.770507: val_loss -0.6148 
2025-07-08 20:10:53.770627: Pseudo dice [np.float32(0.8102)] 
2025-07-08 20:10:53.770769: Epoch time: 46.28 s 
2025-07-08 20:10:55.880445:  
2025-07-08 20:10:55.880791: Epoch 290 
2025-07-08 20:10:55.880974: Current learning rate: 0.00735 
2025-07-08 20:11:43.338871: train_loss -0.5894 
2025-07-08 20:11:43.339569: val_loss -0.5914 
2025-07-08 20:11:43.339712: Pseudo dice [np.float32(0.8191)] 
2025-07-08 20:11:43.339864: Epoch time: 47.46 s 
2025-07-08 20:11:44.536115:  
2025-07-08 20:11:44.536556: Epoch 291 
2025-07-08 20:11:44.536688: Current learning rate: 0.00734 
2025-07-08 20:12:31.418424: train_loss -0.6072 
2025-07-08 20:12:31.419171: val_loss -0.6241 
2025-07-08 20:12:31.419303: Pseudo dice [np.float32(0.8194)] 
2025-07-08 20:12:31.419447: Epoch time: 46.88 s 
2025-07-08 20:12:32.665762:  
2025-07-08 20:12:32.666418: Epoch 292 
2025-07-08 20:12:32.666659: Current learning rate: 0.00733 
2025-07-08 20:13:19.296803: train_loss -0.6012 
2025-07-08 20:13:19.297282: val_loss -0.6217 
2025-07-08 20:13:19.297479: Pseudo dice [np.float32(0.8323)] 
2025-07-08 20:13:19.297764: Epoch time: 46.63 s 
2025-07-08 20:13:20.554645:  
2025-07-08 20:13:20.555151: Epoch 293 
2025-07-08 20:13:20.555285: Current learning rate: 0.00732 
2025-07-08 20:14:07.988964: train_loss -0.5996 
2025-07-08 20:14:07.989240: val_loss -0.6216 
2025-07-08 20:14:07.989316: Pseudo dice [np.float32(0.8191)] 
2025-07-08 20:14:07.989410: Epoch time: 47.44 s 
2025-07-08 20:14:09.119477:  
2025-07-08 20:14:09.119704: Epoch 294 
2025-07-08 20:14:09.119886: Current learning rate: 0.00731 
2025-07-08 20:14:55.647197: train_loss -0.607 
2025-07-08 20:14:55.647750: val_loss -0.6415 
2025-07-08 20:14:55.647839: Pseudo dice [np.float32(0.8202)] 
2025-07-08 20:14:55.647952: Epoch time: 46.53 s 
2025-07-08 20:14:56.821412:  
2025-07-08 20:14:56.821739: Epoch 295 
2025-07-08 20:14:56.821933: Current learning rate: 0.0073 
2025-07-08 20:15:43.408593: train_loss -0.6208 
2025-07-08 20:15:43.409062: val_loss -0.6275 
2025-07-08 20:15:43.409169: Pseudo dice [np.float32(0.83)] 
2025-07-08 20:15:43.409276: Epoch time: 46.59 s 
2025-07-08 20:15:44.542804:  
2025-07-08 20:15:44.543254: Epoch 296 
2025-07-08 20:15:44.543415: Current learning rate: 0.00729 
2025-07-08 20:16:30.535554: train_loss -0.6117 
2025-07-08 20:16:30.536597: val_loss -0.6385 
2025-07-08 20:16:30.536721: Pseudo dice [np.float32(0.8143)] 
2025-07-08 20:16:30.536893: Epoch time: 45.99 s 
2025-07-08 20:16:31.759746:  
2025-07-08 20:16:31.760072: Epoch 297 
2025-07-08 20:16:31.760270: Current learning rate: 0.00728 
2025-07-08 20:17:18.460010: train_loss -0.5924 
2025-07-08 20:17:18.460671: val_loss -0.6052 
2025-07-08 20:17:18.460788: Pseudo dice [np.float32(0.8109)] 
2025-07-08 20:17:18.460935: Epoch time: 46.7 s 
2025-07-08 20:17:19.604699:  
2025-07-08 20:17:19.604966: Epoch 298 
2025-07-08 20:17:19.605073: Current learning rate: 0.00727 
2025-07-08 20:18:06.809383: train_loss -0.6058 
2025-07-08 20:18:06.810128: val_loss -0.6203 
2025-07-08 20:18:06.810226: Pseudo dice [np.float32(0.815)] 
2025-07-08 20:18:06.810369: Epoch time: 47.21 s 
2025-07-08 20:18:08.020569:  
2025-07-08 20:18:08.020964: Epoch 299 
2025-07-08 20:18:08.021410: Current learning rate: 0.00726 
2025-07-08 20:18:53.994431: train_loss -0.6142 
2025-07-08 20:18:53.995643: val_loss -0.6191 
2025-07-08 20:18:53.996061: Pseudo dice [np.float32(0.8181)] 
2025-07-08 20:18:53.996577: Epoch time: 45.98 s 
2025-07-08 20:18:55.740528:  
2025-07-08 20:18:55.740820: Epoch 300 
2025-07-08 20:18:55.741170: Current learning rate: 0.00725 
2025-07-08 20:19:42.517896: train_loss -0.5946 
2025-07-08 20:19:42.518528: val_loss -0.5941 
2025-07-08 20:19:42.518643: Pseudo dice [np.float32(0.7828)] 
2025-07-08 20:19:42.518762: Epoch time: 46.78 s 
2025-07-08 20:19:43.724073:  
2025-07-08 20:19:43.724474: Epoch 301 
2025-07-08 20:19:43.724687: Current learning rate: 0.00724 
2025-07-08 20:20:29.764777: train_loss -0.6022 
2025-07-08 20:20:29.765477: val_loss -0.6192 
2025-07-08 20:20:29.765594: Pseudo dice [np.float32(0.7928)] 
2025-07-08 20:20:29.765732: Epoch time: 46.04 s 
2025-07-08 20:20:30.967920:  
2025-07-08 20:20:30.968256: Epoch 302 
2025-07-08 20:20:30.968498: Current learning rate: 0.00724 
2025-07-08 20:21:17.158565: train_loss -0.5784 
2025-07-08 20:21:17.159221: val_loss -0.6058 
2025-07-08 20:21:17.159316: Pseudo dice [np.float32(0.8088)] 
2025-07-08 20:21:17.159458: Epoch time: 46.19 s 
2025-07-08 20:21:18.409718:  
2025-07-08 20:21:18.410013: Epoch 303 
2025-07-08 20:21:18.410238: Current learning rate: 0.00723 
2025-07-08 20:22:05.075606: train_loss -0.615 
2025-07-08 20:22:05.076002: val_loss -0.615 
2025-07-08 20:22:05.076180: Pseudo dice [np.float32(0.8055)] 
2025-07-08 20:22:05.076359: Epoch time: 46.67 s 
2025-07-08 20:22:07.081711:  
2025-07-08 20:22:07.082083: Epoch 304 
2025-07-08 20:22:07.082229: Current learning rate: 0.00722 
2025-07-08 20:22:53.653472: train_loss -0.6209 
2025-07-08 20:22:53.654695: val_loss -0.6287 
2025-07-08 20:22:53.654804: Pseudo dice [np.float32(0.8378)] 
2025-07-08 20:22:53.654936: Epoch time: 46.57 s 
2025-07-08 20:22:54.787401:  
2025-07-08 20:22:54.787651: Epoch 305 
2025-07-08 20:22:54.787775: Current learning rate: 0.00721 
2025-07-08 20:23:41.209105: train_loss -0.6271 
2025-07-08 20:23:41.209828: val_loss -0.6366 
2025-07-08 20:23:41.209946: Pseudo dice [np.float32(0.8332)] 
2025-07-08 20:23:41.210084: Epoch time: 46.42 s 
2025-07-08 20:23:42.435685:  
2025-07-08 20:23:42.436157: Epoch 306 
2025-07-08 20:23:42.436463: Current learning rate: 0.0072 
2025-07-08 20:24:28.891186: train_loss -0.6247 
2025-07-08 20:24:28.891707: val_loss -0.6347 
2025-07-08 20:24:28.891797: Pseudo dice [np.float32(0.8237)] 
2025-07-08 20:24:28.891911: Epoch time: 46.46 s 
2025-07-08 20:24:30.147557:  
2025-07-08 20:24:30.148103: Epoch 307 
2025-07-08 20:24:30.148354: Current learning rate: 0.00719 
2025-07-08 20:25:16.358669: train_loss -0.6226 
2025-07-08 20:25:16.359059: val_loss -0.6504 
2025-07-08 20:25:16.359142: Pseudo dice [np.float32(0.8295)] 
2025-07-08 20:25:16.359246: Epoch time: 46.21 s 
2025-07-08 20:25:17.585013:  
2025-07-08 20:25:17.585255: Epoch 308 
2025-07-08 20:25:17.585386: Current learning rate: 0.00718 
2025-07-08 20:26:03.806495: train_loss -0.6301 
2025-07-08 20:26:03.806753: val_loss -0.6651 
2025-07-08 20:26:03.806828: Pseudo dice [np.float32(0.8479)] 
2025-07-08 20:26:03.807058: Epoch time: 46.22 s 
2025-07-08 20:26:05.002254:  
2025-07-08 20:26:05.002650: Epoch 309 
2025-07-08 20:26:05.002817: Current learning rate: 0.00717 
2025-07-08 20:26:51.248328: train_loss -0.6096 
2025-07-08 20:26:51.248877: val_loss -0.5895 
2025-07-08 20:26:51.248960: Pseudo dice [np.float32(0.8123)] 
2025-07-08 20:26:51.249071: Epoch time: 46.25 s 
2025-07-08 20:26:52.396829:  
2025-07-08 20:26:52.397346: Epoch 310 
2025-07-08 20:26:52.397614: Current learning rate: 0.00716 
2025-07-08 20:27:38.619929: train_loss -0.6012 
2025-07-08 20:27:38.620505: val_loss -0.6272 
2025-07-08 20:27:38.620625: Pseudo dice [np.float32(0.8048)] 
2025-07-08 20:27:38.620806: Epoch time: 46.22 s 
2025-07-08 20:27:39.822033:  
2025-07-08 20:27:39.822505: Epoch 311 
2025-07-08 20:27:39.822642: Current learning rate: 0.00715 
2025-07-08 20:28:26.275804: train_loss -0.6183 
2025-07-08 20:28:26.276889: val_loss -0.6347 
2025-07-08 20:28:26.277078: Pseudo dice [np.float32(0.8388)] 
2025-07-08 20:28:26.277242: Epoch time: 46.45 s 
2025-07-08 20:28:27.485452:  
2025-07-08 20:28:27.485719: Epoch 312 
2025-07-08 20:28:27.485837: Current learning rate: 0.00714 
2025-07-08 20:29:14.515621: train_loss -0.6233 
2025-07-08 20:29:14.515950: val_loss -0.6361 
2025-07-08 20:29:14.516031: Pseudo dice [np.float32(0.8321)] 
2025-07-08 20:29:14.516125: Epoch time: 47.03 s 
2025-07-08 20:29:15.680126:  
2025-07-08 20:29:15.680403: Epoch 313 
2025-07-08 20:29:15.680537: Current learning rate: 0.00713 
2025-07-08 20:30:01.674289: train_loss -0.6283 
2025-07-08 20:30:01.674636: val_loss -0.5914 
2025-07-08 20:30:01.674716: Pseudo dice [np.float32(0.8365)] 
2025-07-08 20:30:01.674867: Epoch time: 46.0 s 
2025-07-08 20:30:02.798819:  
2025-07-08 20:30:02.799060: Epoch 314 
2025-07-08 20:30:02.799290: Current learning rate: 0.00712 
2025-07-08 20:30:49.571053: train_loss -0.6274 
2025-07-08 20:30:49.571394: val_loss -0.6367 
2025-07-08 20:30:49.571476: Pseudo dice [np.float32(0.8382)] 
2025-07-08 20:30:49.571590: Epoch time: 46.77 s 
2025-07-08 20:30:50.744134:  
2025-07-08 20:30:50.744308: Epoch 315 
2025-07-08 20:30:50.744706: Current learning rate: 0.00711 
2025-07-08 20:31:37.152720: train_loss -0.6274 
2025-07-08 20:31:37.153668: val_loss -0.6279 
2025-07-08 20:31:37.153867: Pseudo dice [np.float32(0.8333)] 
2025-07-08 20:31:37.154412: Epoch time: 46.41 s 
2025-07-08 20:31:38.365827:  
2025-07-08 20:31:38.366095: Epoch 316 
2025-07-08 20:31:38.366212: Current learning rate: 0.0071 
2025-07-08 20:32:25.048495: train_loss -0.6332 
2025-07-08 20:32:25.048985: val_loss -0.6489 
2025-07-08 20:32:25.049070: Pseudo dice [np.float32(0.8442)] 
2025-07-08 20:32:25.049187: Epoch time: 46.68 s 
2025-07-08 20:32:26.234869:  
2025-07-08 20:32:26.235476: Epoch 317 
2025-07-08 20:32:26.235713: Current learning rate: 0.0071 
2025-07-08 20:33:13.810651: train_loss -0.6249 
2025-07-08 20:33:13.811271: val_loss -0.6446 
2025-07-08 20:33:13.811378: Pseudo dice [np.float32(0.8285)] 
2025-07-08 20:33:13.811518: Epoch time: 47.58 s 
2025-07-08 20:33:15.026388:  
2025-07-08 20:33:15.026730: Epoch 318 
2025-07-08 20:33:15.026854: Current learning rate: 0.00709 
2025-07-08 20:34:03.247157: train_loss -0.627 
2025-07-08 20:34:03.247664: val_loss -0.6397 
2025-07-08 20:34:03.247751: Pseudo dice [np.float32(0.8539)] 
2025-07-08 20:34:03.247866: Epoch time: 48.22 s 
2025-07-08 20:34:05.103863:  
2025-07-08 20:34:05.104673: Epoch 319 
2025-07-08 20:34:05.104799: Current learning rate: 0.00708 
2025-07-08 20:34:53.412158: train_loss -0.6281 
2025-07-08 20:34:53.413029: val_loss -0.6487 
2025-07-08 20:34:53.413293: Pseudo dice [np.float32(0.8489)] 
2025-07-08 20:34:53.413479: Epoch time: 48.31 s 
2025-07-08 20:34:54.679061:  
2025-07-08 20:34:54.679248: Epoch 320 
2025-07-08 20:34:54.679365: Current learning rate: 0.00707 
2025-07-08 20:35:43.966724: train_loss -0.6317 
2025-07-08 20:35:43.967310: val_loss -0.6471 
2025-07-08 20:35:43.967537: Pseudo dice [np.float32(0.8457)] 
2025-07-08 20:35:43.967814: Epoch time: 49.29 s 
2025-07-08 20:35:45.255189:  
2025-07-08 20:35:45.255397: Epoch 321 
2025-07-08 20:35:45.255521: Current learning rate: 0.00706 
2025-07-08 20:36:35.448617: train_loss -0.6286 
2025-07-08 20:36:35.448983: val_loss -0.6129 
2025-07-08 20:36:35.449063: Pseudo dice [np.float32(0.8333)] 
2025-07-08 20:36:35.449157: Epoch time: 50.19 s 
2025-07-08 20:36:36.647753:  
2025-07-08 20:36:36.648198: Epoch 322 
2025-07-08 20:36:36.648318: Current learning rate: 0.00705 
2025-07-08 20:37:27.079129: train_loss -0.6163 
2025-07-08 20:37:27.079480: val_loss -0.6412 
2025-07-08 20:37:27.079573: Pseudo dice [np.float32(0.823)] 
2025-07-08 20:37:27.079679: Epoch time: 50.43 s 
2025-07-08 20:37:28.232135:  
2025-07-08 20:37:28.232650: Epoch 323 
2025-07-08 20:37:28.232783: Current learning rate: 0.00704 
2025-07-08 20:38:17.141583: train_loss -0.5991 
2025-07-08 20:38:17.142200: val_loss -0.5518 
2025-07-08 20:38:17.142295: Pseudo dice [np.float32(0.7664)] 
2025-07-08 20:38:17.142421: Epoch time: 48.91 s 
2025-07-08 20:38:18.357502:  
2025-07-08 20:38:18.357831: Epoch 324 
2025-07-08 20:38:18.357962: Current learning rate: 0.00703 
2025-07-08 20:39:07.254678: train_loss -0.5887 
2025-07-08 20:39:07.255061: val_loss -0.599 
2025-07-08 20:39:07.255142: Pseudo dice [np.float32(0.7958)] 
2025-07-08 20:39:07.255251: Epoch time: 48.9 s 
2025-07-08 20:39:08.413197:  
2025-07-08 20:39:08.413488: Epoch 325 
2025-07-08 20:39:08.413727: Current learning rate: 0.00702 
2025-07-08 20:39:57.128213: train_loss -0.5939 
2025-07-08 20:39:57.128558: val_loss -0.6145 
2025-07-08 20:39:57.128641: Pseudo dice [np.float32(0.8293)] 
2025-07-08 20:39:57.128749: Epoch time: 48.72 s 
2025-07-08 20:39:58.289011:  
2025-07-08 20:39:58.289243: Epoch 326 
2025-07-08 20:39:58.289361: Current learning rate: 0.00701 
2025-07-08 20:40:47.753676: train_loss -0.6182 
2025-07-08 20:40:47.754012: val_loss -0.6482 
2025-07-08 20:40:47.754097: Pseudo dice [np.float32(0.8151)] 
2025-07-08 20:40:47.754191: Epoch time: 49.47 s 
2025-07-08 20:40:48.925587:  
2025-07-08 20:40:48.925914: Epoch 327 
2025-07-08 20:40:48.926097: Current learning rate: 0.007 
2025-07-08 20:41:37.753278: train_loss -0.5882 
2025-07-08 20:41:37.754894: val_loss -0.6075 
2025-07-08 20:41:37.755104: Pseudo dice [np.float32(0.8057)] 
2025-07-08 20:41:37.755306: Epoch time: 48.83 s 
2025-07-08 20:41:38.992869:  
2025-07-08 20:41:38.993261: Epoch 328 
2025-07-08 20:41:38.993408: Current learning rate: 0.00699 
2025-07-08 20:42:26.779655: train_loss -0.5987 
2025-07-08 20:42:26.780131: val_loss -0.5891 
2025-07-08 20:42:26.780223: Pseudo dice [np.float32(0.7675)] 
2025-07-08 20:42:26.780345: Epoch time: 47.79 s 
2025-07-08 20:42:27.933707:  
2025-07-08 20:42:27.934338: Epoch 329 
2025-07-08 20:42:27.934530: Current learning rate: 0.00698 
2025-07-08 20:43:16.298878: train_loss -0.5924 
2025-07-08 20:43:16.299556: val_loss -0.6128 
2025-07-08 20:43:16.299647: Pseudo dice [np.float32(0.8109)] 
2025-07-08 20:43:16.299767: Epoch time: 48.37 s 
2025-07-08 20:43:17.456927:  
2025-07-08 20:43:17.457360: Epoch 330 
2025-07-08 20:43:17.457486: Current learning rate: 0.00697 
2025-07-08 20:44:05.216652: train_loss -0.6313 
2025-07-08 20:44:05.217352: val_loss -0.6338 
2025-07-08 20:44:05.217452: Pseudo dice [np.float32(0.8276)] 
2025-07-08 20:44:05.217588: Epoch time: 47.76 s 
2025-07-08 20:44:06.351494:  
2025-07-08 20:44:06.351917: Epoch 331 
2025-07-08 20:44:06.352039: Current learning rate: 0.00696 
2025-07-08 20:44:54.358073: train_loss -0.6212 
2025-07-08 20:44:54.359162: val_loss -0.6227 
2025-07-08 20:44:54.359280: Pseudo dice [np.float32(0.8324)] 
2025-07-08 20:44:54.359462: Epoch time: 48.01 s 
2025-07-08 20:44:55.517127:  
2025-07-08 20:44:55.517517: Epoch 332 
2025-07-08 20:44:55.517822: Current learning rate: 0.00696 
2025-07-08 20:45:43.002131: train_loss -0.6142 
2025-07-08 20:45:43.002896: val_loss -0.6343 
2025-07-08 20:45:43.003017: Pseudo dice [np.float32(0.8038)] 
2025-07-08 20:45:43.003172: Epoch time: 47.49 s 
2025-07-08 20:45:44.250652:  
2025-07-08 20:45:44.250810: Epoch 333 
2025-07-08 20:45:44.250947: Current learning rate: 0.00695 
2025-07-08 20:46:32.054743: train_loss -0.5986 
2025-07-08 20:46:32.055186: val_loss -0.6095 
2025-07-08 20:46:32.055272: Pseudo dice [np.float32(0.7997)] 
2025-07-08 20:46:32.055381: Epoch time: 47.81 s 
2025-07-08 20:46:34.254837:  
2025-07-08 20:46:34.255073: Epoch 334 
2025-07-08 20:46:34.255387: Current learning rate: 0.00694 
2025-07-08 20:47:22.143195: train_loss -0.5995 
2025-07-08 20:47:22.144078: val_loss -0.6136 
2025-07-08 20:47:22.144181: Pseudo dice [np.float32(0.824)] 
2025-07-08 20:47:22.144310: Epoch time: 47.89 s 
2025-07-08 20:47:23.390089:  
2025-07-08 20:47:23.390388: Epoch 335 
2025-07-08 20:47:23.390617: Current learning rate: 0.00693 
2025-07-08 20:48:11.103534: train_loss -0.6163 
2025-07-08 20:48:11.104289: val_loss -0.6351 
2025-07-08 20:48:11.104389: Pseudo dice [np.float32(0.8206)] 
2025-07-08 20:48:11.104509: Epoch time: 47.71 s 
2025-07-08 20:48:12.285400:  
2025-07-08 20:48:12.285826: Epoch 336 
2025-07-08 20:48:12.286060: Current learning rate: 0.00692 
2025-07-08 20:48:59.926551: train_loss -0.6335 
2025-07-08 20:48:59.927192: val_loss -0.6426 
2025-07-08 20:48:59.927395: Pseudo dice [np.float32(0.8234)] 
2025-07-08 20:48:59.927657: Epoch time: 47.64 s 
2025-07-08 20:49:01.242938:  
2025-07-08 20:49:01.243480: Epoch 337 
2025-07-08 20:49:01.243768: Current learning rate: 0.00691 
2025-07-08 20:49:48.772699: train_loss -0.6452 
2025-07-08 20:49:48.773036: val_loss -0.6556 
2025-07-08 20:49:48.773116: Pseudo dice [np.float32(0.8487)] 
2025-07-08 20:49:48.773222: Epoch time: 47.53 s 
2025-07-08 20:49:49.960828:  
2025-07-08 20:49:49.961313: Epoch 338 
2025-07-08 20:49:49.961445: Current learning rate: 0.0069 
2025-07-08 20:50:37.330916: train_loss -0.6409 
2025-07-08 20:50:37.331351: val_loss -0.6523 
2025-07-08 20:50:37.331441: Pseudo dice [np.float32(0.8429)] 
2025-07-08 20:50:37.331570: Epoch time: 47.37 s 
2025-07-08 20:50:38.563359:  
2025-07-08 20:50:38.563876: Epoch 339 
2025-07-08 20:50:38.564038: Current learning rate: 0.00689 
2025-07-08 20:51:25.712081: train_loss -0.6476 
2025-07-08 20:51:25.712503: val_loss -0.6477 
2025-07-08 20:51:25.712595: Pseudo dice [np.float32(0.8571)] 
2025-07-08 20:51:25.712709: Epoch time: 47.15 s 
2025-07-08 20:51:26.905478:  
2025-07-08 20:51:26.906013: Epoch 340 
2025-07-08 20:51:26.906250: Current learning rate: 0.00688 
2025-07-08 20:52:14.700157: train_loss -0.6367 
2025-07-08 20:52:14.700886: val_loss -0.6383 
2025-07-08 20:52:14.700974: Pseudo dice [np.float32(0.8372)] 
2025-07-08 20:52:14.701095: Epoch time: 47.8 s 
2025-07-08 20:52:15.866777:  
2025-07-08 20:52:15.867144: Epoch 341 
2025-07-08 20:52:15.867332: Current learning rate: 0.00687 
2025-07-08 20:53:02.975677: train_loss -0.6149 
2025-07-08 20:53:02.976200: val_loss -0.6253 
2025-07-08 20:53:02.976285: Pseudo dice [np.float32(0.8218)] 
2025-07-08 20:53:02.976396: Epoch time: 47.11 s 
2025-07-08 20:53:04.174984:  
2025-07-08 20:53:04.175272: Epoch 342 
2025-07-08 20:53:04.175727: Current learning rate: 0.00686 
2025-07-08 20:53:50.733395: train_loss -0.6008 
2025-07-08 20:53:50.734828: val_loss -0.6444 
2025-07-08 20:53:50.735041: Pseudo dice [np.float32(0.8284)] 
2025-07-08 20:53:50.735638: Epoch time: 46.56 s 
2025-07-08 20:53:52.030114:  
2025-07-08 20:53:52.030437: Epoch 343 
2025-07-08 20:53:52.030562: Current learning rate: 0.00685 
2025-07-08 20:54:40.369570: train_loss -0.6098 
2025-07-08 20:54:40.370209: val_loss -0.6228 
2025-07-08 20:54:40.370298: Pseudo dice [np.float32(0.8186)] 
2025-07-08 20:54:40.370428: Epoch time: 48.34 s 
2025-07-08 20:54:41.566359:  
2025-07-08 20:54:41.566620: Epoch 344 
2025-07-08 20:54:41.566805: Current learning rate: 0.00684 
2025-07-08 20:55:29.351186: train_loss -0.6113 
2025-07-08 20:55:29.351686: val_loss -0.6434 
2025-07-08 20:55:29.351775: Pseudo dice [np.float32(0.8342)] 
2025-07-08 20:55:29.351886: Epoch time: 47.79 s 
2025-07-08 20:55:30.642747:  
2025-07-08 20:55:30.643440: Epoch 345 
2025-07-08 20:55:30.643589: Current learning rate: 0.00683 
2025-07-08 20:56:17.676056: train_loss -0.6312 
2025-07-08 20:56:17.676408: val_loss -0.6244 
2025-07-08 20:56:17.676489: Pseudo dice [np.float32(0.8217)] 
2025-07-08 20:56:17.676631: Epoch time: 47.03 s 
2025-07-08 20:56:18.867865:  
2025-07-08 20:56:18.868087: Epoch 346 
2025-07-08 20:56:18.868254: Current learning rate: 0.00682 
2025-07-08 20:57:05.146889: train_loss -0.6437 
2025-07-08 20:57:05.147679: val_loss -0.6602 
2025-07-08 20:57:05.147768: Pseudo dice [np.float32(0.8553)] 
2025-07-08 20:57:05.147882: Epoch time: 46.28 s 
2025-07-08 20:57:06.324960:  
2025-07-08 20:57:06.325147: Epoch 347 
2025-07-08 20:57:06.325271: Current learning rate: 0.00681 
2025-07-08 20:57:53.505282: train_loss -0.6373 
2025-07-08 20:57:53.505857: val_loss -0.6422 
2025-07-08 20:57:53.505943: Pseudo dice [np.float32(0.8291)] 
2025-07-08 20:57:53.506081: Epoch time: 47.18 s 
2025-07-08 20:57:55.684231:  
2025-07-08 20:57:55.684890: Epoch 348 
2025-07-08 20:57:55.685044: Current learning rate: 0.0068 
2025-07-08 20:58:42.970361: train_loss -0.6236 
2025-07-08 20:58:42.970760: val_loss -0.6064 
2025-07-08 20:58:42.970842: Pseudo dice [np.float32(0.8232)] 
2025-07-08 20:58:42.970956: Epoch time: 47.29 s 
2025-07-08 20:58:44.123000:  
2025-07-08 20:58:44.123325: Epoch 349 
2025-07-08 20:58:44.123451: Current learning rate: 0.0068 
2025-07-08 20:59:30.967565: train_loss -0.6171 
2025-07-08 20:59:30.968276: val_loss -0.6532 
2025-07-08 20:59:30.968369: Pseudo dice [np.float32(0.8455)] 
2025-07-08 20:59:30.968513: Epoch time: 46.85 s 
2025-07-08 20:59:32.642526:  
2025-07-08 20:59:32.642882: Epoch 350 
2025-07-08 20:59:32.643028: Current learning rate: 0.00679 
2025-07-08 21:00:19.262212: train_loss -0.6225 
2025-07-08 21:00:19.262868: val_loss -0.6294 
2025-07-08 21:00:19.262982: Pseudo dice [np.float32(0.8158)] 
2025-07-08 21:00:19.263099: Epoch time: 46.62 s 
2025-07-08 21:00:20.508153:  
2025-07-08 21:00:20.508489: Epoch 351 
2025-07-08 21:00:20.508698: Current learning rate: 0.00678 
2025-07-08 21:01:07.755199: train_loss -0.6119 
2025-07-08 21:01:07.755682: val_loss -0.6363 
2025-07-08 21:01:07.755763: Pseudo dice [np.float32(0.8413)] 
2025-07-08 21:01:07.755859: Epoch time: 47.25 s 
2025-07-08 21:01:08.933654:  
2025-07-08 21:01:08.933874: Epoch 352 
2025-07-08 21:01:08.934150: Current learning rate: 0.00677 
2025-07-08 21:01:55.432981: train_loss -0.6294 
2025-07-08 21:01:55.433494: val_loss -0.6498 
2025-07-08 21:01:55.433597: Pseudo dice [np.float32(0.8239)] 
2025-07-08 21:01:55.433703: Epoch time: 46.5 s 
2025-07-08 21:01:56.608806:  
2025-07-08 21:01:56.609199: Epoch 353 
2025-07-08 21:01:56.609438: Current learning rate: 0.00676 
2025-07-08 21:02:44.524411: train_loss -0.6314 
2025-07-08 21:02:44.525808: val_loss -0.6406 
2025-07-08 21:02:44.526044: Pseudo dice [np.float32(0.8395)] 
2025-07-08 21:02:44.526198: Epoch time: 47.92 s 
2025-07-08 21:02:45.767861:  
2025-07-08 21:02:45.768121: Epoch 354 
2025-07-08 21:02:45.768281: Current learning rate: 0.00675 
2025-07-08 21:03:32.547708: train_loss -0.595 
2025-07-08 21:03:32.548342: val_loss -0.5912 
2025-07-08 21:03:32.548447: Pseudo dice [np.float32(0.775)] 
2025-07-08 21:03:32.548637: Epoch time: 46.78 s 
2025-07-08 21:03:33.705576:  
2025-07-08 21:03:33.705865: Epoch 355 
2025-07-08 21:03:33.706015: Current learning rate: 0.00674 
2025-07-08 21:04:19.888479: train_loss -0.5794 
2025-07-08 21:04:19.888886: val_loss -0.6273 
2025-07-08 21:04:19.888968: Pseudo dice [np.float32(0.8237)] 
2025-07-08 21:04:19.889067: Epoch time: 46.18 s 
2025-07-08 21:04:21.206383:  
2025-07-08 21:04:21.206641: Epoch 356 
2025-07-08 21:04:21.206819: Current learning rate: 0.00673 
2025-07-08 21:05:08.846295: train_loss -0.6088 
2025-07-08 21:05:08.846836: val_loss -0.6238 
2025-07-08 21:05:08.846950: Pseudo dice [np.float32(0.8341)] 
2025-07-08 21:05:08.847089: Epoch time: 47.64 s 
2025-07-08 21:05:10.044880:  
2025-07-08 21:05:10.045141: Epoch 357 
2025-07-08 21:05:10.045286: Current learning rate: 0.00672 
2025-07-08 21:05:56.864807: train_loss -0.5926 
2025-07-08 21:05:56.865289: val_loss -0.6272 
2025-07-08 21:05:56.865379: Pseudo dice [np.float32(0.8252)] 
2025-07-08 21:05:56.865590: Epoch time: 46.82 s 
2025-07-08 21:05:57.999246:  
2025-07-08 21:05:57.999692: Epoch 358 
2025-07-08 21:05:57.999859: Current learning rate: 0.00671 
2025-07-08 21:06:44.381147: train_loss -0.6118 
2025-07-08 21:06:44.382000: val_loss -0.6239 
2025-07-08 21:06:44.382104: Pseudo dice [np.float32(0.8243)] 
2025-07-08 21:06:44.382236: Epoch time: 46.38 s 
2025-07-08 21:06:45.570946:  
2025-07-08 21:06:45.571443: Epoch 359 
2025-07-08 21:06:45.571583: Current learning rate: 0.0067 
2025-07-08 21:07:33.146430: train_loss -0.6209 
2025-07-08 21:07:33.146940: val_loss -0.6561 
2025-07-08 21:07:33.147039: Pseudo dice [np.float32(0.8238)] 
2025-07-08 21:07:33.147159: Epoch time: 47.58 s 
2025-07-08 21:07:34.299871:  
2025-07-08 21:07:34.300146: Epoch 360 
2025-07-08 21:07:34.300321: Current learning rate: 0.00669 
2025-07-08 21:08:21.972731: train_loss -0.6226 
2025-07-08 21:08:21.973300: val_loss -0.6282 
2025-07-08 21:08:21.973387: Pseudo dice [np.float32(0.8133)] 
2025-07-08 21:08:21.973484: Epoch time: 47.67 s 
2025-07-08 21:08:23.167074:  
2025-07-08 21:08:23.167465: Epoch 361 
2025-07-08 21:08:23.167609: Current learning rate: 0.00668 
2025-07-08 21:09:12.197287: train_loss -0.6199 
2025-07-08 21:09:12.197906: val_loss -0.6295 
2025-07-08 21:09:12.198002: Pseudo dice [np.float32(0.8236)] 
2025-07-08 21:09:12.198118: Epoch time: 49.03 s 
2025-07-08 21:09:14.014632:  
2025-07-08 21:09:14.015139: Epoch 362 
2025-07-08 21:09:14.015316: Current learning rate: 0.00667 
2025-07-08 21:10:02.221237: train_loss -0.6257 
2025-07-08 21:10:02.221690: val_loss -0.6523 
2025-07-08 21:10:02.221771: Pseudo dice [np.float32(0.8448)] 
2025-07-08 21:10:02.221871: Epoch time: 48.21 s 
2025-07-08 21:10:03.386137:  
2025-07-08 21:10:03.386757: Epoch 363 
2025-07-08 21:10:03.386882: Current learning rate: 0.00666 
2025-07-08 21:10:49.747916: train_loss -0.6305 
2025-07-08 21:10:49.748258: val_loss -0.6563 
2025-07-08 21:10:49.748343: Pseudo dice [np.float32(0.8396)] 
2025-07-08 21:10:49.748566: Epoch time: 46.36 s 
2025-07-08 21:10:50.948803:  
2025-07-08 21:10:50.949061: Epoch 364 
2025-07-08 21:10:50.949330: Current learning rate: 0.00665 
2025-07-08 21:11:37.199730: train_loss -0.6306 
2025-07-08 21:11:37.200519: val_loss -0.6317 
2025-07-08 21:11:37.200725: Pseudo dice [np.float32(0.8418)] 
2025-07-08 21:11:37.200873: Epoch time: 46.25 s 
2025-07-08 21:11:38.480037:  
2025-07-08 21:11:38.480244: Epoch 365 
2025-07-08 21:11:38.480360: Current learning rate: 0.00665 
2025-07-08 21:12:24.841524: train_loss -0.6352 
2025-07-08 21:12:24.842258: val_loss -0.6574 
2025-07-08 21:12:24.842405: Pseudo dice [np.float32(0.8406)] 
2025-07-08 21:12:24.842524: Epoch time: 46.36 s 
2025-07-08 21:12:26.117782:  
2025-07-08 21:12:26.118299: Epoch 366 
2025-07-08 21:12:26.118429: Current learning rate: 0.00664 
2025-07-08 21:13:13.086523: train_loss -0.6489 
2025-07-08 21:13:13.086867: val_loss -0.6657 
2025-07-08 21:13:13.086952: Pseudo dice [np.float32(0.8448)] 
2025-07-08 21:13:13.087054: Epoch time: 46.97 s 
2025-07-08 21:13:14.255170:  
2025-07-08 21:13:14.255434: Epoch 367 
2025-07-08 21:13:14.255648: Current learning rate: 0.00663 
2025-07-08 21:14:01.304204: train_loss -0.6453 
2025-07-08 21:14:01.304687: val_loss -0.6606 
2025-07-08 21:14:01.304803: Pseudo dice [np.float32(0.8439)] 
2025-07-08 21:14:01.304919: Epoch time: 47.05 s 
2025-07-08 21:14:02.519585:  
2025-07-08 21:14:02.520056: Epoch 368 
2025-07-08 21:14:02.520268: Current learning rate: 0.00662 
2025-07-08 21:14:49.918471: train_loss -0.6466 
2025-07-08 21:14:49.919516: val_loss -0.6532 
2025-07-08 21:14:49.919695: Pseudo dice [np.float32(0.8433)] 
2025-07-08 21:14:49.919848: Epoch time: 47.4 s 
2025-07-08 21:14:51.147125:  
2025-07-08 21:14:51.147653: Epoch 369 
2025-07-08 21:14:51.147792: Current learning rate: 0.00661 
2025-07-08 21:15:38.264781: train_loss -0.6499 
2025-07-08 21:15:38.265559: val_loss -0.6611 
2025-07-08 21:15:38.265663: Pseudo dice [np.float32(0.8486)] 
2025-07-08 21:15:38.265806: Epoch time: 47.12 s 
2025-07-08 21:15:39.460563:  
2025-07-08 21:15:39.460947: Epoch 370 
2025-07-08 21:15:39.461117: Current learning rate: 0.0066 
2025-07-08 21:16:26.002801: train_loss -0.6345 
2025-07-08 21:16:26.003403: val_loss -0.6719 
2025-07-08 21:16:26.003495: Pseudo dice [np.float32(0.8507)] 
2025-07-08 21:16:26.003624: Epoch time: 46.54 s 
2025-07-08 21:16:27.229572:  
2025-07-08 21:16:27.229936: Epoch 371 
2025-07-08 21:16:27.230138: Current learning rate: 0.00659 
2025-07-08 21:17:14.306569: train_loss -0.642 
2025-07-08 21:17:14.307056: val_loss -0.6676 
2025-07-08 21:17:14.307144: Pseudo dice [np.float32(0.8444)] 
2025-07-08 21:17:14.307250: Epoch time: 47.08 s 
2025-07-08 21:17:15.604525:  
2025-07-08 21:17:15.604935: Epoch 372 
2025-07-08 21:17:15.605125: Current learning rate: 0.00658 
2025-07-08 21:18:02.678197: train_loss -0.6421 
2025-07-08 21:18:02.678633: val_loss -0.6376 
2025-07-08 21:18:02.678716: Pseudo dice [np.float32(0.8387)] 
2025-07-08 21:18:02.678823: Epoch time: 47.07 s 
2025-07-08 21:18:03.824468:  
2025-07-08 21:18:03.824793: Epoch 373 
2025-07-08 21:18:03.824998: Current learning rate: 0.00657 
2025-07-08 21:18:49.701175: train_loss -0.6317 
2025-07-08 21:18:49.701789: val_loss -0.6369 
2025-07-08 21:18:49.701913: Pseudo dice [np.float32(0.8343)] 
2025-07-08 21:18:49.702057: Epoch time: 45.88 s 
2025-07-08 21:18:50.894034:  
2025-07-08 21:18:50.894383: Epoch 374 
2025-07-08 21:18:50.894562: Current learning rate: 0.00656 
2025-07-08 21:19:37.405015: train_loss -0.6358 
2025-07-08 21:19:37.405508: val_loss -0.6635 
2025-07-08 21:19:37.405617: Pseudo dice [np.float32(0.8491)] 
2025-07-08 21:19:37.405733: Epoch time: 46.51 s 
2025-07-08 21:19:38.610423:  
2025-07-08 21:19:38.610704: Epoch 375 
2025-07-08 21:19:38.610838: Current learning rate: 0.00655 
2025-07-08 21:20:25.060832: train_loss -0.6344 
2025-07-08 21:20:25.061537: val_loss -0.6393 
2025-07-08 21:20:25.061682: Pseudo dice [np.float32(0.8297)] 
2025-07-08 21:20:25.061835: Epoch time: 46.45 s 
2025-07-08 21:20:27.018687:  
2025-07-08 21:20:27.019110: Epoch 376 
2025-07-08 21:20:27.019593: Current learning rate: 0.00654 
2025-07-08 21:21:13.609572: train_loss -0.6456 
2025-07-08 21:21:13.610183: val_loss -0.6558 
2025-07-08 21:21:13.610263: Pseudo dice [np.float32(0.8513)] 
2025-07-08 21:21:13.610372: Epoch time: 46.59 s 
2025-07-08 21:21:14.847701:  
2025-07-08 21:21:14.848350: Epoch 377 
2025-07-08 21:21:14.848635: Current learning rate: 0.00653 
2025-07-08 21:22:01.517786: train_loss -0.6417 
2025-07-08 21:22:01.518413: val_loss -0.625 
2025-07-08 21:22:01.518525: Pseudo dice [np.float32(0.8341)] 
2025-07-08 21:22:01.518674: Epoch time: 46.67 s 
2025-07-08 21:22:02.788381:  
2025-07-08 21:22:02.788884: Epoch 378 
2025-07-08 21:22:02.789019: Current learning rate: 0.00652 
2025-07-08 21:22:50.105392: train_loss -0.6242 
2025-07-08 21:22:50.105817: val_loss -0.6466 
2025-07-08 21:22:50.105903: Pseudo dice [np.float32(0.8365)] 
2025-07-08 21:22:50.106004: Epoch time: 47.32 s 
2025-07-08 21:22:51.324107:  
2025-07-08 21:22:51.324583: Epoch 379 
2025-07-08 21:22:51.324761: Current learning rate: 0.00651 
2025-07-08 21:23:39.390177: train_loss -0.6368 
2025-07-08 21:23:39.390968: val_loss -0.658 
2025-07-08 21:23:39.391066: Pseudo dice [np.float32(0.8559)] 
2025-07-08 21:23:39.391222: Epoch time: 48.07 s 
2025-07-08 21:23:40.591841:  
2025-07-08 21:23:40.592273: Epoch 380 
2025-07-08 21:23:40.592518: Current learning rate: 0.0065 
2025-07-08 21:24:27.555101: train_loss -0.6508 
2025-07-08 21:24:27.555677: val_loss -0.6612 
2025-07-08 21:24:27.555762: Pseudo dice [np.float32(0.8535)] 
2025-07-08 21:24:27.555909: Epoch time: 46.96 s 
2025-07-08 21:24:28.786642:  
2025-07-08 21:24:28.786880: Epoch 381 
2025-07-08 21:24:28.787023: Current learning rate: 0.00649 
2025-07-08 21:25:16.347311: train_loss -0.6082 
2025-07-08 21:25:16.347867: val_loss -0.6253 
2025-07-08 21:25:16.347952: Pseudo dice [np.float32(0.8303)] 
2025-07-08 21:25:16.348073: Epoch time: 47.56 s 
2025-07-08 21:25:17.624547:  
2025-07-08 21:25:17.624917: Epoch 382 
2025-07-08 21:25:17.625020: Current learning rate: 0.00648 
2025-07-08 21:26:04.219997: train_loss -0.6182 
2025-07-08 21:26:04.220348: val_loss -0.6405 
2025-07-08 21:26:04.220434: Pseudo dice [np.float32(0.8274)] 
2025-07-08 21:26:04.220532: Epoch time: 46.6 s 
2025-07-08 21:26:05.510981:  
2025-07-08 21:26:05.511416: Epoch 383 
2025-07-08 21:26:05.511648: Current learning rate: 0.00648 
2025-07-08 21:26:51.776050: train_loss -0.6267 
2025-07-08 21:26:51.776524: val_loss -0.6514 
2025-07-08 21:26:51.776612: Pseudo dice [np.float32(0.8473)] 
2025-07-08 21:26:51.776726: Epoch time: 46.27 s 
2025-07-08 21:26:52.982104:  
2025-07-08 21:26:52.982688: Epoch 384 
2025-07-08 21:26:52.982958: Current learning rate: 0.00647 
2025-07-08 21:27:39.484020: train_loss -0.641 
2025-07-08 21:27:39.485015: val_loss -0.6506 
2025-07-08 21:27:39.485320: Pseudo dice [np.float32(0.8411)] 
2025-07-08 21:27:39.485574: Epoch time: 46.5 s 
2025-07-08 21:27:40.747975:  
2025-07-08 21:27:40.748652: Epoch 385 
2025-07-08 21:27:40.748828: Current learning rate: 0.00646 
2025-07-08 21:28:28.043051: train_loss -0.6269 
2025-07-08 21:28:28.043568: val_loss -0.5995 
2025-07-08 21:28:28.043675: Pseudo dice [np.float32(0.8243)] 
2025-07-08 21:28:28.043805: Epoch time: 47.3 s 
2025-07-08 21:28:29.244666:  
2025-07-08 21:28:29.245078: Epoch 386 
2025-07-08 21:28:29.245432: Current learning rate: 0.00645 
2025-07-08 21:29:15.041270: train_loss -0.617 
2025-07-08 21:29:15.042045: val_loss -0.635 
2025-07-08 21:29:15.042131: Pseudo dice [np.float32(0.842)] 
2025-07-08 21:29:15.042252: Epoch time: 45.8 s 
2025-07-08 21:29:16.326384:  
2025-07-08 21:29:16.326941: Epoch 387 
2025-07-08 21:29:16.327145: Current learning rate: 0.00644 
2025-07-08 21:30:02.930949: train_loss -0.6301 
2025-07-08 21:30:02.931697: val_loss -0.6474 
2025-07-08 21:30:02.931796: Pseudo dice [np.float32(0.8563)] 
2025-07-08 21:30:02.931915: Epoch time: 46.61 s 
2025-07-08 21:30:04.183744:  
2025-07-08 21:30:04.184187: Epoch 388 
2025-07-08 21:30:04.184365: Current learning rate: 0.00643 
2025-07-08 21:30:50.397368: train_loss -0.631 
2025-07-08 21:30:50.397804: val_loss -0.6179 
2025-07-08 21:30:50.397981: Pseudo dice [np.float32(0.8163)] 
2025-07-08 21:30:50.398085: Epoch time: 46.21 s 
2025-07-08 21:30:51.653674:  
2025-07-08 21:30:51.653875: Epoch 389 
2025-07-08 21:30:51.654192: Current learning rate: 0.00642 
2025-07-08 21:31:38.930522: train_loss -0.6272 
2025-07-08 21:31:38.930882: val_loss -0.6478 
2025-07-08 21:31:38.930961: Pseudo dice [np.float32(0.8377)] 
2025-07-08 21:31:38.931132: Epoch time: 47.28 s 
2025-07-08 21:31:41.045775:  
2025-07-08 21:31:41.046244: Epoch 390 
2025-07-08 21:31:41.046502: Current learning rate: 0.00641 
2025-07-08 21:32:27.613963: train_loss -0.6543 
2025-07-08 21:32:27.614713: val_loss -0.6435 
2025-07-08 21:32:27.614829: Pseudo dice [np.float32(0.8502)] 
2025-07-08 21:32:27.614981: Epoch time: 46.57 s 
2025-07-08 21:32:28.816202:  
2025-07-08 21:32:28.816569: Epoch 391 
2025-07-08 21:32:28.816832: Current learning rate: 0.0064 
2025-07-08 21:33:16.022865: train_loss -0.65 
2025-07-08 21:33:16.023302: val_loss -0.6486 
2025-07-08 21:33:16.023403: Pseudo dice [np.float32(0.841)] 
2025-07-08 21:33:16.023575: Epoch time: 47.21 s 
2025-07-08 21:33:17.220736:  
2025-07-08 21:33:17.221273: Epoch 392 
2025-07-08 21:33:17.221622: Current learning rate: 0.00639 
2025-07-08 21:34:04.617638: train_loss -0.6287 
2025-07-08 21:34:04.618119: val_loss -0.6503 
2025-07-08 21:34:04.618231: Pseudo dice [np.float32(0.8602)] 
2025-07-08 21:34:04.618422: Epoch time: 47.4 s 
2025-07-08 21:34:05.813226:  
2025-07-08 21:34:05.813781: Epoch 393 
2025-07-08 21:34:05.813944: Current learning rate: 0.00638 
2025-07-08 21:34:52.626702: train_loss -0.6372 
2025-07-08 21:34:52.628093: val_loss -0.6561 
2025-07-08 21:34:52.628479: Pseudo dice [np.float32(0.8553)] 
2025-07-08 21:34:52.628873: Epoch time: 46.81 s 
2025-07-08 21:34:53.823295:  
2025-07-08 21:34:53.823729: Epoch 394 
2025-07-08 21:34:53.823860: Current learning rate: 0.00637 
2025-07-08 21:35:40.817290: train_loss -0.6376 
2025-07-08 21:35:40.817812: val_loss -0.6323 
2025-07-08 21:35:40.817904: Pseudo dice [np.float32(0.8438)] 
2025-07-08 21:35:40.818019: Epoch time: 47.0 s 
2025-07-08 21:35:42.098599:  
2025-07-08 21:35:42.099073: Epoch 395 
2025-07-08 21:35:42.099303: Current learning rate: 0.00636 
2025-07-08 21:36:29.008274: train_loss -0.6318 
2025-07-08 21:36:29.008709: val_loss -0.6516 
2025-07-08 21:36:29.008802: Pseudo dice [np.float32(0.8498)] 
2025-07-08 21:36:29.008923: Epoch time: 46.91 s 
2025-07-08 21:36:30.199492:  
2025-07-08 21:36:30.199695: Epoch 396 
2025-07-08 21:36:30.199825: Current learning rate: 0.00635 
2025-07-08 21:37:17.253889: train_loss -0.6487 
2025-07-08 21:37:17.254465: val_loss -0.6616 
2025-07-08 21:37:17.254565: Pseudo dice [np.float32(0.8631)] 
2025-07-08 21:37:17.254684: Epoch time: 47.06 s 
2025-07-08 21:37:18.537288:  
2025-07-08 21:37:18.537698: Epoch 397 
2025-07-08 21:37:18.537936: Current learning rate: 0.00634 
2025-07-08 21:38:05.668799: train_loss -0.6517 
2025-07-08 21:38:05.669212: val_loss -0.6543 
2025-07-08 21:38:05.669301: Pseudo dice [np.float32(0.8616)] 
2025-07-08 21:38:05.669422: Epoch time: 47.13 s 
2025-07-08 21:38:06.876389:  
2025-07-08 21:38:06.876768: Epoch 398 
2025-07-08 21:38:06.876908: Current learning rate: 0.00633 
2025-07-08 21:38:54.556602: train_loss -0.6218 
2025-07-08 21:38:54.557346: val_loss -0.6435 
2025-07-08 21:38:54.557572: Pseudo dice [np.float32(0.8359)] 
2025-07-08 21:38:54.557755: Epoch time: 47.68 s 
2025-07-08 21:38:55.835940:  
2025-07-08 21:38:55.836305: Epoch 399 
2025-07-08 21:38:55.836434: Current learning rate: 0.00632 
2025-07-08 21:39:42.902314: train_loss -0.6097 
2025-07-08 21:39:42.902712: val_loss -0.657 
2025-07-08 21:39:42.902789: Pseudo dice [np.float32(0.8268)] 
2025-07-08 21:39:42.902893: Epoch time: 47.07 s 
2025-07-08 21:39:44.596450:  
2025-07-08 21:39:44.596916: Epoch 400 
2025-07-08 21:39:44.597118: Current learning rate: 0.00631 
2025-07-08 21:40:30.929275: train_loss -0.6432 
2025-07-08 21:40:30.930257: val_loss -0.6509 
2025-07-08 21:40:30.930371: Pseudo dice [np.float32(0.8444)] 
2025-07-08 21:40:30.930533: Epoch time: 46.33 s 
2025-07-08 21:40:32.144421:  
2025-07-08 21:40:32.144980: Epoch 401 
2025-07-08 21:40:32.145205: Current learning rate: 0.0063 
2025-07-08 21:41:19.361631: train_loss -0.618 
2025-07-08 21:41:19.362424: val_loss -0.6313 
2025-07-08 21:41:19.366090: Pseudo dice [np.float32(0.8281)] 
2025-07-08 21:41:19.366245: Epoch time: 47.22 s 
2025-07-08 21:41:20.559456:  
2025-07-08 21:41:20.559627: Epoch 402 
2025-07-08 21:41:20.559749: Current learning rate: 0.0063 
2025-07-08 21:42:06.934446: train_loss -0.6372 
2025-07-08 21:42:06.934922: val_loss -0.6554 
2025-07-08 21:42:06.935026: Pseudo dice [np.float32(0.8473)] 
2025-07-08 21:42:06.935164: Epoch time: 46.38 s 
2025-07-08 21:42:08.169847:  
2025-07-08 21:42:08.170342: Epoch 403 
2025-07-08 21:42:08.170479: Current learning rate: 0.00629 
2025-07-08 21:42:55.001923: train_loss -0.6103 
2025-07-08 21:42:55.002606: val_loss -0.6551 
2025-07-08 21:42:55.002775: Pseudo dice [np.float32(0.835)] 
2025-07-08 21:42:55.002990: Epoch time: 46.83 s 
2025-07-08 21:42:57.161344:  
2025-07-08 21:42:57.161774: Epoch 404 
2025-07-08 21:42:57.161934: Current learning rate: 0.00628 
2025-07-08 21:43:44.351403: train_loss -0.6372 
2025-07-08 21:43:44.352021: val_loss -0.6462 
2025-07-08 21:43:44.352119: Pseudo dice [np.float32(0.8198)] 
2025-07-08 21:43:44.352249: Epoch time: 47.19 s 
2025-07-08 21:43:45.605977:  
2025-07-08 21:43:45.606828: Epoch 405 
2025-07-08 21:43:45.607048: Current learning rate: 0.00627 
2025-07-08 21:44:32.312469: train_loss -0.6296 
2025-07-08 21:44:32.313206: val_loss -0.6385 
2025-07-08 21:44:32.313317: Pseudo dice [np.float32(0.8379)] 
2025-07-08 21:44:32.313531: Epoch time: 46.71 s 
2025-07-08 21:44:33.677891:  
2025-07-08 21:44:33.679143: Epoch 406 
2025-07-08 21:44:33.679521: Current learning rate: 0.00626 
2025-07-08 21:45:23.210871: train_loss -0.6301 
2025-07-08 21:45:23.211428: val_loss -0.6367 
2025-07-08 21:45:23.211525: Pseudo dice [np.float32(0.8472)] 
2025-07-08 21:45:23.211671: Epoch time: 49.53 s 
2025-07-08 21:45:24.425533:  
2025-07-08 21:45:24.425972: Epoch 407 
2025-07-08 21:45:24.426136: Current learning rate: 0.00625 
2025-07-08 21:46:11.397270: train_loss -0.6155 
2025-07-08 21:46:11.397891: val_loss -0.6337 
2025-07-08 21:46:11.397990: Pseudo dice [np.float32(0.848)] 
2025-07-08 21:46:11.398105: Epoch time: 46.97 s 
2025-07-08 21:46:12.630827:  
2025-07-08 21:46:12.631311: Epoch 408 
2025-07-08 21:46:12.631446: Current learning rate: 0.00624 
2025-07-08 21:47:01.311105: train_loss -0.6159 
2025-07-08 21:47:01.312424: val_loss -0.6206 
2025-07-08 21:47:01.312628: Pseudo dice [np.float32(0.8388)] 
2025-07-08 21:47:01.312789: Epoch time: 48.68 s 
2025-07-08 21:47:02.649910:  
2025-07-08 21:47:02.650253: Epoch 409 
2025-07-08 21:47:02.650413: Current learning rate: 0.00623 
2025-07-08 21:47:52.247694: train_loss -0.6329 
2025-07-08 21:47:52.248445: val_loss -0.6361 
2025-07-08 21:47:52.248842: Pseudo dice [np.float32(0.8377)] 
2025-07-08 21:47:52.249143: Epoch time: 49.6 s 
2025-07-08 21:47:53.466383:  
2025-07-08 21:47:53.466717: Epoch 410 
2025-07-08 21:47:53.466925: Current learning rate: 0.00622 
2025-07-08 21:48:41.496324: train_loss -0.6411 
2025-07-08 21:48:41.497161: val_loss -0.6623 
2025-07-08 21:48:41.497289: Pseudo dice [np.float32(0.8542)] 
2025-07-08 21:48:41.497432: Epoch time: 48.03 s 
2025-07-08 21:48:42.738986:  
2025-07-08 21:48:42.739364: Epoch 411 
2025-07-08 21:48:42.739550: Current learning rate: 0.00621 
2025-07-08 21:49:30.721948: train_loss -0.6412 
2025-07-08 21:49:30.722569: val_loss -0.6369 
2025-07-08 21:49:30.726141: Pseudo dice [np.float32(0.8427)] 
2025-07-08 21:49:30.726368: Epoch time: 47.98 s 
2025-07-08 21:49:31.946618:  
2025-07-08 21:49:31.947574: Epoch 412 
2025-07-08 21:49:31.948036: Current learning rate: 0.0062 
2025-07-08 21:50:19.735991: train_loss -0.6379 
2025-07-08 21:50:19.736390: val_loss -0.6463 
2025-07-08 21:50:19.736581: Pseudo dice [np.float32(0.8459)] 
2025-07-08 21:50:19.736698: Epoch time: 47.79 s 
2025-07-08 21:50:20.979187:  
2025-07-08 21:50:20.979534: Epoch 413 
2025-07-08 21:50:20.979904: Current learning rate: 0.00619 
2025-07-08 21:51:10.236827: train_loss -0.6463 
2025-07-08 21:51:10.237454: val_loss -0.6593 
2025-07-08 21:51:10.237578: Pseudo dice [np.float32(0.8386)] 
2025-07-08 21:51:10.237747: Epoch time: 49.26 s 
2025-07-08 21:51:11.396035:  
2025-07-08 21:51:11.396557: Epoch 414 
2025-07-08 21:51:11.396691: Current learning rate: 0.00618 
2025-07-08 21:52:01.160841: train_loss -0.6506 
2025-07-08 21:52:01.161503: val_loss -0.6536 
2025-07-08 21:52:01.161619: Pseudo dice [np.float32(0.85)] 
2025-07-08 21:52:01.161746: Epoch time: 49.77 s 
2025-07-08 21:52:02.299278:  
2025-07-08 21:52:02.299575: Epoch 415 
2025-07-08 21:52:02.299752: Current learning rate: 0.00617 
2025-07-08 21:52:51.511645: train_loss -0.6521 
2025-07-08 21:52:51.512149: val_loss -0.6592 
2025-07-08 21:52:51.512223: Pseudo dice [np.float32(0.8589)] 
2025-07-08 21:52:51.512317: Epoch time: 49.21 s 
2025-07-08 21:52:52.651231:  
2025-07-08 21:52:52.651448: Epoch 416 
2025-07-08 21:52:52.651725: Current learning rate: 0.00616 
2025-07-08 21:53:42.274280: train_loss -0.6533 
2025-07-08 21:53:42.274690: val_loss -0.6692 
2025-07-08 21:53:42.274771: Pseudo dice [np.float32(0.8589)] 
2025-07-08 21:53:42.274893: Epoch time: 49.62 s 
2025-07-08 21:53:43.464061:  
2025-07-08 21:53:43.464434: Epoch 417 
2025-07-08 21:53:43.464691: Current learning rate: 0.00615 
2025-07-08 21:54:33.026139: train_loss -0.6574 
2025-07-08 21:54:33.026972: val_loss -0.6844 
2025-07-08 21:54:33.027097: Pseudo dice [np.float32(0.848)] 
2025-07-08 21:54:33.027242: Epoch time: 49.56 s 
2025-07-08 21:54:34.187064:  
2025-07-08 21:54:34.187261: Epoch 418 
2025-07-08 21:54:34.187608: Current learning rate: 0.00614 
2025-07-08 21:55:22.983967: train_loss -0.6422 
2025-07-08 21:55:22.984758: val_loss -0.6672 
2025-07-08 21:55:22.984863: Pseudo dice [np.float32(0.8518)] 
2025-07-08 21:55:22.985031: Epoch time: 48.8 s 
2025-07-08 21:55:24.884487:  
2025-07-08 21:55:24.885041: Epoch 419 
2025-07-08 21:55:24.885164: Current learning rate: 0.00613 
2025-07-08 21:56:13.629396: train_loss -0.6357 
2025-07-08 21:56:13.630024: val_loss -0.6498 
2025-07-08 21:56:13.630131: Pseudo dice [np.float32(0.8339)] 
2025-07-08 21:56:13.630265: Epoch time: 48.75 s 
2025-07-08 21:56:14.793818:  
2025-07-08 21:56:14.794071: Epoch 420 
2025-07-08 21:56:14.794437: Current learning rate: 0.00612 
2025-07-08 21:57:02.902470: train_loss -0.6435 
2025-07-08 21:57:02.902938: val_loss -0.6612 
2025-07-08 21:57:02.903022: Pseudo dice [np.float32(0.8613)] 
2025-07-08 21:57:02.903126: Epoch time: 48.11 s 
2025-07-08 21:57:04.063318:  
2025-07-08 21:57:04.063553: Epoch 421 
2025-07-08 21:57:04.063718: Current learning rate: 0.00612 
2025-07-08 21:57:50.994497: train_loss -0.6619 
2025-07-08 21:57:50.994997: val_loss -0.6856 
2025-07-08 21:57:50.995129: Pseudo dice [np.float32(0.8638)] 
2025-07-08 21:57:50.995246: Epoch time: 46.93 s 
2025-07-08 21:57:52.249342:  
2025-07-08 21:57:52.249843: Epoch 422 
2025-07-08 21:57:52.249981: Current learning rate: 0.00611 
2025-07-08 21:58:38.800760: train_loss -0.6328 
2025-07-08 21:58:38.801377: val_loss -0.6434 
2025-07-08 21:58:38.801462: Pseudo dice [np.float32(0.7943)] 
2025-07-08 21:58:38.801578: Epoch time: 46.55 s 
2025-07-08 21:58:39.984705:  
2025-07-08 21:58:39.985101: Epoch 423 
2025-07-08 21:58:39.985342: Current learning rate: 0.0061 
2025-07-08 21:59:27.191425: train_loss -0.6422 
2025-07-08 21:59:27.191934: val_loss -0.6473 
2025-07-08 21:59:27.192016: Pseudo dice [np.float32(0.8511)] 
2025-07-08 21:59:27.192122: Epoch time: 47.21 s 
2025-07-08 21:59:28.402478:  
2025-07-08 21:59:28.403047: Epoch 424 
2025-07-08 21:59:28.403183: Current learning rate: 0.00609 
2025-07-08 22:00:15.913897: train_loss -0.6529 
2025-07-08 22:00:15.914246: val_loss -0.6777 
2025-07-08 22:00:15.914388: Pseudo dice [np.float32(0.8391)] 
2025-07-08 22:00:15.914584: Epoch time: 47.51 s 
2025-07-08 22:00:17.060396:  
2025-07-08 22:00:17.060934: Epoch 425 
2025-07-08 22:00:17.061265: Current learning rate: 0.00608 
2025-07-08 22:01:03.893988: train_loss -0.6424 
2025-07-08 22:01:03.894586: val_loss -0.6591 
2025-07-08 22:01:03.894697: Pseudo dice [np.float32(0.8468)] 
2025-07-08 22:01:03.894829: Epoch time: 46.83 s 
2025-07-08 22:01:05.097074:  
2025-07-08 22:01:05.097560: Epoch 426 
2025-07-08 22:01:05.097769: Current learning rate: 0.00607 
2025-07-08 22:01:52.543658: train_loss -0.6366 
2025-07-08 22:01:52.544087: val_loss -0.6463 
2025-07-08 22:01:52.544218: Pseudo dice [np.float32(0.8385)] 
2025-07-08 22:01:52.544330: Epoch time: 47.45 s 
2025-07-08 22:01:53.669620:  
2025-07-08 22:01:53.670003: Epoch 427 
2025-07-08 22:01:53.670127: Current learning rate: 0.00606 
2025-07-08 22:02:41.407400: train_loss -0.6075 
2025-07-08 22:02:41.408092: val_loss -0.6321 
2025-07-08 22:02:41.408195: Pseudo dice [np.float32(0.8204)] 
2025-07-08 22:02:41.408321: Epoch time: 47.74 s 
2025-07-08 22:02:42.583605:  
2025-07-08 22:02:42.583919: Epoch 428 
2025-07-08 22:02:42.584080: Current learning rate: 0.00605 
2025-07-08 22:03:30.697043: train_loss -0.6331 
2025-07-08 22:03:30.697632: val_loss -0.6617 
2025-07-08 22:03:30.697714: Pseudo dice [np.float32(0.8491)] 
2025-07-08 22:03:30.697820: Epoch time: 48.11 s 
2025-07-08 22:03:31.871727:  
2025-07-08 22:03:31.872144: Epoch 429 
2025-07-08 22:03:31.872276: Current learning rate: 0.00604 
2025-07-08 22:04:18.552857: train_loss -0.6314 
2025-07-08 22:04:18.553532: val_loss -0.6516 
2025-07-08 22:04:18.553647: Pseudo dice [np.float32(0.8369)] 
2025-07-08 22:04:18.553791: Epoch time: 46.68 s 
2025-07-08 22:04:19.784214:  
2025-07-08 22:04:19.784507: Epoch 430 
2025-07-08 22:04:19.784719: Current learning rate: 0.00603 
2025-07-08 22:05:05.760757: train_loss -0.6443 
2025-07-08 22:05:05.761351: val_loss -0.6488 
2025-07-08 22:05:05.761441: Pseudo dice [np.float32(0.8504)] 
2025-07-08 22:05:05.761585: Epoch time: 45.98 s 
2025-07-08 22:05:07.032158:  
2025-07-08 22:05:07.032395: Epoch 431 
2025-07-08 22:05:07.032608: Current learning rate: 0.00602 
2025-07-08 22:05:53.582338: train_loss -0.6355 
2025-07-08 22:05:53.584222: val_loss -0.6462 
2025-07-08 22:05:53.584467: Pseudo dice [np.float32(0.8566)] 
2025-07-08 22:05:53.584859: Epoch time: 46.55 s 
2025-07-08 22:05:54.754028:  
2025-07-08 22:05:54.754240: Epoch 432 
2025-07-08 22:05:54.754536: Current learning rate: 0.00601 
2025-07-08 22:06:42.030733: train_loss -0.649 
2025-07-08 22:06:42.031398: val_loss -0.6459 
2025-07-08 22:06:42.031488: Pseudo dice [np.float32(0.8524)] 
2025-07-08 22:06:42.031619: Epoch time: 47.28 s 
2025-07-08 22:06:44.170065:  
2025-07-08 22:06:44.170693: Epoch 433 
2025-07-08 22:06:44.170850: Current learning rate: 0.006 
2025-07-08 22:07:30.301536: train_loss -0.6448 
2025-07-08 22:07:30.302219: val_loss -0.6554 
2025-07-08 22:07:30.302299: Pseudo dice [np.float32(0.8431)] 
2025-07-08 22:07:30.302415: Epoch time: 46.13 s 
2025-07-08 22:07:31.445962:  
2025-07-08 22:07:31.446576: Epoch 434 
2025-07-08 22:07:31.446927: Current learning rate: 0.00599 
2025-07-08 22:08:19.074104: train_loss -0.6529 
2025-07-08 22:08:19.074749: val_loss -0.6478 
2025-07-08 22:08:19.074831: Pseudo dice [np.float32(0.8453)] 
2025-07-08 22:08:19.074950: Epoch time: 47.63 s 
2025-07-08 22:08:20.265659:  
2025-07-08 22:08:20.266392: Epoch 435 
2025-07-08 22:08:20.266594: Current learning rate: 0.00598 
2025-07-08 22:09:07.894807: train_loss -0.6384 
2025-07-08 22:09:07.895307: val_loss -0.6466 
2025-07-08 22:09:07.895392: Pseudo dice [np.float32(0.852)] 
2025-07-08 22:09:07.895495: Epoch time: 47.63 s 
2025-07-08 22:09:09.067357:  
2025-07-08 22:09:09.067724: Epoch 436 
2025-07-08 22:09:09.067991: Current learning rate: 0.00597 
2025-07-08 22:09:55.630327: train_loss -0.6433 
2025-07-08 22:09:55.630815: val_loss -0.65 
2025-07-08 22:09:55.634382: Pseudo dice [np.float32(0.8386)] 
2025-07-08 22:09:55.634518: Epoch time: 46.56 s 
2025-07-08 22:09:56.791158:  
2025-07-08 22:09:56.791571: Epoch 437 
2025-07-08 22:09:56.791773: Current learning rate: 0.00596 
2025-07-08 22:10:43.786475: train_loss -0.6494 
2025-07-08 22:10:43.786978: val_loss -0.6599 
2025-07-08 22:10:43.790482: Pseudo dice [np.float32(0.8415)] 
2025-07-08 22:10:43.790613: Epoch time: 47.0 s 
2025-07-08 22:10:44.977749:  
2025-07-08 22:10:44.978560: Epoch 438 
2025-07-08 22:10:44.978702: Current learning rate: 0.00595 
2025-07-08 22:11:32.490996: train_loss -0.6534 
2025-07-08 22:11:32.491498: val_loss -0.6571 
2025-07-08 22:11:32.491602: Pseudo dice [np.float32(0.8588)] 
2025-07-08 22:11:32.491728: Epoch time: 47.51 s 
2025-07-08 22:11:33.713856:  
2025-07-08 22:11:33.714559: Epoch 439 
2025-07-08 22:11:33.714710: Current learning rate: 0.00594 
2025-07-08 22:12:22.164967: train_loss -0.6525 
2025-07-08 22:12:22.165471: val_loss -0.6656 
2025-07-08 22:12:22.165572: Pseudo dice [np.float32(0.8556)] 
2025-07-08 22:12:22.165684: Epoch time: 48.45 s 
2025-07-08 22:12:23.478071:  
2025-07-08 22:12:23.478519: Epoch 440 
2025-07-08 22:12:23.478802: Current learning rate: 0.00593 
2025-07-08 22:13:11.897810: train_loss -0.6616 
2025-07-08 22:13:11.898071: val_loss -0.6494 
2025-07-08 22:13:11.898348: Pseudo dice [np.float32(0.8531)] 
2025-07-08 22:13:11.898452: Epoch time: 48.42 s 
2025-07-08 22:13:13.029643:  
2025-07-08 22:13:13.029815: Epoch 441 
2025-07-08 22:13:13.029927: Current learning rate: 0.00592 
2025-07-08 22:14:00.930329: train_loss -0.6594 
2025-07-08 22:14:00.930915: val_loss -0.6625 
2025-07-08 22:14:00.931050: Pseudo dice [np.float32(0.8522)] 
2025-07-08 22:14:00.931224: Epoch time: 47.9 s 
2025-07-08 22:14:02.135559:  
2025-07-08 22:14:02.135961: Epoch 442 
2025-07-08 22:14:02.136141: Current learning rate: 0.00592 
2025-07-08 22:14:49.858699: train_loss -0.6585 
2025-07-08 22:14:49.859228: val_loss -0.6714 
2025-07-08 22:14:49.859324: Pseudo dice [np.float32(0.8549)] 
2025-07-08 22:14:49.859451: Epoch time: 47.72 s 
2025-07-08 22:14:51.040869:  
2025-07-08 22:14:51.041220: Epoch 443 
2025-07-08 22:14:51.041420: Current learning rate: 0.00591 
2025-07-08 22:15:37.941169: train_loss -0.6487 
2025-07-08 22:15:37.941896: val_loss -0.6514 
2025-07-08 22:15:37.942031: Pseudo dice [np.float32(0.8527)] 
2025-07-08 22:15:37.942184: Epoch time: 46.9 s 
2025-07-08 22:15:39.159425:  
2025-07-08 22:15:39.159705: Epoch 444 
2025-07-08 22:15:39.159888: Current learning rate: 0.0059 
2025-07-08 22:16:27.132677: train_loss -0.6513 
2025-07-08 22:16:27.133174: val_loss -0.6698 
2025-07-08 22:16:27.133256: Pseudo dice [np.float32(0.8565)] 
2025-07-08 22:16:27.133369: Epoch time: 47.97 s 
2025-07-08 22:16:28.297501:  
2025-07-08 22:16:28.298123: Epoch 445 
2025-07-08 22:16:28.298293: Current learning rate: 0.00589 
2025-07-08 22:17:16.144080: train_loss -0.6588 
2025-07-08 22:17:16.144403: val_loss -0.663 
2025-07-08 22:17:16.144549: Pseudo dice [np.float32(0.8675)] 
2025-07-08 22:17:16.144743: Epoch time: 47.85 s 
2025-07-08 22:17:17.274143:  
2025-07-08 22:17:17.274465: Epoch 446 
2025-07-08 22:17:17.274615: Current learning rate: 0.00588 
2025-07-08 22:18:04.974828: train_loss -0.6525 
2025-07-08 22:18:04.975357: val_loss -0.668 
2025-07-08 22:18:04.975459: Pseudo dice [np.float32(0.8542)] 
2025-07-08 22:18:04.975595: Epoch time: 47.7 s 
2025-07-08 22:18:06.178273:  
2025-07-08 22:18:06.178741: Epoch 447 
2025-07-08 22:18:06.178869: Current learning rate: 0.00587 
2025-07-08 22:18:51.516282: train_loss -0.6608 
2025-07-08 22:18:51.516744: val_loss -0.663 
2025-07-08 22:18:51.520265: Pseudo dice [np.float32(0.8565)] 
2025-07-08 22:18:51.520386: Epoch time: 45.34 s 
2025-07-08 22:18:53.440317:  
2025-07-08 22:18:53.440955: Epoch 448 
2025-07-08 22:18:53.441140: Current learning rate: 0.00586 
2025-07-08 22:19:40.270336: train_loss -0.6469 
2025-07-08 22:19:40.270788: val_loss -0.6689 
2025-07-08 22:19:40.270876: Pseudo dice [np.float32(0.8586)] 
2025-07-08 22:19:40.270986: Epoch time: 46.83 s 
2025-07-08 22:19:41.482354:  
2025-07-08 22:19:41.482747: Epoch 449 
2025-07-08 22:19:41.482886: Current learning rate: 0.00585 
2025-07-08 22:20:28.441894: train_loss -0.6602 
2025-07-08 22:20:28.442580: val_loss -0.6517 
2025-07-08 22:20:28.442678: Pseudo dice [np.float32(0.8517)] 
2025-07-08 22:20:28.442800: Epoch time: 46.96 s 
2025-07-08 22:20:30.135335:  
2025-07-08 22:20:30.135773: Epoch 450 
2025-07-08 22:20:30.135903: Current learning rate: 0.00584 
2025-07-08 22:21:16.641607: train_loss -0.6586 
2025-07-08 22:21:16.642109: val_loss -0.6493 
2025-07-08 22:21:16.645711: Pseudo dice [np.float32(0.8527)] 
2025-07-08 22:21:16.645885: Epoch time: 46.51 s 
2025-07-08 22:21:17.864269:  
2025-07-08 22:21:17.864563: Epoch 451 
2025-07-08 22:21:17.864695: Current learning rate: 0.00583 
2025-07-08 22:22:04.999154: train_loss -0.6657 
2025-07-08 22:22:04.999684: val_loss -0.6814 
2025-07-08 22:22:04.999813: Pseudo dice [np.float32(0.8675)] 
2025-07-08 22:22:04.999965: Epoch time: 47.14 s 
2025-07-08 22:22:06.342342:  
2025-07-08 22:22:06.342988: Epoch 452 
2025-07-08 22:22:06.343133: Current learning rate: 0.00582 
2025-07-08 22:22:53.804842: train_loss -0.6679 
2025-07-08 22:22:53.805776: val_loss -0.6772 
2025-07-08 22:22:53.806027: Pseudo dice [np.float32(0.8753)] 
2025-07-08 22:22:53.806257: Epoch time: 47.46 s 
2025-07-08 22:22:55.068138:  
2025-07-08 22:22:55.068602: Epoch 453 
2025-07-08 22:22:55.069108: Current learning rate: 0.00581 
2025-07-08 22:23:42.250490: train_loss -0.6638 
2025-07-08 22:23:42.250890: val_loss -0.673 
2025-07-08 22:23:42.250993: Pseudo dice [np.float32(0.8598)] 
2025-07-08 22:23:42.251093: Epoch time: 47.18 s 
2025-07-08 22:23:43.399352:  
2025-07-08 22:23:43.399828: Epoch 454 
2025-07-08 22:23:43.400025: Current learning rate: 0.0058 
2025-07-08 22:24:31.265104: train_loss -0.6563 
2025-07-08 22:24:31.265894: val_loss -0.659 
2025-07-08 22:24:31.269616: Pseudo dice [np.float32(0.8612)] 
2025-07-08 22:24:31.269738: Epoch time: 47.87 s 
2025-07-08 22:24:31.269834: Yayy! New best EMA pseudo Dice: 0.8571000099182129 
2025-07-08 22:24:32.925026:  
2025-07-08 22:24:32.925612: Epoch 455 
2025-07-08 22:24:32.925834: Current learning rate: 0.00579 
2025-07-08 22:25:20.871268: train_loss -0.6573 
2025-07-08 22:25:20.871901: val_loss -0.6778 
2025-07-08 22:25:20.872011: Pseudo dice [np.float32(0.8707)] 
2025-07-08 22:25:20.872138: Epoch time: 47.95 s 
2025-07-08 22:25:20.872218: Yayy! New best EMA pseudo Dice: 0.8585000038146973 
2025-07-08 22:25:22.539512:  
2025-07-08 22:25:22.539721: Epoch 456 
2025-07-08 22:25:22.539860: Current learning rate: 0.00578 
2025-07-08 22:26:11.668200: train_loss -0.6624 
2025-07-08 22:26:11.668725: val_loss -0.677 
2025-07-08 22:26:11.668828: Pseudo dice [np.float32(0.8594)] 
2025-07-08 22:26:11.669013: Epoch time: 49.13 s 
2025-07-08 22:26:11.669109: Yayy! New best EMA pseudo Dice: 0.8586000204086304 
2025-07-08 22:26:13.245203:  
2025-07-08 22:26:13.245770: Epoch 457 
2025-07-08 22:26:13.245931: Current learning rate: 0.00577 
2025-07-08 22:27:02.760424: train_loss -0.6617 
2025-07-08 22:27:02.760905: val_loss -0.6705 
2025-07-08 22:27:02.761034: Pseudo dice [np.float32(0.8672)] 
2025-07-08 22:27:02.761135: Epoch time: 49.52 s 
2025-07-08 22:27:02.761207: Yayy! New best EMA pseudo Dice: 0.8593999743461609 
2025-07-08 22:27:04.385922:  
2025-07-08 22:27:04.386347: Epoch 458 
2025-07-08 22:27:04.386476: Current learning rate: 0.00576 
2025-07-08 22:27:54.377283: train_loss -0.6361 
2025-07-08 22:27:54.377864: val_loss -0.6534 
2025-07-08 22:27:54.378116: Pseudo dice [np.float32(0.8398)] 
2025-07-08 22:27:54.378237: Epoch time: 49.99 s 
2025-07-08 22:27:55.655274:  
2025-07-08 22:27:55.655678: Epoch 459 
2025-07-08 22:27:55.655837: Current learning rate: 0.00575 
2025-07-08 22:28:45.991605: train_loss -0.6373 
2025-07-08 22:28:45.992379: val_loss -0.6513 
2025-07-08 22:28:45.992478: Pseudo dice [np.float32(0.8477)] 
2025-07-08 22:28:45.992620: Epoch time: 50.34 s 
2025-07-08 22:28:47.174550:  
2025-07-08 22:28:47.174920: Epoch 460 
2025-07-08 22:28:47.175104: Current learning rate: 0.00574 
2025-07-08 22:29:36.794739: train_loss -0.6465 
2025-07-08 22:29:36.795356: val_loss -0.6627 
2025-07-08 22:29:36.795441: Pseudo dice [np.float32(0.8481)] 
2025-07-08 22:29:36.795574: Epoch time: 49.62 s 
2025-07-08 22:29:37.977292:  
2025-07-08 22:29:37.977772: Epoch 461 
2025-07-08 22:29:37.977903: Current learning rate: 0.00573 
2025-07-08 22:30:27.794138: train_loss -0.6536 
2025-07-08 22:30:27.794627: val_loss -0.6574 
2025-07-08 22:30:27.794715: Pseudo dice [np.float32(0.8588)] 
2025-07-08 22:30:27.794825: Epoch time: 49.82 s 
2025-07-08 22:30:29.033409:  
2025-07-08 22:30:29.033749: Epoch 462 
2025-07-08 22:30:29.033887: Current learning rate: 0.00572 
2025-07-08 22:31:20.620119: train_loss -0.643 
2025-07-08 22:31:20.620593: val_loss -0.648 
2025-07-08 22:31:20.620743: Pseudo dice [np.float32(0.8555)] 
2025-07-08 22:31:20.620847: Epoch time: 51.59 s 
2025-07-08 22:31:22.771631:  
2025-07-08 22:31:22.771806: Epoch 463 
2025-07-08 22:31:22.771925: Current learning rate: 0.00571 
2025-07-08 22:32:14.988429: train_loss -0.648 
2025-07-08 22:32:14.988938: val_loss -0.6685 
2025-07-08 22:32:14.989024: Pseudo dice [np.float32(0.8522)] 
2025-07-08 22:32:14.989133: Epoch time: 52.22 s 
2025-07-08 22:32:16.102639:  
2025-07-08 22:32:16.103036: Epoch 464 
2025-07-08 22:32:16.103196: Current learning rate: 0.0057 
2025-07-08 22:33:07.598439: train_loss -0.6599 
2025-07-08 22:33:07.599054: val_loss -0.6859 
2025-07-08 22:33:07.599205: Pseudo dice [np.float32(0.8573)] 
2025-07-08 22:33:07.599349: Epoch time: 51.5 s 
2025-07-08 22:33:08.739949:  
2025-07-08 22:33:08.740344: Epoch 465 
2025-07-08 22:33:08.740562: Current learning rate: 0.0057 
2025-07-08 22:33:59.032776: train_loss -0.6691 
2025-07-08 22:33:59.033293: val_loss -0.677 
2025-07-08 22:33:59.033377: Pseudo dice [np.float32(0.8628)] 
2025-07-08 22:33:59.033484: Epoch time: 50.29 s 
2025-07-08 22:34:00.203407:  
2025-07-08 22:34:00.203759: Epoch 466 
2025-07-08 22:34:00.203957: Current learning rate: 0.00569 
2025-07-08 22:34:47.372067: train_loss -0.6567 
2025-07-08 22:34:47.372639: val_loss -0.6707 
2025-07-08 22:34:47.372746: Pseudo dice [np.float32(0.8529)] 
2025-07-08 22:34:47.372870: Epoch time: 47.17 s 
2025-07-08 22:34:48.592301:  
2025-07-08 22:34:48.592920: Epoch 467 
2025-07-08 22:34:48.593059: Current learning rate: 0.00568 
2025-07-08 22:35:35.153404: train_loss -0.6675 
2025-07-08 22:35:35.154148: val_loss -0.6576 
2025-07-08 22:35:35.154309: Pseudo dice [np.float32(0.8562)] 
2025-07-08 22:35:35.154480: Epoch time: 46.56 s 
2025-07-08 22:35:36.404962:  
2025-07-08 22:35:36.405297: Epoch 468 
2025-07-08 22:35:36.405479: Current learning rate: 0.00567 
2025-07-08 22:36:23.484410: train_loss -0.6868 
2025-07-08 22:36:23.484871: val_loss -0.8326 
2025-07-08 22:36:23.484957: Pseudo dice [np.float32(0.854)] 
2025-07-08 22:36:23.485078: Epoch time: 47.08 s 
2025-07-08 22:36:24.629951:  
2025-07-08 22:36:24.630334: Epoch 469 
2025-07-08 22:36:24.630497: Current learning rate: 0.00566 
2025-07-08 22:37:11.508448: train_loss -0.7636 
2025-07-08 22:37:11.508861: val_loss -0.7504 
2025-07-08 22:37:11.508937: Pseudo dice [np.float32(0.8079)] 
2025-07-08 22:37:11.509040: Epoch time: 46.88 s 
2025-07-08 22:37:12.612553:  
2025-07-08 22:37:12.612855: Epoch 470 
2025-07-08 22:37:12.612975: Current learning rate: 0.00565 
2025-07-08 22:38:00.207822: train_loss -0.6944 
2025-07-08 22:38:00.208376: val_loss -0.5941 
2025-07-08 22:38:00.211940: Pseudo dice [np.float32(0.6844)] 
2025-07-08 22:38:00.212155: Epoch time: 47.6 s 
2025-07-08 22:38:01.361783:  
2025-07-08 22:38:01.362581: Epoch 471 
2025-07-08 22:38:01.362834: Current learning rate: 0.00564 
2025-07-08 22:38:48.250263: train_loss -0.5502 
2025-07-08 22:38:48.250720: val_loss -0.6008 
2025-07-08 22:38:48.250807: Pseudo dice [np.float32(0.7571)] 
2025-07-08 22:38:48.250925: Epoch time: 46.89 s 
2025-07-08 22:38:49.423836:  
2025-07-08 22:38:49.424078: Epoch 472 
2025-07-08 22:38:49.424281: Current learning rate: 0.00563 
2025-07-08 22:39:36.048157: train_loss -0.5869 
2025-07-08 22:39:36.048685: val_loss -0.6273 
2025-07-08 22:39:36.048772: Pseudo dice [np.float32(0.6968)] 
2025-07-08 22:39:36.048883: Epoch time: 46.63 s 
2025-07-08 22:39:37.252789:  
2025-07-08 22:39:37.253382: Epoch 473 
2025-07-08 22:39:37.253522: Current learning rate: 0.00562 
2025-07-08 22:40:25.948302: train_loss -0.5774 
2025-07-08 22:40:25.948730: val_loss -0.5406 
2025-07-08 22:40:25.948811: Pseudo dice [np.float32(0.677)] 
2025-07-08 22:40:25.948907: Epoch time: 48.7 s 
2025-07-08 22:40:27.072476:  
2025-07-08 22:40:27.072740: Epoch 474 
2025-07-08 22:40:27.072869: Current learning rate: 0.00561 
2025-07-08 22:41:14.731099: train_loss -0.603 
2025-07-08 22:41:14.731460: val_loss -0.6418 
2025-07-08 22:41:14.731548: Pseudo dice [np.float32(0.7758)] 
2025-07-08 22:41:14.731653: Epoch time: 47.66 s 
2025-07-08 22:41:15.897282:  
2025-07-08 22:41:15.897642: Epoch 475 
2025-07-08 22:41:15.897803: Current learning rate: 0.0056 
2025-07-08 22:42:03.137309: train_loss -0.6121 
2025-07-08 22:42:03.138030: val_loss -0.6532 
2025-07-08 22:42:03.138126: Pseudo dice [np.float32(0.7498)] 
2025-07-08 22:42:03.138241: Epoch time: 47.24 s 
2025-07-08 22:42:04.375375:  
2025-07-08 22:42:04.375814: Epoch 476 
2025-07-08 22:42:04.375954: Current learning rate: 0.00559 
2025-07-08 22:42:52.045303: train_loss -0.5952 
2025-07-08 22:42:52.046090: val_loss -0.6399 
2025-07-08 22:42:52.046260: Pseudo dice [np.float32(0.7033)] 
2025-07-08 22:42:52.046439: Epoch time: 47.67 s 
2025-07-08 22:42:53.224017:  
2025-07-08 22:42:53.224214: Epoch 477 
2025-07-08 22:42:53.224348: Current learning rate: 0.00558 
2025-07-08 22:43:39.669459: train_loss -0.6207 
2025-07-08 22:43:39.669945: val_loss -0.6097 
2025-07-08 22:43:39.670037: Pseudo dice [np.float32(0.7358)] 
2025-07-08 22:43:39.670155: Epoch time: 46.45 s 
2025-07-08 22:43:40.892761:  
2025-07-08 22:43:40.893230: Epoch 478 
2025-07-08 22:43:40.893374: Current learning rate: 0.00557 
2025-07-08 22:44:28.880589: train_loss -0.5994 
2025-07-08 22:44:28.881883: val_loss -0.6384 
2025-07-08 22:44:28.882075: Pseudo dice [np.float32(0.7407)] 
2025-07-08 22:44:28.882241: Epoch time: 47.99 s 
2025-07-08 22:44:30.892315:  
2025-07-08 22:44:30.892751: Epoch 479 
2025-07-08 22:44:30.892884: Current learning rate: 0.00556 
2025-07-08 22:45:18.371575: train_loss -0.6019 
2025-07-08 22:45:18.372069: val_loss -0.5077 
2025-07-08 22:45:18.372165: Pseudo dice [np.float32(0.704)] 
2025-07-08 22:45:18.372298: Epoch time: 47.48 s 
2025-07-08 22:45:19.608328:  
2025-07-08 22:45:19.608652: Epoch 480 
2025-07-08 22:45:19.609010: Current learning rate: 0.00555 
2025-07-08 22:46:07.869928: train_loss -0.6083 
2025-07-08 22:46:07.870408: val_loss -0.606 
2025-07-08 22:46:07.870496: Pseudo dice [np.float32(0.7683)] 
2025-07-08 22:46:07.870621: Epoch time: 48.26 s 
2025-07-08 22:46:09.035557:  
2025-07-08 22:46:09.036034: Epoch 481 
2025-07-08 22:46:09.036293: Current learning rate: 0.00554 
2025-07-08 22:46:55.699785: train_loss -0.6072 
2025-07-08 22:46:55.700261: val_loss -0.5752 
2025-07-08 22:46:55.700348: Pseudo dice [np.float32(0.7539)] 
2025-07-08 22:46:55.700455: Epoch time: 46.67 s 
2025-07-08 22:46:56.921558:  
2025-07-08 22:46:56.921783: Epoch 482 
2025-07-08 22:46:56.921917: Current learning rate: 0.00553 
2025-07-08 22:47:43.022568: train_loss -0.6216 
2025-07-08 22:47:43.022956: val_loss -0.6223 
2025-07-08 22:47:43.023033: Pseudo dice [np.float32(0.7494)] 
2025-07-08 22:47:43.023136: Epoch time: 46.1 s 
2025-07-08 22:47:44.182297:  
2025-07-08 22:47:44.182477: Epoch 483 
2025-07-08 22:47:44.182709: Current learning rate: 0.00552 
2025-07-08 22:48:29.444854: train_loss -0.6347 
2025-07-08 22:48:29.445606: val_loss -0.5884 
2025-07-08 22:48:29.445713: Pseudo dice [np.float32(0.717)] 
2025-07-08 22:48:29.445848: Epoch time: 45.26 s 
2025-07-08 22:48:30.661198:  
2025-07-08 22:48:30.661736: Epoch 484 
2025-07-08 22:48:30.661932: Current learning rate: 0.00551 
2025-07-08 22:49:17.124174: train_loss -0.6457 
2025-07-08 22:49:17.124677: val_loss -0.6356 
2025-07-08 22:49:17.124761: Pseudo dice [np.float32(0.7313)] 
2025-07-08 22:49:17.124866: Epoch time: 46.46 s 
2025-07-08 22:49:18.311973:  
2025-07-08 22:49:18.312587: Epoch 485 
2025-07-08 22:49:18.312799: Current learning rate: 0.0055 
2025-07-08 22:50:04.717275: train_loss -0.6239 
2025-07-08 22:50:04.717703: val_loss -0.6566 
2025-07-08 22:50:04.717803: Pseudo dice [np.float32(0.7664)] 
2025-07-08 22:50:04.717953: Epoch time: 46.41 s 
2025-07-08 22:50:05.900467:  
2025-07-08 22:50:05.901012: Epoch 486 
2025-07-08 22:50:05.901227: Current learning rate: 0.00549 
2025-07-08 22:50:51.825870: train_loss -0.6292 
2025-07-08 22:50:51.826685: val_loss -0.6222 
2025-07-08 22:50:51.826793: Pseudo dice [np.float32(0.7762)] 
2025-07-08 22:50:51.826935: Epoch time: 45.93 s 
2025-07-08 22:50:52.988059:  
2025-07-08 22:50:52.988616: Epoch 487 
2025-07-08 22:50:52.988844: Current learning rate: 0.00548 
2025-07-08 22:51:39.678641: train_loss -0.6194 
2025-07-08 22:51:39.679100: val_loss -0.6024 
2025-07-08 22:51:39.679222: Pseudo dice [np.float32(0.7372)] 
2025-07-08 22:51:39.679412: Epoch time: 46.69 s 
2025-07-08 22:51:40.818665:  
2025-07-08 22:51:40.819134: Epoch 488 
2025-07-08 22:51:40.819315: Current learning rate: 0.00547 
2025-07-08 22:52:27.557360: train_loss -0.6151 
2025-07-08 22:52:27.557964: val_loss -0.659 
2025-07-08 22:52:27.558048: Pseudo dice [np.float32(0.777)] 
2025-07-08 22:52:27.558161: Epoch time: 46.74 s 
2025-07-08 22:52:28.750655:  
2025-07-08 22:52:28.751002: Epoch 489 
2025-07-08 22:52:28.751210: Current learning rate: 0.00546 
2025-07-08 22:53:14.861801: train_loss -0.614 
2025-07-08 22:53:14.862162: val_loss -0.6378 
2025-07-08 22:53:14.862238: Pseudo dice [np.float32(0.751)] 
2025-07-08 22:53:14.862387: Epoch time: 46.11 s 
2025-07-08 22:53:16.029740:  
2025-07-08 22:53:16.030141: Epoch 490 
2025-07-08 22:53:16.030263: Current learning rate: 0.00546 
2025-07-08 22:54:01.779440: train_loss -0.6095 
2025-07-08 22:54:01.779982: val_loss -0.6004 
2025-07-08 22:54:01.780077: Pseudo dice [np.float32(0.731)] 
2025-07-08 22:54:01.780221: Epoch time: 45.75 s 
2025-07-08 22:54:02.930637:  
2025-07-08 22:54:02.931110: Epoch 491 
2025-07-08 22:54:02.931356: Current learning rate: 0.00545 
2025-07-08 22:54:48.722097: train_loss -0.6259 
2025-07-08 22:54:48.723199: val_loss -0.6034 
2025-07-08 22:54:48.723605: Pseudo dice [np.float32(0.7112)] 
2025-07-08 22:54:48.723827: Epoch time: 45.79 s 
2025-07-08 22:54:49.933122:  
2025-07-08 22:54:49.933695: Epoch 492 
2025-07-08 22:54:49.934012: Current learning rate: 0.00544 
2025-07-08 22:55:36.711480: train_loss -0.5075 
2025-07-08 22:55:36.711925: val_loss -0.5298 
2025-07-08 22:55:36.712006: Pseudo dice [np.float32(0.6472)] 
2025-07-08 22:55:36.712106: Epoch time: 46.78 s 
2025-07-08 22:55:37.854388:  
2025-07-08 22:55:37.854931: Epoch 493 
2025-07-08 22:55:37.855163: Current learning rate: 0.00543 
2025-07-08 22:56:24.802349: train_loss -0.5794 
2025-07-08 22:56:24.802981: val_loss -0.6208 
2025-07-08 22:56:24.803077: Pseudo dice [np.float32(0.774)] 
2025-07-08 22:56:24.803200: Epoch time: 46.95 s 
2025-07-08 22:56:25.992473:  
2025-07-08 22:56:25.992772: Epoch 494 
2025-07-08 22:56:25.992897: Current learning rate: 0.00542 
2025-07-08 22:57:11.962511: train_loss -0.5856 
2025-07-08 22:57:11.963124: val_loss -0.4851 
2025-07-08 22:57:11.963235: Pseudo dice [np.float32(0.6431)] 
2025-07-08 22:57:11.963372: Epoch time: 45.97 s 
2025-07-08 22:57:13.318865:  
2025-07-08 22:57:13.319328: Epoch 495 
2025-07-08 22:57:13.319527: Current learning rate: 0.00541 
2025-07-08 22:57:59.677930: train_loss -0.599 
2025-07-08 22:57:59.678467: val_loss -0.643 
2025-07-08 22:57:59.678564: Pseudo dice [np.float32(0.7578)] 
2025-07-08 22:57:59.678674: Epoch time: 46.36 s 
2025-07-08 22:58:00.869630:  
2025-07-08 22:58:00.870072: Epoch 496 
2025-07-08 22:58:00.870206: Current learning rate: 0.0054 
2025-07-08 22:58:47.548404: train_loss -0.5594 
2025-07-08 22:58:47.548885: val_loss -0.6277 
2025-07-08 22:58:47.548969: Pseudo dice [np.float32(0.7284)] 
2025-07-08 22:58:47.549068: Epoch time: 46.68 s 
2025-07-08 22:58:48.804605:  
2025-07-08 22:58:48.805019: Epoch 497 
2025-07-08 22:58:48.805177: Current learning rate: 0.00539 
2025-07-08 22:59:35.737250: train_loss -0.6217 
2025-07-08 22:59:35.737854: val_loss -0.6262 
2025-07-08 22:59:35.738011: Pseudo dice [np.float32(0.7184)] 
2025-07-08 22:59:35.738122: Epoch time: 46.93 s 
2025-07-08 22:59:36.981071:  
2025-07-08 22:59:36.981462: Epoch 498 
2025-07-08 22:59:36.981646: Current learning rate: 0.00538 
2025-07-08 23:00:23.473607: train_loss -0.6247 
2025-07-08 23:00:23.474015: val_loss -0.6658 
2025-07-08 23:00:23.474089: Pseudo dice [np.float32(0.7579)] 
2025-07-08 23:00:23.474179: Epoch time: 46.49 s 
2025-07-08 23:00:24.756411:  
2025-07-08 23:00:24.756759: Epoch 499 
2025-07-08 23:00:24.756927: Current learning rate: 0.00537 
2025-07-08 23:01:11.310603: train_loss -0.611 
2025-07-08 23:01:11.310890: val_loss -0.6238 
2025-07-08 23:01:11.310964: Pseudo dice [np.float32(0.7601)] 
2025-07-08 23:01:11.311060: Epoch time: 46.56 s 
2025-07-08 23:01:12.935052:  
2025-07-08 23:01:12.935451: Epoch 500 
2025-07-08 23:01:12.935591: Current learning rate: 0.00536 
2025-07-08 23:01:59.487913: train_loss -0.5694 
2025-07-08 23:01:59.488415: val_loss -0.6241 
2025-07-08 23:01:59.488498: Pseudo dice [np.float32(0.7316)] 
2025-07-08 23:01:59.488634: Epoch time: 46.55 s 
2025-07-08 23:02:00.671783:  
2025-07-08 23:02:00.671986: Epoch 501 
2025-07-08 23:02:00.672353: Current learning rate: 0.00535 
2025-07-08 23:02:46.272187: train_loss -0.6562 
2025-07-08 23:02:46.272585: val_loss -0.6678 
2025-07-08 23:02:46.272665: Pseudo dice [np.float32(0.7924)] 
2025-07-08 23:02:46.272788: Epoch time: 45.6 s 
2025-07-08 23:02:47.479732:  
2025-07-08 23:02:47.480371: Epoch 502 
2025-07-08 23:02:47.480497: Current learning rate: 0.00534 
2025-07-08 23:03:33.985430: train_loss -0.6542 
2025-07-08 23:03:33.986103: val_loss -0.6278 
2025-07-08 23:03:33.986192: Pseudo dice [np.float32(0.7514)] 
2025-07-08 23:03:33.986306: Epoch time: 46.51 s 
2025-07-08 23:03:35.276891:  
2025-07-08 23:03:35.277316: Epoch 503 
2025-07-08 23:03:35.277447: Current learning rate: 0.00533 
2025-07-08 23:04:21.536272: train_loss -0.6378 
2025-07-08 23:04:21.536717: val_loss -0.6616 
2025-07-08 23:04:21.536798: Pseudo dice [np.float32(0.7731)] 
2025-07-08 23:04:21.536889: Epoch time: 46.26 s 
2025-07-08 23:04:22.673960:  
2025-07-08 23:04:22.674334: Epoch 504 
2025-07-08 23:04:22.674588: Current learning rate: 0.00532 
2025-07-08 23:05:08.439369: train_loss -0.6491 
2025-07-08 23:05:08.439731: val_loss -0.6118 
2025-07-08 23:05:08.439814: Pseudo dice [np.float32(0.7576)] 
2025-07-08 23:05:08.439913: Epoch time: 45.77 s 
2025-07-08 23:05:09.587199:  
2025-07-08 23:05:09.587610: Epoch 505 
2025-07-08 23:05:09.587850: Current learning rate: 0.00531 
2025-07-08 23:05:56.140676: train_loss -0.6001 
2025-07-08 23:05:56.141263: val_loss -0.6721 
2025-07-08 23:05:56.141357: Pseudo dice [np.float32(0.7532)] 
2025-07-08 23:05:56.141473: Epoch time: 46.55 s 
2025-07-08 23:05:57.332300:  
2025-07-08 23:05:57.332566: Epoch 506 
2025-07-08 23:05:57.332733: Current learning rate: 0.0053 
2025-07-08 23:06:43.866955: train_loss -0.5751 
2025-07-08 23:06:43.867471: val_loss -0.5722 
2025-07-08 23:06:43.867568: Pseudo dice [np.float32(0.7198)] 
2025-07-08 23:06:43.867674: Epoch time: 46.54 s 
2025-07-08 23:06:45.029086:  
2025-07-08 23:06:45.029696: Epoch 507 
2025-07-08 23:06:45.029825: Current learning rate: 0.00529 
2025-07-08 23:07:31.328558: train_loss -0.6368 
2025-07-08 23:07:31.329209: val_loss -0.6286 
2025-07-08 23:07:31.329302: Pseudo dice [np.float32(0.7412)] 
2025-07-08 23:07:31.329448: Epoch time: 46.3 s 
2025-07-08 23:07:33.434959:  
2025-07-08 23:07:33.435277: Epoch 508 
2025-07-08 23:07:33.435402: Current learning rate: 0.00528 
2025-07-08 23:08:19.484390: train_loss -0.6482 
2025-07-08 23:08:19.484885: val_loss -0.6724 
2025-07-08 23:08:19.485113: Pseudo dice [np.float32(0.7613)] 
2025-07-08 23:08:19.485225: Epoch time: 46.05 s 
2025-07-08 23:08:20.692165:  
2025-07-08 23:08:20.692731: Epoch 509 
2025-07-08 23:08:20.692925: Current learning rate: 0.00527 
2025-07-08 23:09:07.577853: train_loss -0.6625 
2025-07-08 23:09:07.578183: val_loss -0.6646 
2025-07-08 23:09:07.578263: Pseudo dice [np.float32(0.7794)] 
2025-07-08 23:09:07.578357: Epoch time: 46.89 s 
2025-07-08 23:09:08.823517:  
2025-07-08 23:09:08.823908: Epoch 510 
2025-07-08 23:09:08.824093: Current learning rate: 0.00526 
2025-07-08 23:09:54.812706: train_loss -0.6397 
2025-07-08 23:09:54.813103: val_loss -0.6184 
2025-07-08 23:09:54.813179: Pseudo dice [np.float32(0.7628)] 
2025-07-08 23:09:54.813282: Epoch time: 45.99 s 
2025-07-08 23:09:55.976759:  
2025-07-08 23:09:55.977346: Epoch 511 
2025-07-08 23:09:55.977486: Current learning rate: 0.00525 
2025-07-08 23:10:42.430218: train_loss -0.6532 
2025-07-08 23:10:42.430808: val_loss -0.6714 
2025-07-08 23:10:42.430894: Pseudo dice [np.float32(0.7659)] 
2025-07-08 23:10:42.431016: Epoch time: 46.45 s 
2025-07-08 23:10:43.581186:  
2025-07-08 23:10:43.581418: Epoch 512 
2025-07-08 23:10:43.581723: Current learning rate: 0.00524 
2025-07-08 23:11:29.671646: train_loss -0.6347 
2025-07-08 23:11:29.672031: val_loss -0.6113 
2025-07-08 23:11:29.672107: Pseudo dice [np.float32(0.7525)] 
2025-07-08 23:11:29.672205: Epoch time: 46.09 s 
2025-07-08 23:11:30.833388:  
2025-07-08 23:11:30.833907: Epoch 513 
2025-07-08 23:11:30.834108: Current learning rate: 0.00523 
2025-07-08 23:12:17.097706: train_loss -0.656 
2025-07-08 23:12:17.098477: val_loss -0.6923 
2025-07-08 23:12:17.098642: Pseudo dice [np.float32(0.7657)] 
2025-07-08 23:12:17.098818: Epoch time: 46.27 s 
2025-07-08 23:12:18.370045:  
2025-07-08 23:12:18.370503: Epoch 514 
2025-07-08 23:12:18.370652: Current learning rate: 0.00522 
2025-07-08 23:13:05.073318: train_loss -0.6809 
2025-07-08 23:13:05.073788: val_loss -0.6719 
2025-07-08 23:13:05.073883: Pseudo dice [np.float32(0.787)] 
2025-07-08 23:13:05.074008: Epoch time: 46.7 s 
2025-07-08 23:13:06.226225:  
2025-07-08 23:13:06.226393: Epoch 515 
2025-07-08 23:13:06.226512: Current learning rate: 0.00521 
2025-07-08 23:13:52.645533: train_loss -0.6484 
2025-07-08 23:13:52.646246: val_loss -0.708 
2025-07-08 23:13:52.646333: Pseudo dice [np.float32(0.8003)] 
2025-07-08 23:13:52.646444: Epoch time: 46.42 s 
2025-07-08 23:13:53.922223:  
2025-07-08 23:13:53.922618: Epoch 516 
2025-07-08 23:13:53.922775: Current learning rate: 0.0052 
2025-07-08 23:14:39.373271: train_loss -0.7114 
2025-07-08 23:14:39.374304: val_loss -0.7052 
2025-07-08 23:14:39.374473: Pseudo dice [np.float32(0.7879)] 
2025-07-08 23:14:39.374668: Epoch time: 45.45 s 
2025-07-08 23:14:40.525962:  
2025-07-08 23:14:40.526239: Epoch 517 
2025-07-08 23:14:40.526440: Current learning rate: 0.00519 
2025-07-08 23:15:27.301431: train_loss -0.6792 
2025-07-08 23:15:27.301956: val_loss -0.6541 
2025-07-08 23:15:27.302045: Pseudo dice [np.float32(0.7772)] 
2025-07-08 23:15:27.302158: Epoch time: 46.78 s 
2025-07-08 23:15:28.499156:  
2025-07-08 23:15:28.499659: Epoch 518 
2025-07-08 23:15:28.499798: Current learning rate: 0.00518 
2025-07-08 23:16:15.060587: train_loss -0.6573 
2025-07-08 23:16:15.061135: val_loss -0.6527 
2025-07-08 23:16:15.061216: Pseudo dice [np.float32(0.7458)] 
2025-07-08 23:16:15.061323: Epoch time: 46.56 s 
2025-07-08 23:16:16.278830:  
2025-07-08 23:16:16.279232: Epoch 519 
2025-07-08 23:16:16.279405: Current learning rate: 0.00518 
2025-07-08 23:17:02.582208: train_loss -0.671 
2025-07-08 23:17:02.582808: val_loss -0.6519 
2025-07-08 23:17:02.582896: Pseudo dice [np.float32(0.7581)] 
2025-07-08 23:17:02.583020: Epoch time: 46.3 s 
2025-07-08 23:17:03.802207:  
2025-07-08 23:17:03.802515: Epoch 520 
2025-07-08 23:17:03.802662: Current learning rate: 0.00517 
2025-07-08 23:17:50.132596: train_loss -0.6148 
2025-07-08 23:17:50.133055: val_loss -0.6325 
2025-07-08 23:17:50.136744: Pseudo dice [np.float32(0.7531)] 
2025-07-08 23:17:50.136980: Epoch time: 46.33 s 
2025-07-08 23:17:51.325845:  
2025-07-08 23:17:51.326334: Epoch 521 
2025-07-08 23:17:51.326466: Current learning rate: 0.00516 
2025-07-08 23:18:37.560258: train_loss -0.6415 
2025-07-08 23:18:37.560783: val_loss -0.6672 
2025-07-08 23:18:37.560868: Pseudo dice [np.float32(0.7825)] 
2025-07-08 23:18:37.560975: Epoch time: 46.24 s 
2025-07-08 23:18:38.749100:  
2025-07-08 23:18:38.749717: Epoch 522 
2025-07-08 23:18:38.749917: Current learning rate: 0.00515 
2025-07-08 23:19:24.518125: train_loss -0.6697 
2025-07-08 23:19:24.518506: val_loss -0.6581 
2025-07-08 23:19:24.518599: Pseudo dice [np.float32(0.7516)] 
2025-07-08 23:19:24.518717: Epoch time: 45.77 s 
2025-07-08 23:19:26.500663:  
2025-07-08 23:19:26.500965: Epoch 523 
2025-07-08 23:19:26.501105: Current learning rate: 0.00514 
2025-07-08 23:20:13.528802: train_loss -0.6462 
2025-07-08 23:20:13.529197: val_loss -0.6533 
2025-07-08 23:20:13.529286: Pseudo dice [np.float32(0.74)] 
2025-07-08 23:20:13.529390: Epoch time: 47.03 s 
2025-07-08 23:20:14.944308:  
2025-07-08 23:20:14.944626: Epoch 524 
2025-07-08 23:20:14.944757: Current learning rate: 0.00513 
2025-07-08 23:21:02.101120: train_loss -0.6766 
2025-07-08 23:21:02.101397: val_loss -0.6693 
2025-07-08 23:21:02.101511: Pseudo dice [np.float32(0.771)] 
2025-07-08 23:21:02.101624: Epoch time: 47.16 s 
2025-07-08 23:21:03.234861:  
2025-07-08 23:21:03.235299: Epoch 525 
2025-07-08 23:21:03.235572: Current learning rate: 0.00512 
2025-07-08 23:21:51.569839: train_loss -0.6624 
2025-07-08 23:21:51.570223: val_loss -0.543 
2025-07-08 23:21:51.570299: Pseudo dice [np.float32(0.6917)] 
2025-07-08 23:21:51.570420: Epoch time: 48.34 s 
2025-07-08 23:21:52.723866:  
2025-07-08 23:21:52.724148: Epoch 526 
2025-07-08 23:21:52.724352: Current learning rate: 0.00511 
2025-07-08 23:22:39.622579: train_loss -0.6551 
2025-07-08 23:22:39.623150: val_loss -0.6746 
2025-07-08 23:22:39.623234: Pseudo dice [np.float32(0.7302)] 
2025-07-08 23:22:39.623346: Epoch time: 46.9 s 
2025-07-08 23:22:40.892069:  
2025-07-08 23:22:40.892743: Epoch 527 
2025-07-08 23:22:40.893063: Current learning rate: 0.0051 
2025-07-08 23:23:28.856353: train_loss -0.675 
2025-07-08 23:23:28.857295: val_loss -0.714 
2025-07-08 23:23:28.857401: Pseudo dice [np.float32(0.7627)] 
2025-07-08 23:23:28.857519: Epoch time: 47.97 s 
2025-07-08 23:23:30.086612:  
2025-07-08 23:23:30.087064: Epoch 528 
2025-07-08 23:23:30.087270: Current learning rate: 0.00509 
2025-07-08 23:24:18.019524: train_loss -0.62 
2025-07-08 23:24:18.020366: val_loss -0.6276 
2025-07-08 23:24:18.020504: Pseudo dice [np.float32(0.7573)] 
2025-07-08 23:24:18.020689: Epoch time: 47.93 s 
2025-07-08 23:24:19.233964:  
2025-07-08 23:24:19.234121: Epoch 529 
2025-07-08 23:24:19.234248: Current learning rate: 0.00508 
2025-07-08 23:25:07.575287: train_loss -0.6388 
2025-07-08 23:25:07.575646: val_loss -0.6272 
2025-07-08 23:25:07.575728: Pseudo dice [np.float32(0.7451)] 
2025-07-08 23:25:07.575826: Epoch time: 48.34 s 
2025-07-08 23:25:08.754122:  
2025-07-08 23:25:08.754863: Epoch 530 
2025-07-08 23:25:08.755018: Current learning rate: 0.00507 
2025-07-08 23:25:56.893790: train_loss -0.6037 
2025-07-08 23:25:56.894383: val_loss -0.636 
2025-07-08 23:25:56.894491: Pseudo dice [np.float32(0.7762)] 
2025-07-08 23:25:56.894636: Epoch time: 48.14 s 
2025-07-08 23:25:58.057602:  
2025-07-08 23:25:58.057865: Epoch 531 
2025-07-08 23:25:58.058056: Current learning rate: 0.00506 
2025-07-08 23:26:47.078075: train_loss -0.6516 
2025-07-08 23:26:47.079146: val_loss -0.6872 
2025-07-08 23:26:47.079273: Pseudo dice [np.float32(0.7876)] 
2025-07-08 23:26:47.079437: Epoch time: 49.02 s 
2025-07-08 23:26:48.286168:  
2025-07-08 23:26:48.286369: Epoch 532 
2025-07-08 23:26:48.286488: Current learning rate: 0.00505 
2025-07-08 23:27:35.795380: train_loss -0.6892 
2025-07-08 23:27:35.795940: val_loss -0.6515 
2025-07-08 23:27:35.796044: Pseudo dice [np.float32(0.7819)] 
2025-07-08 23:27:35.796176: Epoch time: 47.51 s 
2025-07-08 23:27:37.053466:  
2025-07-08 23:27:37.054257: Epoch 533 
2025-07-08 23:27:37.054480: Current learning rate: 0.00504 
2025-07-08 23:28:25.062916: train_loss -0.6242 
2025-07-08 23:28:25.063249: val_loss -0.6693 
2025-07-08 23:28:25.063339: Pseudo dice [np.float32(0.7679)] 
2025-07-08 23:28:25.063448: Epoch time: 48.01 s 
2025-07-08 23:28:26.259481:  
2025-07-08 23:28:26.259767: Epoch 534 
2025-07-08 23:28:26.259895: Current learning rate: 0.00503 
2025-07-08 23:29:13.989424: train_loss -0.6785 
2025-07-08 23:29:13.989882: val_loss -0.7033 
2025-07-08 23:29:13.989967: Pseudo dice [np.float32(0.805)] 
2025-07-08 23:29:13.990072: Epoch time: 47.73 s 
2025-07-08 23:29:15.204586:  
2025-07-08 23:29:15.204751: Epoch 535 
2025-07-08 23:29:15.204879: Current learning rate: 0.00502 
2025-07-08 23:30:02.033577: train_loss -0.6714 
2025-07-08 23:30:02.033951: val_loss -0.6671 
2025-07-08 23:30:02.034031: Pseudo dice [np.float32(0.8052)] 
2025-07-08 23:30:02.034127: Epoch time: 46.83 s 
2025-07-08 23:30:03.255246:  
2025-07-08 23:30:03.255605: Epoch 536 
2025-07-08 23:30:03.255727: Current learning rate: 0.00501 
2025-07-08 23:30:49.756574: train_loss -0.6844 
2025-07-08 23:30:49.757216: val_loss -0.7146 
2025-07-08 23:30:49.757296: Pseudo dice [np.float32(0.7986)] 
2025-07-08 23:30:49.757438: Epoch time: 46.5 s 
2025-07-08 23:30:50.948707:  
2025-07-08 23:30:50.949036: Epoch 537 
2025-07-08 23:30:50.949424: Current learning rate: 0.005 
2025-07-08 23:31:37.359314: train_loss -0.6927 
2025-07-08 23:31:37.359849: val_loss -0.7241 
2025-07-08 23:31:37.359931: Pseudo dice [np.float32(0.7877)] 
2025-07-08 23:31:37.360053: Epoch time: 46.41 s 
2025-07-08 23:31:39.457748:  
2025-07-08 23:31:39.458028: Epoch 538 
2025-07-08 23:31:39.458377: Current learning rate: 0.00499 
2025-07-08 23:32:26.781779: train_loss -0.6888 
2025-07-08 23:32:26.782181: val_loss -0.681 
2025-07-08 23:32:26.782291: Pseudo dice [np.float32(0.8008)] 
2025-07-08 23:32:26.782398: Epoch time: 47.32 s 
2025-07-08 23:32:27.965842:  
2025-07-08 23:32:27.966187: Epoch 539 
2025-07-08 23:32:27.966315: Current learning rate: 0.00498 
2025-07-08 23:33:14.413640: train_loss -0.6851 
2025-07-08 23:33:14.414104: val_loss -0.7292 
2025-07-08 23:33:14.417603: Pseudo dice [np.float32(0.7864)] 
2025-07-08 23:33:14.417763: Epoch time: 46.45 s 
2025-07-08 23:33:15.602258:  
2025-07-08 23:33:15.602482: Epoch 540 
2025-07-08 23:33:15.602832: Current learning rate: 0.00497 
2025-07-08 23:34:01.877671: train_loss -0.7031 
2025-07-08 23:34:01.878096: val_loss -0.7307 
2025-07-08 23:34:01.878178: Pseudo dice [np.float32(0.8022)] 
2025-07-08 23:34:01.878275: Epoch time: 46.28 s 
2025-07-08 23:34:03.090877:  
2025-07-08 23:34:03.091322: Epoch 541 
2025-07-08 23:34:03.091579: Current learning rate: 0.00496 
2025-07-08 23:34:49.368042: train_loss -0.7103 
2025-07-08 23:34:49.368718: val_loss -0.6705 
2025-07-08 23:34:49.368832: Pseudo dice [np.float32(0.7755)] 
2025-07-08 23:34:49.368959: Epoch time: 46.28 s 
2025-07-08 23:34:50.622269:  
2025-07-08 23:34:50.622714: Epoch 542 
2025-07-08 23:34:50.622987: Current learning rate: 0.00495 
2025-07-08 23:35:37.251466: train_loss -0.5939 
2025-07-08 23:35:37.252354: val_loss -0.5985 
2025-07-08 23:35:37.252495: Pseudo dice [np.float32(0.7502)] 
2025-07-08 23:35:37.252656: Epoch time: 46.63 s 
2025-07-08 23:35:38.510426:  
2025-07-08 23:35:38.510722: Epoch 543 
2025-07-08 23:35:38.510862: Current learning rate: 0.00494 
2025-07-08 23:36:25.122393: train_loss -0.6496 
2025-07-08 23:36:25.122872: val_loss -0.5742 
2025-07-08 23:36:25.122956: Pseudo dice [np.float32(0.7209)] 
2025-07-08 23:36:25.123061: Epoch time: 46.61 s 
2025-07-08 23:36:26.281220:  
2025-07-08 23:36:26.281496: Epoch 544 
2025-07-08 23:36:26.281826: Current learning rate: 0.00493 
2025-07-08 23:37:13.326073: train_loss -0.6382 
2025-07-08 23:37:13.326616: val_loss -0.6863 
2025-07-08 23:37:13.326710: Pseudo dice [np.float32(0.7875)] 
2025-07-08 23:37:13.326833: Epoch time: 47.05 s 
2025-07-08 23:37:14.498624:  
2025-07-08 23:37:14.498962: Epoch 545 
2025-07-08 23:37:14.499195: Current learning rate: 0.00492 
2025-07-08 23:38:01.024928: train_loss -0.6901 
2025-07-08 23:38:01.026297: val_loss -0.6987 
2025-07-08 23:38:01.026394: Pseudo dice [np.float32(0.7991)] 
2025-07-08 23:38:01.026576: Epoch time: 46.53 s 
2025-07-08 23:38:02.212371:  
2025-07-08 23:38:02.212616: Epoch 546 
2025-07-08 23:38:02.212752: Current learning rate: 0.00491 
2025-07-08 23:38:49.220115: train_loss -0.6698 
2025-07-08 23:38:49.220825: val_loss -0.6762 
2025-07-08 23:38:49.220929: Pseudo dice [np.float32(0.7636)] 
2025-07-08 23:38:49.221059: Epoch time: 47.01 s 
2025-07-08 23:38:50.419255:  
2025-07-08 23:38:50.419682: Epoch 547 
2025-07-08 23:38:50.419825: Current learning rate: 0.0049 
2025-07-08 23:39:37.524022: train_loss -0.6779 
2025-07-08 23:39:37.524661: val_loss -0.6584 
2025-07-08 23:39:37.524784: Pseudo dice [np.float32(0.7356)] 
2025-07-08 23:39:37.524952: Epoch time: 47.11 s 
2025-07-08 23:39:38.656358:  
2025-07-08 23:39:38.656681: Epoch 548 
2025-07-08 23:39:38.656809: Current learning rate: 0.00489 
2025-07-08 23:40:26.368291: train_loss -0.6375 
2025-07-08 23:40:26.368768: val_loss -0.6726 
2025-07-08 23:40:26.368848: Pseudo dice [np.float32(0.7864)] 
2025-07-08 23:40:26.368949: Epoch time: 47.71 s 
2025-07-08 23:40:27.538013:  
2025-07-08 23:40:27.538193: Epoch 549 
2025-07-08 23:40:27.538301: Current learning rate: 0.00488 
2025-07-08 23:41:14.518727: train_loss -0.6594 
2025-07-08 23:41:14.519289: val_loss -0.6677 
2025-07-08 23:41:14.519374: Pseudo dice [np.float32(0.7908)] 
2025-07-08 23:41:14.519491: Epoch time: 46.98 s 
2025-07-08 23:41:16.226088:  
2025-07-08 23:41:16.226515: Epoch 550 
2025-07-08 23:41:16.226696: Current learning rate: 0.00487 
2025-07-08 23:42:03.020267: train_loss -0.6612 
2025-07-08 23:42:03.021036: val_loss -0.6846 
2025-07-08 23:42:03.021122: Pseudo dice [np.float32(0.7556)] 
2025-07-08 23:42:03.021237: Epoch time: 46.8 s 
2025-07-08 23:42:04.319126:  
2025-07-08 23:42:04.319481: Epoch 551 
2025-07-08 23:42:04.319617: Current learning rate: 0.00486 
2025-07-08 23:42:53.525426: train_loss -0.584 
2025-07-08 23:42:53.526078: val_loss -0.644 
2025-07-08 23:42:53.526200: Pseudo dice [np.float32(0.7498)] 
2025-07-08 23:42:53.526339: Epoch time: 49.21 s 
2025-07-08 23:42:55.577184:  
2025-07-08 23:42:55.577670: Epoch 552 
2025-07-08 23:42:55.577873: Current learning rate: 0.00485 
2025-07-08 23:43:43.298237: train_loss -0.6269 
2025-07-08 23:43:43.298618: val_loss -0.6185 
2025-07-08 23:43:43.298706: Pseudo dice [np.float32(0.7373)] 
2025-07-08 23:43:43.298806: Epoch time: 47.72 s 
2025-07-08 23:43:44.470987:  
2025-07-08 23:43:44.471281: Epoch 553 
2025-07-08 23:43:44.471426: Current learning rate: 0.00484 
2025-07-08 23:44:33.132655: train_loss -0.6419 
2025-07-08 23:44:33.133214: val_loss -0.6425 
2025-07-08 23:44:33.133318: Pseudo dice [np.float32(0.7638)] 
2025-07-08 23:44:33.133443: Epoch time: 48.66 s 
2025-07-08 23:44:34.338777:  
2025-07-08 23:44:34.339025: Epoch 554 
2025-07-08 23:44:34.339167: Current learning rate: 0.00484 
2025-07-08 23:45:22.382256: train_loss -0.6574 
2025-07-08 23:45:22.382935: val_loss -0.6959 
2025-07-08 23:45:22.383040: Pseudo dice [np.float32(0.7733)] 
2025-07-08 23:45:22.383159: Epoch time: 48.04 s 
2025-07-08 23:45:23.560425:  
2025-07-08 23:45:23.561065: Epoch 555 
2025-07-08 23:45:23.561369: Current learning rate: 0.00483 
2025-07-08 23:46:10.840278: train_loss -0.6556 
2025-07-08 23:46:10.840935: val_loss -0.6784 
2025-07-08 23:46:10.841183: Pseudo dice [np.float32(0.759)] 
2025-07-08 23:46:10.841345: Epoch time: 47.28 s 
2025-07-08 23:46:11.989590:  
2025-07-08 23:46:11.989947: Epoch 556 
2025-07-08 23:46:11.990178: Current learning rate: 0.00482 
2025-07-08 23:46:58.149087: train_loss -0.6595 
2025-07-08 23:46:58.149991: val_loss -0.6819 
2025-07-08 23:46:58.150109: Pseudo dice [np.float32(0.7659)] 
2025-07-08 23:46:58.150261: Epoch time: 46.16 s 
2025-07-08 23:46:59.348570:  
2025-07-08 23:46:59.348830: Epoch 557 
2025-07-08 23:46:59.349110: Current learning rate: 0.00481 
2025-07-08 23:47:45.977852: train_loss -0.6502 
2025-07-08 23:47:45.978668: val_loss -0.6486 
2025-07-08 23:47:45.978773: Pseudo dice [np.float32(0.7504)] 
2025-07-08 23:47:45.978889: Epoch time: 46.63 s 
2025-07-08 23:47:47.217738:  
2025-07-08 23:47:47.218288: Epoch 558 
2025-07-08 23:47:47.218422: Current learning rate: 0.0048 
2025-07-08 23:48:33.933460: train_loss -0.6637 
2025-07-08 23:48:33.933947: val_loss -0.6613 
2025-07-08 23:48:33.934033: Pseudo dice [np.float32(0.7623)] 
2025-07-08 23:48:33.934128: Epoch time: 46.72 s 
2025-07-08 23:48:35.160575:  
2025-07-08 23:48:35.160852: Epoch 559 
2025-07-08 23:48:35.161061: Current learning rate: 0.00479 
2025-07-08 23:49:22.283846: train_loss -0.6501 
2025-07-08 23:49:22.284436: val_loss -0.6954 
2025-07-08 23:49:22.284519: Pseudo dice [np.float32(0.7606)] 
2025-07-08 23:49:22.284642: Epoch time: 47.12 s 
2025-07-08 23:49:23.492460:  
2025-07-08 23:49:23.492780: Epoch 560 
2025-07-08 23:49:23.492939: Current learning rate: 0.00478 
2025-07-08 23:50:10.336223: train_loss -0.6265 
2025-07-08 23:50:10.336853: val_loss -0.6755 
2025-07-08 23:50:10.336941: Pseudo dice [np.float32(0.7629)] 
2025-07-08 23:50:10.337061: Epoch time: 46.84 s 
2025-07-08 23:50:11.602030:  
2025-07-08 23:50:11.602718: Epoch 561 
2025-07-08 23:50:11.602938: Current learning rate: 0.00477 
2025-07-08 23:50:57.662787: train_loss -0.6142 
2025-07-08 23:50:57.664029: val_loss -0.6471 
2025-07-08 23:50:57.664175: Pseudo dice [np.float32(0.7532)] 
2025-07-08 23:50:57.664411: Epoch time: 46.06 s 
2025-07-08 23:50:58.919060:  
2025-07-08 23:50:58.919415: Epoch 562 
2025-07-08 23:50:58.919522: Current learning rate: 0.00476 
2025-07-08 23:51:46.537359: train_loss -0.6424 
2025-07-08 23:51:46.537779: val_loss -0.6348 
2025-07-08 23:51:46.537860: Pseudo dice [np.float32(0.7774)] 
2025-07-08 23:51:46.537967: Epoch time: 47.62 s 
2025-07-08 23:51:47.802815:  
2025-07-08 23:51:47.803403: Epoch 563 
2025-07-08 23:51:47.803656: Current learning rate: 0.00475 
2025-07-08 23:52:35.232113: train_loss -0.6797 
2025-07-08 23:52:35.232681: val_loss -0.688 
2025-07-08 23:52:35.232772: Pseudo dice [np.float32(0.7911)] 
2025-07-08 23:52:35.232898: Epoch time: 47.43 s 
2025-07-08 23:52:36.469306:  
2025-07-08 23:52:36.469645: Epoch 564 
2025-07-08 23:52:36.469793: Current learning rate: 0.00474 
2025-07-08 23:53:23.895994: train_loss -0.666 
2025-07-08 23:53:23.896353: val_loss -0.6755 
2025-07-08 23:53:23.896473: Pseudo dice [np.float32(0.7853)] 
2025-07-08 23:53:23.896585: Epoch time: 47.43 s 
2025-07-08 23:53:25.066009:  
2025-07-08 23:53:25.066399: Epoch 565 
2025-07-08 23:53:25.066586: Current learning rate: 0.00473 
2025-07-08 23:54:12.913752: train_loss -0.6818 
2025-07-08 23:54:12.914508: val_loss -0.6953 
2025-07-08 23:54:12.914633: Pseudo dice [np.float32(0.7877)] 
2025-07-08 23:54:12.914766: Epoch time: 47.85 s 
2025-07-08 23:54:14.089130:  
2025-07-08 23:54:14.089258: Epoch 566 
2025-07-08 23:54:14.089368: Current learning rate: 0.00472 
2025-07-08 23:55:02.733748: train_loss -0.6782 
2025-07-08 23:55:02.734146: val_loss -0.676 
2025-07-08 23:55:02.734254: Pseudo dice [np.float32(0.7702)] 
2025-07-08 23:55:02.734394: Epoch time: 48.65 s 
2025-07-08 23:55:04.779104:  
2025-07-08 23:55:04.779649: Epoch 567 
2025-07-08 23:55:04.779837: Current learning rate: 0.00471 
2025-07-08 23:55:52.488859: train_loss -0.6998 
2025-07-08 23:55:52.489908: val_loss -0.7138 
2025-07-08 23:55:52.489995: Pseudo dice [np.float32(0.7906)] 
2025-07-08 23:55:52.490114: Epoch time: 47.71 s 
2025-07-08 23:55:53.712560:  
2025-07-08 23:55:53.712741: Epoch 568 
2025-07-08 23:55:53.712860: Current learning rate: 0.0047 
2025-07-08 23:56:41.102669: train_loss -0.6962 
2025-07-08 23:56:41.103338: val_loss -0.6898 
2025-07-08 23:56:41.103503: Pseudo dice [np.float32(0.7813)] 
2025-07-08 23:56:41.103745: Epoch time: 47.39 s 
2025-07-08 23:56:42.356301:  
2025-07-08 23:56:42.356982: Epoch 569 
2025-07-08 23:56:42.357121: Current learning rate: 0.00469 
2025-07-08 23:57:29.727985: train_loss -0.7033 
2025-07-08 23:57:29.729148: val_loss -0.6875 
2025-07-08 23:57:29.729265: Pseudo dice [np.float32(0.7915)] 
2025-07-08 23:57:29.729483: Epoch time: 47.37 s 
2025-07-08 23:57:30.964214:  
2025-07-08 23:57:30.964534: Epoch 570 
2025-07-08 23:57:30.964645: Current learning rate: 0.00468 
2025-07-08 23:58:18.398660: train_loss -0.7076 
2025-07-08 23:58:18.399026: val_loss -0.7208 
2025-07-08 23:58:18.399173: Pseudo dice [np.float32(0.7809)] 
2025-07-08 23:58:18.399279: Epoch time: 47.44 s 
2025-07-08 23:58:19.641183:  
2025-07-08 23:58:19.641440: Epoch 571 
2025-07-08 23:58:19.641646: Current learning rate: 0.00467 
2025-07-08 23:59:07.439196: train_loss -0.6933 
2025-07-08 23:59:07.439476: val_loss -0.6695 
2025-07-08 23:59:07.439673: Pseudo dice [np.float32(0.8071)] 
2025-07-08 23:59:07.439776: Epoch time: 47.8 s 
2025-07-08 23:59:08.610836:  
2025-07-08 23:59:08.611104: Epoch 572 
2025-07-08 23:59:08.611205: Current learning rate: 0.00466 
2025-07-08 23:59:55.796221: train_loss -0.7019 
2025-07-08 23:59:55.796856: val_loss -0.7059 
2025-07-08 23:59:55.796974: Pseudo dice [np.float32(0.7847)] 
2025-07-08 23:59:55.797140: Epoch time: 47.19 s 
2025-07-08 23:59:57.065835:  
2025-07-08 23:59:57.066072: Epoch 573 
2025-07-08 23:59:57.066212: Current learning rate: 0.00465 
2025-07-09 00:00:44.857155: train_loss -0.7069 
2025-07-09 00:00:44.857921: val_loss -0.715 
2025-07-09 00:00:44.858045: Pseudo dice [np.float32(0.786)] 
2025-07-09 00:00:44.858227: Epoch time: 47.79 s 
2025-07-09 00:00:46.139619:  
2025-07-09 00:00:46.139950: Epoch 574 
2025-07-09 00:00:46.140053: Current learning rate: 0.00464 
2025-07-09 00:01:32.954941: train_loss -0.672 
2025-07-09 00:01:32.955253: val_loss -0.6835 
2025-07-09 00:01:32.955342: Pseudo dice [np.float32(0.7833)] 
2025-07-09 00:01:32.955454: Epoch time: 46.82 s 
2025-07-09 00:01:34.293011:  
2025-07-09 00:01:34.293305: Epoch 575 
2025-07-09 00:01:34.293456: Current learning rate: 0.00463 
2025-07-09 00:02:21.238256: train_loss -0.65 
2025-07-09 00:02:21.238622: val_loss -0.5697 
2025-07-09 00:02:21.238702: Pseudo dice [np.float32(0.791)] 
2025-07-09 00:02:21.238799: Epoch time: 46.95 s 
2025-07-09 00:02:22.453811:  
2025-07-09 00:02:22.454211: Epoch 576 
2025-07-09 00:02:22.454308: Current learning rate: 0.00462 
2025-07-09 00:03:10.364142: train_loss -0.6723 
2025-07-09 00:03:10.364637: val_loss -0.6733 
2025-07-09 00:03:10.364752: Pseudo dice [np.float32(0.78)] 
2025-07-09 00:03:10.365506: Epoch time: 47.91 s 
2025-07-09 00:03:11.704149:  
2025-07-09 00:03:11.704333: Epoch 577 
2025-07-09 00:03:11.704638: Current learning rate: 0.00461 
2025-07-09 00:03:59.821870: train_loss -0.6587 
2025-07-09 00:03:59.822665: val_loss -0.7015 
2025-07-09 00:03:59.822775: Pseudo dice [np.float32(0.7778)] 
2025-07-09 00:03:59.822939: Epoch time: 48.12 s 
2025-07-09 00:04:01.039209:  
2025-07-09 00:04:01.039575: Epoch 578 
2025-07-09 00:04:01.039771: Current learning rate: 0.0046 
2025-07-09 00:04:49.231440: train_loss -0.6865 
2025-07-09 00:04:49.232473: val_loss -0.6827 
2025-07-09 00:04:49.232754: Pseudo dice [np.float32(0.774)] 
2025-07-09 00:04:49.232873: Epoch time: 48.19 s 
2025-07-09 00:04:50.453422:  
2025-07-09 00:04:50.453633: Epoch 579 
2025-07-09 00:04:50.453768: Current learning rate: 0.00459 
2025-07-09 00:05:38.614596: train_loss -0.6906 
2025-07-09 00:05:38.615056: val_loss -0.7092 
2025-07-09 00:05:38.615151: Pseudo dice [np.float32(0.7968)] 
2025-07-09 00:05:38.615268: Epoch time: 48.16 s 
2025-07-09 00:05:39.798068:  
2025-07-09 00:05:39.798483: Epoch 580 
2025-07-09 00:05:39.798624: Current learning rate: 0.00458 
2025-07-09 00:06:28.360215: train_loss -0.7056 
2025-07-09 00:06:28.360921: val_loss -0.7163 
2025-07-09 00:06:28.361039: Pseudo dice [np.float32(0.8007)] 
2025-07-09 00:06:28.361185: Epoch time: 48.56 s 
2025-07-09 00:06:29.636888:  
2025-07-09 00:06:29.637429: Epoch 581 
2025-07-09 00:06:29.637580: Current learning rate: 0.00457 
2025-07-09 00:07:19.000229: train_loss -0.7045 
2025-07-09 00:07:19.000699: val_loss -0.7163 
2025-07-09 00:07:19.000784: Pseudo dice [np.float32(0.7735)] 
2025-07-09 00:07:19.000885: Epoch time: 49.36 s 
2025-07-09 00:07:21.159019:  
2025-07-09 00:07:21.159437: Epoch 582 
2025-07-09 00:07:21.159585: Current learning rate: 0.00456 
2025-07-09 00:08:09.718174: train_loss -0.6979 
2025-07-09 00:08:09.719092: val_loss -0.7406 
2025-07-09 00:08:09.719247: Pseudo dice [np.float32(0.8095)] 
2025-07-09 00:08:09.719404: Epoch time: 48.56 s 
2025-07-09 00:08:10.942680:  
2025-07-09 00:08:10.943090: Epoch 583 
2025-07-09 00:08:10.943281: Current learning rate: 0.00455 
2025-07-09 00:08:57.607045: train_loss -0.7195 
2025-07-09 00:08:57.607631: val_loss -0.7117 
2025-07-09 00:08:57.607724: Pseudo dice [np.float32(0.79)] 
2025-07-09 00:08:57.607833: Epoch time: 46.67 s 
2025-07-09 00:08:58.847974:  
2025-07-09 00:08:58.848960: Epoch 584 
2025-07-09 00:08:58.849244: Current learning rate: 0.00454 
2025-07-09 00:09:46.596207: train_loss -0.7301 
2025-07-09 00:09:46.596977: val_loss -0.7034 
2025-07-09 00:09:46.597087: Pseudo dice [np.float32(0.8069)] 
2025-07-09 00:09:46.597222: Epoch time: 47.75 s 
2025-07-09 00:09:47.850501:  
2025-07-09 00:09:47.851084: Epoch 585 
2025-07-09 00:09:47.851218: Current learning rate: 0.00453 
2025-07-09 00:10:34.948694: train_loss -0.7215 
2025-07-09 00:10:34.949106: val_loss -0.7114 
2025-07-09 00:10:34.949190: Pseudo dice [np.float32(0.7869)] 
2025-07-09 00:10:34.949338: Epoch time: 47.1 s 
2025-07-09 00:10:36.155625:  
2025-07-09 00:10:36.156072: Epoch 586 
2025-07-09 00:10:36.156340: Current learning rate: 0.00452 
2025-07-09 00:11:23.144439: train_loss -0.6963 
2025-07-09 00:11:23.145499: val_loss -0.6585 
2025-07-09 00:11:23.145623: Pseudo dice [np.float32(0.7938)] 
2025-07-09 00:11:23.145764: Epoch time: 46.99 s 
2025-07-09 00:11:24.470316:  
2025-07-09 00:11:24.470657: Epoch 587 
2025-07-09 00:11:24.470765: Current learning rate: 0.00451 
2025-07-09 00:12:12.254091: train_loss -0.6892 
2025-07-09 00:12:12.254643: val_loss -0.7104 
2025-07-09 00:12:12.254728: Pseudo dice [np.float32(0.7912)] 
2025-07-09 00:12:12.254855: Epoch time: 47.78 s 
2025-07-09 00:12:13.524145:  
2025-07-09 00:12:13.524626: Epoch 588 
2025-07-09 00:12:13.524760: Current learning rate: 0.0045 
2025-07-09 00:13:01.095443: train_loss -0.7013 
2025-07-09 00:13:01.095896: val_loss -0.6985 
2025-07-09 00:13:01.096060: Pseudo dice [np.float32(0.8123)] 
2025-07-09 00:13:01.096265: Epoch time: 47.57 s 
2025-07-09 00:13:02.347409:  
2025-07-09 00:13:02.347664: Epoch 589 
2025-07-09 00:13:02.347767: Current learning rate: 0.00449 
2025-07-09 00:13:49.226729: train_loss -0.6697 
2025-07-09 00:13:49.227570: val_loss -0.7186 
2025-07-09 00:13:49.227789: Pseudo dice [np.float32(0.7915)] 
2025-07-09 00:13:49.228043: Epoch time: 46.88 s 
2025-07-09 00:13:50.545902:  
2025-07-09 00:13:50.546530: Epoch 590 
2025-07-09 00:13:50.546730: Current learning rate: 0.00448 
2025-07-09 00:14:37.726737: train_loss -0.6982 
2025-07-09 00:14:37.727332: val_loss -0.7274 
2025-07-09 00:14:37.727418: Pseudo dice [np.float32(0.8)] 
2025-07-09 00:14:37.727568: Epoch time: 47.18 s 
2025-07-09 00:14:38.999569:  
2025-07-09 00:14:39.000114: Epoch 591 
2025-07-09 00:14:39.000329: Current learning rate: 0.00447 
2025-07-09 00:15:26.805259: train_loss -0.7039 
2025-07-09 00:15:26.805743: val_loss -0.6834 
2025-07-09 00:15:26.805917: Pseudo dice [np.float32(0.759)] 
2025-07-09 00:15:26.806019: Epoch time: 47.81 s 
2025-07-09 00:15:28.006260:  
2025-07-09 00:15:28.006550: Epoch 592 
2025-07-09 00:15:28.006769: Current learning rate: 0.00446 
2025-07-09 00:16:15.371872: train_loss -0.686 
2025-07-09 00:16:15.372232: val_loss -0.6723 
2025-07-09 00:16:15.372322: Pseudo dice [np.float32(0.7764)] 
2025-07-09 00:16:15.372427: Epoch time: 47.37 s 
2025-07-09 00:16:16.601683:  
2025-07-09 00:16:16.601928: Epoch 593 
2025-07-09 00:16:16.602076: Current learning rate: 0.00445 
2025-07-09 00:17:03.525440: train_loss -0.7191 
2025-07-09 00:17:03.525978: val_loss -0.7659 
2025-07-09 00:17:03.526064: Pseudo dice [np.float32(0.8147)] 
2025-07-09 00:17:03.526165: Epoch time: 46.92 s 
2025-07-09 00:17:04.851489:  
2025-07-09 00:17:04.851975: Epoch 594 
2025-07-09 00:17:04.852153: Current learning rate: 0.00444 
2025-07-09 00:17:52.506845: train_loss -0.735 
2025-07-09 00:17:52.507179: val_loss -0.6986 
2025-07-09 00:17:52.507357: Pseudo dice [np.float32(0.7926)] 
2025-07-09 00:17:52.507462: Epoch time: 47.66 s 
2025-07-09 00:17:53.692606:  
2025-07-09 00:17:53.692765: Epoch 595 
2025-07-09 00:17:53.692888: Current learning rate: 0.00443 
2025-07-09 00:18:40.526226: train_loss -0.7066 
2025-07-09 00:18:40.526522: val_loss -0.7014 
2025-07-09 00:18:40.526604: Pseudo dice [np.float32(0.7739)] 
2025-07-09 00:18:40.526696: Epoch time: 46.83 s 
2025-07-09 00:18:42.668660:  
2025-07-09 00:18:42.668976: Epoch 596 
2025-07-09 00:18:42.669118: Current learning rate: 0.00442 
2025-07-09 00:19:29.715830: train_loss -0.6704 
2025-07-09 00:19:29.716252: val_loss -0.6493 
2025-07-09 00:19:29.716340: Pseudo dice [np.float32(0.7469)] 
2025-07-09 00:19:29.716459: Epoch time: 47.05 s 
2025-07-09 00:19:30.925084:  
2025-07-09 00:19:30.925869: Epoch 597 
2025-07-09 00:19:30.926012: Current learning rate: 0.00441 
2025-07-09 00:20:19.655105: train_loss -0.6879 
2025-07-09 00:20:19.655749: val_loss -0.7107 
2025-07-09 00:20:19.655853: Pseudo dice [np.float32(0.8121)] 
2025-07-09 00:20:19.655996: Epoch time: 48.73 s 
2025-07-09 00:20:20.828911:  
2025-07-09 00:20:20.829311: Epoch 598 
2025-07-09 00:20:20.829436: Current learning rate: 0.0044 
2025-07-09 00:21:09.908969: train_loss -0.7157 
2025-07-09 00:21:09.909557: val_loss -0.7253 
2025-07-09 00:21:09.909642: Pseudo dice [np.float32(0.7876)] 
2025-07-09 00:21:09.909800: Epoch time: 49.08 s 
2025-07-09 00:21:11.105026:  
2025-07-09 00:21:11.105384: Epoch 599 
2025-07-09 00:21:11.105559: Current learning rate: 0.00439 
2025-07-09 00:21:59.693874: train_loss -0.6898 
2025-07-09 00:21:59.694563: val_loss -0.684 
2025-07-09 00:21:59.694720: Pseudo dice [np.float32(0.7875)] 
2025-07-09 00:21:59.694844: Epoch time: 48.59 s 
2025-07-09 00:22:01.413347:  
2025-07-09 00:22:01.413814: Epoch 600 
2025-07-09 00:22:01.413948: Current learning rate: 0.00438 
2025-07-09 00:22:50.719202: train_loss -0.68 
2025-07-09 00:22:50.719930: val_loss -0.7068 
2025-07-09 00:22:50.720044: Pseudo dice [np.float32(0.7806)] 
2025-07-09 00:22:50.720190: Epoch time: 49.31 s 
2025-07-09 00:22:51.898652:  
2025-07-09 00:22:51.898899: Epoch 601 
2025-07-09 00:22:51.899098: Current learning rate: 0.00437 
2025-07-09 00:23:40.120343: train_loss -0.6912 
2025-07-09 00:23:40.120957: val_loss -0.6906 
2025-07-09 00:23:40.121045: Pseudo dice [np.float32(0.8019)] 
2025-07-09 00:23:40.121169: Epoch time: 48.22 s 
2025-07-09 00:23:41.427506:  
2025-07-09 00:23:41.428006: Epoch 602 
2025-07-09 00:23:41.428186: Current learning rate: 0.00436 
2025-07-09 00:24:29.454280: train_loss -0.7172 
2025-07-09 00:24:29.454858: val_loss -0.6965 
2025-07-09 00:24:29.454950: Pseudo dice [np.float32(0.8028)] 
2025-07-09 00:24:29.455056: Epoch time: 48.03 s 
2025-07-09 00:24:30.719347:  
2025-07-09 00:24:30.719530: Epoch 603 
2025-07-09 00:24:30.719806: Current learning rate: 0.00435 
2025-07-09 00:25:19.389382: train_loss -0.7052 
2025-07-09 00:25:19.390004: val_loss -0.7357 
2025-07-09 00:25:19.390100: Pseudo dice [np.float32(0.8049)] 
2025-07-09 00:25:19.390220: Epoch time: 48.67 s 
2025-07-09 00:25:20.599845:  
2025-07-09 00:25:20.600207: Epoch 604 
2025-07-09 00:25:20.600406: Current learning rate: 0.00434 
2025-07-09 00:26:09.131879: train_loss -0.7312 
2025-07-09 00:26:09.132338: val_loss -0.7254 
2025-07-09 00:26:09.132426: Pseudo dice [np.float32(0.7919)] 
2025-07-09 00:26:09.132537: Epoch time: 48.53 s 
2025-07-09 00:26:10.393219:  
2025-07-09 00:26:10.393458: Epoch 605 
2025-07-09 00:26:10.393614: Current learning rate: 0.00433 
2025-07-09 00:26:59.109320: train_loss -0.7016 
2025-07-09 00:26:59.109815: val_loss -0.7498 
2025-07-09 00:26:59.109952: Pseudo dice [np.float32(0.8185)] 
2025-07-09 00:26:59.110069: Epoch time: 48.72 s 
2025-07-09 00:27:00.322479:  
2025-07-09 00:27:00.323050: Epoch 606 
2025-07-09 00:27:00.323230: Current learning rate: 0.00432 
2025-07-09 00:27:48.112506: train_loss -0.7017 
2025-07-09 00:27:48.113061: val_loss -0.7068 
2025-07-09 00:27:48.113143: Pseudo dice [np.float32(0.7832)] 
2025-07-09 00:27:48.113249: Epoch time: 47.79 s 
2025-07-09 00:27:49.330705:  
2025-07-09 00:27:49.331057: Epoch 607 
2025-07-09 00:27:49.331469: Current learning rate: 0.00431 
2025-07-09 00:28:36.697480: train_loss -0.6956 
2025-07-09 00:28:36.697983: val_loss -0.7318 
2025-07-09 00:28:36.698079: Pseudo dice [np.float32(0.7853)] 
2025-07-09 00:28:36.698190: Epoch time: 47.37 s 
2025-07-09 00:28:37.980397:  
2025-07-09 00:28:37.980681: Epoch 608 
2025-07-09 00:28:37.980807: Current learning rate: 0.0043 
2025-07-09 00:29:25.739020: train_loss -0.7103 
2025-07-09 00:29:25.739395: val_loss -0.7277 
2025-07-09 00:29:25.739473: Pseudo dice [np.float32(0.7812)] 
2025-07-09 00:29:25.739584: Epoch time: 47.76 s 
2025-07-09 00:29:26.931871:  
2025-07-09 00:29:26.932019: Epoch 609 
2025-07-09 00:29:26.932136: Current learning rate: 0.00429 
2025-07-09 00:30:14.029045: train_loss -0.6855 
2025-07-09 00:30:14.029837: val_loss -0.5856 
2025-07-09 00:30:14.029987: Pseudo dice [np.float32(0.76)] 
2025-07-09 00:30:14.030159: Epoch time: 47.1 s 
2025-07-09 00:30:15.938533:  
2025-07-09 00:30:15.938918: Epoch 610 
2025-07-09 00:30:15.939042: Current learning rate: 0.00429 
2025-07-09 00:31:01.948165: train_loss -0.6612 
2025-07-09 00:31:01.948461: val_loss -0.7093 
2025-07-09 00:31:01.948552: Pseudo dice [np.float32(0.8039)] 
2025-07-09 00:31:01.948648: Epoch time: 46.01 s 
2025-07-09 00:31:03.085055:  
2025-07-09 00:31:03.085562: Epoch 611 
2025-07-09 00:31:03.085705: Current learning rate: 0.00428 
2025-07-09 00:31:49.826841: train_loss -0.677 
2025-07-09 00:31:49.827486: val_loss -0.6771 
2025-07-09 00:31:49.827587: Pseudo dice [np.float32(0.7478)] 
2025-07-09 00:31:49.827704: Epoch time: 46.74 s 
2025-07-09 00:31:51.066614:  
2025-07-09 00:31:51.066915: Epoch 612 
2025-07-09 00:31:51.067181: Current learning rate: 0.00427 
2025-07-09 00:32:37.089377: train_loss -0.692 
2025-07-09 00:32:37.090048: val_loss -0.7155 
2025-07-09 00:32:37.090149: Pseudo dice [np.float32(0.8012)] 
2025-07-09 00:32:37.090270: Epoch time: 46.02 s 
2025-07-09 00:32:38.359300:  
2025-07-09 00:32:38.359955: Epoch 613 
2025-07-09 00:32:38.360235: Current learning rate: 0.00426 
2025-07-09 00:33:26.219829: train_loss -0.6814 
2025-07-09 00:33:26.220177: val_loss -0.6803 
2025-07-09 00:33:26.220261: Pseudo dice [np.float32(0.7846)] 
2025-07-09 00:33:26.220373: Epoch time: 47.86 s 
2025-07-09 00:33:27.389383:  
2025-07-09 00:33:27.389808: Epoch 614 
2025-07-09 00:33:27.389944: Current learning rate: 0.00425 
2025-07-09 00:34:14.603719: train_loss -0.6876 
2025-07-09 00:34:14.604215: val_loss -0.7201 
2025-07-09 00:34:14.604296: Pseudo dice [np.float32(0.802)] 
2025-07-09 00:34:14.604398: Epoch time: 47.22 s 
2025-07-09 00:34:15.790790:  
2025-07-09 00:34:15.791210: Epoch 615 
2025-07-09 00:34:15.791346: Current learning rate: 0.00424 
2025-07-09 00:35:03.105387: train_loss -0.7054 
2025-07-09 00:35:03.105958: val_loss -0.713 
2025-07-09 00:35:03.106054: Pseudo dice [np.float32(0.807)] 
2025-07-09 00:35:03.106179: Epoch time: 47.32 s 
2025-07-09 00:35:04.345237:  
2025-07-09 00:35:04.345478: Epoch 616 
2025-07-09 00:35:04.345671: Current learning rate: 0.00423 
2025-07-09 00:35:52.842974: train_loss -0.7369 
2025-07-09 00:35:52.844297: val_loss -0.7649 
2025-07-09 00:35:52.844514: Pseudo dice [np.float32(0.811)] 
2025-07-09 00:35:52.844748: Epoch time: 48.5 s 
2025-07-09 00:35:54.065892:  
2025-07-09 00:35:54.066225: Epoch 617 
2025-07-09 00:35:54.066418: Current learning rate: 0.00422 
2025-07-09 00:36:42.709309: train_loss -0.7286 
2025-07-09 00:36:42.709934: val_loss -0.7617 
2025-07-09 00:36:42.710030: Pseudo dice [np.float32(0.8065)] 
2025-07-09 00:36:42.710149: Epoch time: 48.64 s 
2025-07-09 00:36:43.987061:  
2025-07-09 00:36:43.987661: Epoch 618 
2025-07-09 00:36:43.987843: Current learning rate: 0.00421 
2025-07-09 00:37:32.206426: train_loss -0.7424 
2025-07-09 00:37:32.207514: val_loss -0.7365 
2025-07-09 00:37:32.207634: Pseudo dice [np.float32(0.817)] 
2025-07-09 00:37:32.207817: Epoch time: 48.22 s 
2025-07-09 00:37:33.454356:  
2025-07-09 00:37:33.454563: Epoch 619 
2025-07-09 00:37:33.454811: Current learning rate: 0.0042 
2025-07-09 00:38:23.286821: train_loss -0.6914 
2025-07-09 00:38:23.287242: val_loss -0.7157 
2025-07-09 00:38:23.287326: Pseudo dice [np.float32(0.794)] 
2025-07-09 00:38:23.287432: Epoch time: 49.83 s 
2025-07-09 00:38:24.600013:  
2025-07-09 00:38:24.600263: Epoch 620 
2025-07-09 00:38:24.600387: Current learning rate: 0.00419 
2025-07-09 00:39:14.330812: train_loss -0.6968 
2025-07-09 00:39:14.331242: val_loss -0.6908 
2025-07-09 00:39:14.331329: Pseudo dice [np.float32(0.8097)] 
2025-07-09 00:39:14.331423: Epoch time: 49.73 s 
2025-07-09 00:39:15.523652:  
2025-07-09 00:39:15.524133: Epoch 621 
2025-07-09 00:39:15.524312: Current learning rate: 0.00418 
2025-07-09 00:40:03.945782: train_loss -0.7059 
2025-07-09 00:40:03.946191: val_loss -0.7367 
2025-07-09 00:40:03.946292: Pseudo dice [np.float32(0.8025)] 
2025-07-09 00:40:03.946410: Epoch time: 48.42 s 
2025-07-09 00:40:05.134254:  
2025-07-09 00:40:05.134435: Epoch 622 
2025-07-09 00:40:05.134588: Current learning rate: 0.00417 
2025-07-09 00:40:54.263878: train_loss -0.7155 
2025-07-09 00:40:54.264291: val_loss -0.7238 
2025-07-09 00:40:54.264391: Pseudo dice [np.float32(0.7935)] 
2025-07-09 00:40:54.264528: Epoch time: 49.13 s 
2025-07-09 00:40:55.454504:  
2025-07-09 00:40:55.454725: Epoch 623 
2025-07-09 00:40:55.455006: Current learning rate: 0.00416 
2025-07-09 00:41:43.000242: train_loss -0.7158 
2025-07-09 00:41:43.001266: val_loss -0.6834 
2025-07-09 00:41:43.001410: Pseudo dice [np.float32(0.8014)] 
2025-07-09 00:41:43.001607: Epoch time: 47.55 s 
2025-07-09 00:41:44.360171:  
2025-07-09 00:41:44.360571: Epoch 624 
2025-07-09 00:41:44.360770: Current learning rate: 0.00415 
2025-07-09 00:42:32.819484: train_loss -0.7394 
2025-07-09 00:42:32.819988: val_loss -0.7653 
2025-07-09 00:42:32.820104: Pseudo dice [np.float32(0.8192)] 
2025-07-09 00:42:32.820222: Epoch time: 48.46 s 
2025-07-09 00:42:34.710622:  
2025-07-09 00:42:34.711036: Epoch 625 
2025-07-09 00:42:34.711163: Current learning rate: 0.00414 
2025-07-09 00:43:23.573892: train_loss -0.7645 
2025-07-09 00:43:23.575758: val_loss -0.7673 
2025-07-09 00:43:23.576056: Pseudo dice [np.float32(0.8183)] 
2025-07-09 00:43:23.576292: Epoch time: 48.86 s 
2025-07-09 00:43:24.812227:  
2025-07-09 00:43:24.812642: Epoch 626 
2025-07-09 00:43:24.812842: Current learning rate: 0.00413 
2025-07-09 00:44:12.222566: train_loss -0.7257 
2025-07-09 00:44:12.222980: val_loss -0.7333 
2025-07-09 00:44:12.223054: Pseudo dice [np.float32(0.7969)] 
2025-07-09 00:44:12.223171: Epoch time: 47.41 s 
2025-07-09 00:44:13.450114:  
2025-07-09 00:44:13.450978: Epoch 627 
2025-07-09 00:44:13.451438: Current learning rate: 0.00412 
2025-07-09 00:45:02.031728: train_loss -0.711 
2025-07-09 00:45:02.032411: val_loss -0.7156 
2025-07-09 00:45:02.032511: Pseudo dice [np.float32(0.7757)] 
2025-07-09 00:45:02.032682: Epoch time: 48.58 s 
2025-07-09 00:45:03.351252:  
2025-07-09 00:45:03.351717: Epoch 628 
2025-07-09 00:45:03.351901: Current learning rate: 0.00411 
2025-07-09 00:45:52.092182: train_loss -0.7232 
2025-07-09 00:45:52.093274: val_loss -0.7208 
2025-07-09 00:45:52.093365: Pseudo dice [np.float32(0.8071)] 
2025-07-09 00:45:52.093495: Epoch time: 48.74 s 
2025-07-09 00:45:53.323695:  
2025-07-09 00:45:53.323890: Epoch 629 
2025-07-09 00:45:53.324008: Current learning rate: 0.0041 
2025-07-09 00:46:41.313911: train_loss -0.7467 
2025-07-09 00:46:41.314394: val_loss -0.7641 
2025-07-09 00:46:41.314490: Pseudo dice [np.float32(0.8111)] 
2025-07-09 00:46:41.314622: Epoch time: 47.99 s 
2025-07-09 00:46:42.538198:  
2025-07-09 00:46:42.538673: Epoch 630 
2025-07-09 00:46:42.538813: Current learning rate: 0.00409 
2025-07-09 00:47:31.239668: train_loss -0.7334 
2025-07-09 00:47:31.240128: val_loss -0.7076 
2025-07-09 00:47:31.240210: Pseudo dice [np.float32(0.7958)] 
2025-07-09 00:47:31.240316: Epoch time: 48.7 s 
2025-07-09 00:47:32.416028:  
2025-07-09 00:47:32.416239: Epoch 631 
2025-07-09 00:47:32.416364: Current learning rate: 0.00408 
2025-07-09 00:48:21.228693: train_loss -0.7345 
2025-07-09 00:48:21.229225: val_loss -0.7745 
2025-07-09 00:48:21.229314: Pseudo dice [np.float32(0.8259)] 
2025-07-09 00:48:21.229432: Epoch time: 48.81 s 
2025-07-09 00:48:22.430221:  
2025-07-09 00:48:22.430688: Epoch 632 
2025-07-09 00:48:22.430823: Current learning rate: 0.00407 
2025-07-09 00:49:09.441633: train_loss -0.7485 
2025-07-09 00:49:09.442148: val_loss -0.7617 
2025-07-09 00:49:09.442235: Pseudo dice [np.float32(0.8239)] 
2025-07-09 00:49:09.442362: Epoch time: 47.01 s 
2025-07-09 00:49:10.616188:  
2025-07-09 00:49:10.616440: Epoch 633 
2025-07-09 00:49:10.616632: Current learning rate: 0.00406 
2025-07-09 00:49:57.375443: train_loss -0.7442 
2025-07-09 00:49:57.375938: val_loss -0.7444 
2025-07-09 00:49:57.376021: Pseudo dice [np.float32(0.8275)] 
2025-07-09 00:49:57.376141: Epoch time: 46.76 s 
2025-07-09 00:49:58.611256:  
2025-07-09 00:49:58.612064: Epoch 634 
2025-07-09 00:49:58.612214: Current learning rate: 0.00405 
2025-07-09 00:50:45.564600: train_loss -0.7622 
2025-07-09 00:50:45.565063: val_loss -0.7764 
2025-07-09 00:50:45.565146: Pseudo dice [np.float32(0.8224)] 
2025-07-09 00:50:45.565252: Epoch time: 46.95 s 
2025-07-09 00:50:46.790582:  
2025-07-09 00:50:46.790798: Epoch 635 
2025-07-09 00:50:46.790996: Current learning rate: 0.00404 
2025-07-09 00:51:33.183736: train_loss -0.7623 
2025-07-09 00:51:33.184214: val_loss -0.7738 
2025-07-09 00:51:33.184348: Pseudo dice [np.float32(0.8329)] 
2025-07-09 00:51:33.184479: Epoch time: 46.39 s 
2025-07-09 00:51:34.395530:  
2025-07-09 00:51:34.395936: Epoch 636 
2025-07-09 00:51:34.396068: Current learning rate: 0.00403 
2025-07-09 00:52:22.627311: train_loss -0.761 
2025-07-09 00:52:22.627820: val_loss -0.7771 
2025-07-09 00:52:22.627909: Pseudo dice [np.float32(0.832)] 
2025-07-09 00:52:22.628031: Epoch time: 48.23 s 
2025-07-09 00:52:23.837847:  
2025-07-09 00:52:23.838141: Epoch 637 
2025-07-09 00:52:23.838378: Current learning rate: 0.00402 
2025-07-09 00:53:14.064826: train_loss -0.7279 
2025-07-09 00:53:14.065861: val_loss -0.7734 
2025-07-09 00:53:14.065980: Pseudo dice [np.float32(0.803)] 
2025-07-09 00:53:14.066133: Epoch time: 50.23 s 
2025-07-09 00:53:15.338891:  
2025-07-09 00:53:15.339199: Epoch 638 
2025-07-09 00:53:15.339442: Current learning rate: 0.00401 
2025-07-09 00:54:04.758574: train_loss -0.7609 
2025-07-09 00:54:04.758987: val_loss -0.7769 
2025-07-09 00:54:04.759071: Pseudo dice [np.float32(0.825)] 
2025-07-09 00:54:04.759202: Epoch time: 49.42 s 
2025-07-09 00:54:07.057107:  
2025-07-09 00:54:07.057379: Epoch 639 
2025-07-09 00:54:07.057562: Current learning rate: 0.004 
2025-07-09 00:54:54.765415: train_loss -0.7479 
2025-07-09 00:54:54.766846: val_loss -0.7735 
2025-07-09 00:54:54.770769: Pseudo dice [np.float32(0.8234)] 
2025-07-09 00:54:54.771333: Epoch time: 47.71 s 
2025-07-09 00:54:56.026587:  
2025-07-09 00:54:56.026821: Epoch 640 
2025-07-09 00:54:56.027132: Current learning rate: 0.00399 
2025-07-09 00:55:45.739239: train_loss -0.7417 
2025-07-09 00:55:45.740076: val_loss -0.7585 
2025-07-09 00:55:45.740179: Pseudo dice [np.float32(0.8279)] 
2025-07-09 00:55:45.740351: Epoch time: 49.71 s 
2025-07-09 00:55:46.945147:  
2025-07-09 00:55:46.945521: Epoch 641 
2025-07-09 00:55:46.945882: Current learning rate: 0.00398 
2025-07-09 00:56:34.340773: train_loss -0.7483 
2025-07-09 00:56:34.341199: val_loss -0.7458 
2025-07-09 00:56:34.341277: Pseudo dice [np.float32(0.8356)] 
2025-07-09 00:56:34.341378: Epoch time: 47.4 s 
2025-07-09 00:56:35.536874:  
2025-07-09 00:56:35.537163: Epoch 642 
2025-07-09 00:56:35.537615: Current learning rate: 0.00397 
2025-07-09 00:57:22.622675: train_loss -0.7054 
2025-07-09 00:57:22.623233: val_loss -0.7282 
2025-07-09 00:57:22.623321: Pseudo dice [np.float32(0.7861)] 
2025-07-09 00:57:22.623423: Epoch time: 47.09 s 
2025-07-09 00:57:23.784161:  
2025-07-09 00:57:23.784606: Epoch 643 
2025-07-09 00:57:23.784742: Current learning rate: 0.00396 
2025-07-09 00:58:11.061692: train_loss -0.7345 
2025-07-09 00:58:11.062266: val_loss -0.7654 
2025-07-09 00:58:11.062394: Pseudo dice [np.float32(0.7914)] 
2025-07-09 00:58:11.062499: Epoch time: 47.28 s 
2025-07-09 00:58:12.226467:  
2025-07-09 00:58:12.226899: Epoch 644 
2025-07-09 00:58:12.227022: Current learning rate: 0.00395 
2025-07-09 00:58:59.585350: train_loss -0.7377 
2025-07-09 00:58:59.586804: val_loss -0.7275 
2025-07-09 00:58:59.586980: Pseudo dice [np.float32(0.8196)] 
2025-07-09 00:58:59.587185: Epoch time: 47.36 s 
2025-07-09 00:59:00.826859:  
2025-07-09 00:59:00.827403: Epoch 645 
2025-07-09 00:59:00.827627: Current learning rate: 0.00394 
2025-07-09 00:59:49.630354: train_loss -0.7622 
2025-07-09 00:59:49.631185: val_loss -0.7481 
2025-07-09 00:59:49.631298: Pseudo dice [np.float32(0.8127)] 
2025-07-09 00:59:49.631440: Epoch time: 48.81 s 
2025-07-09 00:59:50.868947:  
2025-07-09 00:59:50.869226: Epoch 646 
2025-07-09 00:59:50.869401: Current learning rate: 0.00393 
2025-07-09 01:00:39.679738: train_loss -0.756 
2025-07-09 01:00:39.680192: val_loss -0.7638 
2025-07-09 01:00:39.680279: Pseudo dice [np.float32(0.811)] 
2025-07-09 01:00:39.680374: Epoch time: 48.81 s 
2025-07-09 01:00:40.922693:  
2025-07-09 01:00:40.923341: Epoch 647 
2025-07-09 01:00:40.923535: Current learning rate: 0.00392 
2025-07-09 01:01:28.796976: train_loss -0.738 
2025-07-09 01:01:28.797678: val_loss -0.7355 
2025-07-09 01:01:28.797768: Pseudo dice [np.float32(0.8121)] 
2025-07-09 01:01:28.797885: Epoch time: 47.88 s 
2025-07-09 01:01:30.081170:  
2025-07-09 01:01:30.081940: Epoch 648 
2025-07-09 01:01:30.082075: Current learning rate: 0.00391 
2025-07-09 01:02:16.873496: train_loss -0.7112 
2025-07-09 01:02:16.873886: val_loss -0.7265 
2025-07-09 01:02:16.873968: Pseudo dice [np.float32(0.8064)] 
2025-07-09 01:02:16.874079: Epoch time: 46.79 s 
2025-07-09 01:02:18.127308:  
2025-07-09 01:02:18.127690: Epoch 649 
2025-07-09 01:02:18.128064: Current learning rate: 0.0039 
2025-07-09 01:03:04.877988: train_loss -0.721 
2025-07-09 01:03:04.878581: val_loss -0.7308 
2025-07-09 01:03:04.878685: Pseudo dice [np.float32(0.8141)] 
2025-07-09 01:03:04.878812: Epoch time: 46.75 s 
2025-07-09 01:03:06.639439:  
2025-07-09 01:03:06.639985: Epoch 650 
2025-07-09 01:03:06.640325: Current learning rate: 0.00389 
2025-07-09 01:03:53.866191: train_loss -0.7404 
2025-07-09 01:03:53.866779: val_loss -0.7481 
2025-07-09 01:03:53.866870: Pseudo dice [np.float32(0.8154)] 
2025-07-09 01:03:53.866986: Epoch time: 47.23 s 
2025-07-09 01:03:55.113299:  
2025-07-09 01:03:55.113804: Epoch 651 
2025-07-09 01:03:55.114060: Current learning rate: 0.00388 
2025-07-09 01:04:43.017996: train_loss -0.7543 
2025-07-09 01:04:43.018306: val_loss -0.7644 
2025-07-09 01:04:43.018382: Pseudo dice [np.float32(0.8155)] 
2025-07-09 01:04:43.018503: Epoch time: 47.91 s 
2025-07-09 01:04:44.209037:  
2025-07-09 01:04:44.209326: Epoch 652 
2025-07-09 01:04:44.209492: Current learning rate: 0.00387 
2025-07-09 01:05:33.032715: train_loss -0.7625 
2025-07-09 01:05:33.033183: val_loss -0.7191 
2025-07-09 01:05:33.033272: Pseudo dice [np.float32(0.8143)] 
2025-07-09 01:05:33.033373: Epoch time: 48.82 s 
2025-07-09 01:05:35.192305:  
2025-07-09 01:05:35.192770: Epoch 653 
2025-07-09 01:05:35.192929: Current learning rate: 0.00386 
2025-07-09 01:06:22.731415: train_loss -0.7388 
2025-07-09 01:06:22.731888: val_loss -0.7216 
2025-07-09 01:06:22.731973: Pseudo dice [np.float32(0.8026)] 
2025-07-09 01:06:22.732074: Epoch time: 47.54 s 
2025-07-09 01:06:23.984918:  
2025-07-09 01:06:23.985471: Epoch 654 
2025-07-09 01:06:23.985760: Current learning rate: 0.00385 
2025-07-09 01:07:10.388829: train_loss -0.7177 
2025-07-09 01:07:10.389431: val_loss -0.7441 
2025-07-09 01:07:10.389525: Pseudo dice [np.float32(0.8256)] 
2025-07-09 01:07:10.389647: Epoch time: 46.4 s 
2025-07-09 01:07:11.707311:  
2025-07-09 01:07:11.708048: Epoch 655 
2025-07-09 01:07:11.708481: Current learning rate: 0.00384 
2025-07-09 01:08:00.161011: train_loss -0.758 
2025-07-09 01:08:00.161506: val_loss -0.7771 
2025-07-09 01:08:00.161749: Pseudo dice [np.float32(0.8295)] 
2025-07-09 01:08:00.161912: Epoch time: 48.45 s 
2025-07-09 01:08:01.381343:  
2025-07-09 01:08:01.381785: Epoch 656 
2025-07-09 01:08:01.381916: Current learning rate: 0.00383 
2025-07-09 01:08:48.495337: train_loss -0.7456 
2025-07-09 01:08:48.495883: val_loss -0.7093 
2025-07-09 01:08:48.495983: Pseudo dice [np.float32(0.8146)] 
2025-07-09 01:08:48.496111: Epoch time: 47.12 s 
2025-07-09 01:08:49.719150:  
2025-07-09 01:08:49.719808: Epoch 657 
2025-07-09 01:08:49.719972: Current learning rate: 0.00382 
2025-07-09 01:09:36.891497: train_loss -0.7486 
2025-07-09 01:09:36.891977: val_loss -0.762 
2025-07-09 01:09:36.892067: Pseudo dice [np.float32(0.8257)] 
2025-07-09 01:09:36.892195: Epoch time: 47.17 s 
2025-07-09 01:09:38.128103:  
2025-07-09 01:09:38.128299: Epoch 658 
2025-07-09 01:09:38.128427: Current learning rate: 0.00381 
2025-07-09 01:10:24.167813: train_loss -0.7466 
2025-07-09 01:10:24.168888: val_loss -0.7499 
2025-07-09 01:10:24.169033: Pseudo dice [np.float32(0.8291)] 
2025-07-09 01:10:24.169168: Epoch time: 46.04 s 
2025-07-09 01:10:25.437773:  
2025-07-09 01:10:25.438199: Epoch 659 
2025-07-09 01:10:25.438367: Current learning rate: 0.0038 
2025-07-09 01:11:11.939534: train_loss -0.7628 
2025-07-09 01:11:11.940021: val_loss -0.7257 
2025-07-09 01:11:11.940106: Pseudo dice [np.float32(0.7916)] 
2025-07-09 01:11:11.940227: Epoch time: 46.5 s 
2025-07-09 01:11:13.146927:  
2025-07-09 01:11:13.147228: Epoch 660 
2025-07-09 01:11:13.147577: Current learning rate: 0.00379 
2025-07-09 01:11:59.884862: train_loss -0.7332 
2025-07-09 01:11:59.885413: val_loss -0.7833 
2025-07-09 01:11:59.885499: Pseudo dice [np.float32(0.833)] 
2025-07-09 01:11:59.885621: Epoch time: 46.74 s 
2025-07-09 01:12:01.177593:  
2025-07-09 01:12:01.178253: Epoch 661 
2025-07-09 01:12:01.178387: Current learning rate: 0.00378 
2025-07-09 01:12:47.722338: train_loss -0.7498 
2025-07-09 01:12:47.722898: val_loss -0.7687 
2025-07-09 01:12:47.722987: Pseudo dice [np.float32(0.8248)] 
2025-07-09 01:12:47.723112: Epoch time: 46.55 s 
2025-07-09 01:12:49.068289:  
2025-07-09 01:12:49.068657: Epoch 662 
2025-07-09 01:12:49.068919: Current learning rate: 0.00377 
2025-07-09 01:13:35.530800: train_loss -0.7418 
2025-07-09 01:13:35.531351: val_loss -0.7005 
2025-07-09 01:13:35.531459: Pseudo dice [np.float32(0.7988)] 
2025-07-09 01:13:35.531600: Epoch time: 46.46 s 
2025-07-09 01:13:36.858972:  
2025-07-09 01:13:36.859428: Epoch 663 
2025-07-09 01:13:36.859581: Current learning rate: 0.00376 
2025-07-09 01:14:23.897028: train_loss -0.7369 
2025-07-09 01:14:23.897391: val_loss -0.7689 
2025-07-09 01:14:23.897472: Pseudo dice [np.float32(0.8219)] 
2025-07-09 01:14:23.897590: Epoch time: 47.04 s 
2025-07-09 01:14:25.042181:  
2025-07-09 01:14:25.042375: Epoch 664 
2025-07-09 01:14:25.042498: Current learning rate: 0.00375 
2025-07-09 01:15:11.267051: train_loss -0.7562 
2025-07-09 01:15:11.267451: val_loss -0.7727 
2025-07-09 01:15:11.267534: Pseudo dice [np.float32(0.8231)] 
2025-07-09 01:15:11.267649: Epoch time: 46.23 s 
2025-07-09 01:15:12.435946:  
2025-07-09 01:15:12.436232: Epoch 665 
2025-07-09 01:15:12.436390: Current learning rate: 0.00374 
2025-07-09 01:15:58.487559: train_loss -0.7561 
2025-07-09 01:15:58.488132: val_loss -0.7749 
2025-07-09 01:15:58.488219: Pseudo dice [np.float32(0.8193)] 
2025-07-09 01:15:58.488335: Epoch time: 46.05 s 
2025-07-09 01:15:59.739871:  
2025-07-09 01:15:59.740237: Epoch 666 
2025-07-09 01:15:59.740361: Current learning rate: 0.00373 
2025-07-09 01:16:45.944197: train_loss -0.7651 
2025-07-09 01:16:45.944834: val_loss -0.7647 
2025-07-09 01:16:45.944924: Pseudo dice [np.float32(0.8241)] 
2025-07-09 01:16:45.945046: Epoch time: 46.21 s 
2025-07-09 01:16:48.145918:  
2025-07-09 01:16:48.146267: Epoch 667 
2025-07-09 01:16:48.146441: Current learning rate: 0.00372 
2025-07-09 01:17:35.092429: train_loss -0.7551 
2025-07-09 01:17:35.093322: val_loss -0.7706 
2025-07-09 01:17:35.093475: Pseudo dice [np.float32(0.8192)] 
2025-07-09 01:17:35.093660: Epoch time: 46.95 s 
2025-07-09 01:17:36.302639:  
2025-07-09 01:17:36.302924: Epoch 668 
2025-07-09 01:17:36.303289: Current learning rate: 0.00371 
2025-07-09 01:18:22.846800: train_loss -0.7656 
2025-07-09 01:18:22.847827: val_loss -0.7822 
2025-07-09 01:18:22.847929: Pseudo dice [np.float32(0.824)] 
2025-07-09 01:18:22.848086: Epoch time: 46.55 s 
2025-07-09 01:18:24.042832:  
2025-07-09 01:18:24.043364: Epoch 669 
2025-07-09 01:18:24.043696: Current learning rate: 0.0037 
2025-07-09 01:19:11.412986: train_loss -0.7617 
2025-07-09 01:19:11.413706: val_loss -0.7768 
2025-07-09 01:19:11.413817: Pseudo dice [np.float32(0.8315)] 
2025-07-09 01:19:11.413952: Epoch time: 47.37 s 
2025-07-09 01:19:12.692640:  
2025-07-09 01:19:12.693072: Epoch 670 
2025-07-09 01:19:12.693380: Current learning rate: 0.00369 
2025-07-09 01:20:00.643609: train_loss -0.762 
2025-07-09 01:20:00.644511: val_loss -0.8133 
2025-07-09 01:20:00.644612: Pseudo dice [np.float32(0.8308)] 
2025-07-09 01:20:00.644781: Epoch time: 47.95 s 
2025-07-09 01:20:01.881730:  
2025-07-09 01:20:01.882338: Epoch 671 
2025-07-09 01:20:01.882509: Current learning rate: 0.00368 
2025-07-09 01:20:48.679640: train_loss -0.7799 
2025-07-09 01:20:48.679956: val_loss -0.8059 
2025-07-09 01:20:48.680061: Pseudo dice [np.float32(0.8369)] 
2025-07-09 01:20:48.680176: Epoch time: 46.8 s 
2025-07-09 01:20:49.922834:  
2025-07-09 01:20:49.923206: Epoch 672 
2025-07-09 01:20:49.923455: Current learning rate: 0.00367 
2025-07-09 01:21:36.469828: train_loss -0.7757 
2025-07-09 01:21:36.470305: val_loss -0.7959 
2025-07-09 01:21:36.470385: Pseudo dice [np.float32(0.8414)] 
2025-07-09 01:21:36.470494: Epoch time: 46.55 s 
2025-07-09 01:21:37.662833:  
2025-07-09 01:21:37.663455: Epoch 673 
2025-07-09 01:21:37.663645: Current learning rate: 0.00366 
2025-07-09 01:22:24.122614: train_loss -0.7608 
2025-07-09 01:22:24.123460: val_loss -0.771 
2025-07-09 01:22:24.123579: Pseudo dice [np.float32(0.8256)] 
2025-07-09 01:22:24.123737: Epoch time: 46.46 s 
2025-07-09 01:22:25.424257:  
2025-07-09 01:22:25.424673: Epoch 674 
2025-07-09 01:22:25.424979: Current learning rate: 0.00365 
2025-07-09 01:23:11.608816: train_loss -0.7519 
2025-07-09 01:23:11.609441: val_loss -0.7806 
2025-07-09 01:23:11.609526: Pseudo dice [np.float32(0.8334)] 
2025-07-09 01:23:11.609662: Epoch time: 46.19 s 
2025-07-09 01:23:12.794946:  
2025-07-09 01:23:12.795233: Epoch 675 
2025-07-09 01:23:12.795504: Current learning rate: 0.00364 
2025-07-09 01:23:59.048819: train_loss -0.7643 
2025-07-09 01:23:59.049127: val_loss -0.7727 
2025-07-09 01:23:59.049201: Pseudo dice [np.float32(0.8147)] 
2025-07-09 01:23:59.049292: Epoch time: 46.25 s 
2025-07-09 01:24:00.260081:  
2025-07-09 01:24:00.260463: Epoch 676 
2025-07-09 01:24:00.260607: Current learning rate: 0.00363 
2025-07-09 01:24:47.392527: train_loss -0.7513 
2025-07-09 01:24:47.393064: val_loss -0.7984 
2025-07-09 01:24:47.393155: Pseudo dice [np.float32(0.8252)] 
2025-07-09 01:24:47.393269: Epoch time: 47.13 s 
2025-07-09 01:24:48.631874:  
2025-07-09 01:24:48.632207: Epoch 677 
2025-07-09 01:24:48.632460: Current learning rate: 0.00362 
2025-07-09 01:25:35.579155: train_loss -0.7675 
2025-07-09 01:25:35.580055: val_loss -0.7765 
2025-07-09 01:25:35.580195: Pseudo dice [np.float32(0.8271)] 
2025-07-09 01:25:35.580353: Epoch time: 46.95 s 
2025-07-09 01:25:36.939273:  
2025-07-09 01:25:36.939689: Epoch 678 
2025-07-09 01:25:36.939883: Current learning rate: 0.00361 
2025-07-09 01:26:23.475597: train_loss -0.762 
2025-07-09 01:26:23.476322: val_loss -0.7716 
2025-07-09 01:26:23.476595: Pseudo dice [np.float32(0.8311)] 
2025-07-09 01:26:23.476727: Epoch time: 46.54 s 
2025-07-09 01:26:24.692262:  
2025-07-09 01:26:24.692863: Epoch 679 
2025-07-09 01:26:24.693013: Current learning rate: 0.0036 
2025-07-09 01:27:12.080748: train_loss -0.7651 
2025-07-09 01:27:12.081327: val_loss -0.7583 
2025-07-09 01:27:12.081414: Pseudo dice [np.float32(0.8242)] 
2025-07-09 01:27:12.081530: Epoch time: 47.39 s 
2025-07-09 01:27:13.324040:  
2025-07-09 01:27:13.324394: Epoch 680 
2025-07-09 01:27:13.324524: Current learning rate: 0.00359 
2025-07-09 01:28:00.335168: train_loss -0.7445 
2025-07-09 01:28:00.335777: val_loss -0.7537 
2025-07-09 01:28:00.335878: Pseudo dice [np.float32(0.825)] 
2025-07-09 01:28:00.336029: Epoch time: 47.01 s 
2025-07-09 01:28:02.422526:  
2025-07-09 01:28:02.423001: Epoch 681 
2025-07-09 01:28:02.423430: Current learning rate: 0.00358 
2025-07-09 01:28:50.937213: train_loss -0.7653 
2025-07-09 01:28:50.937955: val_loss -0.7497 
2025-07-09 01:28:50.938036: Pseudo dice [np.float32(0.8217)] 
2025-07-09 01:28:50.938148: Epoch time: 48.52 s 
2025-07-09 01:28:52.155525:  
2025-07-09 01:28:52.155950: Epoch 682 
2025-07-09 01:28:52.156245: Current learning rate: 0.00357 
2025-07-09 01:29:40.006677: train_loss -0.7359 
2025-07-09 01:29:40.007021: val_loss -0.7967 
2025-07-09 01:29:40.007100: Pseudo dice [np.float32(0.8362)] 
2025-07-09 01:29:40.007198: Epoch time: 47.85 s 
2025-07-09 01:29:41.186948:  
2025-07-09 01:29:41.187253: Epoch 683 
2025-07-09 01:29:41.187563: Current learning rate: 0.00356 
2025-07-09 01:30:28.767778: train_loss -0.7753 
2025-07-09 01:30:28.768312: val_loss -0.7929 
2025-07-09 01:30:28.768410: Pseudo dice [np.float32(0.8426)] 
2025-07-09 01:30:28.768528: Epoch time: 47.58 s 
2025-07-09 01:30:29.971698:  
2025-07-09 01:30:29.971974: Epoch 684 
2025-07-09 01:30:29.972214: Current learning rate: 0.00355 
2025-07-09 01:31:16.456306: train_loss -0.7745 
2025-07-09 01:31:16.456652: val_loss -0.7694 
2025-07-09 01:31:16.456735: Pseudo dice [np.float32(0.8188)] 
2025-07-09 01:31:16.456852: Epoch time: 46.49 s 
2025-07-09 01:31:17.669064:  
2025-07-09 01:31:17.669628: Epoch 685 
2025-07-09 01:31:17.669774: Current learning rate: 0.00354 
2025-07-09 01:32:03.225482: train_loss -0.7005 
2025-07-09 01:32:03.226233: val_loss -0.697 
2025-07-09 01:32:03.226363: Pseudo dice [np.float32(0.8001)] 
2025-07-09 01:32:03.226571: Epoch time: 45.56 s 
2025-07-09 01:32:04.503079:  
2025-07-09 01:32:04.503501: Epoch 686 
2025-07-09 01:32:04.503694: Current learning rate: 0.00353 
2025-07-09 01:32:50.700047: train_loss -0.7278 
2025-07-09 01:32:50.700557: val_loss -0.717 
2025-07-09 01:32:50.700676: Pseudo dice [np.float32(0.8108)] 
2025-07-09 01:32:50.700815: Epoch time: 46.2 s 
2025-07-09 01:32:51.915843:  
2025-07-09 01:32:51.916379: Epoch 687 
2025-07-09 01:32:51.916592: Current learning rate: 0.00352 
2025-07-09 01:33:39.392105: train_loss -0.7221 
2025-07-09 01:33:39.392771: val_loss -0.729 
2025-07-09 01:33:39.392853: Pseudo dice [np.float32(0.8093)] 
2025-07-09 01:33:39.392972: Epoch time: 47.48 s 
2025-07-09 01:33:40.578405:  
2025-07-09 01:33:40.578842: Epoch 688 
2025-07-09 01:33:40.578980: Current learning rate: 0.00351 
2025-07-09 01:34:26.935350: train_loss -0.7172 
2025-07-09 01:34:26.936030: val_loss -0.7261 
2025-07-09 01:34:26.936172: Pseudo dice [np.float32(0.8079)] 
2025-07-09 01:34:26.936313: Epoch time: 46.36 s 
2025-07-09 01:34:28.164642:  
2025-07-09 01:34:28.165008: Epoch 689 
2025-07-09 01:34:28.165188: Current learning rate: 0.0035 
2025-07-09 01:35:14.934680: train_loss -0.7439 
2025-07-09 01:35:14.935574: val_loss -0.7869 
2025-07-09 01:35:14.935892: Pseudo dice [np.float32(0.8164)] 
2025-07-09 01:35:14.936134: Epoch time: 46.77 s 
2025-07-09 01:35:16.150568:  
2025-07-09 01:35:16.150944: Epoch 690 
2025-07-09 01:35:16.151066: Current learning rate: 0.00349 
2025-07-09 01:36:02.313789: train_loss -0.7518 
2025-07-09 01:36:02.314623: val_loss -0.7714 
2025-07-09 01:36:02.314759: Pseudo dice [np.float32(0.8222)] 
2025-07-09 01:36:02.314902: Epoch time: 46.16 s 
2025-07-09 01:36:03.550323:  
2025-07-09 01:36:03.550529: Epoch 691 
2025-07-09 01:36:03.550637: Current learning rate: 0.00348 
2025-07-09 01:36:50.269391: train_loss -0.7716 
2025-07-09 01:36:50.269922: val_loss -0.7657 
2025-07-09 01:36:50.270005: Pseudo dice [np.float32(0.8389)] 
2025-07-09 01:36:50.270123: Epoch time: 46.72 s 
2025-07-09 01:36:51.434736:  
2025-07-09 01:36:51.435053: Epoch 692 
2025-07-09 01:36:51.435228: Current learning rate: 0.00346 
2025-07-09 01:37:37.622452: train_loss -0.7613 
2025-07-09 01:37:37.623313: val_loss -0.7533 
2025-07-09 01:37:37.623419: Pseudo dice [np.float32(0.8146)] 
2025-07-09 01:37:37.623597: Epoch time: 46.19 s 
2025-07-09 01:37:38.829021:  
2025-07-09 01:37:38.829385: Epoch 693 
2025-07-09 01:37:38.829563: Current learning rate: 0.00345 
2025-07-09 01:38:25.476867: train_loss -0.7538 
2025-07-09 01:38:25.477425: val_loss -0.7672 
2025-07-09 01:38:25.477534: Pseudo dice [np.float32(0.8259)] 
2025-07-09 01:38:25.477689: Epoch time: 46.65 s 
2025-07-09 01:38:26.698007:  
2025-07-09 01:38:26.698421: Epoch 694 
2025-07-09 01:38:26.698633: Current learning rate: 0.00344 
2025-07-09 01:39:13.610050: train_loss -0.7548 
2025-07-09 01:39:13.610508: val_loss -0.7778 
2025-07-09 01:39:13.610661: Pseudo dice [np.float32(0.8163)] 
2025-07-09 01:39:13.610769: Epoch time: 46.91 s 
2025-07-09 01:39:15.584265:  
2025-07-09 01:39:15.584487: Epoch 695 
2025-07-09 01:39:15.584825: Current learning rate: 0.00343 
2025-07-09 01:40:03.055377: train_loss -0.7588 
2025-07-09 01:40:03.055897: val_loss -0.779 
2025-07-09 01:40:03.059625: Pseudo dice [np.float32(0.827)] 
2025-07-09 01:40:03.059764: Epoch time: 47.47 s 
2025-07-09 01:40:04.263305:  
2025-07-09 01:40:04.263705: Epoch 696 
2025-07-09 01:40:04.263928: Current learning rate: 0.00342 
2025-07-09 01:40:52.018473: train_loss -0.7492 
2025-07-09 01:40:52.019039: val_loss -0.7833 
2025-07-09 01:40:52.019119: Pseudo dice [np.float32(0.8205)] 
2025-07-09 01:40:52.019298: Epoch time: 47.76 s 
2025-07-09 01:40:53.178854:  
2025-07-09 01:40:53.179061: Epoch 697 
2025-07-09 01:40:53.179182: Current learning rate: 0.00341 
2025-07-09 01:41:40.487845: train_loss -0.7663 
2025-07-09 01:41:40.488335: val_loss -0.7878 
2025-07-09 01:41:40.488409: Pseudo dice [np.float32(0.8354)] 
2025-07-09 01:41:40.488502: Epoch time: 47.31 s 
2025-07-09 01:41:41.800311:  
2025-07-09 01:41:41.800742: Epoch 698 
2025-07-09 01:41:41.800880: Current learning rate: 0.0034 
2025-07-09 01:42:29.506450: train_loss -0.7624 
2025-07-09 01:42:29.507065: val_loss -0.7349 
2025-07-09 01:42:29.510671: Pseudo dice [np.float32(0.8146)] 
2025-07-09 01:42:29.510896: Epoch time: 47.71 s 
2025-07-09 01:42:30.678053:  
2025-07-09 01:42:30.678463: Epoch 699 
2025-07-09 01:42:30.678676: Current learning rate: 0.00339 
2025-07-09 01:43:17.836961: train_loss -0.7376 
2025-07-09 01:43:17.838001: val_loss -0.7678 
2025-07-09 01:43:17.838137: Pseudo dice [np.float32(0.8328)] 
2025-07-09 01:43:17.838295: Epoch time: 47.16 s 
2025-07-09 01:43:19.616495:  
2025-07-09 01:43:19.617016: Epoch 700 
2025-07-09 01:43:19.617231: Current learning rate: 0.00338 
2025-07-09 01:44:06.794721: train_loss -0.7609 
2025-07-09 01:44:06.795335: val_loss -0.7863 
2025-07-09 01:44:06.795451: Pseudo dice [np.float32(0.8256)] 
2025-07-09 01:44:06.795591: Epoch time: 47.18 s 
2025-07-09 01:44:08.122213:  
2025-07-09 01:44:08.122636: Epoch 701 
2025-07-09 01:44:08.122862: Current learning rate: 0.00337 
2025-07-09 01:44:54.761258: train_loss -0.7678 
2025-07-09 01:44:54.762424: val_loss -0.7686 
2025-07-09 01:44:54.762605: Pseudo dice [np.float32(0.8205)] 
2025-07-09 01:44:54.762771: Epoch time: 46.64 s 
2025-07-09 01:44:56.186419:  
2025-07-09 01:44:56.187063: Epoch 702 
2025-07-09 01:44:56.187218: Current learning rate: 0.00336 
2025-07-09 01:45:42.694927: train_loss -0.7607 
2025-07-09 01:45:42.695485: val_loss -0.7472 
2025-07-09 01:45:42.695604: Pseudo dice [np.float32(0.83)] 
2025-07-09 01:45:42.695718: Epoch time: 46.51 s 
2025-07-09 01:45:43.943465:  
2025-07-09 01:45:43.943793: Epoch 703 
2025-07-09 01:45:43.944118: Current learning rate: 0.00335 
2025-07-09 01:46:31.765953: train_loss -0.7389 
2025-07-09 01:46:31.766529: val_loss -0.7606 
2025-07-09 01:46:31.766627: Pseudo dice [np.float32(0.8405)] 
2025-07-09 01:46:31.766734: Epoch time: 47.82 s 
2025-07-09 01:46:33.043275:  
2025-07-09 01:46:33.043466: Epoch 704 
2025-07-09 01:46:33.043770: Current learning rate: 0.00334 
2025-07-09 01:47:20.646042: train_loss -0.7427 
2025-07-09 01:47:20.646472: val_loss -0.7362 
2025-07-09 01:47:20.646595: Pseudo dice [np.float32(0.8215)] 
2025-07-09 01:47:20.646703: Epoch time: 47.6 s 
2025-07-09 01:47:21.842297:  
2025-07-09 01:47:21.842500: Epoch 705 
2025-07-09 01:47:21.842824: Current learning rate: 0.00333 
2025-07-09 01:48:07.996918: train_loss -0.7365 
2025-07-09 01:48:07.997640: val_loss -0.7377 
2025-07-09 01:48:07.997764: Pseudo dice [np.float32(0.8155)] 
2025-07-09 01:48:07.997897: Epoch time: 46.16 s 
2025-07-09 01:48:09.239836:  
2025-07-09 01:48:09.240309: Epoch 706 
2025-07-09 01:48:09.240441: Current learning rate: 0.00332 
2025-07-09 01:48:55.895169: train_loss -0.7419 
2025-07-09 01:48:55.895610: val_loss -0.7526 
2025-07-09 01:48:55.895697: Pseudo dice [np.float32(0.8098)] 
2025-07-09 01:48:55.895808: Epoch time: 46.66 s 
2025-07-09 01:48:57.076562:  
2025-07-09 01:48:57.076819: Epoch 707 
2025-07-09 01:48:57.076952: Current learning rate: 0.00331 
2025-07-09 01:49:45.755029: train_loss -0.7115 
2025-07-09 01:49:45.755640: val_loss -0.7027 
2025-07-09 01:49:45.755724: Pseudo dice [np.float32(0.8117)] 
2025-07-09 01:49:45.755829: Epoch time: 48.68 s 
2025-07-09 01:49:46.954004:  
2025-07-09 01:49:46.954366: Epoch 708 
2025-07-09 01:49:46.954495: Current learning rate: 0.0033 
2025-07-09 01:50:35.514244: train_loss -0.7364 
2025-07-09 01:50:35.515219: val_loss -0.7482 
2025-07-09 01:50:35.515334: Pseudo dice [np.float32(0.8248)] 
2025-07-09 01:50:35.515481: Epoch time: 48.56 s 
2025-07-09 01:50:37.704515:  
2025-07-09 01:50:37.704752: Epoch 709 
2025-07-09 01:50:37.705003: Current learning rate: 0.00329 
2025-07-09 01:51:26.140974: train_loss -0.7578 
2025-07-09 01:51:26.141595: val_loss -0.76 
2025-07-09 01:51:26.141687: Pseudo dice [np.float32(0.8221)] 
2025-07-09 01:51:26.141805: Epoch time: 48.44 s 
2025-07-09 01:51:27.352856:  
2025-07-09 01:51:27.353343: Epoch 710 
2025-07-09 01:51:27.353471: Current learning rate: 0.00328 
2025-07-09 01:52:14.406830: train_loss -0.7547 
2025-07-09 01:52:14.407266: val_loss -0.7905 
2025-07-09 01:52:14.407365: Pseudo dice [np.float32(0.8351)] 
2025-07-09 01:52:14.407458: Epoch time: 47.05 s 
2025-07-09 01:52:15.591738:  
2025-07-09 01:52:15.592215: Epoch 711 
2025-07-09 01:52:15.592371: Current learning rate: 0.00327 
2025-07-09 01:53:02.859432: train_loss -0.7334 
2025-07-09 01:53:02.860457: val_loss -0.7845 
2025-07-09 01:53:02.860629: Pseudo dice [np.float32(0.8341)] 
2025-07-09 01:53:02.860758: Epoch time: 47.27 s 
2025-07-09 01:53:04.031863:  
2025-07-09 01:53:04.032157: Epoch 712 
2025-07-09 01:53:04.032415: Current learning rate: 0.00326 
2025-07-09 01:53:51.787197: train_loss -0.7702 
2025-07-09 01:53:51.787571: val_loss -0.7519 
2025-07-09 01:53:51.787654: Pseudo dice [np.float32(0.8247)] 
2025-07-09 01:53:51.787756: Epoch time: 47.76 s 
2025-07-09 01:53:52.978869:  
2025-07-09 01:53:52.979223: Epoch 713 
2025-07-09 01:53:52.979351: Current learning rate: 0.00325 
2025-07-09 01:54:40.224442: train_loss -0.7539 
2025-07-09 01:54:40.225086: val_loss -0.7585 
2025-07-09 01:54:40.225173: Pseudo dice [np.float32(0.8171)] 
2025-07-09 01:54:40.225281: Epoch time: 47.25 s 
2025-07-09 01:54:41.399681:  
2025-07-09 01:54:41.400228: Epoch 714 
2025-07-09 01:54:41.400348: Current learning rate: 0.00324 
2025-07-09 01:55:28.073083: train_loss -0.7518 
2025-07-09 01:55:28.074073: val_loss -0.7787 
2025-07-09 01:55:28.074198: Pseudo dice [np.float32(0.8142)] 
2025-07-09 01:55:28.074344: Epoch time: 46.67 s 
2025-07-09 01:55:29.292722:  
2025-07-09 01:55:29.293473: Epoch 715 
2025-07-09 01:55:29.293616: Current learning rate: 0.00323 
2025-07-09 01:56:17.337784: train_loss -0.7754 
2025-07-09 01:56:17.338238: val_loss -0.7914 
2025-07-09 01:56:17.338329: Pseudo dice [np.float32(0.8377)] 
2025-07-09 01:56:17.338436: Epoch time: 48.05 s 
2025-07-09 01:56:18.523798:  
2025-07-09 01:56:18.524086: Epoch 716 
2025-07-09 01:56:18.524220: Current learning rate: 0.00322 
2025-07-09 01:57:04.713475: train_loss -0.787 
2025-07-09 01:57:04.713954: val_loss -0.7934 
2025-07-09 01:57:04.714064: Pseudo dice [np.float32(0.8444)] 
2025-07-09 01:57:04.714193: Epoch time: 46.19 s 
2025-07-09 01:57:06.000073:  
2025-07-09 01:57:06.000388: Epoch 717 
2025-07-09 01:57:06.000583: Current learning rate: 0.00321 
2025-07-09 01:57:53.544732: train_loss -0.7916 
2025-07-09 01:57:53.545324: val_loss -0.8006 
2025-07-09 01:57:53.545444: Pseudo dice [np.float32(0.8392)] 
2025-07-09 01:57:53.545622: Epoch time: 47.55 s 
2025-07-09 01:57:54.724305:  
2025-07-09 01:57:54.724601: Epoch 718 
2025-07-09 01:57:54.724797: Current learning rate: 0.0032 
2025-07-09 01:58:42.248178: train_loss -0.7776 
2025-07-09 01:58:42.248791: val_loss -0.7982 
2025-07-09 01:58:42.248986: Pseudo dice [np.float32(0.8122)] 
2025-07-09 01:58:42.249103: Epoch time: 47.52 s 
2025-07-09 01:58:43.408376:  
2025-07-09 01:58:43.408813: Epoch 719 
2025-07-09 01:58:43.409099: Current learning rate: 0.00319 
2025-07-09 01:59:30.597492: train_loss -0.7799 
2025-07-09 01:59:30.598391: val_loss -0.797 
2025-07-09 01:59:30.598569: Pseudo dice [np.float32(0.8276)] 
2025-07-09 01:59:30.598722: Epoch time: 47.19 s 
2025-07-09 01:59:31.897033:  
2025-07-09 01:59:31.897407: Epoch 720 
2025-07-09 01:59:31.897688: Current learning rate: 0.00318 
2025-07-09 02:00:19.779611: train_loss -0.7834 
2025-07-09 02:00:19.780109: val_loss -0.783 
2025-07-09 02:00:19.780331: Pseudo dice [np.float32(0.8308)] 
2025-07-09 02:00:19.780575: Epoch time: 47.88 s 
2025-07-09 02:00:20.959410:  
2025-07-09 02:00:20.959850: Epoch 721 
2025-07-09 02:00:20.960055: Current learning rate: 0.00317 
2025-07-09 02:01:09.179353: train_loss -0.7746 
2025-07-09 02:01:09.179962: val_loss -0.8006 
2025-07-09 02:01:09.180075: Pseudo dice [np.float32(0.8123)] 
2025-07-09 02:01:09.180216: Epoch time: 48.22 s 
2025-07-09 02:01:10.443941:  
2025-07-09 02:01:10.444346: Epoch 722 
2025-07-09 02:01:10.444468: Current learning rate: 0.00316 
2025-07-09 02:01:58.982628: train_loss -0.75 
2025-07-09 02:01:58.983072: val_loss -0.7758 
2025-07-09 02:01:58.983169: Pseudo dice [np.float32(0.8356)] 
2025-07-09 02:01:58.983377: Epoch time: 48.54 s 
2025-07-09 02:02:00.919097:  
2025-07-09 02:02:00.919342: Epoch 723 
2025-07-09 02:02:00.919517: Current learning rate: 0.00315 
2025-07-09 02:02:47.297140: train_loss -0.7804 
2025-07-09 02:02:47.297485: val_loss -0.7944 
2025-07-09 02:02:47.297572: Pseudo dice [np.float32(0.8382)] 
2025-07-09 02:02:47.297669: Epoch time: 46.38 s 
2025-07-09 02:02:48.477271:  
2025-07-09 02:02:48.477576: Epoch 724 
2025-07-09 02:02:48.477772: Current learning rate: 0.00314 
2025-07-09 02:03:35.639005: train_loss -0.7763 
2025-07-09 02:03:35.639419: val_loss -0.7693 
2025-07-09 02:03:35.639497: Pseudo dice [np.float32(0.8271)] 
2025-07-09 02:03:35.639598: Epoch time: 47.16 s 
2025-07-09 02:03:36.907812:  
2025-07-09 02:03:36.908243: Epoch 725 
2025-07-09 02:03:36.908507: Current learning rate: 0.00313 
2025-07-09 02:04:23.979560: train_loss -0.7621 
2025-07-09 02:04:23.979885: val_loss -0.7875 
2025-07-09 02:04:23.979962: Pseudo dice [np.float32(0.8232)] 
2025-07-09 02:04:23.980057: Epoch time: 47.07 s 
2025-07-09 02:04:25.152083:  
2025-07-09 02:04:25.152423: Epoch 726 
2025-07-09 02:04:25.152707: Current learning rate: 0.00312 
2025-07-09 02:05:12.418737: train_loss -0.7492 
2025-07-09 02:05:12.419143: val_loss -0.7709 
2025-07-09 02:05:12.419332: Pseudo dice [np.float32(0.8185)] 
2025-07-09 02:05:12.419437: Epoch time: 47.27 s 
2025-07-09 02:05:13.648773:  
2025-07-09 02:05:13.649362: Epoch 727 
2025-07-09 02:05:13.649497: Current learning rate: 0.00311 
2025-07-09 02:06:00.814421: train_loss -0.7679 
2025-07-09 02:06:00.815087: val_loss -0.8196 
2025-07-09 02:06:00.815197: Pseudo dice [np.float32(0.8337)] 
2025-07-09 02:06:00.815347: Epoch time: 47.17 s 
2025-07-09 02:06:01.997522:  
2025-07-09 02:06:01.997944: Epoch 728 
2025-07-09 02:06:01.998068: Current learning rate: 0.0031 
2025-07-09 02:06:49.499686: train_loss -0.7668 
2025-07-09 02:06:49.500006: val_loss -0.7806 
2025-07-09 02:06:49.503569: Pseudo dice [np.float32(0.8379)] 
2025-07-09 02:06:49.503690: Epoch time: 47.5 s 
2025-07-09 02:06:50.694077:  
2025-07-09 02:06:50.694574: Epoch 729 
2025-07-09 02:06:50.694766: Current learning rate: 0.00309 
2025-07-09 02:07:38.790147: train_loss -0.7824 
2025-07-09 02:07:38.790602: val_loss -0.812 
2025-07-09 02:07:38.790733: Pseudo dice [np.float32(0.8297)] 
2025-07-09 02:07:38.790840: Epoch time: 48.1 s 
2025-07-09 02:07:39.956654:  
2025-07-09 02:07:39.956815: Epoch 730 
2025-07-09 02:07:39.956935: Current learning rate: 0.00308 
2025-07-09 02:08:27.127879: train_loss -0.7833 
2025-07-09 02:08:27.128813: val_loss -0.7858 
2025-07-09 02:08:27.128990: Pseudo dice [np.float32(0.835)] 
2025-07-09 02:08:27.129187: Epoch time: 47.17 s 
2025-07-09 02:08:28.310115:  
2025-07-09 02:08:28.310373: Epoch 731 
2025-07-09 02:08:28.310585: Current learning rate: 0.00307 
2025-07-09 02:09:14.870255: train_loss -0.7733 
2025-07-09 02:09:14.870638: val_loss -0.7893 
2025-07-09 02:09:14.870721: Pseudo dice [np.float32(0.823)] 
2025-07-09 02:09:14.870822: Epoch time: 46.56 s 
2025-07-09 02:09:16.066383:  
2025-07-09 02:09:16.066797: Epoch 732 
2025-07-09 02:09:16.067014: Current learning rate: 0.00306 
2025-07-09 02:10:03.175526: train_loss -0.7644 
2025-07-09 02:10:03.175931: val_loss -0.7935 
2025-07-09 02:10:03.176019: Pseudo dice [np.float32(0.833)] 
2025-07-09 02:10:03.176121: Epoch time: 47.11 s 
2025-07-09 02:10:04.386841:  
2025-07-09 02:10:04.387108: Epoch 733 
2025-07-09 02:10:04.387290: Current learning rate: 0.00305 
2025-07-09 02:10:51.320359: train_loss -0.7901 
2025-07-09 02:10:51.320958: val_loss -0.8181 
2025-07-09 02:10:51.321056: Pseudo dice [np.float32(0.8387)] 
2025-07-09 02:10:51.321169: Epoch time: 46.93 s 
2025-07-09 02:10:52.599106:  
2025-07-09 02:10:52.599402: Epoch 734 
2025-07-09 02:10:52.599551: Current learning rate: 0.00304 
2025-07-09 02:11:39.919930: train_loss -0.7826 
2025-07-09 02:11:39.920342: val_loss -0.7929 
2025-07-09 02:11:39.920430: Pseudo dice [np.float32(0.838)] 
2025-07-09 02:11:39.920555: Epoch time: 47.32 s 
2025-07-09 02:11:41.139055:  
2025-07-09 02:11:41.139327: Epoch 735 
2025-07-09 02:11:41.139471: Current learning rate: 0.00303 
2025-07-09 02:12:27.371392: train_loss -0.7927 
2025-07-09 02:12:27.371790: val_loss -0.7924 
2025-07-09 02:12:27.371872: Pseudo dice [np.float32(0.841)] 
2025-07-09 02:12:27.371969: Epoch time: 46.23 s 
2025-07-09 02:12:28.575892:  
2025-07-09 02:12:28.576061: Epoch 736 
2025-07-09 02:12:28.576186: Current learning rate: 0.00302 
2025-07-09 02:13:15.565112: train_loss -0.7846 
2025-07-09 02:13:15.565569: val_loss -0.7966 
2025-07-09 02:13:15.565707: Pseudo dice [np.float32(0.8269)] 
2025-07-09 02:13:15.565814: Epoch time: 46.99 s 
2025-07-09 02:13:17.706591:  
2025-07-09 02:13:17.707172: Epoch 737 
2025-07-09 02:13:17.707354: Current learning rate: 0.00301 
2025-07-09 02:14:04.198564: train_loss -0.759 
2025-07-09 02:14:04.198968: val_loss -0.6837 
2025-07-09 02:14:04.199062: Pseudo dice [np.float32(0.8089)] 
2025-07-09 02:14:04.199178: Epoch time: 46.49 s 
2025-07-09 02:14:05.434562:  
2025-07-09 02:14:05.435130: Epoch 738 
2025-07-09 02:14:05.435380: Current learning rate: 0.003 
2025-07-09 02:14:51.618315: train_loss -0.7272 
2025-07-09 02:14:51.618740: val_loss -0.7456 
2025-07-09 02:14:51.618819: Pseudo dice [np.float32(0.8254)] 
2025-07-09 02:14:51.618935: Epoch time: 46.18 s 
2025-07-09 02:14:52.835632:  
2025-07-09 02:14:52.835905: Epoch 739 
2025-07-09 02:14:52.836142: Current learning rate: 0.00299 
2025-07-09 02:15:38.490913: train_loss -0.7351 
2025-07-09 02:15:38.491394: val_loss -0.7334 
2025-07-09 02:15:38.491515: Pseudo dice [np.float32(0.7925)] 
2025-07-09 02:15:38.491665: Epoch time: 45.66 s 
2025-07-09 02:15:39.707899:  
2025-07-09 02:15:39.708308: Epoch 740 
2025-07-09 02:15:39.708434: Current learning rate: 0.00297 
2025-07-09 02:16:25.794663: train_loss -0.7227 
2025-07-09 02:16:25.795326: val_loss -0.763 
2025-07-09 02:16:25.795421: Pseudo dice [np.float32(0.8158)] 
2025-07-09 02:16:25.795528: Epoch time: 46.09 s 
2025-07-09 02:16:27.022797:  
2025-07-09 02:16:27.023129: Epoch 741 
2025-07-09 02:16:27.023401: Current learning rate: 0.00296 
2025-07-09 02:17:13.669158: train_loss -0.7526 
2025-07-09 02:17:13.669633: val_loss -0.7642 
2025-07-09 02:17:13.669718: Pseudo dice [np.float32(0.8141)] 
2025-07-09 02:17:13.669818: Epoch time: 46.65 s 
2025-07-09 02:17:14.855211:  
2025-07-09 02:17:14.855655: Epoch 742 
2025-07-09 02:17:14.855930: Current learning rate: 0.00295 
2025-07-09 02:18:01.380360: train_loss -0.7542 
2025-07-09 02:18:01.380773: val_loss -0.7808 
2025-07-09 02:18:01.380852: Pseudo dice [np.float32(0.833)] 
2025-07-09 02:18:01.380952: Epoch time: 46.53 s 
2025-07-09 02:18:02.595033:  
2025-07-09 02:18:02.595393: Epoch 743 
2025-07-09 02:18:02.595523: Current learning rate: 0.00294 
2025-07-09 02:18:49.264906: train_loss -0.7678 
2025-07-09 02:18:49.265410: val_loss -0.7853 
2025-07-09 02:18:49.265519: Pseudo dice [np.float32(0.8325)] 
2025-07-09 02:18:49.265668: Epoch time: 46.67 s 
2025-07-09 02:18:50.462222:  
2025-07-09 02:18:50.462754: Epoch 744 
2025-07-09 02:18:50.462937: Current learning rate: 0.00293 
2025-07-09 02:19:37.225651: train_loss -0.7797 
2025-07-09 02:19:37.226577: val_loss -0.7674 
2025-07-09 02:19:37.226708: Pseudo dice [np.float32(0.8399)] 
2025-07-09 02:19:37.226862: Epoch time: 46.76 s 
2025-07-09 02:19:38.428157:  
2025-07-09 02:19:38.428448: Epoch 745 
2025-07-09 02:19:38.428739: Current learning rate: 0.00292 
2025-07-09 02:20:24.819792: train_loss -0.7595 
2025-07-09 02:20:24.820464: val_loss -0.7757 
2025-07-09 02:20:24.820637: Pseudo dice [np.float32(0.8409)] 
2025-07-09 02:20:24.820866: Epoch time: 46.39 s 
2025-07-09 02:20:26.047576:  
2025-07-09 02:20:26.048254: Epoch 746 
2025-07-09 02:20:26.048501: Current learning rate: 0.00291 
2025-07-09 02:21:12.354137: train_loss -0.7793 
2025-07-09 02:21:12.354676: val_loss -0.8049 
2025-07-09 02:21:12.354820: Pseudo dice [np.float32(0.8347)] 
2025-07-09 02:21:12.354936: Epoch time: 46.31 s 
2025-07-09 02:21:13.631864:  
2025-07-09 02:21:13.632167: Epoch 747 
2025-07-09 02:21:13.632393: Current learning rate: 0.0029 
2025-07-09 02:22:00.414432: train_loss -0.7635 
2025-07-09 02:22:00.414977: val_loss -0.7838 
2025-07-09 02:22:00.415060: Pseudo dice [np.float32(0.8428)] 
2025-07-09 02:22:00.415161: Epoch time: 46.78 s 
2025-07-09 02:22:01.652569:  
2025-07-09 02:22:01.652847: Epoch 748 
2025-07-09 02:22:01.653105: Current learning rate: 0.00289 
2025-07-09 02:22:48.585714: train_loss -0.7834 
2025-07-09 02:22:48.586341: val_loss -0.7893 
2025-07-09 02:22:48.586426: Pseudo dice [np.float32(0.8243)] 
2025-07-09 02:22:48.586535: Epoch time: 46.93 s 
2025-07-09 02:22:49.782999:  
2025-07-09 02:22:49.783239: Epoch 749 
2025-07-09 02:22:49.783371: Current learning rate: 0.00288 
2025-07-09 02:23:36.336462: train_loss -0.7689 
2025-07-09 02:23:36.337226: val_loss -0.7788 
2025-07-09 02:23:36.337348: Pseudo dice [np.float32(0.8269)] 
2025-07-09 02:23:36.337488: Epoch time: 46.55 s 
2025-07-09 02:23:38.021190:  
2025-07-09 02:23:38.021523: Epoch 750 
2025-07-09 02:23:38.021675: Current learning rate: 0.00287 
2025-07-09 02:24:25.147217: train_loss -0.7832 
2025-07-09 02:24:25.148046: val_loss -0.8076 
2025-07-09 02:24:25.148226: Pseudo dice [np.float32(0.842)] 
2025-07-09 02:24:25.148461: Epoch time: 47.13 s 
2025-07-09 02:24:27.258307:  
2025-07-09 02:24:27.258496: Epoch 751 
2025-07-09 02:24:27.258698: Current learning rate: 0.00286 
2025-07-09 02:25:12.618831: train_loss -0.7916 
2025-07-09 02:25:12.619701: val_loss -0.8 
2025-07-09 02:25:12.619823: Pseudo dice [np.float32(0.8405)] 
2025-07-09 02:25:12.619986: Epoch time: 45.36 s 
2025-07-09 02:25:13.859527:  
2025-07-09 02:25:13.859929: Epoch 752 
2025-07-09 02:25:13.860054: Current learning rate: 0.00285 
2025-07-09 02:26:00.069772: train_loss -0.7748 
2025-07-09 02:26:00.070354: val_loss -0.773 
2025-07-09 02:26:00.070437: Pseudo dice [np.float32(0.8326)] 
2025-07-09 02:26:00.070585: Epoch time: 46.21 s 
2025-07-09 02:26:01.244888:  
2025-07-09 02:26:01.245314: Epoch 753 
2025-07-09 02:26:01.245433: Current learning rate: 0.00284 
2025-07-09 02:26:48.100313: train_loss -0.7618 
2025-07-09 02:26:48.101115: val_loss -0.7788 
2025-07-09 02:26:48.101230: Pseudo dice [np.float32(0.8309)] 
2025-07-09 02:26:48.101506: Epoch time: 46.86 s 
2025-07-09 02:26:49.322881:  
2025-07-09 02:26:49.323027: Epoch 754 
2025-07-09 02:26:49.323121: Current learning rate: 0.00283 
2025-07-09 02:27:35.395392: train_loss -0.7649 
2025-07-09 02:27:35.395870: val_loss -0.7839 
2025-07-09 02:27:35.395970: Pseudo dice [np.float32(0.8396)] 
2025-07-09 02:27:35.396094: Epoch time: 46.07 s 
2025-07-09 02:27:36.599737:  
2025-07-09 02:27:36.600133: Epoch 755 
2025-07-09 02:27:36.600271: Current learning rate: 0.00282 
2025-07-09 02:28:22.407813: train_loss -0.743 
2025-07-09 02:28:22.408246: val_loss -0.7655 
2025-07-09 02:28:22.408331: Pseudo dice [np.float32(0.8214)] 
2025-07-09 02:28:22.408444: Epoch time: 45.81 s 
2025-07-09 02:28:23.596370:  
2025-07-09 02:28:23.596713: Epoch 756 
2025-07-09 02:28:23.597143: Current learning rate: 0.00281 
2025-07-09 02:29:09.462110: train_loss -0.77 
2025-07-09 02:29:09.462808: val_loss -0.7674 
2025-07-09 02:29:09.462920: Pseudo dice [np.float32(0.8312)] 
2025-07-09 02:29:09.463101: Epoch time: 45.87 s 
2025-07-09 02:29:10.698316:  
2025-07-09 02:29:10.698641: Epoch 757 
2025-07-09 02:29:10.698812: Current learning rate: 0.0028 
2025-07-09 02:29:56.060426: train_loss -0.76 
2025-07-09 02:29:56.061110: val_loss -0.7888 
2025-07-09 02:29:56.061201: Pseudo dice [np.float32(0.8395)] 
2025-07-09 02:29:56.061306: Epoch time: 45.36 s 
2025-07-09 02:29:57.346450:  
2025-07-09 02:29:57.346653: Epoch 758 
2025-07-09 02:29:57.346920: Current learning rate: 0.00279 
2025-07-09 02:30:43.700315: train_loss -0.7836 
2025-07-09 02:30:43.700839: val_loss -0.7801 
2025-07-09 02:30:43.701003: Pseudo dice [np.float32(0.8473)] 
2025-07-09 02:30:43.701169: Epoch time: 46.35 s 
2025-07-09 02:30:44.943629:  
2025-07-09 02:30:44.944272: Epoch 759 
2025-07-09 02:30:44.944394: Current learning rate: 0.00278 
2025-07-09 02:31:30.857659: train_loss -0.7804 
2025-07-09 02:31:30.858281: val_loss -0.7989 
2025-07-09 02:31:30.858364: Pseudo dice [np.float32(0.8344)] 
2025-07-09 02:31:30.858537: Epoch time: 45.92 s 
2025-07-09 02:31:32.045076:  
2025-07-09 02:31:32.045503: Epoch 760 
2025-07-09 02:31:32.045644: Current learning rate: 0.00277 
2025-07-09 02:32:18.196651: train_loss -0.7793 
2025-07-09 02:32:18.197436: val_loss -0.806 
2025-07-09 02:32:18.197536: Pseudo dice [np.float32(0.8188)] 
2025-07-09 02:32:18.197723: Epoch time: 46.15 s 
2025-07-09 02:32:19.377454:  
2025-07-09 02:32:19.377739: Epoch 761 
2025-07-09 02:32:19.377907: Current learning rate: 0.00276 
2025-07-09 02:33:05.662327: train_loss -0.7937 
2025-07-09 02:33:05.662895: val_loss -0.8018 
2025-07-09 02:33:05.662980: Pseudo dice [np.float32(0.8348)] 
2025-07-09 02:33:05.663100: Epoch time: 46.29 s 
2025-07-09 02:33:06.868037:  
2025-07-09 02:33:06.868662: Epoch 762 
2025-07-09 02:33:06.868939: Current learning rate: 0.00275 
2025-07-09 02:33:53.524342: train_loss -0.7734 
2025-07-09 02:33:53.524806: val_loss -0.7605 
2025-07-09 02:33:53.524890: Pseudo dice [np.float32(0.8307)] 
2025-07-09 02:33:53.524992: Epoch time: 46.66 s 
2025-07-09 02:33:54.727004:  
2025-07-09 02:33:54.727441: Epoch 763 
2025-07-09 02:33:54.727710: Current learning rate: 0.00274 
2025-07-09 02:34:40.975858: train_loss -0.7767 
2025-07-09 02:34:40.976263: val_loss -0.7853 
2025-07-09 02:34:40.976341: Pseudo dice [np.float32(0.8337)] 
2025-07-09 02:34:40.976445: Epoch time: 46.25 s 
2025-07-09 02:34:43.075042:  
2025-07-09 02:34:43.075455: Epoch 764 
2025-07-09 02:34:43.075610: Current learning rate: 0.00273 
2025-07-09 02:35:30.483321: train_loss -0.7741 
2025-07-09 02:35:30.483621: val_loss -0.7922 
2025-07-09 02:35:30.483713: Pseudo dice [np.float32(0.8434)] 
2025-07-09 02:35:30.483820: Epoch time: 47.41 s 
2025-07-09 02:35:31.737800:  
2025-07-09 02:35:31.738240: Epoch 765 
2025-07-09 02:35:31.738555: Current learning rate: 0.00272 
2025-07-09 02:36:17.981834: train_loss -0.7776 
2025-07-09 02:36:17.982324: val_loss -0.7992 
2025-07-09 02:36:17.982410: Pseudo dice [np.float32(0.851)] 
2025-07-09 02:36:17.982522: Epoch time: 46.25 s 
2025-07-09 02:36:19.250124:  
2025-07-09 02:36:19.250736: Epoch 766 
2025-07-09 02:36:19.250925: Current learning rate: 0.00271 
2025-07-09 02:37:05.928439: train_loss -0.7921 
2025-07-09 02:37:05.929383: val_loss -0.8072 
2025-07-09 02:37:05.929488: Pseudo dice [np.float32(0.8416)] 
2025-07-09 02:37:05.929667: Epoch time: 46.68 s 
2025-07-09 02:37:07.146144:  
2025-07-09 02:37:07.146354: Epoch 767 
2025-07-09 02:37:07.146556: Current learning rate: 0.0027 
2025-07-09 02:37:54.384715: train_loss -0.7941 
2025-07-09 02:37:54.385025: val_loss -0.8145 
2025-07-09 02:37:54.385173: Pseudo dice [np.float32(0.8511)] 
2025-07-09 02:37:54.385343: Epoch time: 47.24 s 
2025-07-09 02:37:55.576643:  
2025-07-09 02:37:55.576960: Epoch 768 
2025-07-09 02:37:55.577143: Current learning rate: 0.00268 
2025-07-09 02:38:43.270629: train_loss -0.8026 
2025-07-09 02:38:43.271030: val_loss -0.8237 
2025-07-09 02:38:43.271124: Pseudo dice [np.float32(0.8485)] 
2025-07-09 02:38:43.271234: Epoch time: 47.7 s 
2025-07-09 02:38:44.489797:  
2025-07-09 02:38:44.490240: Epoch 769 
2025-07-09 02:38:44.490378: Current learning rate: 0.00267 
2025-07-09 02:39:30.839560: train_loss -0.8 
2025-07-09 02:39:30.840589: val_loss -0.8157 
2025-07-09 02:39:30.840682: Pseudo dice [np.float32(0.8505)] 
2025-07-09 02:39:30.840821: Epoch time: 46.35 s 
2025-07-09 02:39:32.091400:  
2025-07-09 02:39:32.091823: Epoch 770 
2025-07-09 02:39:32.092031: Current learning rate: 0.00266 
2025-07-09 02:40:18.575037: train_loss -0.807 
2025-07-09 02:40:18.575500: val_loss -0.8264 
2025-07-09 02:40:18.575603: Pseudo dice [np.float32(0.8558)] 
2025-07-09 02:40:18.575818: Epoch time: 46.48 s 
2025-07-09 02:40:19.814524:  
2025-07-09 02:40:19.814947: Epoch 771 
2025-07-09 02:40:19.815090: Current learning rate: 0.00265 
2025-07-09 02:41:05.499904: train_loss -0.7921 
2025-07-09 02:41:05.500723: val_loss -0.8113 
2025-07-09 02:41:05.500991: Pseudo dice [np.float32(0.837)] 
2025-07-09 02:41:05.501137: Epoch time: 45.69 s 
2025-07-09 02:41:06.710071:  
2025-07-09 02:41:06.710394: Epoch 772 
2025-07-09 02:41:06.710587: Current learning rate: 0.00264 
2025-07-09 02:41:52.946814: train_loss -0.7929 
2025-07-09 02:41:52.947068: val_loss -0.7891 
2025-07-09 02:41:52.947140: Pseudo dice [np.float32(0.8392)] 
2025-07-09 02:41:52.947224: Epoch time: 46.24 s 
2025-07-09 02:41:54.132132:  
2025-07-09 02:41:54.132485: Epoch 773 
2025-07-09 02:41:54.132620: Current learning rate: 0.00263 
2025-07-09 02:42:39.676860: train_loss -0.7926 
2025-07-09 02:42:39.677239: val_loss -0.7917 
2025-07-09 02:42:39.677317: Pseudo dice [np.float32(0.8447)] 
2025-07-09 02:42:39.677420: Epoch time: 45.55 s 
2025-07-09 02:42:40.871552:  
2025-07-09 02:42:40.871896: Epoch 774 
2025-07-09 02:42:40.872155: Current learning rate: 0.00262 
2025-07-09 02:43:27.370802: train_loss -0.7856 
2025-07-09 02:43:27.371488: val_loss -0.7993 
2025-07-09 02:43:27.371604: Pseudo dice [np.float32(0.838)] 
2025-07-09 02:43:27.371754: Epoch time: 46.5 s 
2025-07-09 02:43:28.613878:  
2025-07-09 02:43:28.614419: Epoch 775 
2025-07-09 02:43:28.614790: Current learning rate: 0.00261 
2025-07-09 02:44:14.391690: train_loss -0.7859 
2025-07-09 02:44:14.392236: val_loss -0.8108 
2025-07-09 02:44:14.392349: Pseudo dice [np.float32(0.843)] 
2025-07-09 02:44:14.392491: Epoch time: 45.78 s 
2025-07-09 02:44:15.615714:  
2025-07-09 02:44:15.616118: Epoch 776 
2025-07-09 02:44:15.616263: Current learning rate: 0.0026 
2025-07-09 02:45:01.436851: train_loss -0.795 
2025-07-09 02:45:01.437310: val_loss -0.8196 
2025-07-09 02:45:01.437394: Pseudo dice [np.float32(0.8564)] 
2025-07-09 02:45:01.437494: Epoch time: 45.82 s 
2025-07-09 02:45:02.640552:  
2025-07-09 02:45:02.640829: Epoch 777 
2025-07-09 02:45:02.641081: Current learning rate: 0.00259 
2025-07-09 02:45:48.319900: train_loss -0.7996 
2025-07-09 02:45:48.320280: val_loss -0.7964 
2025-07-09 02:45:48.320367: Pseudo dice [np.float32(0.8351)] 
2025-07-09 02:45:48.320483: Epoch time: 45.68 s 
2025-07-09 02:45:50.526261:  
2025-07-09 02:45:50.527033: Epoch 778 
2025-07-09 02:45:50.527174: Current learning rate: 0.00258 
2025-07-09 02:46:36.408259: train_loss -0.7944 
2025-07-09 02:46:36.408696: val_loss -0.8154 
2025-07-09 02:46:36.408771: Pseudo dice [np.float32(0.8484)] 
2025-07-09 02:46:36.408867: Epoch time: 45.88 s 
2025-07-09 02:46:37.604312:  
2025-07-09 02:46:37.604685: Epoch 779 
2025-07-09 02:46:37.604917: Current learning rate: 0.00257 
2025-07-09 02:47:24.290222: train_loss -0.8058 
2025-07-09 02:47:24.290524: val_loss -0.815 
2025-07-09 02:47:24.290610: Pseudo dice [np.float32(0.8593)] 
2025-07-09 02:47:24.290702: Epoch time: 46.69 s 
2025-07-09 02:47:25.523080:  
2025-07-09 02:47:25.523471: Epoch 780 
2025-07-09 02:47:25.523724: Current learning rate: 0.00256 
2025-07-09 02:48:11.431481: train_loss -0.7884 
2025-07-09 02:48:11.432054: val_loss -0.7787 
2025-07-09 02:48:11.432133: Pseudo dice [np.float32(0.8507)] 
2025-07-09 02:48:11.432234: Epoch time: 45.91 s 
2025-07-09 02:48:12.648002:  
2025-07-09 02:48:12.648585: Epoch 781 
2025-07-09 02:48:12.648725: Current learning rate: 0.00255 
2025-07-09 02:48:57.708476: train_loss -0.7968 
2025-07-09 02:48:57.709130: val_loss -0.7893 
2025-07-09 02:48:57.709228: Pseudo dice [np.float32(0.8408)] 
2025-07-09 02:48:57.709356: Epoch time: 45.06 s 
2025-07-09 02:48:58.991174:  
2025-07-09 02:48:58.991571: Epoch 782 
2025-07-09 02:48:58.991672: Current learning rate: 0.00254 
2025-07-09 02:49:45.824668: train_loss -0.796 
2025-07-09 02:49:45.824995: val_loss -0.7926 
2025-07-09 02:49:45.825071: Pseudo dice [np.float32(0.8441)] 
2025-07-09 02:49:45.825168: Epoch time: 46.83 s 
2025-07-09 02:49:47.050469:  
2025-07-09 02:49:47.050777: Epoch 783 
2025-07-09 02:49:47.050953: Current learning rate: 0.00253 
2025-07-09 02:50:33.304788: train_loss -0.7984 
2025-07-09 02:50:33.305337: val_loss -0.8272 
2025-07-09 02:50:33.305422: Pseudo dice [np.float32(0.8446)] 
2025-07-09 02:50:33.305527: Epoch time: 46.26 s 
2025-07-09 02:50:34.515732:  
2025-07-09 02:50:34.516185: Epoch 784 
2025-07-09 02:50:34.516314: Current learning rate: 0.00252 
2025-07-09 02:51:21.470053: train_loss -0.7934 
2025-07-09 02:51:21.470774: val_loss -0.8202 
2025-07-09 02:51:21.470873: Pseudo dice [np.float32(0.8611)] 
2025-07-09 02:51:21.471004: Epoch time: 46.96 s 
2025-07-09 02:51:22.697634:  
2025-07-09 02:51:22.698055: Epoch 785 
2025-07-09 02:51:22.698350: Current learning rate: 0.00251 
2025-07-09 02:52:08.701454: train_loss -0.8011 
2025-07-09 02:52:08.702116: val_loss -0.7913 
2025-07-09 02:52:08.702212: Pseudo dice [np.float32(0.8429)] 
2025-07-09 02:52:08.702341: Epoch time: 46.0 s 
2025-07-09 02:52:09.938280:  
2025-07-09 02:52:09.938877: Epoch 786 
2025-07-09 02:52:09.939019: Current learning rate: 0.0025 
2025-07-09 02:52:56.102239: train_loss -0.7923 
2025-07-09 02:52:56.102957: val_loss -0.8257 
2025-07-09 02:52:56.103117: Pseudo dice [np.float32(0.8572)] 
2025-07-09 02:52:56.103256: Epoch time: 46.16 s 
2025-07-09 02:52:57.327824:  
2025-07-09 02:52:57.328167: Epoch 787 
2025-07-09 02:52:57.328491: Current learning rate: 0.00249 
2025-07-09 02:53:43.444529: train_loss -0.8049 
2025-07-09 02:53:43.444923: val_loss -0.8114 
2025-07-09 02:53:43.448448: Pseudo dice [np.float32(0.8618)] 
2025-07-09 02:53:43.448628: Epoch time: 46.12 s 
2025-07-09 02:53:44.862728:  
2025-07-09 02:53:44.863181: Epoch 788 
2025-07-09 02:53:44.863319: Current learning rate: 0.00248 
2025-07-09 02:54:31.578558: train_loss -0.8068 
2025-07-09 02:54:31.579200: val_loss -0.8369 
2025-07-09 02:54:31.579287: Pseudo dice [np.float32(0.8489)] 
2025-07-09 02:54:31.579401: Epoch time: 46.72 s 
2025-07-09 02:54:32.815556:  
2025-07-09 02:54:32.815773: Epoch 789 
2025-07-09 02:54:32.815897: Current learning rate: 0.00247 
2025-07-09 02:55:19.336265: train_loss -0.8089 
2025-07-09 02:55:19.336792: val_loss -0.8149 
2025-07-09 02:55:19.336875: Pseudo dice [np.float32(0.8568)] 
2025-07-09 02:55:19.336974: Epoch time: 46.52 s 
2025-07-09 02:55:20.537411:  
2025-07-09 02:55:20.537941: Epoch 790 
2025-07-09 02:55:20.538072: Current learning rate: 0.00245 
2025-07-09 02:56:07.448840: train_loss -0.7942 
2025-07-09 02:56:07.449300: val_loss -0.7991 
2025-07-09 02:56:07.449450: Pseudo dice [np.float32(0.84)] 
2025-07-09 02:56:07.449572: Epoch time: 46.91 s 
2025-07-09 02:56:08.679390:  
2025-07-09 02:56:08.679749: Epoch 791 
2025-07-09 02:56:08.679993: Current learning rate: 0.00244 
2025-07-09 02:56:55.301735: train_loss -0.7981 
2025-07-09 02:56:55.302167: val_loss -0.8086 
2025-07-09 02:56:55.302249: Pseudo dice [np.float32(0.8509)] 
2025-07-09 02:56:55.302355: Epoch time: 46.62 s 
2025-07-09 02:56:57.481022:  
2025-07-09 02:56:57.481479: Epoch 792 
2025-07-09 02:56:57.481617: Current learning rate: 0.00243 
2025-07-09 02:57:44.301115: train_loss -0.7935 
2025-07-09 02:57:44.301758: val_loss -0.8025 
2025-07-09 02:57:44.301866: Pseudo dice [np.float32(0.8386)] 
2025-07-09 02:57:44.301992: Epoch time: 46.82 s 
2025-07-09 02:57:45.584460:  
2025-07-09 02:57:45.584704: Epoch 793 
2025-07-09 02:57:45.584887: Current learning rate: 0.00242 
2025-07-09 02:58:32.845074: train_loss -0.7975 
2025-07-09 02:58:32.845600: val_loss -0.8217 
2025-07-09 02:58:32.845690: Pseudo dice [np.float32(0.86)] 
2025-07-09 02:58:32.845804: Epoch time: 47.26 s 
2025-07-09 02:58:34.129749:  
2025-07-09 02:58:34.130444: Epoch 794 
2025-07-09 02:58:34.130639: Current learning rate: 0.00241 
2025-07-09 02:59:20.038070: train_loss -0.8143 
2025-07-09 02:59:20.038589: val_loss -0.8209 
2025-07-09 02:59:20.038680: Pseudo dice [np.float32(0.8497)] 
2025-07-09 02:59:20.038796: Epoch time: 45.91 s 
2025-07-09 02:59:21.236216:  
2025-07-09 02:59:21.236675: Epoch 795 
2025-07-09 02:59:21.236816: Current learning rate: 0.0024 
2025-07-09 03:00:08.280606: train_loss -0.8086 
2025-07-09 03:00:08.280947: val_loss -0.8085 
2025-07-09 03:00:08.281019: Pseudo dice [np.float32(0.8538)] 
2025-07-09 03:00:08.281113: Epoch time: 47.05 s 
2025-07-09 03:00:09.486872:  
2025-07-09 03:00:09.487216: Epoch 796 
2025-07-09 03:00:09.487391: Current learning rate: 0.00239 
2025-07-09 03:00:56.064663: train_loss -0.8102 
2025-07-09 03:00:56.065219: val_loss -0.8253 
2025-07-09 03:00:56.065335: Pseudo dice [np.float32(0.8616)] 
2025-07-09 03:00:56.065442: Epoch time: 46.58 s 
2025-07-09 03:00:57.325375:  
2025-07-09 03:00:57.325783: Epoch 797 
2025-07-09 03:00:57.326015: Current learning rate: 0.00238 
2025-07-09 03:01:43.353024: train_loss -0.8053 
2025-07-09 03:01:43.353662: val_loss -0.8063 
2025-07-09 03:01:43.353776: Pseudo dice [np.float32(0.8433)] 
2025-07-09 03:01:43.353918: Epoch time: 46.03 s 
2025-07-09 03:01:44.571059:  
2025-07-09 03:01:44.571479: Epoch 798 
2025-07-09 03:01:44.571632: Current learning rate: 0.00237 
2025-07-09 03:02:31.463847: train_loss -0.7826 
2025-07-09 03:02:31.464584: val_loss -0.7889 
2025-07-09 03:02:31.464704: Pseudo dice [np.float32(0.8406)] 
2025-07-09 03:02:31.464813: Epoch time: 46.89 s 
2025-07-09 03:02:32.690451:  
2025-07-09 03:02:32.691134: Epoch 799 
2025-07-09 03:02:32.691271: Current learning rate: 0.00236 
2025-07-09 03:03:19.462130: train_loss -0.8006 
2025-07-09 03:03:19.462611: val_loss -0.8065 
2025-07-09 03:03:19.462694: Pseudo dice [np.float32(0.8449)] 
2025-07-09 03:03:19.462812: Epoch time: 46.77 s 
2025-07-09 03:03:21.179061:  
2025-07-09 03:03:21.179424: Epoch 800 
2025-07-09 03:03:21.179703: Current learning rate: 0.00235 
2025-07-09 03:04:07.640965: train_loss -0.8011 
2025-07-09 03:04:07.641452: val_loss -0.7985 
2025-07-09 03:04:07.641576: Pseudo dice [np.float32(0.8395)] 
2025-07-09 03:04:07.641683: Epoch time: 46.46 s 
2025-07-09 03:04:08.860365:  
2025-07-09 03:04:08.860879: Epoch 801 
2025-07-09 03:04:08.861008: Current learning rate: 0.00234 
2025-07-09 03:04:55.719070: train_loss -0.78 
2025-07-09 03:04:55.719479: val_loss -0.7985 
2025-07-09 03:04:55.719608: Pseudo dice [np.float32(0.8294)] 
2025-07-09 03:04:55.719719: Epoch time: 46.86 s 
2025-07-09 03:04:56.929507:  
2025-07-09 03:04:56.929819: Epoch 802 
2025-07-09 03:04:56.930152: Current learning rate: 0.00233 
2025-07-09 03:05:44.066026: train_loss -0.7878 
2025-07-09 03:05:44.066508: val_loss -0.7916 
2025-07-09 03:05:44.066732: Pseudo dice [np.float32(0.8388)] 
2025-07-09 03:05:44.066881: Epoch time: 47.14 s 
2025-07-09 03:05:45.278960:  
2025-07-09 03:05:45.279257: Epoch 803 
2025-07-09 03:05:45.279503: Current learning rate: 0.00232 
2025-07-09 03:06:31.573091: train_loss -0.8013 
2025-07-09 03:06:31.573480: val_loss -0.8268 
2025-07-09 03:06:31.573568: Pseudo dice [np.float32(0.8468)] 
2025-07-09 03:06:31.573680: Epoch time: 46.3 s 
2025-07-09 03:06:32.767279:  
2025-07-09 03:06:32.767692: Epoch 804 
2025-07-09 03:06:32.767904: Current learning rate: 0.00231 
2025-07-09 03:07:18.933805: train_loss -0.8027 
2025-07-09 03:07:18.934442: val_loss -0.8166 
2025-07-09 03:07:18.934529: Pseudo dice [np.float32(0.8513)] 
2025-07-09 03:07:18.934661: Epoch time: 46.17 s 
2025-07-09 03:07:21.095129:  
2025-07-09 03:07:21.095468: Epoch 805 
2025-07-09 03:07:21.095758: Current learning rate: 0.0023 
2025-07-09 03:08:07.332867: train_loss -0.7936 
2025-07-09 03:08:07.333380: val_loss -0.8007 
2025-07-09 03:08:07.333459: Pseudo dice [np.float32(0.8468)] 
2025-07-09 03:08:07.333581: Epoch time: 46.24 s 
2025-07-09 03:08:08.688473:  
2025-07-09 03:08:08.688838: Epoch 806 
2025-07-09 03:08:08.689151: Current learning rate: 0.00229 
2025-07-09 03:08:55.672183: train_loss -0.7988 
2025-07-09 03:08:55.672829: val_loss -0.8008 
2025-07-09 03:08:55.672979: Pseudo dice [np.float32(0.8491)] 
2025-07-09 03:08:55.673161: Epoch time: 46.98 s 
2025-07-09 03:08:56.947050:  
2025-07-09 03:08:56.947694: Epoch 807 
2025-07-09 03:08:56.947969: Current learning rate: 0.00228 
2025-07-09 03:09:44.196595: train_loss -0.8028 
2025-07-09 03:09:44.197477: val_loss -0.7982 
2025-07-09 03:09:44.197574: Pseudo dice [np.float32(0.8452)] 
2025-07-09 03:09:44.197802: Epoch time: 47.25 s 
2025-07-09 03:09:45.452415:  
2025-07-09 03:09:45.452630: Epoch 808 
2025-07-09 03:09:45.452794: Current learning rate: 0.00226 
2025-07-09 03:10:31.785090: train_loss -0.8036 
2025-07-09 03:10:31.785947: val_loss -0.8156 
2025-07-09 03:10:31.786028: Pseudo dice [np.float32(0.8623)] 
2025-07-09 03:10:31.786148: Epoch time: 46.33 s 
2025-07-09 03:10:32.971005:  
2025-07-09 03:10:32.971426: Epoch 809 
2025-07-09 03:10:32.971732: Current learning rate: 0.00225 
2025-07-09 03:11:19.730768: train_loss -0.7977 
2025-07-09 03:11:19.731624: val_loss -0.8207 
2025-07-09 03:11:19.731729: Pseudo dice [np.float32(0.8636)] 
2025-07-09 03:11:19.731864: Epoch time: 46.76 s 
2025-07-09 03:11:20.959899:  
2025-07-09 03:11:20.960285: Epoch 810 
2025-07-09 03:11:20.960695: Current learning rate: 0.00224 
2025-07-09 03:12:08.081659: train_loss -0.7965 
2025-07-09 03:12:08.082459: val_loss -0.8254 
2025-07-09 03:12:08.082557: Pseudo dice [np.float32(0.855)] 
2025-07-09 03:12:08.082674: Epoch time: 47.12 s 
2025-07-09 03:12:09.280123:  
2025-07-09 03:12:09.280431: Epoch 811 
2025-07-09 03:12:09.280619: Current learning rate: 0.00223 
2025-07-09 03:12:55.911648: train_loss -0.806 
2025-07-09 03:12:55.912182: val_loss -0.8106 
2025-07-09 03:12:55.912277: Pseudo dice [np.float32(0.8475)] 
2025-07-09 03:12:55.912395: Epoch time: 46.63 s 
2025-07-09 03:12:57.111993:  
2025-07-09 03:12:57.112298: Epoch 812 
2025-07-09 03:12:57.112518: Current learning rate: 0.00222 
2025-07-09 03:13:43.476357: train_loss -0.8077 
2025-07-09 03:13:43.476665: val_loss -0.8259 
2025-07-09 03:13:43.476743: Pseudo dice [np.float32(0.8571)] 
2025-07-09 03:13:43.476844: Epoch time: 46.37 s 
2025-07-09 03:13:44.733341:  
2025-07-09 03:13:44.733685: Epoch 813 
2025-07-09 03:13:44.733874: Current learning rate: 0.00221 
2025-07-09 03:14:31.536852: train_loss -0.8072 
2025-07-09 03:14:31.537218: val_loss -0.8172 
2025-07-09 03:14:31.537406: Pseudo dice [np.float32(0.8511)] 
2025-07-09 03:14:31.537512: Epoch time: 46.8 s 
2025-07-09 03:14:32.720958:  
2025-07-09 03:14:32.721322: Epoch 814 
2025-07-09 03:14:32.721453: Current learning rate: 0.0022 
2025-07-09 03:15:19.360933: train_loss -0.805 
2025-07-09 03:15:19.361565: val_loss -0.8271 
2025-07-09 03:15:19.361643: Pseudo dice [np.float32(0.8384)] 
2025-07-09 03:15:19.361742: Epoch time: 46.64 s 
2025-07-09 03:15:20.571440:  
2025-07-09 03:15:20.571964: Epoch 815 
2025-07-09 03:15:20.572239: Current learning rate: 0.00219 
2025-07-09 03:16:07.343360: train_loss -0.8139 
2025-07-09 03:16:07.345275: val_loss -0.8179 
2025-07-09 03:16:07.345430: Pseudo dice [np.float32(0.8524)] 
2025-07-09 03:16:07.345622: Epoch time: 46.77 s 
2025-07-09 03:16:08.582373:  
2025-07-09 03:16:08.582695: Epoch 816 
2025-07-09 03:16:08.582793: Current learning rate: 0.00218 
2025-07-09 03:16:55.027292: train_loss -0.8005 
2025-07-09 03:16:55.027906: val_loss -0.8065 
2025-07-09 03:16:55.028006: Pseudo dice [np.float32(0.8616)] 
2025-07-09 03:16:55.028126: Epoch time: 46.45 s 
2025-07-09 03:16:56.245588:  
2025-07-09 03:16:56.245748: Epoch 817 
2025-07-09 03:16:56.245969: Current learning rate: 0.00217 
2025-07-09 03:17:42.780581: train_loss -0.7932 
2025-07-09 03:17:42.781051: val_loss -0.8133 
2025-07-09 03:17:42.781137: Pseudo dice [np.float32(0.8441)] 
2025-07-09 03:17:42.781246: Epoch time: 46.54 s 
2025-07-09 03:17:44.016715:  
2025-07-09 03:17:44.017206: Epoch 818 
2025-07-09 03:17:44.017356: Current learning rate: 0.00216 
2025-07-09 03:18:29.234297: train_loss -0.8086 
2025-07-09 03:18:29.234901: val_loss -0.8185 
2025-07-09 03:18:29.234987: Pseudo dice [np.float32(0.8533)] 
2025-07-09 03:18:29.235106: Epoch time: 45.22 s 
2025-07-09 03:18:31.347436:  
2025-07-09 03:18:31.347872: Epoch 819 
2025-07-09 03:18:31.348010: Current learning rate: 0.00215 
2025-07-09 03:19:18.216987: train_loss -0.818 
2025-07-09 03:19:18.217623: val_loss -0.8235 
2025-07-09 03:19:18.217709: Pseudo dice [np.float32(0.8452)] 
2025-07-09 03:19:18.217818: Epoch time: 46.87 s 
2025-07-09 03:19:19.435170:  
2025-07-09 03:19:19.435467: Epoch 820 
2025-07-09 03:19:19.435655: Current learning rate: 0.00214 
2025-07-09 03:20:05.503142: train_loss -0.8072 
2025-07-09 03:20:05.504115: val_loss -0.8094 
2025-07-09 03:20:05.504205: Pseudo dice [np.float32(0.8573)] 
2025-07-09 03:20:05.504343: Epoch time: 46.07 s 
2025-07-09 03:20:06.653355:  
2025-07-09 03:20:06.653724: Epoch 821 
2025-07-09 03:20:06.653923: Current learning rate: 0.00213 
2025-07-09 03:20:53.627679: train_loss -0.7962 
2025-07-09 03:20:53.628221: val_loss -0.8258 
2025-07-09 03:20:53.628302: Pseudo dice [np.float32(0.8441)] 
2025-07-09 03:20:53.628396: Epoch time: 46.98 s 
2025-07-09 03:20:54.802219:  
2025-07-09 03:20:54.802782: Epoch 822 
2025-07-09 03:20:54.802963: Current learning rate: 0.00212 
2025-07-09 03:21:42.515319: train_loss -0.811 
2025-07-09 03:21:42.515831: val_loss -0.8172 
2025-07-09 03:21:42.515909: Pseudo dice [np.float32(0.8419)] 
2025-07-09 03:21:42.516015: Epoch time: 47.71 s 
2025-07-09 03:21:43.705953:  
2025-07-09 03:21:43.706266: Epoch 823 
2025-07-09 03:21:43.706500: Current learning rate: 0.0021 
2025-07-09 03:22:30.738902: train_loss -0.787 
2025-07-09 03:22:30.739357: val_loss -0.8229 
2025-07-09 03:22:30.739438: Pseudo dice [np.float32(0.8536)] 
2025-07-09 03:22:30.739553: Epoch time: 47.03 s 
2025-07-09 03:22:31.903454:  
2025-07-09 03:22:31.903860: Epoch 824 
2025-07-09 03:22:31.904012: Current learning rate: 0.00209 
2025-07-09 03:23:19.016168: train_loss -0.8074 
2025-07-09 03:23:19.016551: val_loss -0.8231 
2025-07-09 03:23:19.016714: Pseudo dice [np.float32(0.8552)] 
2025-07-09 03:23:19.016841: Epoch time: 47.11 s 
2025-07-09 03:23:20.221189:  
2025-07-09 03:23:20.221624: Epoch 825 
2025-07-09 03:23:20.221947: Current learning rate: 0.00208 
2025-07-09 03:24:09.047191: train_loss -0.7939 
2025-07-09 03:24:09.048113: val_loss -0.8171 
2025-07-09 03:24:09.048793: Pseudo dice [np.float32(0.8521)] 
2025-07-09 03:24:09.049085: Epoch time: 48.83 s 
2025-07-09 03:24:10.204441:  
2025-07-09 03:24:10.205286: Epoch 826 
2025-07-09 03:24:10.205413: Current learning rate: 0.00207 
2025-07-09 03:24:57.654825: train_loss -0.8087 
2025-07-09 03:24:57.655333: val_loss -0.8239 
2025-07-09 03:24:57.658873: Pseudo dice [np.float32(0.8557)] 
2025-07-09 03:24:57.659017: Epoch time: 47.45 s 
2025-07-09 03:24:58.815716:  
2025-07-09 03:24:58.816145: Epoch 827 
2025-07-09 03:24:58.816389: Current learning rate: 0.00206 
2025-07-09 03:25:46.795157: train_loss -0.7999 
2025-07-09 03:25:46.795975: val_loss -0.81 
2025-07-09 03:25:46.796062: Pseudo dice [np.float32(0.8455)] 
2025-07-09 03:25:46.796240: Epoch time: 47.98 s 
2025-07-09 03:25:47.945209:  
2025-07-09 03:25:47.945616: Epoch 828 
2025-07-09 03:25:47.945747: Current learning rate: 0.00205 
2025-07-09 03:26:34.676202: train_loss -0.8049 
2025-07-09 03:26:34.677207: val_loss -0.8136 
2025-07-09 03:26:34.677304: Pseudo dice [np.float32(0.8489)] 
2025-07-09 03:26:34.677428: Epoch time: 46.73 s 
2025-07-09 03:26:35.909147:  
2025-07-09 03:26:35.909600: Epoch 829 
2025-07-09 03:26:35.909881: Current learning rate: 0.00204 
2025-07-09 03:27:22.890057: train_loss -0.786 
2025-07-09 03:27:22.890624: val_loss -0.8017 
2025-07-09 03:27:22.890706: Pseudo dice [np.float32(0.8418)] 
2025-07-09 03:27:22.890825: Epoch time: 46.98 s 
2025-07-09 03:27:24.062144:  
2025-07-09 03:27:24.062360: Epoch 830 
2025-07-09 03:27:24.062488: Current learning rate: 0.00203 
2025-07-09 03:28:09.806119: train_loss -0.7958 
2025-07-09 03:28:09.806953: val_loss -0.8277 
2025-07-09 03:28:09.807041: Pseudo dice [np.float32(0.8597)] 
2025-07-09 03:28:09.807176: Epoch time: 45.74 s 
2025-07-09 03:28:10.964649:  
2025-07-09 03:28:10.964909: Epoch 831 
2025-07-09 03:28:10.965088: Current learning rate: 0.00202 
2025-07-09 03:28:56.620422: train_loss -0.8147 
2025-07-09 03:28:56.620886: val_loss -0.823 
2025-07-09 03:28:56.620960: Pseudo dice [np.float32(0.8504)] 
2025-07-09 03:28:56.621058: Epoch time: 45.66 s 
2025-07-09 03:28:57.796875:  
2025-07-09 03:28:57.797282: Epoch 832 
2025-07-09 03:28:57.797410: Current learning rate: 0.00201 
2025-07-09 03:29:44.675620: train_loss -0.8138 
2025-07-09 03:29:44.676093: val_loss -0.8389 
2025-07-09 03:29:44.676169: Pseudo dice [np.float32(0.8497)] 
2025-07-09 03:29:44.676277: Epoch time: 46.88 s 
2025-07-09 03:29:45.881171:  
2025-07-09 03:29:45.881500: Epoch 833 
2025-07-09 03:29:45.881672: Current learning rate: 0.002 
2025-07-09 03:30:33.258451: train_loss -0.8057 
2025-07-09 03:30:33.259203: val_loss -0.7989 
2025-07-09 03:30:33.259277: Pseudo dice [np.float32(0.8449)] 
2025-07-09 03:30:33.259399: Epoch time: 47.38 s 
2025-07-09 03:30:35.456976:  
2025-07-09 03:30:35.457206: Epoch 834 
2025-07-09 03:30:35.457341: Current learning rate: 0.00199 
2025-07-09 03:31:22.460288: train_loss -0.8038 
2025-07-09 03:31:22.462515: val_loss -0.8081 
2025-07-09 03:31:22.462856: Pseudo dice [np.float32(0.8439)] 
2025-07-09 03:31:22.463171: Epoch time: 47.0 s 
2025-07-09 03:31:23.763268:  
2025-07-09 03:31:23.763632: Epoch 835 
2025-07-09 03:31:23.763763: Current learning rate: 0.00198 
2025-07-09 03:32:10.636758: train_loss -0.8009 
2025-07-09 03:32:10.637619: val_loss -0.8248 
2025-07-09 03:32:10.641073: Pseudo dice [np.float32(0.8508)] 
2025-07-09 03:32:10.641332: Epoch time: 46.87 s 
2025-07-09 03:32:11.849176:  
2025-07-09 03:32:11.850336: Epoch 836 
2025-07-09 03:32:11.850525: Current learning rate: 0.00196 
2025-07-09 03:32:57.722343: train_loss -0.8196 
2025-07-09 03:32:57.723176: val_loss -0.8182 
2025-07-09 03:32:57.723275: Pseudo dice [np.float32(0.8708)] 
2025-07-09 03:32:57.723407: Epoch time: 45.87 s 
2025-07-09 03:32:58.953501:  
2025-07-09 03:32:58.953969: Epoch 837 
2025-07-09 03:32:58.954098: Current learning rate: 0.00195 
2025-07-09 03:33:44.636436: train_loss -0.8104 
2025-07-09 03:33:44.637041: val_loss -0.8239 
2025-07-09 03:33:44.637125: Pseudo dice [np.float32(0.8437)] 
2025-07-09 03:33:44.637238: Epoch time: 45.68 s 
2025-07-09 03:33:45.847380:  
2025-07-09 03:33:45.847936: Epoch 838 
2025-07-09 03:33:45.848114: Current learning rate: 0.00194 
2025-07-09 03:34:32.346919: train_loss -0.8095 
2025-07-09 03:34:32.347647: val_loss -0.8308 
2025-07-09 03:34:32.351387: Pseudo dice [np.float32(0.8598)] 
2025-07-09 03:34:32.351689: Epoch time: 46.5 s 
2025-07-09 03:34:33.589746:  
2025-07-09 03:34:33.590240: Epoch 839 
2025-07-09 03:34:33.590366: Current learning rate: 0.00193 
2025-07-09 03:35:19.672713: train_loss -0.8125 
2025-07-09 03:35:19.673280: val_loss -0.8344 
2025-07-09 03:35:19.673381: Pseudo dice [np.float32(0.8519)] 
2025-07-09 03:35:19.673491: Epoch time: 46.08 s 
2025-07-09 03:35:20.886931:  
2025-07-09 03:35:20.887395: Epoch 840 
2025-07-09 03:35:20.887583: Current learning rate: 0.00192 
2025-07-09 03:36:08.481270: train_loss -0.8143 
2025-07-09 03:36:08.481675: val_loss -0.8288 
2025-07-09 03:36:08.481755: Pseudo dice [np.float32(0.8616)] 
2025-07-09 03:36:08.481856: Epoch time: 47.6 s 
2025-07-09 03:36:09.614562:  
2025-07-09 03:36:09.614775: Epoch 841 
2025-07-09 03:36:09.614916: Current learning rate: 0.00191 
2025-07-09 03:36:56.709867: train_loss -0.7997 
2025-07-09 03:36:56.710561: val_loss -0.794 
2025-07-09 03:36:56.710722: Pseudo dice [np.float32(0.8431)] 
2025-07-09 03:36:56.710866: Epoch time: 47.1 s 
2025-07-09 03:36:57.847858:  
2025-07-09 03:36:57.848187: Epoch 842 
2025-07-09 03:36:57.848404: Current learning rate: 0.0019 
2025-07-09 03:37:45.086328: train_loss -0.798 
2025-07-09 03:37:45.086925: val_loss -0.8066 
2025-07-09 03:37:45.087031: Pseudo dice [np.float32(0.8426)] 
2025-07-09 03:37:45.087162: Epoch time: 47.24 s 
2025-07-09 03:37:46.298047:  
2025-07-09 03:37:46.298627: Epoch 843 
2025-07-09 03:37:46.298766: Current learning rate: 0.00189 
2025-07-09 03:38:32.824039: train_loss -0.8114 
2025-07-09 03:38:32.824663: val_loss -0.8209 
2025-07-09 03:38:32.824769: Pseudo dice [np.float32(0.8503)] 
2025-07-09 03:38:32.824918: Epoch time: 46.53 s 
2025-07-09 03:38:33.959093:  
2025-07-09 03:38:33.959354: Epoch 844 
2025-07-09 03:38:33.959553: Current learning rate: 0.00188 
2025-07-09 03:39:19.887560: train_loss -0.8144 
2025-07-09 03:39:19.887985: val_loss -0.8355 
2025-07-09 03:39:19.888062: Pseudo dice [np.float32(0.8635)] 
2025-07-09 03:39:19.888154: Epoch time: 45.93 s 
2025-07-09 03:39:21.056747:  
2025-07-09 03:39:21.057131: Epoch 845 
2025-07-09 03:39:21.057416: Current learning rate: 0.00187 
2025-07-09 03:40:07.670190: train_loss -0.8196 
2025-07-09 03:40:07.670590: val_loss -0.8236 
2025-07-09 03:40:07.670673: Pseudo dice [np.float32(0.8522)] 
2025-07-09 03:40:07.670785: Epoch time: 46.61 s 
2025-07-09 03:40:08.840976:  
2025-07-09 03:40:08.841224: Epoch 846 
2025-07-09 03:40:08.841367: Current learning rate: 0.00186 
2025-07-09 03:40:55.418866: train_loss -0.8105 
2025-07-09 03:40:55.419360: val_loss -0.8206 
2025-07-09 03:40:55.419440: Pseudo dice [np.float32(0.8586)] 
2025-07-09 03:40:55.419556: Epoch time: 46.58 s 
2025-07-09 03:40:56.566072:  
2025-07-09 03:40:56.566314: Epoch 847 
2025-07-09 03:40:56.566636: Current learning rate: 0.00185 
2025-07-09 03:41:42.975107: train_loss -0.8071 
2025-07-09 03:41:42.975693: val_loss -0.8395 
2025-07-09 03:41:42.975781: Pseudo dice [np.float32(0.8571)] 
2025-07-09 03:41:42.975893: Epoch time: 46.41 s 
2025-07-09 03:41:44.180161:  
2025-07-09 03:41:44.180386: Epoch 848 
2025-07-09 03:41:44.180688: Current learning rate: 0.00184 
2025-07-09 03:42:30.315682: train_loss -0.8139 
2025-07-09 03:42:30.316052: val_loss -0.8275 
2025-07-09 03:42:30.316128: Pseudo dice [np.float32(0.8558)] 
2025-07-09 03:42:30.316224: Epoch time: 46.14 s 
2025-07-09 03:42:32.522884:  
2025-07-09 03:42:32.523364: Epoch 849 
2025-07-09 03:42:32.523559: Current learning rate: 0.00182 
2025-07-09 03:43:18.483790: train_loss -0.8065 
2025-07-09 03:43:18.484200: val_loss -0.8232 
2025-07-09 03:43:18.484276: Pseudo dice [np.float32(0.8536)] 
2025-07-09 03:43:18.484412: Epoch time: 45.96 s 
2025-07-09 03:43:20.141261:  
2025-07-09 03:43:20.141439: Epoch 850 
2025-07-09 03:43:20.141771: Current learning rate: 0.00181 
2025-07-09 03:44:06.737370: train_loss -0.8172 
2025-07-09 03:44:06.738458: val_loss -0.8359 
2025-07-09 03:44:06.738832: Pseudo dice [np.float32(0.8549)] 
2025-07-09 03:44:06.739291: Epoch time: 46.6 s 
2025-07-09 03:44:07.980282:  
2025-07-09 03:44:07.981057: Epoch 851 
2025-07-09 03:44:07.981202: Current learning rate: 0.0018 
2025-07-09 03:44:54.643670: train_loss -0.8134 
2025-07-09 03:44:54.644222: val_loss -0.8143 
2025-07-09 03:44:54.644344: Pseudo dice [np.float32(0.852)] 
2025-07-09 03:44:54.644574: Epoch time: 46.66 s 
2025-07-09 03:44:55.887843:  
2025-07-09 03:44:55.888186: Epoch 852 
2025-07-09 03:44:55.888420: Current learning rate: 0.00179 
2025-07-09 03:45:42.256098: train_loss -0.8121 
2025-07-09 03:45:42.257235: val_loss -0.8314 
2025-07-09 03:45:42.257445: Pseudo dice [np.float32(0.8567)] 
2025-07-09 03:45:42.257648: Epoch time: 46.37 s 
2025-07-09 03:45:43.457531:  
2025-07-09 03:45:43.457799: Epoch 853 
2025-07-09 03:45:43.457925: Current learning rate: 0.00178 
2025-07-09 03:46:30.115117: train_loss -0.8069 
2025-07-09 03:46:30.115628: val_loss -0.8301 
2025-07-09 03:46:30.115711: Pseudo dice [np.float32(0.8621)] 
2025-07-09 03:46:30.115840: Epoch time: 46.66 s 
2025-07-09 03:46:31.554042:  
2025-07-09 03:46:31.554315: Epoch 854 
2025-07-09 03:46:31.554447: Current learning rate: 0.00177 
2025-07-09 03:47:18.520957: train_loss -0.8204 
2025-07-09 03:47:18.521349: val_loss -0.8277 
2025-07-09 03:47:18.521438: Pseudo dice [np.float32(0.8623)] 
2025-07-09 03:47:18.521555: Epoch time: 46.97 s 
2025-07-09 03:47:19.676726:  
2025-07-09 03:47:19.676931: Epoch 855 
2025-07-09 03:47:19.677087: Current learning rate: 0.00176 
2025-07-09 03:48:06.850918: train_loss -0.815 
2025-07-09 03:48:06.851211: val_loss -0.8174 
2025-07-09 03:48:06.851288: Pseudo dice [np.float32(0.8524)] 
2025-07-09 03:48:06.851395: Epoch time: 47.18 s 
2025-07-09 03:48:08.042444:  
2025-07-09 03:48:08.042957: Epoch 856 
2025-07-09 03:48:08.043109: Current learning rate: 0.00175 
2025-07-09 03:48:54.789481: train_loss -0.8034 
2025-07-09 03:48:54.789840: val_loss -0.8153 
2025-07-09 03:48:54.789929: Pseudo dice [np.float32(0.8555)] 
2025-07-09 03:48:54.790046: Epoch time: 46.75 s 
2025-07-09 03:48:55.946263:  
2025-07-09 03:48:55.946650: Epoch 857 
2025-07-09 03:48:55.946832: Current learning rate: 0.00174 
2025-07-09 03:49:41.824891: train_loss -0.8226 
2025-07-09 03:49:41.825390: val_loss -0.8195 
2025-07-09 03:49:41.825470: Pseudo dice [np.float32(0.8588)] 
2025-07-09 03:49:41.825593: Epoch time: 45.88 s 
2025-07-09 03:49:42.971621:  
2025-07-09 03:49:42.972024: Epoch 858 
2025-07-09 03:49:42.972307: Current learning rate: 0.00173 
2025-07-09 03:50:28.999109: train_loss -0.8181 
2025-07-09 03:50:28.999791: val_loss -0.8141 
2025-07-09 03:50:29.000012: Pseudo dice [np.float32(0.8495)] 
2025-07-09 03:50:29.000121: Epoch time: 46.03 s 
2025-07-09 03:50:30.157613:  
2025-07-09 03:50:30.157917: Epoch 859 
2025-07-09 03:50:30.158048: Current learning rate: 0.00172 
2025-07-09 03:51:16.600575: train_loss -0.8181 
2025-07-09 03:51:16.601045: val_loss -0.8323 
2025-07-09 03:51:16.601126: Pseudo dice [np.float32(0.8455)] 
2025-07-09 03:51:16.601224: Epoch time: 46.44 s 
2025-07-09 03:51:17.763046:  
2025-07-09 03:51:17.763417: Epoch 860 
2025-07-09 03:51:17.763614: Current learning rate: 0.0017 
2025-07-09 03:52:02.777713: train_loss -0.8229 
2025-07-09 03:52:02.778078: val_loss -0.8202 
2025-07-09 03:52:02.778171: Pseudo dice [np.float32(0.8643)] 
2025-07-09 03:52:02.778278: Epoch time: 45.02 s 
2025-07-09 03:52:03.982007:  
2025-07-09 03:52:03.982401: Epoch 861 
2025-07-09 03:52:03.982535: Current learning rate: 0.00169 
2025-07-09 03:52:49.957298: train_loss -0.8119 
2025-07-09 03:52:49.957793: val_loss -0.8343 
2025-07-09 03:52:49.957882: Pseudo dice [np.float32(0.8485)] 
2025-07-09 03:52:49.957987: Epoch time: 45.98 s 
2025-07-09 03:52:51.141581:  
2025-07-09 03:52:51.141946: Epoch 862 
2025-07-09 03:52:51.142164: Current learning rate: 0.00168 
2025-07-09 03:53:37.056346: train_loss -0.8203 
2025-07-09 03:53:37.057031: val_loss -0.8303 
2025-07-09 03:53:37.057114: Pseudo dice [np.float32(0.861)] 
2025-07-09 03:53:37.057220: Epoch time: 45.92 s 
2025-07-09 03:53:38.300985:  
2025-07-09 03:53:38.301166: Epoch 863 
2025-07-09 03:53:38.301303: Current learning rate: 0.00167 
2025-07-09 03:54:25.043361: train_loss -0.8146 
2025-07-09 03:54:25.043838: val_loss -0.8243 
2025-07-09 03:54:25.043927: Pseudo dice [np.float32(0.8714)] 
2025-07-09 03:54:25.044036: Epoch time: 46.74 s 
2025-07-09 03:54:26.242932:  
2025-07-09 03:54:26.243516: Epoch 864 
2025-07-09 03:54:26.243666: Current learning rate: 0.00166 
2025-07-09 03:55:12.122611: train_loss -0.8143 
2025-07-09 03:55:12.122948: val_loss -0.8308 
2025-07-09 03:55:12.123089: Pseudo dice [np.float32(0.8541)] 
2025-07-09 03:55:12.123178: Epoch time: 45.88 s 
2025-07-09 03:55:13.266932:  
2025-07-09 03:55:13.267368: Epoch 865 
2025-07-09 03:55:13.267497: Current learning rate: 0.00165 
2025-07-09 03:56:00.033740: train_loss -0.824 
2025-07-09 03:56:00.034259: val_loss -0.8215 
2025-07-09 03:56:00.034345: Pseudo dice [np.float32(0.8592)] 
2025-07-09 03:56:00.034459: Epoch time: 46.77 s 
2025-07-09 03:56:01.282869:  
2025-07-09 03:56:01.283093: Epoch 866 
2025-07-09 03:56:01.283353: Current learning rate: 0.00164 
2025-07-09 03:56:47.823068: train_loss -0.8118 
2025-07-09 03:56:47.823408: val_loss -0.8406 
2025-07-09 03:56:47.823478: Pseudo dice [np.float32(0.8502)] 
2025-07-09 03:56:47.823575: Epoch time: 46.54 s 
2025-07-09 03:56:48.941360:  
2025-07-09 03:56:48.941695: Epoch 867 
2025-07-09 03:56:48.941925: Current learning rate: 0.00163 
2025-07-09 03:57:35.412975: train_loss -0.8262 
2025-07-09 03:57:35.413275: val_loss -0.8426 
2025-07-09 03:57:35.413357: Pseudo dice [np.float32(0.8497)] 
2025-07-09 03:57:35.413453: Epoch time: 46.47 s 
2025-07-09 03:57:36.625793:  
2025-07-09 03:57:36.626082: Epoch 868 
2025-07-09 03:57:36.626263: Current learning rate: 0.00162 
2025-07-09 03:58:22.968097: train_loss -0.8178 
2025-07-09 03:58:22.968526: val_loss -0.8404 
2025-07-09 03:58:22.968697: Pseudo dice [np.float32(0.8609)] 
2025-07-09 03:58:22.968833: Epoch time: 46.34 s 
2025-07-09 03:58:24.112520:  
2025-07-09 03:58:24.112781: Epoch 869 
2025-07-09 03:58:24.112918: Current learning rate: 0.00161 
2025-07-09 03:59:11.008472: train_loss -0.8264 
2025-07-09 03:59:11.008970: val_loss -0.8421 
2025-07-09 03:59:11.009054: Pseudo dice [np.float32(0.858)] 
2025-07-09 03:59:11.009160: Epoch time: 46.9 s 
2025-07-09 03:59:12.221052:  
2025-07-09 03:59:12.221713: Epoch 870 
2025-07-09 03:59:12.221914: Current learning rate: 0.00159 
2025-07-09 03:59:58.422241: train_loss -0.8236 
2025-07-09 03:59:58.422875: val_loss -0.8391 
2025-07-09 03:59:58.422996: Pseudo dice [np.float32(0.8602)] 
2025-07-09 03:59:58.423111: Epoch time: 46.2 s 
2025-07-09 03:59:59.606923:  
2025-07-09 03:59:59.607292: Epoch 871 
2025-07-09 03:59:59.607450: Current learning rate: 0.00158 
2025-07-09 04:00:45.957827: train_loss -0.8307 
2025-07-09 04:00:45.958483: val_loss -0.8376 
2025-07-09 04:00:45.958602: Pseudo dice [np.float32(0.8642)] 
2025-07-09 04:00:45.958725: Epoch time: 46.35 s 
2025-07-09 04:00:47.090026:  
2025-07-09 04:00:47.090496: Epoch 872 
2025-07-09 04:00:47.090723: Current learning rate: 0.00157 
2025-07-09 04:01:32.684840: train_loss -0.8258 
2025-07-09 04:01:32.685328: val_loss -0.8323 
2025-07-09 04:01:32.685413: Pseudo dice [np.float32(0.8528)] 
2025-07-09 04:01:32.685515: Epoch time: 45.6 s 
2025-07-09 04:01:33.866298:  
2025-07-09 04:01:33.866535: Epoch 873 
2025-07-09 04:01:33.866675: Current learning rate: 0.00156 
2025-07-09 04:02:20.243079: train_loss -0.8227 
2025-07-09 04:02:20.243563: val_loss -0.8391 
2025-07-09 04:02:20.243654: Pseudo dice [np.float32(0.8569)] 
2025-07-09 04:02:20.243764: Epoch time: 46.38 s 
2025-07-09 04:02:21.516395:  
2025-07-09 04:02:21.516632: Epoch 874 
2025-07-09 04:02:21.516761: Current learning rate: 0.00155 
2025-07-09 04:03:07.741141: train_loss -0.8211 
2025-07-09 04:03:07.741858: val_loss -0.8183 
2025-07-09 04:03:07.741978: Pseudo dice [np.float32(0.8663)] 
2025-07-09 04:03:07.742140: Epoch time: 46.23 s 
2025-07-09 04:03:09.014388:  
2025-07-09 04:03:09.014996: Epoch 875 
2025-07-09 04:03:09.015212: Current learning rate: 0.00154 
2025-07-09 04:03:55.927063: train_loss -0.8272 
2025-07-09 04:03:55.927660: val_loss -0.828 
2025-07-09 04:03:55.927754: Pseudo dice [np.float32(0.8515)] 
2025-07-09 04:03:55.927880: Epoch time: 46.91 s 
2025-07-09 04:03:57.123187:  
2025-07-09 04:03:57.123740: Epoch 876 
2025-07-09 04:03:57.124112: Current learning rate: 0.00153 
2025-07-09 04:04:43.761157: train_loss -0.8232 
2025-07-09 04:04:43.761699: val_loss -0.8196 
2025-07-09 04:04:43.761821: Pseudo dice [np.float32(0.8649)] 
2025-07-09 04:04:43.761932: Epoch time: 46.64 s 
2025-07-09 04:04:44.960099:  
2025-07-09 04:04:44.960433: Epoch 877 
2025-07-09 04:04:44.960584: Current learning rate: 0.00152 
2025-07-09 04:05:30.994076: train_loss -0.8266 
2025-07-09 04:05:30.994896: val_loss -0.8502 
2025-07-09 04:05:30.995116: Pseudo dice [np.float32(0.8665)] 
2025-07-09 04:05:30.995233: Epoch time: 46.03 s 
2025-07-09 04:05:33.136613:  
2025-07-09 04:05:33.136869: Epoch 878 
2025-07-09 04:05:33.137025: Current learning rate: 0.00151 
2025-07-09 04:06:19.912028: train_loss -0.8174 
2025-07-09 04:06:19.912561: val_loss -0.8445 
2025-07-09 04:06:19.912725: Pseudo dice [np.float32(0.858)] 
2025-07-09 04:06:19.912874: Epoch time: 46.78 s 
2025-07-09 04:06:21.041770:  
2025-07-09 04:06:21.042002: Epoch 879 
2025-07-09 04:06:21.042144: Current learning rate: 0.00149 
2025-07-09 04:07:08.113365: train_loss -0.8134 
2025-07-09 04:07:08.113754: val_loss -0.8269 
2025-07-09 04:07:08.113846: Pseudo dice [np.float32(0.8683)] 
2025-07-09 04:07:08.113956: Epoch time: 47.07 s 
2025-07-09 04:07:08.114036: Yayy! New best EMA pseudo Dice: 0.8597000241279602 
2025-07-09 04:07:09.827694:  
2025-07-09 04:07:09.828083: Epoch 880 
2025-07-09 04:07:09.828259: Current learning rate: 0.00148 
2025-07-09 04:07:56.162372: train_loss -0.8164 
2025-07-09 04:07:56.162800: val_loss -0.8465 
2025-07-09 04:07:56.163010: Pseudo dice [np.float32(0.8502)] 
2025-07-09 04:07:56.163139: Epoch time: 46.34 s 
2025-07-09 04:07:57.411266:  
2025-07-09 04:07:57.411681: Epoch 881 
2025-07-09 04:07:57.411984: Current learning rate: 0.00147 
2025-07-09 04:08:43.761503: train_loss -0.8308 
2025-07-09 04:08:43.761999: val_loss -0.8278 
2025-07-09 04:08:43.762088: Pseudo dice [np.float32(0.8591)] 
2025-07-09 04:08:43.762201: Epoch time: 46.35 s 
2025-07-09 04:08:44.989343:  
2025-07-09 04:08:44.989834: Epoch 882 
2025-07-09 04:08:44.990010: Current learning rate: 0.00146 
2025-07-09 04:09:31.398777: train_loss -0.8166 
2025-07-09 04:09:31.399263: val_loss -0.8308 
2025-07-09 04:09:31.399353: Pseudo dice [np.float32(0.8598)] 
2025-07-09 04:09:31.399475: Epoch time: 46.41 s 
2025-07-09 04:09:32.597558:  
2025-07-09 04:09:32.597752: Epoch 883 
2025-07-09 04:09:32.598114: Current learning rate: 0.00145 
2025-07-09 04:10:19.165822: train_loss -0.8243 
2025-07-09 04:10:19.166555: val_loss -0.84 
2025-07-09 04:10:19.166690: Pseudo dice [np.float32(0.8523)] 
2025-07-09 04:10:19.166823: Epoch time: 46.57 s 
2025-07-09 04:10:20.411231:  
2025-07-09 04:10:20.411611: Epoch 884 
2025-07-09 04:10:20.411760: Current learning rate: 0.00144 
2025-07-09 04:11:06.118432: train_loss -0.8148 
2025-07-09 04:11:06.118823: val_loss -0.8356 
2025-07-09 04:11:06.118935: Pseudo dice [np.float32(0.8584)] 
2025-07-09 04:11:06.119025: Epoch time: 45.71 s 
2025-07-09 04:11:07.290391:  
2025-07-09 04:11:07.290811: Epoch 885 
2025-07-09 04:11:07.290943: Current learning rate: 0.00143 
2025-07-09 04:11:53.438302: train_loss -0.8193 
2025-07-09 04:11:53.438738: val_loss -0.8366 
2025-07-09 04:11:53.438919: Pseudo dice [np.float32(0.8673)] 
2025-07-09 04:11:53.439026: Epoch time: 46.15 s 
2025-07-09 04:11:54.606349:  
2025-07-09 04:11:54.606866: Epoch 886 
2025-07-09 04:11:54.606996: Current learning rate: 0.00142 
2025-07-09 04:12:40.843393: train_loss -0.8289 
2025-07-09 04:12:40.843956: val_loss -0.8388 
2025-07-09 04:12:40.844069: Pseudo dice [np.float32(0.8659)] 
2025-07-09 04:12:40.844193: Epoch time: 46.24 s 
2025-07-09 04:12:40.844285: Yayy! New best EMA pseudo Dice: 0.8597999811172485 
2025-07-09 04:12:42.537795:  
2025-07-09 04:12:42.538474: Epoch 887 
2025-07-09 04:12:42.538949: Current learning rate: 0.00141 
2025-07-09 04:13:28.541110: train_loss -0.8222 
2025-07-09 04:13:28.541572: val_loss -0.8411 
2025-07-09 04:13:28.541731: Pseudo dice [np.float32(0.8584)] 
2025-07-09 04:13:28.541847: Epoch time: 46.0 s 
2025-07-09 04:13:29.729577:  
2025-07-09 04:13:29.729871: Epoch 888 
2025-07-09 04:13:29.730014: Current learning rate: 0.00139 
2025-07-09 04:14:16.021026: train_loss -0.8194 
2025-07-09 04:14:16.021513: val_loss -0.8161 
2025-07-09 04:14:16.021627: Pseudo dice [np.float32(0.8548)] 
2025-07-09 04:14:16.021739: Epoch time: 46.29 s 
2025-07-09 04:14:17.230166:  
2025-07-09 04:14:17.230728: Epoch 889 
2025-07-09 04:14:17.231066: Current learning rate: 0.00138 
2025-07-09 04:15:03.496331: train_loss -0.8284 
2025-07-09 04:15:03.496914: val_loss -0.8173 
2025-07-09 04:15:03.497000: Pseudo dice [np.float32(0.855)] 
2025-07-09 04:15:03.497104: Epoch time: 46.27 s 
2025-07-09 04:15:04.715523:  
2025-07-09 04:15:04.715809: Epoch 890 
2025-07-09 04:15:04.716040: Current learning rate: 0.00137 
2025-07-09 04:15:51.539575: train_loss -0.8217 
2025-07-09 04:15:51.540174: val_loss -0.8442 
2025-07-09 04:15:51.540275: Pseudo dice [np.float32(0.8631)] 
2025-07-09 04:15:51.540398: Epoch time: 46.82 s 
2025-07-09 04:15:52.771781:  
2025-07-09 04:15:52.772258: Epoch 891 
2025-07-09 04:15:52.772400: Current learning rate: 0.00136 
2025-07-09 04:16:39.148174: train_loss -0.8293 
2025-07-09 04:16:39.148408: val_loss -0.837 
2025-07-09 04:16:39.148483: Pseudo dice [np.float32(0.8759)] 
2025-07-09 04:16:39.148590: Epoch time: 46.38 s 
2025-07-09 04:16:39.148663: Yayy! New best EMA pseudo Dice: 0.8608999848365784 
2025-07-09 04:16:40.808570:  
2025-07-09 04:16:40.808904: Epoch 892 
2025-07-09 04:16:40.809036: Current learning rate: 0.00135 
2025-07-09 04:17:26.713452: train_loss -0.8248 
2025-07-09 04:17:26.714390: val_loss -0.8278 
2025-07-09 04:17:26.714473: Pseudo dice [np.float32(0.8579)] 
2025-07-09 04:17:26.714633: Epoch time: 45.91 s 
2025-07-09 04:17:28.787429:  
2025-07-09 04:17:28.787955: Epoch 893 
2025-07-09 04:17:28.788240: Current learning rate: 0.00134 
2025-07-09 04:18:15.172972: train_loss -0.8262 
2025-07-09 04:18:15.173649: val_loss -0.822 
2025-07-09 04:18:15.173823: Pseudo dice [np.float32(0.8565)] 
2025-07-09 04:18:15.173975: Epoch time: 46.39 s 
2025-07-09 04:18:16.309131:  
2025-07-09 04:18:16.309399: Epoch 894 
2025-07-09 04:18:16.309583: Current learning rate: 0.00133 
2025-07-09 04:19:02.704852: train_loss -0.8306 
2025-07-09 04:19:02.705221: val_loss -0.8382 
2025-07-09 04:19:02.705304: Pseudo dice [np.float32(0.8709)] 
2025-07-09 04:19:02.705420: Epoch time: 46.4 s 
2025-07-09 04:19:02.705500: Yayy! New best EMA pseudo Dice: 0.8611999750137329 
2025-07-09 04:19:04.322192:  
2025-07-09 04:19:04.322527: Epoch 895 
2025-07-09 04:19:04.322802: Current learning rate: 0.00132 
2025-07-09 04:19:50.473469: train_loss -0.8276 
2025-07-09 04:19:50.473858: val_loss -0.8358 
2025-07-09 04:19:50.473992: Pseudo dice [np.float32(0.8624)] 
2025-07-09 04:19:50.474096: Epoch time: 46.15 s 
2025-07-09 04:19:50.474169: Yayy! New best EMA pseudo Dice: 0.8614000082015991 
2025-07-09 04:19:52.145662:  
2025-07-09 04:19:52.145994: Epoch 896 
2025-07-09 04:19:52.146359: Current learning rate: 0.0013 
2025-07-09 04:20:38.338911: train_loss -0.8313 
2025-07-09 04:20:38.339274: val_loss -0.8253 
2025-07-09 04:20:38.339351: Pseudo dice [np.float32(0.8607)] 
2025-07-09 04:20:38.339456: Epoch time: 46.19 s 
2025-07-09 04:20:39.512067:  
2025-07-09 04:20:39.512354: Epoch 897 
2025-07-09 04:20:39.512657: Current learning rate: 0.00129 
2025-07-09 04:21:25.057311: train_loss -0.8317 
2025-07-09 04:21:25.057831: val_loss -0.8472 
2025-07-09 04:21:25.058039: Pseudo dice [np.float32(0.8643)] 
2025-07-09 04:21:25.058228: Epoch time: 45.55 s 
2025-07-09 04:21:25.058311: Yayy! New best EMA pseudo Dice: 0.8615999817848206 
2025-07-09 04:21:26.712095:  
2025-07-09 04:21:26.712710: Epoch 898 
2025-07-09 04:21:26.712842: Current learning rate: 0.00128 
2025-07-09 04:22:12.041784: train_loss -0.8229 
2025-07-09 04:22:12.042191: val_loss -0.8454 
2025-07-09 04:22:12.042269: Pseudo dice [np.float32(0.8694)] 
2025-07-09 04:22:12.042368: Epoch time: 45.33 s 
2025-07-09 04:22:12.042578: Yayy! New best EMA pseudo Dice: 0.8623999953269958 
2025-07-09 04:22:13.713366:  
2025-07-09 04:22:13.713560: Epoch 899 
2025-07-09 04:22:13.713752: Current learning rate: 0.00127 
2025-07-09 04:23:00.222708: train_loss -0.8245 
2025-07-09 04:23:00.223181: val_loss -0.8585 
2025-07-09 04:23:00.223264: Pseudo dice [np.float32(0.8558)] 
2025-07-09 04:23:00.223377: Epoch time: 46.51 s 
2025-07-09 04:23:01.888871:  
2025-07-09 04:23:01.889048: Epoch 900 
2025-07-09 04:23:01.889178: Current learning rate: 0.00126 
2025-07-09 04:23:47.714473: train_loss -0.8292 
2025-07-09 04:23:47.714878: val_loss -0.8583 
2025-07-09 04:23:47.714972: Pseudo dice [np.float32(0.8623)] 
2025-07-09 04:23:47.715090: Epoch time: 45.83 s 
2025-07-09 04:23:48.969451:  
2025-07-09 04:23:48.969641: Epoch 901 
2025-07-09 04:23:48.969894: Current learning rate: 0.00125 
2025-07-09 04:24:36.294872: train_loss -0.8332 
2025-07-09 04:24:36.295382: val_loss -0.8371 
2025-07-09 04:24:36.295464: Pseudo dice [np.float32(0.8588)] 
2025-07-09 04:24:36.295587: Epoch time: 47.33 s 
2025-07-09 04:24:37.451216:  
2025-07-09 04:24:37.451382: Epoch 902 
2025-07-09 04:24:37.451503: Current learning rate: 0.00124 
2025-07-09 04:25:24.284350: train_loss -0.8206 
2025-07-09 04:25:24.284776: val_loss -0.8519 
2025-07-09 04:25:24.284855: Pseudo dice [np.float32(0.8677)] 
2025-07-09 04:25:24.284955: Epoch time: 46.83 s 
2025-07-09 04:25:25.562753:  
2025-07-09 04:25:25.563147: Epoch 903 
2025-07-09 04:25:25.563279: Current learning rate: 0.00122 
2025-07-09 04:26:11.933803: train_loss -0.8244 
2025-07-09 04:26:11.934269: val_loss -0.8396 
2025-07-09 04:26:11.934370: Pseudo dice [np.float32(0.8631)] 
2025-07-09 04:26:11.934473: Epoch time: 46.37 s 
2025-07-09 04:26:13.109469:  
2025-07-09 04:26:13.110193: Epoch 904 
2025-07-09 04:26:13.110324: Current learning rate: 0.00121 
2025-07-09 04:26:59.101608: train_loss -0.8213 
2025-07-09 04:26:59.102057: val_loss -0.8046 
2025-07-09 04:26:59.102161: Pseudo dice [np.float32(0.8505)] 
2025-07-09 04:26:59.102325: Epoch time: 45.99 s 
2025-07-09 04:27:00.314834:  
2025-07-09 04:27:00.315030: Epoch 905 
2025-07-09 04:27:00.315270: Current learning rate: 0.0012 
2025-07-09 04:27:46.010265: train_loss -0.8263 
2025-07-09 04:27:46.011230: val_loss -0.8444 
2025-07-09 04:27:46.011323: Pseudo dice [np.float32(0.8525)] 
2025-07-09 04:27:46.011480: Epoch time: 45.7 s 
2025-07-09 04:27:47.186306:  
2025-07-09 04:27:47.186689: Epoch 906 
2025-07-09 04:27:47.186809: Current learning rate: 0.00119 
2025-07-09 04:28:32.942257: train_loss -0.8278 
2025-07-09 04:28:32.942652: val_loss -0.8447 
2025-07-09 04:28:32.942831: Pseudo dice [np.float32(0.8627)] 
2025-07-09 04:28:32.942968: Epoch time: 45.76 s 
2025-07-09 04:28:34.068013:  
2025-07-09 04:28:34.068361: Epoch 907 
2025-07-09 04:28:34.068553: Current learning rate: 0.00118 
2025-07-09 04:29:20.965329: train_loss -0.8281 
2025-07-09 04:29:20.965999: val_loss -0.8221 
2025-07-09 04:29:20.966094: Pseudo dice [np.float32(0.8557)] 
2025-07-09 04:29:20.966225: Epoch time: 46.9 s 
2025-07-09 04:29:23.057189:  
2025-07-09 04:29:23.057588: Epoch 908 
2025-07-09 04:29:23.057730: Current learning rate: 0.00117 
2025-07-09 04:30:08.879886: train_loss -0.8337 
2025-07-09 04:30:08.881020: val_loss -0.846 
2025-07-09 04:30:08.881196: Pseudo dice [np.float32(0.8638)] 
2025-07-09 04:30:08.881460: Epoch time: 45.82 s 
2025-07-09 04:30:10.094391:  
2025-07-09 04:30:10.094789: Epoch 909 
2025-07-09 04:30:10.095086: Current learning rate: 0.00116 
2025-07-09 04:30:55.771367: train_loss -0.833 
2025-07-09 04:30:55.771776: val_loss -0.824 
2025-07-09 04:30:55.771953: Pseudo dice [np.float32(0.8566)] 
2025-07-09 04:30:55.772070: Epoch time: 45.68 s 
2025-07-09 04:30:56.977364:  
2025-07-09 04:30:56.977785: Epoch 910 
2025-07-09 04:30:56.977912: Current learning rate: 0.00115 
2025-07-09 04:31:42.821233: train_loss -0.8358 
2025-07-09 04:31:42.821582: val_loss -0.8467 
2025-07-09 04:31:42.821671: Pseudo dice [np.float32(0.8712)] 
2025-07-09 04:31:42.821774: Epoch time: 45.84 s 
2025-07-09 04:31:43.985509:  
2025-07-09 04:31:43.985715: Epoch 911 
2025-07-09 04:31:43.985942: Current learning rate: 0.00113 
2025-07-09 04:32:30.723950: train_loss -0.8265 
2025-07-09 04:32:30.724254: val_loss -0.8299 
2025-07-09 04:32:30.724338: Pseudo dice [np.float32(0.8633)] 
2025-07-09 04:32:30.724448: Epoch time: 46.74 s 
2025-07-09 04:32:31.919852:  
2025-07-09 04:32:31.920268: Epoch 912 
2025-07-09 04:32:31.920403: Current learning rate: 0.00112 
2025-07-09 04:33:18.426402: train_loss -0.831 
2025-07-09 04:33:18.427069: val_loss -0.8464 
2025-07-09 04:33:18.427154: Pseudo dice [np.float32(0.8647)] 
2025-07-09 04:33:18.427277: Epoch time: 46.51 s 
2025-07-09 04:33:19.629998:  
2025-07-09 04:33:19.630409: Epoch 913 
2025-07-09 04:33:19.630578: Current learning rate: 0.00111 
2025-07-09 04:34:05.323906: train_loss -0.8307 
2025-07-09 04:34:05.324711: val_loss -0.8487 
2025-07-09 04:34:05.324804: Pseudo dice [np.float32(0.8671)] 
2025-07-09 04:34:05.324919: Epoch time: 45.69 s 
2025-07-09 04:34:06.470200:  
2025-07-09 04:34:06.470339: Epoch 914 
2025-07-09 04:34:06.470439: Current learning rate: 0.0011 
2025-07-09 04:34:52.472195: train_loss -0.8303 
2025-07-09 04:34:52.472817: val_loss -0.8523 
2025-07-09 04:34:52.472898: Pseudo dice [np.float32(0.8746)] 
2025-07-09 04:34:52.473012: Epoch time: 46.0 s 
2025-07-09 04:34:52.473086: Yayy! New best EMA pseudo Dice: 0.8633999824523926 
2025-07-09 04:34:54.103899:  
2025-07-09 04:34:54.104162: Epoch 915 
2025-07-09 04:34:54.104405: Current learning rate: 0.00109 
2025-07-09 04:35:41.179523: train_loss -0.8288 
2025-07-09 04:35:41.179813: val_loss -0.8477 
2025-07-09 04:35:41.179894: Pseudo dice [np.float32(0.8697)] 
2025-07-09 04:35:41.179994: Epoch time: 47.08 s 
2025-07-09 04:35:41.180068: Yayy! New best EMA pseudo Dice: 0.8640999794006348 
2025-07-09 04:35:42.814965:  
2025-07-09 04:35:42.815161: Epoch 916 
2025-07-09 04:35:42.815266: Current learning rate: 0.00108 
2025-07-09 04:36:29.211889: train_loss -0.8296 
2025-07-09 04:36:29.212296: val_loss -0.8585 
2025-07-09 04:36:29.212374: Pseudo dice [np.float32(0.8712)] 
2025-07-09 04:36:29.212636: Epoch time: 46.4 s 
2025-07-09 04:36:29.212741: Yayy! New best EMA pseudo Dice: 0.864799976348877 
2025-07-09 04:36:30.857188:  
2025-07-09 04:36:30.857601: Epoch 917 
2025-07-09 04:36:30.857846: Current learning rate: 0.00106 
2025-07-09 04:37:17.328164: train_loss -0.831 
2025-07-09 04:37:17.328765: val_loss -0.8519 
2025-07-09 04:37:17.328888: Pseudo dice [np.float32(0.8588)] 
2025-07-09 04:37:17.329030: Epoch time: 46.47 s 
2025-07-09 04:37:18.523054:  
2025-07-09 04:37:18.523579: Epoch 918 
2025-07-09 04:37:18.523914: Current learning rate: 0.00105 
2025-07-09 04:38:05.694615: train_loss -0.8231 
2025-07-09 04:38:05.695473: val_loss -0.8387 
2025-07-09 04:38:05.695575: Pseudo dice [np.float32(0.8559)] 
2025-07-09 04:38:05.695681: Epoch time: 47.17 s 
2025-07-09 04:38:06.886772:  
2025-07-09 04:38:06.887288: Epoch 919 
2025-07-09 04:38:06.887481: Current learning rate: 0.00104 
2025-07-09 04:38:53.208810: train_loss -0.8259 
2025-07-09 04:38:53.209409: val_loss -0.8402 
2025-07-09 04:38:53.209489: Pseudo dice [np.float32(0.8619)] 
2025-07-09 04:38:53.209601: Epoch time: 46.32 s 
2025-07-09 04:38:54.363671:  
2025-07-09 04:38:54.363944: Epoch 920 
2025-07-09 04:38:54.364128: Current learning rate: 0.00103 
2025-07-09 04:39:40.836898: train_loss -0.8323 
2025-07-09 04:39:40.837717: val_loss -0.8455 
2025-07-09 04:39:40.837815: Pseudo dice [np.float32(0.8635)] 
2025-07-09 04:39:40.837989: Epoch time: 46.47 s 
2025-07-09 04:39:42.080611:  
2025-07-09 04:39:42.081157: Epoch 921 
2025-07-09 04:39:42.081349: Current learning rate: 0.00102 
2025-07-09 04:40:29.489836: train_loss -0.8245 
2025-07-09 04:40:29.490326: val_loss -0.831 
2025-07-09 04:40:29.490424: Pseudo dice [np.float32(0.8575)] 
2025-07-09 04:40:29.490582: Epoch time: 47.41 s 
2025-07-09 04:40:30.647857:  
2025-07-09 04:40:30.648525: Epoch 922 
2025-07-09 04:40:30.648672: Current learning rate: 0.00101 
2025-07-09 04:41:17.130377: train_loss -0.8193 
2025-07-09 04:41:17.130923: val_loss -0.835 
2025-07-09 04:41:17.131024: Pseudo dice [np.float32(0.8643)] 
2025-07-09 04:41:17.131146: Epoch time: 46.48 s 
2025-07-09 04:41:19.046863:  
2025-07-09 04:41:19.047159: Epoch 923 
2025-07-09 04:41:19.047318: Current learning rate: 0.001 
2025-07-09 04:42:06.135252: train_loss -0.8294 
2025-07-09 04:42:06.135713: val_loss -0.8304 
2025-07-09 04:42:06.135800: Pseudo dice [np.float32(0.8604)] 
2025-07-09 04:42:06.135903: Epoch time: 47.09 s 
2025-07-09 04:42:07.339955:  
2025-07-09 04:42:07.340342: Epoch 924 
2025-07-09 04:42:07.340671: Current learning rate: 0.00098 
2025-07-09 04:42:54.474918: train_loss -0.8245 
2025-07-09 04:42:54.475194: val_loss -0.8473 
2025-07-09 04:42:54.475382: Pseudo dice [np.float32(0.8663)] 
2025-07-09 04:42:54.475562: Epoch time: 47.14 s 
2025-07-09 04:42:55.659339:  
2025-07-09 04:42:55.659568: Epoch 925 
2025-07-09 04:42:55.659672: Current learning rate: 0.00097 
2025-07-09 04:43:42.321150: train_loss -0.8267 
2025-07-09 04:43:42.321665: val_loss -0.8481 
2025-07-09 04:43:42.321744: Pseudo dice [np.float32(0.8679)] 
2025-07-09 04:43:42.321857: Epoch time: 46.66 s 
2025-07-09 04:43:43.574783:  
2025-07-09 04:43:43.575138: Epoch 926 
2025-07-09 04:43:43.575303: Current learning rate: 0.00096 
2025-07-09 04:44:29.537135: train_loss -0.836 
2025-07-09 04:44:29.537609: val_loss -0.8456 
2025-07-09 04:44:29.541005: Pseudo dice [np.float32(0.8673)] 
2025-07-09 04:44:29.541130: Epoch time: 45.96 s 
2025-07-09 04:44:30.726781:  
2025-07-09 04:44:30.727228: Epoch 927 
2025-07-09 04:44:30.727602: Current learning rate: 0.00095 
2025-07-09 04:45:17.230166: train_loss -0.836 
2025-07-09 04:45:17.230803: val_loss -0.83 
2025-07-09 04:45:17.230898: Pseudo dice [np.float32(0.8669)] 
2025-07-09 04:45:17.231019: Epoch time: 46.5 s 
2025-07-09 04:45:18.439994:  
2025-07-09 04:45:18.440347: Epoch 928 
2025-07-09 04:45:18.440585: Current learning rate: 0.00094 
2025-07-09 04:46:04.631237: train_loss -0.8346 
2025-07-09 04:46:04.631655: val_loss -0.8457 
2025-07-09 04:46:04.631867: Pseudo dice [np.float32(0.8686)] 
2025-07-09 04:46:04.631985: Epoch time: 46.19 s 
2025-07-09 04:46:05.810642:  
2025-07-09 04:46:05.811062: Epoch 929 
2025-07-09 04:46:05.811191: Current learning rate: 0.00092 
2025-07-09 04:46:51.471142: train_loss -0.8332 
2025-07-09 04:46:51.471688: val_loss -0.8454 
2025-07-09 04:46:51.471874: Pseudo dice [np.float32(0.8615)] 
2025-07-09 04:46:51.472007: Epoch time: 45.66 s 
2025-07-09 04:46:52.631743:  
2025-07-09 04:46:52.631930: Epoch 930 
2025-07-09 04:46:52.632054: Current learning rate: 0.00091 
2025-07-09 04:47:38.513897: train_loss -0.8295 
2025-07-09 04:47:38.514981: val_loss -0.8321 
2025-07-09 04:47:38.515275: Pseudo dice [np.float32(0.8596)] 
2025-07-09 04:47:38.515424: Epoch time: 45.88 s 
2025-07-09 04:47:39.723828:  
2025-07-09 04:47:39.724048: Epoch 931 
2025-07-09 04:47:39.724211: Current learning rate: 0.0009 
2025-07-09 04:48:26.318887: train_loss -0.8273 
2025-07-09 04:48:26.319223: val_loss -0.8389 
2025-07-09 04:48:26.319299: Pseudo dice [np.float32(0.8821)] 
2025-07-09 04:48:26.319397: Epoch time: 46.6 s 
2025-07-09 04:48:26.319469: Yayy! New best EMA pseudo Dice: 0.8655999898910522 
2025-07-09 04:48:28.032690:  
2025-07-09 04:48:28.033314: Epoch 932 
2025-07-09 04:48:28.033457: Current learning rate: 0.00089 
2025-07-09 04:49:14.925156: train_loss -0.8326 
2025-07-09 04:49:14.925970: val_loss -0.8314 
2025-07-09 04:49:14.926067: Pseudo dice [np.float32(0.8601)] 
2025-07-09 04:49:14.926234: Epoch time: 46.89 s 
2025-07-09 04:49:16.125332:  
2025-07-09 04:49:16.125551: Epoch 933 
2025-07-09 04:49:16.125800: Current learning rate: 0.00088 
2025-07-09 04:50:02.974939: train_loss -0.8321 
2025-07-09 04:50:02.975506: val_loss -0.8433 
2025-07-09 04:50:02.975628: Pseudo dice [np.float32(0.8667)] 
2025-07-09 04:50:02.975771: Epoch time: 46.85 s 
2025-07-09 04:50:04.204896:  
2025-07-09 04:50:04.205402: Epoch 934 
2025-07-09 04:50:04.205613: Current learning rate: 0.00087 
2025-07-09 04:50:51.248499: train_loss -0.8327 
2025-07-09 04:50:51.249019: val_loss -0.8586 
2025-07-09 04:50:51.249107: Pseudo dice [np.float32(0.8693)] 
2025-07-09 04:50:51.249219: Epoch time: 47.04 s 
2025-07-09 04:50:51.249293: Yayy! New best EMA pseudo Dice: 0.8655999898910522 
2025-07-09 04:50:52.902754:  
2025-07-09 04:50:52.903080: Epoch 935 
2025-07-09 04:50:52.903298: Current learning rate: 0.00085 
2025-07-09 04:51:39.437196: train_loss -0.8317 
2025-07-09 04:51:39.437951: val_loss -0.826 
2025-07-09 04:51:39.438052: Pseudo dice [np.float32(0.857)] 
2025-07-09 04:51:39.438179: Epoch time: 46.54 s 
2025-07-09 04:51:40.692948:  
2025-07-09 04:51:40.693265: Epoch 936 
2025-07-09 04:51:40.693565: Current learning rate: 0.00084 
2025-07-09 04:52:27.019534: train_loss -0.8305 
2025-07-09 04:52:27.020056: val_loss -0.8505 
2025-07-09 04:52:27.020141: Pseudo dice [np.float32(0.8588)] 
2025-07-09 04:52:27.020250: Epoch time: 46.33 s 
2025-07-09 04:52:28.266993:  
2025-07-09 04:52:28.267451: Epoch 937 
2025-07-09 04:52:28.267667: Current learning rate: 0.00083 
2025-07-09 04:53:14.811940: train_loss -0.8308 
2025-07-09 04:53:14.812342: val_loss -0.8442 
2025-07-09 04:53:14.813658: Pseudo dice [np.float32(0.8711)] 
2025-07-09 04:53:14.813763: Epoch time: 46.55 s 
2025-07-09 04:53:16.924858:  
2025-07-09 04:53:16.925306: Epoch 938 
2025-07-09 04:53:16.925604: Current learning rate: 0.00082 
2025-07-09 04:54:03.598142: train_loss -0.8318 
2025-07-09 04:54:03.598657: val_loss -0.8371 
2025-07-09 04:54:03.598758: Pseudo dice [np.float32(0.8755)] 
2025-07-09 04:54:03.598874: Epoch time: 46.67 s 
2025-07-09 04:54:03.598961: Yayy! New best EMA pseudo Dice: 0.8658999800682068 
2025-07-09 04:54:05.333287:  
2025-07-09 04:54:05.333674: Epoch 939 
2025-07-09 04:54:05.333806: Current learning rate: 0.00081 
2025-07-09 04:54:52.383631: train_loss -0.8342 
2025-07-09 04:54:52.384859: val_loss -0.8338 
2025-07-09 04:54:52.385024: Pseudo dice [np.float32(0.8724)] 
2025-07-09 04:54:52.385161: Epoch time: 47.05 s 
2025-07-09 04:54:52.385250: Yayy! New best EMA pseudo Dice: 0.866599977016449 
2025-07-09 04:54:54.054441:  
2025-07-09 04:54:54.054743: Epoch 940 
2025-07-09 04:54:54.054845: Current learning rate: 0.00079 
2025-07-09 04:55:40.508685: train_loss -0.8335 
2025-07-09 04:55:40.509236: val_loss -0.839 
2025-07-09 04:55:40.509343: Pseudo dice [np.float32(0.8627)] 
2025-07-09 04:55:40.509449: Epoch time: 46.46 s 
2025-07-09 04:55:41.794157:  
2025-07-09 04:55:41.794355: Epoch 941 
2025-07-09 04:55:41.794615: Current learning rate: 0.00078 
2025-07-09 04:56:28.750399: train_loss -0.8391 
2025-07-09 04:56:28.750824: val_loss -0.843 
2025-07-09 04:56:28.750901: Pseudo dice [np.float32(0.8566)] 
2025-07-09 04:56:28.751011: Epoch time: 46.96 s 
2025-07-09 04:56:29.929872:  
2025-07-09 04:56:29.930041: Epoch 942 
2025-07-09 04:56:29.930506: Current learning rate: 0.00077 
2025-07-09 04:57:16.478676: train_loss -0.8371 
2025-07-09 04:57:16.479053: val_loss -0.8462 
2025-07-09 04:57:16.482464: Pseudo dice [np.float32(0.8679)] 
2025-07-09 04:57:16.482611: Epoch time: 46.55 s 
2025-07-09 04:57:17.698567:  
2025-07-09 04:57:17.698922: Epoch 943 
2025-07-09 04:57:17.699244: Current learning rate: 0.00076 
2025-07-09 04:58:04.606218: train_loss -0.8384 
2025-07-09 04:58:04.606719: val_loss -0.8465 
2025-07-09 04:58:04.606804: Pseudo dice [np.float32(0.8675)] 
2025-07-09 04:58:04.606920: Epoch time: 46.91 s 
2025-07-09 04:58:05.773729:  
2025-07-09 04:58:05.774084: Epoch 944 
2025-07-09 04:58:05.774212: Current learning rate: 0.00075 
2025-07-09 04:58:52.683173: train_loss -0.8341 
2025-07-09 04:58:52.683508: val_loss -0.837 
2025-07-09 04:58:52.683595: Pseudo dice [np.float32(0.8642)] 
2025-07-09 04:58:52.683698: Epoch time: 46.91 s 
2025-07-09 04:58:53.844681:  
2025-07-09 04:58:53.845012: Epoch 945 
2025-07-09 04:58:53.845152: Current learning rate: 0.00074 
2025-07-09 04:59:41.100436: train_loss -0.8322 
2025-07-09 04:59:41.100725: val_loss -0.8384 
2025-07-09 04:59:41.100808: Pseudo dice [np.float32(0.8684)] 
2025-07-09 04:59:41.100909: Epoch time: 47.26 s 
2025-07-09 04:59:42.239999:  
2025-07-09 04:59:42.240243: Epoch 946 
2025-07-09 04:59:42.240416: Current learning rate: 0.00072 
2025-07-09 05:00:29.198951: train_loss -0.844 
2025-07-09 05:00:29.199254: val_loss -0.8572 
2025-07-09 05:00:29.199330: Pseudo dice [np.float32(0.8716)] 
2025-07-09 05:00:29.199427: Epoch time: 46.96 s 
2025-07-09 05:00:30.334619:  
2025-07-09 05:00:30.334839: Epoch 947 
2025-07-09 05:00:30.334981: Current learning rate: 0.00071 
2025-07-09 05:01:17.575233: train_loss -0.8309 
2025-07-09 05:01:17.575953: val_loss -0.8484 
2025-07-09 05:01:17.576096: Pseudo dice [np.float32(0.8614)] 
2025-07-09 05:01:17.576259: Epoch time: 47.24 s 
2025-07-09 05:01:18.712449:  
2025-07-09 05:01:18.712787: Epoch 948 
2025-07-09 05:01:18.712962: Current learning rate: 0.0007 
2025-07-09 05:02:05.774226: train_loss -0.83 
2025-07-09 05:02:05.774666: val_loss -0.8525 
2025-07-09 05:02:05.774760: Pseudo dice [np.float32(0.8538)] 
2025-07-09 05:02:05.774888: Epoch time: 47.06 s 
2025-07-09 05:02:06.970800:  
2025-07-09 05:02:06.971114: Epoch 949 
2025-07-09 05:02:06.971493: Current learning rate: 0.00069 
2025-07-09 05:02:53.446456: train_loss -0.8199 
2025-07-09 05:02:53.447066: val_loss -0.851 
2025-07-09 05:02:53.447164: Pseudo dice [np.float32(0.8798)] 
2025-07-09 05:02:53.447297: Epoch time: 46.48 s 
2025-07-09 05:02:55.163879:  
2025-07-09 05:02:55.164219: Epoch 950 
2025-07-09 05:02:55.164394: Current learning rate: 0.00067 
2025-07-09 05:03:41.790167: train_loss -0.8341 
2025-07-09 05:03:41.790648: val_loss -0.8536 
2025-07-09 05:03:41.790739: Pseudo dice [np.float32(0.8554)] 
2025-07-09 05:03:41.790859: Epoch time: 46.63 s 
2025-07-09 05:03:43.024489:  
2025-07-09 05:03:43.024815: Epoch 951 
2025-07-09 05:03:43.025300: Current learning rate: 0.00066 
2025-07-09 05:04:28.874138: train_loss -0.8374 
2025-07-09 05:04:28.874528: val_loss -0.8532 
2025-07-09 05:04:28.874631: Pseudo dice [np.float32(0.8802)] 
2025-07-09 05:04:28.874747: Epoch time: 45.85 s 
2025-07-09 05:04:28.874829: Yayy! New best EMA pseudo Dice: 0.866599977016449 
2025-07-09 05:04:30.599601:  
2025-07-09 05:04:30.600043: Epoch 952 
2025-07-09 05:04:30.600176: Current learning rate: 0.00065 
2025-07-09 05:05:16.500717: train_loss -0.8362 
2025-07-09 05:05:16.501127: val_loss -0.8431 
2025-07-09 05:05:16.501301: Pseudo dice [np.float32(0.8707)] 
2025-07-09 05:05:16.501413: Epoch time: 45.9 s 
2025-07-09 05:05:16.501483: Yayy! New best EMA pseudo Dice: 0.8669999837875366 
2025-07-09 05:05:18.169125:  
2025-07-09 05:05:18.169499: Epoch 953 
2025-07-09 05:05:18.169615: Current learning rate: 0.00064 
2025-07-09 05:06:04.688212: train_loss -0.8419 
2025-07-09 05:06:04.688587: val_loss -0.8422 
2025-07-09 05:06:04.688667: Pseudo dice [np.float32(0.866)] 
2025-07-09 05:06:04.688757: Epoch time: 46.52 s 
2025-07-09 05:06:05.839867:  
2025-07-09 05:06:05.840240: Epoch 954 
2025-07-09 05:06:05.840385: Current learning rate: 0.00063 
2025-07-09 05:06:51.811742: train_loss -0.8353 
2025-07-09 05:06:51.812062: val_loss -0.8448 
2025-07-09 05:06:51.812135: Pseudo dice [np.float32(0.8697)] 
2025-07-09 05:06:51.812229: Epoch time: 45.97 s 
2025-07-09 05:06:51.812303: Yayy! New best EMA pseudo Dice: 0.8672000169754028 
2025-07-09 05:06:53.526600:  
2025-07-09 05:06:53.527041: Epoch 955 
2025-07-09 05:06:53.527291: Current learning rate: 0.00061 
2025-07-09 05:07:39.755592: train_loss -0.838 
2025-07-09 05:07:39.756075: val_loss -0.8421 
2025-07-09 05:07:39.756162: Pseudo dice [np.float32(0.8623)] 
2025-07-09 05:07:39.756276: Epoch time: 46.23 s 
2025-07-09 05:07:41.010665:  
2025-07-09 05:07:41.011124: Epoch 956 
2025-07-09 05:07:41.011225: Current learning rate: 0.0006 
2025-07-09 05:08:26.571702: train_loss -0.8253 
2025-07-09 05:08:26.572234: val_loss -0.8552 
2025-07-09 05:08:26.572325: Pseudo dice [np.float32(0.8718)] 
2025-07-09 05:08:26.572431: Epoch time: 45.56 s 
2025-07-09 05:08:26.572508: Yayy! New best EMA pseudo Dice: 0.8672000169754028 
2025-07-09 05:08:28.318660:  
2025-07-09 05:08:28.319036: Epoch 957 
2025-07-09 05:08:28.319251: Current learning rate: 0.00059 
2025-07-09 05:09:14.450814: train_loss -0.8362 
2025-07-09 05:09:14.451191: val_loss -0.8564 
2025-07-09 05:09:14.451269: Pseudo dice [np.float32(0.8733)] 
2025-07-09 05:09:14.451475: Epoch time: 46.13 s 
2025-07-09 05:09:14.451597: Yayy! New best EMA pseudo Dice: 0.8677999973297119 
2025-07-09 05:09:16.190407:  
2025-07-09 05:09:16.190818: Epoch 958 
2025-07-09 05:09:16.190990: Current learning rate: 0.00058 
2025-07-09 05:10:01.350767: train_loss -0.8399 
2025-07-09 05:10:01.351337: val_loss -0.8664 
2025-07-09 05:10:01.351440: Pseudo dice [np.float32(0.8698)] 
2025-07-09 05:10:01.351644: Epoch time: 45.16 s 
2025-07-09 05:10:01.351964: Yayy! New best EMA pseudo Dice: 0.8679999709129333 
2025-07-09 05:10:03.054775:  
2025-07-09 05:10:03.055197: Epoch 959 
2025-07-09 05:10:03.055322: Current learning rate: 0.00056 
2025-07-09 05:10:48.441128: train_loss -0.8431 
2025-07-09 05:10:48.441774: val_loss -0.842 
2025-07-09 05:10:48.441858: Pseudo dice [np.float32(0.8651)] 
2025-07-09 05:10:48.441969: Epoch time: 45.39 s 
2025-07-09 05:10:49.621841:  
2025-07-09 05:10:49.622145: Epoch 960 
2025-07-09 05:10:49.622239: Current learning rate: 0.00055 
2025-07-09 05:11:35.628267: train_loss -0.8308 
2025-07-09 05:11:35.628946: val_loss -0.8479 
2025-07-09 05:11:35.629031: Pseudo dice [np.float32(0.8663)] 
2025-07-09 05:11:35.629128: Epoch time: 46.01 s 
2025-07-09 05:11:36.863226:  
2025-07-09 05:11:36.863411: Epoch 961 
2025-07-09 05:11:36.863585: Current learning rate: 0.00054 
2025-07-09 05:12:22.671792: train_loss -0.8373 
2025-07-09 05:12:22.672856: val_loss -0.8547 
2025-07-09 05:12:22.672979: Pseudo dice [np.float32(0.8574)] 
2025-07-09 05:12:22.673128: Epoch time: 45.81 s 
2025-07-09 05:12:23.883493:  
2025-07-09 05:12:23.883927: Epoch 962 
2025-07-09 05:12:23.884104: Current learning rate: 0.00053 
2025-07-09 05:13:10.359221: train_loss -0.8319 
2025-07-09 05:13:10.359834: val_loss -0.8498 
2025-07-09 05:13:10.359927: Pseudo dice [np.float32(0.864)] 
2025-07-09 05:13:10.360058: Epoch time: 46.48 s 
2025-07-09 05:13:11.590537:  
2025-07-09 05:13:11.590747: Epoch 963 
2025-07-09 05:13:11.590868: Current learning rate: 0.00051 
2025-07-09 05:13:58.078141: train_loss -0.8384 
2025-07-09 05:13:58.078627: val_loss -0.848 
2025-07-09 05:13:58.078717: Pseudo dice [np.float32(0.8783)] 
2025-07-09 05:13:58.078851: Epoch time: 46.49 s 
2025-07-09 05:13:59.284487:  
2025-07-09 05:13:59.284786: Epoch 964 
2025-07-09 05:13:59.284985: Current learning rate: 0.0005 
2025-07-09 05:14:45.948184: train_loss -0.8417 
2025-07-09 05:14:45.948629: val_loss -0.8518 
2025-07-09 05:14:45.948713: Pseudo dice [np.float32(0.8726)] 
2025-07-09 05:14:45.948816: Epoch time: 46.67 s 
2025-07-09 05:14:47.132551:  
2025-07-09 05:14:47.133197: Epoch 965 
2025-07-09 05:14:47.133367: Current learning rate: 0.00049 
2025-07-09 05:15:32.375883: train_loss -0.8357 
2025-07-09 05:15:32.377161: val_loss -0.8601 
2025-07-09 05:15:32.377347: Pseudo dice [np.float32(0.8737)] 
2025-07-09 05:15:32.377624: Epoch time: 45.24 s 
2025-07-09 05:15:32.377770: Yayy! New best EMA pseudo Dice: 0.8686000108718872 
2025-07-09 05:15:34.060193:  
2025-07-09 05:15:34.060441: Epoch 966 
2025-07-09 05:15:34.060863: Current learning rate: 0.00048 
2025-07-09 05:16:20.009846: train_loss -0.8394 
2025-07-09 05:16:20.010445: val_loss -0.8341 
2025-07-09 05:16:20.010556: Pseudo dice [np.float32(0.8731)] 
2025-07-09 05:16:20.010690: Epoch time: 45.95 s 
2025-07-09 05:16:20.010784: Yayy! New best EMA pseudo Dice: 0.8690000176429749 
2025-07-09 05:16:22.703722:  
2025-07-09 05:16:22.704444: Epoch 967 
2025-07-09 05:16:22.704956: Current learning rate: 0.00046 
2025-07-09 05:17:08.281307: train_loss -0.8278 
2025-07-09 05:17:08.281787: val_loss -0.842 
2025-07-09 05:17:08.282056: Pseudo dice [np.float32(0.8596)] 
2025-07-09 05:17:08.282197: Epoch time: 45.58 s 
2025-07-09 05:17:09.507083:  
2025-07-09 05:17:09.507595: Epoch 968 
2025-07-09 05:17:09.507735: Current learning rate: 0.00045 
2025-07-09 05:17:56.470881: train_loss -0.8356 
2025-07-09 05:17:56.471377: val_loss -0.8542 
2025-07-09 05:17:56.471490: Pseudo dice [np.float32(0.8682)] 
2025-07-09 05:17:56.471652: Epoch time: 46.96 s 
2025-07-09 05:17:57.695133:  
2025-07-09 05:17:57.695429: Epoch 969 
2025-07-09 05:17:57.695622: Current learning rate: 0.00044 
2025-07-09 05:18:44.585814: train_loss -0.8393 
2025-07-09 05:18:44.586369: val_loss -0.855 
2025-07-09 05:18:44.586466: Pseudo dice [np.float32(0.8663)] 
2025-07-09 05:18:44.586608: Epoch time: 46.89 s 
2025-07-09 05:18:45.787669:  
2025-07-09 05:18:45.788065: Epoch 970 
2025-07-09 05:18:45.788198: Current learning rate: 0.00043 
2025-07-09 05:19:32.733808: train_loss -0.8348 
2025-07-09 05:19:32.734506: val_loss -0.8333 
2025-07-09 05:19:32.734592: Pseudo dice [np.float32(0.8797)] 
2025-07-09 05:19:32.734694: Epoch time: 46.95 s 
2025-07-09 05:19:32.734777: Yayy! New best EMA pseudo Dice: 0.8690999746322632 
2025-07-09 05:19:34.488054:  
2025-07-09 05:19:34.488240: Epoch 971 
2025-07-09 05:19:34.488382: Current learning rate: 0.00041 
2025-07-09 05:20:20.383026: train_loss -0.8385 
2025-07-09 05:20:20.383584: val_loss -0.8586 
2025-07-09 05:20:20.383666: Pseudo dice [np.float32(0.8692)] 
2025-07-09 05:20:20.383773: Epoch time: 45.9 s 
2025-07-09 05:20:20.383852: Yayy! New best EMA pseudo Dice: 0.8690999746322632 
2025-07-09 05:20:22.092179:  
2025-07-09 05:20:22.092951: Epoch 972 
2025-07-09 05:20:22.093255: Current learning rate: 0.0004 
2025-07-09 05:21:08.986416: train_loss -0.834 
2025-07-09 05:21:08.986996: val_loss -0.8516 
2025-07-09 05:21:08.987093: Pseudo dice [np.float32(0.8732)] 
2025-07-09 05:21:08.987252: Epoch time: 46.9 s 
2025-07-09 05:21:08.987335: Yayy! New best EMA pseudo Dice: 0.8694999814033508 
2025-07-09 05:21:10.743862:  
2025-07-09 05:21:10.744305: Epoch 973 
2025-07-09 05:21:10.744426: Current learning rate: 0.00039 
2025-07-09 05:21:57.032218: train_loss -0.8324 
2025-07-09 05:21:57.032640: val_loss -0.8404 
2025-07-09 05:21:57.032730: Pseudo dice [np.float32(0.8792)] 
2025-07-09 05:21:57.032837: Epoch time: 46.29 s 
2025-07-09 05:21:57.033103: Yayy! New best EMA pseudo Dice: 0.8705000281333923 
2025-07-09 05:21:58.831628:  
2025-07-09 05:21:58.832077: Epoch 974 
2025-07-09 05:21:58.832331: Current learning rate: 0.00037 
2025-07-09 05:22:45.346323: train_loss -0.8352 
2025-07-09 05:22:45.346909: val_loss -0.8537 
2025-07-09 05:22:45.347012: Pseudo dice [np.float32(0.8812)] 
2025-07-09 05:22:45.347164: Epoch time: 46.52 s 
2025-07-09 05:22:45.347235: Yayy! New best EMA pseudo Dice: 0.8715999722480774 
2025-07-09 05:22:46.971072:  
2025-07-09 05:22:46.971310: Epoch 975 
2025-07-09 05:22:46.971595: Current learning rate: 0.00036 
2025-07-09 05:23:33.996515: train_loss -0.8368 
2025-07-09 05:23:33.996926: val_loss -0.8323 
2025-07-09 05:23:33.997004: Pseudo dice [np.float32(0.8661)] 
2025-07-09 05:23:33.997104: Epoch time: 47.03 s 
2025-07-09 05:23:35.168866:  
2025-07-09 05:23:35.169041: Epoch 976 
2025-07-09 05:23:35.169238: Current learning rate: 0.00035 
2025-07-09 05:24:21.585515: train_loss -0.8356 
2025-07-09 05:24:21.585952: val_loss -0.839 
2025-07-09 05:24:21.586032: Pseudo dice [np.float32(0.8778)] 
2025-07-09 05:24:21.586146: Epoch time: 46.42 s 
2025-07-09 05:24:21.586261: Yayy! New best EMA pseudo Dice: 0.8716999888420105 
2025-07-09 05:24:23.274827:  
2025-07-09 05:24:23.275193: Epoch 977 
2025-07-09 05:24:23.275449: Current learning rate: 0.00034 
2025-07-09 05:25:10.001896: train_loss -0.8381 
2025-07-09 05:25:10.002369: val_loss -0.8509 
2025-07-09 05:25:10.002471: Pseudo dice [np.float32(0.8732)] 
2025-07-09 05:25:10.002589: Epoch time: 46.73 s 
2025-07-09 05:25:10.002665: Yayy! New best EMA pseudo Dice: 0.8718000054359436 
2025-07-09 05:25:11.643361:  
2025-07-09 05:25:11.643807: Epoch 978 
2025-07-09 05:25:11.644115: Current learning rate: 0.00032 
2025-07-09 05:25:58.002877: train_loss -0.8387 
2025-07-09 05:25:58.003691: val_loss -0.8326 
2025-07-09 05:25:58.003857: Pseudo dice [np.float32(0.8683)] 
2025-07-09 05:25:58.004070: Epoch time: 46.36 s 
2025-07-09 05:25:59.320836:  
2025-07-09 05:25:59.320995: Epoch 979 
2025-07-09 05:25:59.321390: Current learning rate: 0.00031 
2025-07-09 05:26:45.688195: train_loss -0.8333 
2025-07-09 05:26:45.688647: val_loss -0.8684 
2025-07-09 05:26:45.688734: Pseudo dice [np.float32(0.8754)] 
2025-07-09 05:26:45.688845: Epoch time: 46.37 s 
2025-07-09 05:26:45.688929: Yayy! New best EMA pseudo Dice: 0.8719000220298767 
2025-07-09 05:26:48.277970:  
2025-07-09 05:26:48.278355: Epoch 980 
2025-07-09 05:26:48.278633: Current learning rate: 0.0003 
2025-07-09 05:27:34.014379: train_loss -0.8373 
2025-07-09 05:27:34.015053: val_loss -0.838 
2025-07-09 05:27:34.015145: Pseudo dice [np.float32(0.8687)] 
2025-07-09 05:27:34.015269: Epoch time: 45.74 s 
2025-07-09 05:27:35.251055:  
2025-07-09 05:27:35.251313: Epoch 981 
2025-07-09 05:27:35.251450: Current learning rate: 0.00028 
2025-07-09 05:28:22.671422: train_loss -0.8403 
2025-07-09 05:28:22.671773: val_loss -0.851 
2025-07-09 05:28:22.671852: Pseudo dice [np.float32(0.8709)] 
2025-07-09 05:28:22.671951: Epoch time: 47.42 s 
2025-07-09 05:28:23.848110:  
2025-07-09 05:28:23.848435: Epoch 982 
2025-07-09 05:28:23.848580: Current learning rate: 0.00027 
2025-07-09 05:29:10.255973: train_loss -0.8348 
2025-07-09 05:29:10.256337: val_loss -0.8641 
2025-07-09 05:29:10.256417: Pseudo dice [np.float32(0.857)] 
2025-07-09 05:29:10.256511: Epoch time: 46.41 s 
2025-07-09 05:29:11.432257:  
2025-07-09 05:29:11.432773: Epoch 983 
2025-07-09 05:29:11.433038: Current learning rate: 0.00026 
2025-07-09 05:29:57.724722: train_loss -0.8333 
2025-07-09 05:29:57.725811: val_loss -0.8511 
2025-07-09 05:29:57.725936: Pseudo dice [np.float32(0.8682)] 
2025-07-09 05:29:57.726109: Epoch time: 46.29 s 
2025-07-09 05:29:58.986907:  
2025-07-09 05:29:58.987307: Epoch 984 
2025-07-09 05:29:58.987414: Current learning rate: 0.00024 
2025-07-09 05:30:45.590410: train_loss -0.8422 
2025-07-09 05:30:45.590987: val_loss -0.8516 
2025-07-09 05:30:45.591081: Pseudo dice [np.float32(0.8664)] 
2025-07-09 05:30:45.591254: Epoch time: 46.6 s 
2025-07-09 05:30:46.826190:  
2025-07-09 05:30:46.826560: Epoch 985 
2025-07-09 05:30:46.826849: Current learning rate: 0.00023 
2025-07-09 05:31:33.259491: train_loss -0.8327 
2025-07-09 05:31:33.259981: val_loss -0.8467 
2025-07-09 05:31:33.260103: Pseudo dice [np.float32(0.8727)] 
2025-07-09 05:31:33.260221: Epoch time: 46.43 s 
2025-07-09 05:31:34.441061:  
2025-07-09 05:31:34.441584: Epoch 986 
2025-07-09 05:31:34.441768: Current learning rate: 0.00021 
2025-07-09 05:32:21.274719: train_loss -0.8458 
2025-07-09 05:32:21.275602: val_loss -0.8547 
2025-07-09 05:32:21.275732: Pseudo dice [np.float32(0.8719)] 
2025-07-09 05:32:21.275875: Epoch time: 46.83 s 
2025-07-09 05:32:22.529918:  
2025-07-09 05:32:22.530275: Epoch 987 
2025-07-09 05:32:22.530581: Current learning rate: 0.0002 
2025-07-09 05:33:08.998652: train_loss -0.8392 
2025-07-09 05:33:08.999215: val_loss -0.8471 
2025-07-09 05:33:08.999357: Pseudo dice [np.float32(0.8753)] 
2025-07-09 05:33:08.999467: Epoch time: 46.47 s 
2025-07-09 05:33:10.284016:  
2025-07-09 05:33:10.284437: Epoch 988 
2025-07-09 05:33:10.284686: Current learning rate: 0.00019 
2025-07-09 05:33:56.651673: train_loss -0.8374 
2025-07-09 05:33:56.652182: val_loss -0.8536 
2025-07-09 05:33:56.652270: Pseudo dice [np.float32(0.8598)] 
2025-07-09 05:33:56.652375: Epoch time: 46.37 s 
2025-07-09 05:33:57.816878:  
2025-07-09 05:33:57.817221: Epoch 989 
2025-07-09 05:33:57.817349: Current learning rate: 0.00017 
2025-07-09 05:34:44.756243: train_loss -0.839 
2025-07-09 05:34:44.757029: val_loss -0.849 
2025-07-09 05:34:44.757144: Pseudo dice [np.float32(0.8731)] 
2025-07-09 05:34:44.757288: Epoch time: 46.94 s 
2025-07-09 05:34:45.933717:  
2025-07-09 05:34:45.934109: Epoch 990 
2025-07-09 05:34:45.934240: Current learning rate: 0.00016 
2025-07-09 05:35:32.214130: train_loss -0.8332 
2025-07-09 05:35:32.214614: val_loss -0.8576 
2025-07-09 05:35:32.214792: Pseudo dice [np.float32(0.8746)] 
2025-07-09 05:35:32.214917: Epoch time: 46.28 s 
2025-07-09 05:35:33.440943:  
2025-07-09 05:35:33.441328: Epoch 991 
2025-07-09 05:35:33.441500: Current learning rate: 0.00014 
2025-07-09 05:36:20.495258: train_loss -0.8398 
2025-07-09 05:36:20.495796: val_loss -0.843 
2025-07-09 05:36:20.495890: Pseudo dice [np.float32(0.87)] 
2025-07-09 05:36:20.496005: Epoch time: 47.06 s 
2025-07-09 05:36:21.793763:  
2025-07-09 05:36:21.793923: Epoch 992 
2025-07-09 05:36:21.794044: Current learning rate: 0.00013 
2025-07-09 05:37:08.789016: train_loss -0.8473 
2025-07-09 05:37:08.789382: val_loss -0.8506 
2025-07-09 05:37:08.789464: Pseudo dice [np.float32(0.8708)] 
2025-07-09 05:37:08.789581: Epoch time: 47.0 s 
2025-07-09 05:37:09.990866:  
2025-07-09 05:37:09.991183: Epoch 993 
2025-07-09 05:37:09.991367: Current learning rate: 0.00011 
2025-07-09 05:37:56.389458: train_loss -0.8478 
2025-07-09 05:37:56.389935: val_loss -0.8549 
2025-07-09 05:37:56.390015: Pseudo dice [np.float32(0.8758)] 
2025-07-09 05:37:56.390148: Epoch time: 46.4 s 
2025-07-09 05:37:58.502839:  
2025-07-09 05:37:58.503182: Epoch 994 
2025-07-09 05:37:58.503321: Current learning rate: 0.0001 
2025-07-09 05:38:44.770285: train_loss -0.8408 
2025-07-09 05:38:44.770692: val_loss -0.8441 
2025-07-09 05:38:44.770778: Pseudo dice [np.float32(0.8653)] 
2025-07-09 05:38:44.770892: Epoch time: 46.27 s 
2025-07-09 05:38:45.980855:  
2025-07-09 05:38:45.981289: Epoch 995 
2025-07-09 05:38:45.981414: Current learning rate: 8e-05 
2025-07-09 05:39:33.793233: train_loss -0.8382 
2025-07-09 05:39:33.793793: val_loss -0.8491 
2025-07-09 05:39:33.793886: Pseudo dice [np.float32(0.8803)] 
2025-07-09 05:39:33.793987: Epoch time: 47.81 s 
2025-07-09 05:39:35.006522:  
2025-07-09 05:39:35.006783: Epoch 996 
2025-07-09 05:39:35.006916: Current learning rate: 7e-05 
2025-07-09 05:40:22.360905: train_loss -0.8382 
2025-07-09 05:40:22.361304: val_loss -0.8568 
2025-07-09 05:40:22.361385: Pseudo dice [np.float32(0.8783)] 
2025-07-09 05:40:22.361532: Epoch time: 47.36 s 
2025-07-09 05:40:22.361626: Yayy! New best EMA pseudo Dice: 0.871999979019165 
2025-07-09 05:40:24.012374:  
2025-07-09 05:40:24.012844: Epoch 997 
2025-07-09 05:40:24.012974: Current learning rate: 5e-05 
2025-07-09 05:41:10.714701: train_loss -0.8418 
2025-07-09 05:41:10.715075: val_loss -0.8533 
2025-07-09 05:41:10.715154: Pseudo dice [np.float32(0.8709)] 
2025-07-09 05:41:10.715263: Epoch time: 46.7 s 
2025-07-09 05:41:11.966364:  
2025-07-09 05:41:11.966811: Epoch 998 
2025-07-09 05:41:11.967091: Current learning rate: 4e-05 
2025-07-09 05:41:57.712200: train_loss -0.8448 
2025-07-09 05:41:57.712622: val_loss -0.8471 
2025-07-09 05:41:57.712707: Pseudo dice [np.float32(0.8717)] 
2025-07-09 05:41:57.712896: Epoch time: 45.75 s 
2025-07-09 05:41:58.885040:  
2025-07-09 05:41:58.885452: Epoch 999 
2025-07-09 05:41:58.885659: Current learning rate: 2e-05 
2025-07-09 05:42:44.736368: train_loss -0.8336 
2025-07-09 05:42:44.737088: val_loss -0.8437 
2025-07-09 05:42:44.737169: Pseudo dice [np.float32(0.8757)] 
2025-07-09 05:42:44.737280: Epoch time: 45.85 s 
2025-07-09 05:42:44.737356: Yayy! New best EMA pseudo Dice: 0.8723000288009644 
2025-07-09 05:42:46.801897: Training done. 
2025-07-09 05:42:46.825694: predicting BraTS-PED-00001-000 
2025-07-09 05:42:46.876704: BraTS-PED-00001-000, shape torch.Size([4, 112, 112, 112]), rank 0 
2025-07-09 05:42:54.860565: predicting BraTS-PED-00002-000 
2025-07-09 05:42:54.868096: BraTS-PED-00002-000, shape torch.Size([4, 53, 53, 53]), rank 0 
2025-07-09 05:42:54.909861: predicting BraTS-PED-00003-000 
2025-07-09 05:42:54.952482: BraTS-PED-00003-000, shape torch.Size([4, 124, 124, 124]), rank 0 
2025-07-09 05:42:55.551787: predicting BraTS-PED-00004-000 
2025-07-09 05:42:55.591645: BraTS-PED-00004-000, shape torch.Size([4, 114, 114, 114]), rank 0 
2025-07-09 05:42:55.784566: predicting BraTS-PED-00005-000 
2025-07-09 05:42:55.789714: BraTS-PED-00005-000, shape torch.Size([4, 64, 64, 64]), rank 0 
2025-07-09 05:42:55.824251: predicting BraTS-PED-00006-000 
2025-07-09 05:42:55.829417: BraTS-PED-00006-000, shape torch.Size([4, 57, 57, 57]), rank 0 
2025-07-09 05:42:55.863908: predicting BraTS-PED-00008-000 
2025-07-09 05:42:55.884758: BraTS-PED-00008-000, shape torch.Size([4, 104, 104, 104]), rank 0 
2025-07-09 05:42:56.068900: predicting BraTS-PED-00009-000 
2025-07-09 05:42:56.095637: BraTS-PED-00009-000, shape torch.Size([4, 109, 109, 109]), rank 0 
2025-07-09 05:42:56.280676: predicting BraTS-PED-00010-000 
2025-07-09 05:42:56.296187: BraTS-PED-00010-000, shape torch.Size([4, 24, 179, 171]), rank 0 
2025-07-09 05:42:56.683552: predicting BraTS-PED-00013-000 
2025-07-09 05:42:56.695316: BraTS-PED-00013-000, shape torch.Size([4, 81, 81, 81]), rank 0 
2025-07-09 05:42:56.879548: predicting BraTS-PED-00014-000 
2025-07-09 05:42:56.887000: BraTS-PED-00014-000, shape torch.Size([4, 66, 66, 66]), rank 0 
2025-07-09 05:42:56.920359: predicting BraTS-PED-00015-000 
2025-07-09 05:42:56.936132: BraTS-PED-00015-000, shape torch.Size([4, 96, 96, 96]), rank 0 
2025-07-09 05:42:57.119967: predicting BraTS-PED-00016-000 
2025-07-09 05:42:57.132975: BraTS-PED-00016-000, shape torch.Size([4, 85, 85, 85]), rank 0 
2025-07-09 05:42:57.316361: predicting BraTS-PED-00017-000 
2025-07-09 05:42:57.368979: BraTS-PED-00017-000, shape torch.Size([4, 144, 144, 144]), rank 0 
2025-07-09 05:42:57.969154: predicting BraTS-PED-00018-000 
2025-07-09 05:42:57.994468: BraTS-PED-00018-000, shape torch.Size([4, 112, 112, 112]), rank 0 
2025-07-09 05:42:58.182816: predicting BraTS-PED-00019-000 
2025-07-09 05:42:58.240236: BraTS-PED-00019-000, shape torch.Size([4, 144, 144, 144]), rank 0 
2025-07-09 05:42:58.845926: predicting BraTS-PED-00020-000 
2025-07-09 05:42:58.854804: BraTS-PED-00020-000, shape torch.Size([4, 71, 71, 71]), rank 0 
2025-07-09 05:42:58.890937: predicting BraTS-PED-00021-000 
2025-07-09 05:42:58.931332: BraTS-PED-00021-000, shape torch.Size([4, 123, 123, 123]), rank 0 
2025-07-09 05:42:59.528402: predicting BraTS-PED-00022-000 
2025-07-09 05:42:59.555329: BraTS-PED-00022-000, shape torch.Size([4, 110, 110, 110]), rank 0 
2025-07-09 05:42:59.741507: predicting BraTS-PED-00023-000 
2025-07-09 05:42:59.764832: BraTS-PED-00023-000, shape torch.Size([4, 112, 112, 112]), rank 0 
2025-07-09 05:42:59.950318: predicting BraTS-PED-00024-000 
2025-07-09 05:42:59.969155: BraTS-PED-00024-000, shape torch.Size([4, 98, 102, 102]), rank 0 
2025-07-09 05:43:00.154105: predicting BraTS-PED-00025-000 
2025-07-09 05:43:00.163172: BraTS-PED-00025-000, shape torch.Size([4, 76, 76, 76]), rank 0 
2025-07-09 05:43:00.196921: predicting BraTS-PED-00026-000 
2025-07-09 05:43:00.203417: BraTS-PED-00026-000, shape torch.Size([4, 60, 60, 60]), rank 0 
2025-07-09 05:43:00.236495: predicting BraTS-PED-00027-000 
2025-07-09 05:43:00.242417: BraTS-PED-00027-000, shape torch.Size([4, 63, 63, 63]), rank 0 
2025-07-09 05:43:00.276570: predicting BraTS-PED-00028-000 
2025-07-09 05:43:00.312141: BraTS-PED-00028-000, shape torch.Size([4, 122, 122, 122]), rank 0 
2025-07-09 05:43:00.910122: predicting BraTS-PED-00029-000 
2025-07-09 05:43:00.913031: BraTS-PED-00029-000, shape torch.Size([4, 48, 48, 48]), rank 0 
2025-07-09 05:43:00.945425: predicting BraTS-PED-00030-000 
2025-07-09 05:43:00.974667: BraTS-PED-00030-000, shape torch.Size([4, 120, 120, 120]), rank 0 
2025-07-09 05:43:01.165163: predicting BraTS-PED-00031-000 
2025-07-09 05:43:01.192616: BraTS-PED-00031-000, shape torch.Size([4, 107, 107, 107]), rank 0 
2025-07-09 05:43:01.380082: predicting BraTS-PED-00032-000 
2025-07-09 05:43:01.395499: BraTS-PED-00032-000, shape torch.Size([4, 90, 90, 90]), rank 0 
2025-07-09 05:43:01.579322: predicting BraTS-PED-00033-000 
2025-07-09 05:43:01.604620: BraTS-PED-00033-000, shape torch.Size([4, 108, 108, 108]), rank 0 
2025-07-09 05:43:01.792205: predicting BraTS-PED-00034-000 
2025-07-09 05:43:01.814529: BraTS-PED-00034-000, shape torch.Size([4, 103, 103, 103]), rank 0 
2025-07-09 05:43:01.999326: predicting BraTS-PED-00035-000 
2025-07-09 05:43:02.030864: BraTS-PED-00035-000, shape torch.Size([4, 116, 116, 116]), rank 0 
2025-07-09 05:43:02.216560: predicting BraTS-PED-00036-000 
2025-07-09 05:43:02.226196: BraTS-PED-00036-000, shape torch.Size([4, 76, 76, 76]), rank 0 
2025-07-09 05:43:02.260053: predicting BraTS-PED-00037-000 
2025-07-09 05:43:02.267128: BraTS-PED-00037-000, shape torch.Size([4, 66, 66, 66]), rank 0 
2025-07-09 05:43:02.305301: predicting BraTS-PED-00038-000 
2025-07-09 05:43:02.309071: BraTS-PED-00038-000, shape torch.Size([4, 53, 53, 53]), rank 0 
2025-07-09 05:43:02.341859: predicting BraTS-PED-00039-000 
2025-07-09 05:43:02.351116: BraTS-PED-00039-000, shape torch.Size([4, 78, 78, 78]), rank 0 
2025-07-09 05:43:02.384102: predicting BraTS-PED-00040-000 
2025-07-09 05:43:02.394562: BraTS-PED-00040-000, shape torch.Size([4, 78, 78, 78]), rank 0 
2025-07-09 05:43:02.432900: predicting BraTS-PED-00041-000 
2025-07-09 05:43:02.446174: BraTS-PED-00041-000, shape torch.Size([4, 86, 86, 86]), rank 0 
2025-07-09 05:43:02.629071: predicting BraTS-PED-00042-000 
2025-07-09 05:43:02.679890: BraTS-PED-00042-000, shape torch.Size([4, 144, 144, 144]), rank 0 
2025-07-09 05:43:03.284056: predicting BraTS-PED-00043-000 
2025-07-09 05:43:03.316515: BraTS-PED-00043-000, shape torch.Size([4, 120, 120, 120]), rank 0 
2025-07-09 05:43:03.504336: predicting BraTS-PED-00044-000 
2025-07-09 05:43:03.512124: BraTS-PED-00044-000, shape torch.Size([4, 68, 68, 68]), rank 0 
2025-07-09 05:43:03.547609: predicting BraTS-PED-00045-000 
2025-07-09 05:43:03.557326: BraTS-PED-00045-000, shape torch.Size([4, 75, 75, 75]), rank 0 
2025-07-09 05:43:03.592013: predicting BraTS-PED-00046-000 
2025-07-09 05:43:03.601002: BraTS-PED-00046-000, shape torch.Size([4, 69, 69, 69]), rank 0 
2025-07-09 05:43:03.633849: predicting BraTS-PED-00047-000 
2025-07-09 05:43:03.639772: BraTS-PED-00047-000, shape torch.Size([4, 63, 63, 63]), rank 0 
2025-07-09 05:43:03.673259: predicting BraTS-PED-00048-000 
2025-07-09 05:43:03.729446: BraTS-PED-00048-000, shape torch.Size([4, 142, 142, 142]), rank 0 
2025-07-09 05:43:04.328765: predicting BraTS-PED-00049-000 
2025-07-09 05:43:04.365092: BraTS-PED-00049-000, shape torch.Size([4, 124, 124, 124]), rank 0 
2025-07-09 05:43:04.964533: predicting BraTS-PED-00050-000 
2025-07-09 05:43:04.981491: BraTS-PED-00050-000, shape torch.Size([4, 96, 96, 96]), rank 0 
2025-07-09 05:43:05.166360: predicting BraTS-PED-00051-000 
2025-07-09 05:43:05.208707: BraTS-PED-00051-000, shape torch.Size([4, 131, 131, 131]), rank 0 
2025-07-09 05:43:05.808509: predicting BraTS-PED-00052-000 
2025-07-09 05:43:05.816318: BraTS-PED-00052-000, shape torch.Size([4, 68, 68, 68]), rank 0 
2025-07-09 05:43:05.849102: predicting BraTS-PED-00053-000 
2025-07-09 05:43:05.854645: BraTS-PED-00053-000, shape torch.Size([4, 62, 62, 62]), rank 0 
2025-07-09 05:43:05.887951: predicting BraTS-PED-00054-000 
2025-07-09 05:43:05.920719: BraTS-PED-00054-000, shape torch.Size([4, 112, 112, 112]), rank 0 
2025-07-09 05:43:06.106822: predicting BraTS-PED-00055-000 
2025-07-09 05:43:06.109548: BraTS-PED-00055-000, shape torch.Size([4, 48, 48, 48]), rank 0 
2025-07-09 05:43:06.140692: predicting BraTS-PED-00056-000 
2025-07-09 05:43:06.157480: BraTS-PED-00056-000, shape torch.Size([4, 89, 89, 89]), rank 0 
2025-07-09 05:43:06.339991: predicting BraTS-PED-00057-000 
2025-07-09 05:43:06.349353: BraTS-PED-00057-000, shape torch.Size([4, 77, 77, 77]), rank 0 
2025-07-09 05:43:06.383467: predicting BraTS-PED-00058-000 
2025-07-09 05:43:06.404962: BraTS-PED-00058-000, shape torch.Size([4, 102, 102, 102]), rank 0 
2025-07-09 05:43:06.588845: predicting BraTS-PED-00059-000 
2025-07-09 05:43:06.602655: BraTS-PED-00059-000, shape torch.Size([4, 86, 86, 86]), rank 0 
2025-07-09 05:43:06.786747: predicting BraTS-PED-00060-000 
2025-07-09 05:43:06.820794: BraTS-PED-00060-000, shape torch.Size([4, 120, 120, 120]), rank 0 
2025-07-09 05:43:07.006132: predicting BraTS-PED-00061-000 
2025-07-09 05:43:07.013984: BraTS-PED-00061-000, shape torch.Size([4, 69, 69, 69]), rank 0 
2025-07-09 05:43:07.047424: predicting BraTS-PED-00062-000 
2025-07-09 05:43:07.063978: BraTS-PED-00062-000, shape torch.Size([4, 92, 92, 92]), rank 0 
2025-07-09 05:43:07.248329: predicting BraTS-PED-00063-000 
2025-07-09 05:43:07.280055: BraTS-PED-00063-000, shape torch.Size([4, 120, 120, 120]), rank 0 
2025-07-09 05:43:07.465276: predicting BraTS-PED-00064-000 
2025-07-09 05:43:07.496861: BraTS-PED-00064-000, shape torch.Size([4, 120, 120, 120]), rank 0 
2025-07-09 05:43:07.684849: predicting BraTS-PED-00065-000 
2025-07-09 05:43:07.715665: BraTS-PED-00065-000, shape torch.Size([4, 114, 114, 114]), rank 0 
2025-07-09 05:43:07.902501: predicting BraTS-PED-00066-000 
2025-07-09 05:43:07.955522: BraTS-PED-00066-000, shape torch.Size([4, 138, 138, 138]), rank 0 
2025-07-09 05:43:08.559845: predicting BraTS-PED-00067-000 
2025-07-09 05:43:08.567878: BraTS-PED-00067-000, shape torch.Size([4, 67, 67, 67]), rank 0 
2025-07-09 05:43:08.601528: predicting BraTS-PED-00068-000 
2025-07-09 05:43:08.605587: BraTS-PED-00068-000, shape torch.Size([4, 53, 53, 53]), rank 0 
2025-07-09 05:43:08.639031: predicting BraTS-PED-00069-000 
2025-07-09 05:43:08.653371: BraTS-PED-00069-000, shape torch.Size([4, 87, 87, 87]), rank 0 
2025-07-09 05:43:08.840342: predicting BraTS-PED-00070-000 
2025-07-09 05:43:08.846984: BraTS-PED-00070-000, shape torch.Size([4, 59, 59, 59]), rank 0 
2025-07-09 05:43:08.881598: predicting BraTS-PED-00071-000 
2025-07-09 05:43:08.889911: BraTS-PED-00071-000, shape torch.Size([4, 66, 66, 66]), rank 0 
2025-07-09 05:43:08.923486: predicting BraTS-PED-00072-000 
2025-07-09 05:43:08.928527: BraTS-PED-00072-000, shape torch.Size([4, 57, 57, 57]), rank 0 
2025-07-09 05:43:08.961076: predicting BraTS-PED-00073-000 
2025-07-09 05:43:08.992946: BraTS-PED-00073-000, shape torch.Size([4, 114, 114, 114]), rank 0 
2025-07-09 05:43:09.177902: predicting BraTS-PED-00074-000 
2025-07-09 05:43:09.181549: BraTS-PED-00074-000, shape torch.Size([4, 50, 50, 50]), rank 0 
2025-07-09 05:43:09.213320: predicting BraTS-PED-00075-000 
2025-07-09 05:43:09.217081: BraTS-PED-00075-000, shape torch.Size([4, 49, 49, 49]), rank 0 
2025-07-09 05:43:09.250418: predicting BraTS-PED-00076-000 
2025-07-09 05:43:09.267469: BraTS-PED-00076-000, shape torch.Size([4, 93, 93, 93]), rank 0 
2025-07-09 05:43:09.450764: predicting BraTS-PED-00077-000 
2025-07-09 05:43:09.455161: BraTS-PED-00077-000, shape torch.Size([4, 55, 55, 55]), rank 0 
2025-07-09 05:43:09.488273: predicting BraTS-PED-00078-000 
2025-07-09 05:43:09.498081: BraTS-PED-00078-000, shape torch.Size([4, 73, 73, 73]), rank 0 
2025-07-09 05:43:09.531327: predicting BraTS-PED-00079-000 
2025-07-09 05:43:09.558148: BraTS-PED-00079-000, shape torch.Size([4, 111, 111, 111]), rank 0 
2025-07-09 05:43:09.743511: predicting BraTS-PED-00080-000 
2025-07-09 05:43:09.750368: BraTS-PED-00080-000, shape torch.Size([4, 66, 66, 66]), rank 0 
2025-07-09 05:43:09.783439: predicting BraTS-PED-00081-000 
2025-07-09 05:43:09.791213: BraTS-PED-00081-000, shape torch.Size([4, 69, 69, 69]), rank 0 
2025-07-09 05:43:09.824266: predicting BraTS-PED-00082-000 
2025-07-09 05:43:09.834413: BraTS-PED-00082-000, shape torch.Size([4, 74, 74, 74]), rank 0 
2025-07-09 05:43:09.867614: predicting BraTS-PED-00083-000 
2025-07-09 05:43:09.875995: BraTS-PED-00083-000, shape torch.Size([4, 16, 171, 171]), rank 0 
2025-07-09 05:43:10.257514: predicting BraTS-PED-00084-000 
2025-07-09 05:43:10.265006: BraTS-PED-00084-000, shape torch.Size([4, 70, 70, 70]), rank 0 
2025-07-09 05:43:10.298487: predicting BraTS-PED-00085-000 
2025-07-09 05:43:10.304144: BraTS-PED-00085-000, shape torch.Size([4, 62, 62, 62]), rank 0 
2025-07-09 05:43:10.338225: predicting BraTS-PED-00086-000 
2025-07-09 05:43:10.347581: BraTS-PED-00086-000, shape torch.Size([4, 65, 65, 65]), rank 0 
2025-07-09 05:43:10.380724: predicting BraTS-PED-00087-000 
2025-07-09 05:43:10.386204: BraTS-PED-00087-000, shape torch.Size([4, 59, 59, 59]), rank 0 
2025-07-09 05:43:10.420953: predicting BraTS-PED-00088-000 
2025-07-09 05:43:10.436798: BraTS-PED-00088-000, shape torch.Size([4, 90, 90, 90]), rank 0 
2025-07-09 05:43:10.621523: predicting BraTS-PED-00089-000 
2025-07-09 05:43:10.636929: BraTS-PED-00089-000, shape torch.Size([4, 95, 95, 95]), rank 0 
2025-07-09 05:43:10.821050: predicting BraTS-PED-00091-000 
2025-07-09 05:43:10.876753: BraTS-PED-00091-000, shape torch.Size([4, 139, 139, 139]), rank 0 
2025-07-09 05:43:11.474990: predicting BraTS-PED-00092-000 
2025-07-09 05:43:11.488212: BraTS-PED-00092-000, shape torch.Size([4, 83, 83, 83]), rank 0 
2025-07-09 05:43:11.673940: predicting BraTS-PED-00093-000 
2025-07-09 05:43:11.700511: BraTS-PED-00093-000, shape torch.Size([4, 35, 190, 169]), rank 0 
2025-07-09 05:43:12.087657: predicting BraTS-PED-00094-000 
2025-07-09 05:43:12.092042: BraTS-PED-00094-000, shape torch.Size([4, 56, 56, 56]), rank 0 
2025-07-09 05:43:12.128395: predicting BraTS-PED-00095-000 
2025-07-09 05:43:12.133925: BraTS-PED-00095-000, shape torch.Size([4, 60, 60, 60]), rank 0 
2025-07-09 05:43:12.166850: predicting BraTS-PED-00096-000 
2025-07-09 05:43:12.182747: BraTS-PED-00096-000, shape torch.Size([4, 29, 184, 184]), rank 0 
2025-07-09 05:43:12.567726: predicting BraTS-PED-00097-000 
2025-07-09 05:43:12.589220: BraTS-PED-00097-000, shape torch.Size([4, 103, 103, 103]), rank 0 
2025-07-09 05:43:12.774358: predicting BraTS-PED-00098-000 
2025-07-09 05:43:12.784380: BraTS-PED-00098-000, shape torch.Size([4, 79, 79, 79]), rank 0 
2025-07-09 05:43:12.819246: predicting BraTS-PED-00099-000 
2025-07-09 05:43:12.826468: BraTS-PED-00099-000, shape torch.Size([4, 65, 65, 65]), rank 0 
2025-07-09 05:43:12.860784: predicting BraTS-PED-00100-000 
2025-07-09 05:43:12.914566: BraTS-PED-00100-000, shape torch.Size([4, 144, 144, 144]), rank 0 
2025-07-09 05:43:13.513831: predicting BraTS-PED-00101-000 
2025-07-09 05:43:13.534158: BraTS-PED-00101-000, shape torch.Size([4, 103, 103, 103]), rank 0 
2025-07-09 05:43:13.724224: predicting BraTS-PED-00102-000 
2025-07-09 05:43:13.726855: BraTS-PED-00102-000, shape torch.Size([4, 48, 48, 48]), rank 0 
2025-07-09 05:43:13.759441: predicting BraTS-PED-00103-000 
2025-07-09 05:43:13.793723: BraTS-PED-00103-000, shape torch.Size([4, 120, 120, 120]), rank 0 
2025-07-09 05:43:13.978520: predicting BraTS-PED-00104-000 
2025-07-09 05:43:14.054999: BraTS-PED-00104-000, shape torch.Size([4, 153, 153, 153]), rank 0 
2025-07-09 05:43:14.656785: predicting BraTS-PED-00105-000 
2025-07-09 05:43:14.666522: BraTS-PED-00105-000, shape torch.Size([4, 78, 78, 78]), rank 0 
2025-07-09 05:43:14.700628: predicting BraTS-PED-00106-000 
2025-07-09 05:43:14.709747: BraTS-PED-00106-000, shape torch.Size([4, 73, 73, 73]), rank 0 
2025-07-09 05:43:14.742841: predicting BraTS-PED-00107-000 
2025-07-09 05:43:14.759885: BraTS-PED-00107-000, shape torch.Size([4, 94, 94, 94]), rank 0 
2025-07-09 05:43:14.943963: predicting BraTS-PED-00108-000 
2025-07-09 05:43:14.965372: BraTS-PED-00108-000, shape torch.Size([4, 98, 98, 98]), rank 0 
2025-07-09 05:43:15.149775: predicting BraTS-PED-00109-000 
2025-07-09 05:43:15.164330: BraTS-PED-00109-000, shape torch.Size([4, 93, 93, 93]), rank 0 
2025-07-09 05:43:15.349865: predicting BraTS-PED-00110-000 
2025-07-09 05:43:15.363838: BraTS-PED-00110-000, shape torch.Size([4, 87, 87, 87]), rank 0 
2025-07-09 05:43:15.547773: predicting BraTS-PED-00112-000 
2025-07-09 05:43:15.555294: BraTS-PED-00112-000, shape torch.Size([4, 70, 70, 70]), rank 0 
2025-07-09 05:43:15.588382: predicting BraTS-PED-00113-000 
2025-07-09 05:43:15.592410: BraTS-PED-00113-000, shape torch.Size([4, 51, 51, 51]), rank 0 
2025-07-09 05:43:15.625128: predicting BraTS-PED-00114-000 
2025-07-09 05:43:15.633780: BraTS-PED-00114-000, shape torch.Size([4, 70, 70, 70]), rank 0 
2025-07-09 05:43:15.666070: predicting BraTS-PED-00115-000 
2025-07-09 05:43:15.676071: BraTS-PED-00115-000, shape torch.Size([4, 76, 76, 76]), rank 0 
2025-07-09 05:43:15.712350: predicting BraTS-PED-00116-000 
2025-07-09 05:43:15.727908: BraTS-PED-00116-000, shape torch.Size([4, 26, 181, 176]), rank 0 
2025-07-09 05:43:16.111915: predicting BraTS-PED-00117-000 
2025-07-09 05:43:16.136492: BraTS-PED-00117-000, shape torch.Size([4, 109, 109, 109]), rank 0 
2025-07-09 05:43:16.320980: predicting BraTS-PED-00118-000 
2025-07-09 05:43:16.330084: BraTS-PED-00118-000, shape torch.Size([4, 78, 78, 78]), rank 0 
2025-07-09 05:43:16.364974: predicting BraTS-PED-00119-000 
2025-07-09 05:43:16.389594: BraTS-PED-00119-000, shape torch.Size([4, 112, 112, 112]), rank 0 
2025-07-09 05:43:16.575244: predicting BraTS-PED-00120-000 
2025-07-09 05:43:16.582692: BraTS-PED-00120-000, shape torch.Size([4, 69, 69, 69]), rank 0 
2025-07-09 05:43:16.615878: predicting BraTS-PED-00121-000 
2025-07-09 05:43:16.656279: BraTS-PED-00121-000, shape torch.Size([4, 126, 126, 126]), rank 0 
2025-07-09 05:43:17.255407: predicting BraTS-PED-00122-000 
2025-07-09 05:43:17.297383: BraTS-PED-00122-000, shape torch.Size([4, 131, 131, 131]), rank 0 
2025-07-09 05:43:17.899442: predicting BraTS-PED-00123-000 
2025-07-09 05:43:17.906926: BraTS-PED-00123-000, shape torch.Size([4, 71, 71, 71]), rank 0 
2025-07-09 05:43:17.941782: predicting BraTS-PED-00124-000 
2025-07-09 05:43:17.956674: BraTS-PED-00124-000, shape torch.Size([4, 85, 85, 85]), rank 0 
2025-07-09 05:43:18.140804: predicting BraTS-PED-00125-000 
2025-07-09 05:43:18.157409: BraTS-PED-00125-000, shape torch.Size([4, 96, 96, 96]), rank 0 
2025-07-09 05:43:18.340521: predicting BraTS-PED-00126-000 
2025-07-09 05:43:18.353721: BraTS-PED-00126-000, shape torch.Size([4, 84, 84, 84]), rank 0 
2025-07-09 05:43:18.536937: predicting BraTS-PED-00127-000 
2025-07-09 05:43:18.554176: BraTS-PED-00127-000, shape torch.Size([4, 92, 92, 92]), rank 0 
2025-07-09 05:43:18.738357: predicting BraTS-PED-00128-000 
2025-07-09 05:43:18.741957: BraTS-PED-00128-000, shape torch.Size([4, 54, 54, 54]), rank 0 
2025-07-09 05:43:18.777073: predicting BraTS-PED-00129-000 
2025-07-09 05:43:18.786953: BraTS-PED-00129-000, shape torch.Size([4, 80, 80, 80]), rank 0 
2025-07-09 05:43:18.818235: predicting BraTS-PED-00130-000 
2025-07-09 05:43:18.843272: BraTS-PED-00130-000, shape torch.Size([4, 111, 111, 111]), rank 0 
2025-07-09 05:43:19.028326: predicting BraTS-PED-00131-000 
2025-07-09 05:43:19.040521: BraTS-PED-00131-000, shape torch.Size([4, 88, 88, 88]), rank 0 
2025-07-09 05:43:19.225203: predicting BraTS-PED-00132-000 
2025-07-09 05:43:19.229566: BraTS-PED-00132-000, shape torch.Size([4, 57, 57, 57]), rank 0 
2025-07-09 05:43:19.262676: predicting BraTS-PED-00133-000 
2025-07-09 05:43:19.284747: BraTS-PED-00133-000, shape torch.Size([4, 112, 112, 112]), rank 0 
2025-07-09 05:43:19.469307: predicting BraTS-PED-00134-000 
2025-07-09 05:43:19.476993: BraTS-PED-00134-000, shape torch.Size([4, 72, 72, 72]), rank 0 
2025-07-09 05:43:19.510309: predicting BraTS-PED-00135-000 
2025-07-09 05:43:19.547166: BraTS-PED-00135-000, shape torch.Size([4, 124, 124, 123]), rank 0 
2025-07-09 05:43:20.145060: predicting BraTS-PED-00136-000 
2025-07-09 05:43:20.170049: BraTS-PED-00136-000, shape torch.Size([4, 108, 108, 108]), rank 0 
2025-07-09 05:43:20.359416: predicting BraTS-PED-00137-000 
2025-07-09 05:43:20.370695: BraTS-PED-00137-000, shape torch.Size([4, 83, 83, 83]), rank 0 
2025-07-09 05:43:20.555329: predicting BraTS-PED-00138-000 
2025-07-09 05:43:20.573244: BraTS-PED-00138-000, shape torch.Size([4, 97, 97, 97]), rank 0 
2025-07-09 05:43:20.759114: predicting BraTS-PED-00139-000 
2025-07-09 05:43:20.768179: BraTS-PED-00139-000, shape torch.Size([4, 78, 78, 78]), rank 0 
2025-07-09 05:43:20.802237: predicting BraTS-PED-00140-000 
2025-07-09 05:43:20.806511: BraTS-PED-00140-000, shape torch.Size([4, 56, 56, 56]), rank 0 
2025-07-09 05:43:20.839869: predicting BraTS-PED-00141-000 
2025-07-09 05:43:20.860245: BraTS-PED-00141-000, shape torch.Size([4, 102, 102, 102]), rank 0 
2025-07-09 05:43:21.045140: predicting BraTS-PED-00142-000 
2025-07-09 05:43:21.059525: BraTS-PED-00142-000, shape torch.Size([4, 85, 85, 85]), rank 0 
2025-07-09 05:43:21.246330: predicting BraTS-PED-00143-000 
2025-07-09 05:43:21.262049: BraTS-PED-00143-000, shape torch.Size([4, 90, 90, 90]), rank 0 
2025-07-09 05:43:21.445241: predicting BraTS-PED-00144-000 
2025-07-09 05:43:21.473511: BraTS-PED-00144-000, shape torch.Size([4, 114, 114, 114]), rank 0 
2025-07-09 05:43:21.659092: predicting BraTS-PED-00145-000 
2025-07-09 05:43:21.667353: BraTS-PED-00145-000, shape torch.Size([4, 71, 71, 71]), rank 0 
2025-07-09 05:43:21.700931: predicting BraTS-PED-00146-000 
2025-07-09 05:43:21.717185: BraTS-PED-00146-000, shape torch.Size([4, 94, 94, 94]), rank 0 
2025-07-09 05:43:21.901761: predicting BraTS-PED-00147-000 
2025-07-09 05:43:21.905987: BraTS-PED-00147-000, shape torch.Size([4, 55, 55, 55]), rank 0 
2025-07-09 05:43:21.941056: predicting BraTS-PED-00148-000 
2025-07-09 05:43:21.962321: BraTS-PED-00148-000, shape torch.Size([4, 103, 103, 103]), rank 0 
2025-07-09 05:43:22.147434: predicting BraTS-PED-00149-000 
2025-07-09 05:43:22.154454: BraTS-PED-00149-000, shape torch.Size([4, 67, 67, 67]), rank 0 
2025-07-09 05:43:22.188417: predicting BraTS-PED-00150-000 
2025-07-09 05:43:22.200553: BraTS-PED-00150-000, shape torch.Size([4, 82, 82, 82]), rank 0 
2025-07-09 05:43:22.383352: predicting BraTS-PED-00151-000 
2025-07-09 05:43:22.389861: BraTS-PED-00151-000, shape torch.Size([4, 66, 66, 66]), rank 0 
2025-07-09 05:43:22.423193: predicting BraTS-PED-00152-000 
2025-07-09 05:43:22.430685: BraTS-PED-00152-000, shape torch.Size([4, 70, 70, 70]), rank 0 
2025-07-09 05:43:22.463817: predicting BraTS-PED-00153-000 
2025-07-09 05:43:22.499768: BraTS-PED-00153-000, shape torch.Size([4, 121, 121, 121]), rank 0 
2025-07-09 05:43:23.096836: predicting BraTS-PED-00154-000 
2025-07-09 05:43:23.132799: BraTS-PED-00154-000, shape torch.Size([4, 124, 124, 124]), rank 0 
2025-07-09 05:43:23.730202: predicting BraTS-PED-00155-000 
2025-07-09 05:43:23.747373: BraTS-PED-00155-000, shape torch.Size([4, 91, 91, 91]), rank 0 
2025-07-09 05:43:23.932253: predicting BraTS-PED-00156-000 
2025-07-09 05:43:23.976123: BraTS-PED-00156-000, shape torch.Size([4, 130, 130, 126]), rank 0 
2025-07-09 05:43:24.574047: predicting BraTS-PED-00157-000 
2025-07-09 05:43:24.579410: BraTS-PED-00157-000, shape torch.Size([4, 57, 57, 57]), rank 0 
2025-07-09 05:43:24.611405: predicting BraTS-PED-00158-000 
2025-07-09 05:43:24.619810: BraTS-PED-00158-000, shape torch.Size([4, 69, 69, 69]), rank 0 
2025-07-09 05:43:24.653234: predicting BraTS-PED-00159-000 
2025-07-09 05:43:24.663320: BraTS-PED-00159-000, shape torch.Size([4, 78, 78, 78]), rank 0 
2025-07-09 05:43:24.698363: predicting BraTS-PED-00160-000 
2025-07-09 05:43:24.704062: BraTS-PED-00160-000, shape torch.Size([4, 59, 59, 59]), rank 0 
2025-07-09 05:43:24.738742: predicting BraTS-PED-00161-000 
2025-07-09 05:43:24.744365: BraTS-PED-00161-000, shape torch.Size([4, 62, 62, 62]), rank 0 
2025-07-09 05:43:24.778310: predicting BraTS-PED-00162-000 
2025-07-09 05:43:24.783525: BraTS-PED-00162-000, shape torch.Size([4, 61, 61, 61]), rank 0 
2025-07-09 05:43:24.816772: predicting BraTS-PED-00163-000 
2025-07-09 05:43:24.860947: BraTS-PED-00163-000, shape torch.Size([4, 135, 135, 128]), rank 0 
2025-07-09 05:43:25.459316: predicting BraTS-PED-00164-000 
2025-07-09 05:43:25.462377: BraTS-PED-00164-000, shape torch.Size([4, 48, 48, 48]), rank 0 
2025-07-09 05:43:25.494455: predicting BraTS-PED-00165-000 
2025-07-09 05:43:25.500584: BraTS-PED-00165-000, shape torch.Size([4, 63, 63, 63]), rank 0 
2025-07-09 05:43:25.533672: predicting BraTS-PED-00166-000 
2025-07-09 05:43:25.541651: BraTS-PED-00166-000, shape torch.Size([4, 69, 69, 69]), rank 0 
2025-07-09 05:43:25.574666: predicting BraTS-PED-00167-000 
2025-07-09 05:43:25.603161: BraTS-PED-00167-000, shape torch.Size([4, 116, 116, 116]), rank 0 
2025-07-09 05:43:25.789176: predicting BraTS-PED-00168-000 
2025-07-09 05:43:25.796753: BraTS-PED-00168-000, shape torch.Size([4, 70, 70, 70]), rank 0 
2025-07-09 05:43:25.830194: predicting BraTS-PED-00169-000 
2025-07-09 05:43:25.835205: BraTS-PED-00169-000, shape torch.Size([4, 64, 64, 64]), rank 0 
2025-07-09 05:43:25.869172: predicting BraTS-PED-00170-000 
2025-07-09 05:43:25.916950: BraTS-PED-00170-000, shape torch.Size([4, 129, 129, 129]), rank 0 
2025-07-09 05:43:26.515003: predicting BraTS-PED-00171-000 
2025-07-09 05:43:26.526624: BraTS-PED-00171-000, shape torch.Size([4, 81, 81, 81]), rank 0 
2025-07-09 05:43:26.711813: predicting BraTS-PED-00172-000 
2025-07-09 05:43:26.727073: BraTS-PED-00172-000, shape torch.Size([4, 93, 93, 93]), rank 0 
2025-07-09 05:43:26.912709: predicting BraTS-PED-00173-000 
2025-07-09 05:43:26.919784: BraTS-PED-00173-000, shape torch.Size([4, 65, 65, 65]), rank 0 
2025-07-09 05:43:26.953733: predicting BraTS-PED-00174-000 
2025-07-09 05:43:26.973923: BraTS-PED-00174-000, shape torch.Size([4, 104, 104, 104]), rank 0 
2025-07-09 05:43:27.157835: predicting BraTS-PED-00175-000 
2025-07-09 05:43:27.163113: BraTS-PED-00175-000, shape torch.Size([4, 64, 64, 64]), rank 0 
2025-07-09 05:43:27.196624: predicting BraTS-PED-00176-000 
2025-07-09 05:43:27.244006: BraTS-PED-00176-000, shape torch.Size([4, 134, 134, 124]), rank 0 
2025-07-09 05:43:27.841856: predicting BraTS-PED-00177-000 
2025-07-09 05:43:27.854442: BraTS-PED-00177-000, shape torch.Size([4, 82, 82, 82]), rank 0 
2025-07-09 05:43:28.039715: predicting BraTS-PED-00178-000 
2025-07-09 05:43:28.049401: BraTS-PED-00178-000, shape torch.Size([4, 78, 78, 78]), rank 0 
2025-07-09 05:43:28.082130: predicting BraTS-PED-00179-000 
2025-07-09 05:43:28.111485: BraTS-PED-00179-000, shape torch.Size([4, 115, 115, 115]), rank 0 
2025-07-09 05:43:28.296098: predicting BraTS-PED-00180-000 
2025-07-09 05:43:28.301288: BraTS-PED-00180-000, shape torch.Size([4, 57, 57, 57]), rank 0 
2025-07-09 05:43:28.332516: predicting BraTS-PED-00181-000 
2025-07-09 05:43:28.337703: BraTS-PED-00181-000, shape torch.Size([4, 58, 58, 58]), rank 0 
2025-07-09 05:43:28.371557: predicting BraTS-PED-00182-000 
2025-07-09 05:43:28.426368: BraTS-PED-00182-000, shape torch.Size([4, 144, 144, 144]), rank 0 
2025-07-09 05:43:29.027169: predicting BraTS-PED-00183-000 
2025-07-09 05:43:29.034709: BraTS-PED-00183-000, shape torch.Size([4, 72, 72, 72]), rank 0 
2025-07-09 05:43:29.068360: predicting BraTS-PED-00184-000 
2025-07-09 05:43:29.075280: BraTS-PED-00184-000, shape torch.Size([4, 67, 67, 67]), rank 0 
2025-07-09 05:43:29.108916: predicting BraTS-PED-00185-000 
2025-07-09 05:43:29.139351: BraTS-PED-00185-000, shape torch.Size([4, 117, 117, 117]), rank 0 
2025-07-09 05:43:29.325927: predicting BraTS-PED-00186-000 
2025-07-09 05:43:29.383709: BraTS-PED-00186-000, shape torch.Size([4, 141, 141, 141]), rank 0 
2025-07-09 05:43:29.983274: predicting BraTS-PED-00187-000 
2025-07-09 05:43:29.988753: BraTS-PED-00187-000, shape torch.Size([4, 60, 60, 60]), rank 0 
2025-07-09 05:43:30.021429: predicting BraTS-PED-00188-000 
2025-07-09 05:43:30.037158: BraTS-PED-00188-000, shape torch.Size([4, 92, 92, 92]), rank 0 
2025-07-09 05:43:30.220281: predicting BraTS-PED-00189-000 
2025-07-09 05:43:30.224028: BraTS-PED-00189-000, shape torch.Size([4, 52, 52, 52]), rank 0 
2025-07-09 05:43:30.256830: predicting BraTS-PED-00190-000 
2025-07-09 05:43:30.269835: BraTS-PED-00190-000, shape torch.Size([4, 83, 83, 83]), rank 0 
2025-07-09 05:43:30.452249: predicting BraTS-PED-00191-000 
2025-07-09 05:43:30.461946: BraTS-PED-00191-000, shape torch.Size([4, 73, 73, 73]), rank 0 
2025-07-09 05:43:30.495086: predicting BraTS-PED-00192-000 
2025-07-09 05:43:30.501646: BraTS-PED-00192-000, shape torch.Size([4, 68, 68, 68]), rank 0 
2025-07-09 05:43:30.535153: predicting BraTS-PED-00193-000 
2025-07-09 05:43:30.545169: BraTS-PED-00193-000, shape torch.Size([4, 75, 75, 75]), rank 0 
2025-07-09 05:43:30.578427: predicting BraTS-PED-00194-000 
2025-07-09 05:43:30.582085: BraTS-PED-00194-000, shape torch.Size([4, 49, 49, 49]), rank 0 
2025-07-09 05:43:30.614446: predicting BraTS-PED-00195-000 
2025-07-09 05:43:30.621710: BraTS-PED-00195-000, shape torch.Size([4, 66, 66, 66]), rank 0 
2025-07-09 05:43:30.653743: predicting BraTS-PED-00196-000 
2025-07-09 05:43:30.658013: BraTS-PED-00196-000, shape torch.Size([4, 55, 55, 55]), rank 0 
2025-07-09 05:43:30.691127: predicting BraTS-PED-00197-000 
2025-07-09 05:43:30.698444: BraTS-PED-00197-000, shape torch.Size([4, 69, 69, 69]), rank 0 
2025-07-09 05:43:30.732890: predicting BraTS-PED-00198-000 
2025-07-09 05:43:30.738424: BraTS-PED-00198-000, shape torch.Size([4, 61, 61, 61]), rank 0 
2025-07-09 05:43:30.771771: predicting BraTS-PED-00199-000 
2025-07-09 05:43:30.776983: BraTS-PED-00199-000, shape torch.Size([4, 59, 59, 59]), rank 0 
2025-07-09 05:43:30.810347: predicting BraTS-PED-00200-000 
2025-07-09 05:43:30.815876: BraTS-PED-00200-000, shape torch.Size([4, 63, 63, 63]), rank 0 
2025-07-09 05:43:30.849942: predicting BraTS-PED-00201-000 
2025-07-09 05:43:30.859217: BraTS-PED-00201-000, shape torch.Size([4, 73, 73, 73]), rank 0 
2025-07-09 05:43:30.892623: predicting BraTS-PED-00202-000 
2025-07-09 05:43:30.898213: BraTS-PED-00202-000, shape torch.Size([4, 63, 63, 63]), rank 0 
2025-07-09 05:43:30.930663: predicting BraTS-PED-00203-000 
2025-07-09 05:43:30.941075: BraTS-PED-00203-000, shape torch.Size([4, 79, 79, 79]), rank 0 
2025-07-09 05:43:30.974096: predicting BraTS-PED-00204-000 
2025-07-09 05:43:30.977080: BraTS-PED-00204-000, shape torch.Size([4, 48, 48, 48]), rank 0 
2025-07-09 05:43:31.011879: predicting BraTS-PED-00205-000 
2025-07-09 05:43:31.019627: BraTS-PED-00205-000, shape torch.Size([4, 66, 66, 66]), rank 0 
2025-07-09 05:43:31.051930: predicting BraTS-PED-00206-000 
2025-07-09 05:43:31.057034: BraTS-PED-00206-000, shape torch.Size([4, 58, 58, 58]), rank 0 
2025-07-09 05:43:31.090523: predicting BraTS-PED-00207-000 
2025-07-09 05:43:31.100165: BraTS-PED-00207-000, shape torch.Size([4, 74, 74, 74]), rank 0 
2025-07-09 05:43:31.133556: predicting BraTS-PED-00208-000 
2025-07-09 05:43:31.138814: BraTS-PED-00208-000, shape torch.Size([4, 61, 61, 61]), rank 0 
2025-07-09 05:43:31.172229: predicting BraTS-PED-00209-000 
2025-07-09 05:43:31.179363: BraTS-PED-00209-000, shape torch.Size([4, 66, 66, 66]), rank 0 
2025-07-09 05:43:31.214892: predicting BraTS-PED-00210-000 
2025-07-09 05:43:31.221215: BraTS-PED-00210-000, shape torch.Size([4, 65, 65, 65]), rank 0 
2025-07-09 05:43:31.254656: predicting BraTS-PED-00211-000 
2025-07-09 05:43:31.320898: BraTS-PED-00211-000, shape torch.Size([4, 153, 153, 153]), rank 0 
2025-07-09 05:43:31.923312: predicting BraTS-PED-00212-000 
2025-07-09 05:43:31.933218: BraTS-PED-00212-000, shape torch.Size([4, 73, 73, 73]), rank 0 
2025-07-09 05:43:31.967328: predicting BraTS-PED-00213-000 
2025-07-09 05:43:31.974979: BraTS-PED-00213-000, shape torch.Size([4, 68, 68, 68]), rank 0 
2025-07-09 05:43:32.007319: predicting BraTS-PED-00214-000 
2025-07-09 05:43:32.015993: BraTS-PED-00214-000, shape torch.Size([4, 68, 68, 68]), rank 0 
2025-07-09 05:43:32.049630: predicting BraTS-PED-00215-000 
2025-07-09 05:43:32.057086: BraTS-PED-00215-000, shape torch.Size([4, 70, 70, 70]), rank 0 
2025-07-09 05:43:32.089442: predicting BraTS-PED-00216-000 
2025-07-09 05:43:32.098510: BraTS-PED-00216-000, shape torch.Size([4, 69, 69, 69]), rank 0 
2025-07-09 05:43:32.131625: predicting BraTS-PED-00217-000 
2025-07-09 05:43:32.139823: BraTS-PED-00217-000, shape torch.Size([4, 69, 69, 69]), rank 0 
2025-07-09 05:43:32.172949: predicting BraTS-PED-00218-000 
2025-07-09 05:43:32.176030: BraTS-PED-00218-000, shape torch.Size([4, 48, 48, 48]), rank 0 
2025-07-09 05:43:32.208114: predicting BraTS-PED-00219-000 
2025-07-09 05:43:32.213369: BraTS-PED-00219-000, shape torch.Size([4, 59, 59, 59]), rank 0 
2025-07-09 05:43:32.246779: predicting BraTS-PED-00220-000 
2025-07-09 05:43:32.250925: BraTS-PED-00220-000, shape torch.Size([4, 56, 56, 56]), rank 0 
2025-07-09 05:43:32.283587: predicting BraTS-PED-00221-000 
2025-07-09 05:43:32.291175: BraTS-PED-00221-000, shape torch.Size([4, 65, 65, 65]), rank 0 
2025-07-09 05:43:32.323536: predicting BraTS-PED-00222-000 
2025-07-09 05:43:32.330327: BraTS-PED-00222-000, shape torch.Size([4, 68, 68, 68]), rank 0 
2025-07-09 05:43:32.363930: predicting BraTS-PED-00223-000 
2025-07-09 05:43:32.367944: BraTS-PED-00223-000, shape torch.Size([4, 50, 50, 50]), rank 0 
2025-07-09 05:43:32.401360: predicting BraTS-PED-00224-000 
2025-07-09 05:43:32.428429: BraTS-PED-00224-000, shape torch.Size([4, 107, 107, 107]), rank 0 
2025-07-09 05:43:32.612973: predicting BraTS-PED-00225-000 
2025-07-09 05:43:32.616513: BraTS-PED-00225-000, shape torch.Size([4, 49, 49, 49]), rank 0 
2025-07-09 05:43:32.651373: predicting BraTS-PED-00226-000 
2025-07-09 05:43:32.657835: BraTS-PED-00226-000, shape torch.Size([4, 63, 63, 63]), rank 0 
2025-07-09 05:43:32.690126: predicting BraTS-PED-00227-000 
2025-07-09 05:43:32.694994: BraTS-PED-00227-000, shape torch.Size([4, 57, 57, 57]), rank 0 
2025-07-09 05:43:32.727827: predicting BraTS-PED-00228-000 
2025-07-09 05:43:32.735379: BraTS-PED-00228-000, shape torch.Size([4, 65, 65, 65]), rank 0 
2025-07-09 05:43:32.767953: predicting BraTS-PED-00229-000 
2025-07-09 05:43:32.773166: BraTS-PED-00229-000, shape torch.Size([4, 60, 60, 60]), rank 0 
2025-07-09 05:43:32.806195: predicting BraTS-PED-00230-000 
2025-07-09 05:43:32.815557: BraTS-PED-00230-000, shape torch.Size([4, 74, 74, 74]), rank 0 
2025-07-09 05:43:32.848590: predicting BraTS-PED-00231-000 
2025-07-09 05:43:32.856442: BraTS-PED-00231-000, shape torch.Size([4, 70, 70, 70]), rank 0 
2025-07-09 05:43:32.889600: predicting BraTS-PED-00232-000 
2025-07-09 05:43:32.899659: BraTS-PED-00232-000, shape torch.Size([4, 74, 74, 74]), rank 0 
2025-07-09 05:43:32.933473: predicting BraTS-PED-00233-000 
2025-07-09 05:43:32.940151: BraTS-PED-00233-000, shape torch.Size([4, 65, 65, 65]), rank 0 
2025-07-09 05:43:32.973006: predicting BraTS-PED-00234-000 
2025-07-09 05:43:32.982328: BraTS-PED-00234-000, shape torch.Size([4, 73, 73, 73]), rank 0 
2025-07-09 05:43:33.017194: predicting BraTS-PED-00235-000 
2025-07-09 05:43:33.027847: BraTS-PED-00235-000, shape torch.Size([4, 76, 76, 76]), rank 0 
2025-07-09 05:43:33.061426: predicting BraTS-PED-00236-000 
2025-07-09 05:43:33.110814: BraTS-PED-00236-000, shape torch.Size([4, 135, 135, 135]), rank 0 
2025-07-09 05:43:33.709303: predicting BraTS-PED-00237-000 
2025-07-09 05:43:33.717258: BraTS-PED-00237-000, shape torch.Size([4, 67, 67, 67]), rank 0 
2025-07-09 05:43:33.750829: predicting BraTS-PED-00238-000 
2025-07-09 05:43:33.756217: BraTS-PED-00238-000, shape torch.Size([4, 63, 63, 63]), rank 0 
2025-07-09 05:43:33.790154: predicting BraTS-PED-00239-000 
2025-07-09 05:43:33.800369: BraTS-PED-00239-000, shape torch.Size([4, 79, 79, 79]), rank 0 
2025-07-09 05:43:33.833681: predicting BraTS-PED-00240-000 
2025-07-09 05:43:33.842400: BraTS-PED-00240-000, shape torch.Size([4, 73, 73, 73]), rank 0 
2025-07-09 05:43:33.875096: predicting BraTS-PED-00241-000 
2025-07-09 05:43:33.882799: BraTS-PED-00241-000, shape torch.Size([4, 70, 70, 70]), rank 0 
2025-07-09 05:43:33.919120: predicting BraTS-PED-00242-000 
2025-07-09 05:43:33.924502: BraTS-PED-00242-000, shape torch.Size([4, 60, 60, 60]), rank 0 
2025-07-09 05:43:33.957453: predicting BraTS-PED-00243-000 
2025-07-09 05:43:33.966885: BraTS-PED-00243-000, shape torch.Size([4, 73, 73, 73]), rank 0 
2025-07-09 05:43:34.000327: predicting BraTS-PED-00244-000 
2025-07-09 05:43:34.008090: BraTS-PED-00244-000, shape torch.Size([4, 71, 71, 71]), rank 0 
2025-07-09 05:43:34.043533: predicting BraTS-PED-00245-000 
2025-07-09 05:43:34.051346: BraTS-PED-00245-000, shape torch.Size([4, 68, 68, 68]), rank 0 
2025-07-09 05:43:34.084510: predicting BraTS-PED-00246-000 
2025-07-09 05:43:34.091770: BraTS-PED-00246-000, shape torch.Size([4, 72, 72, 72]), rank 0 
2025-07-09 05:43:34.127253: predicting BraTS-PED-00247-000 
2025-07-09 05:43:34.129779: BraTS-PED-00247-000, shape torch.Size([4, 48, 48, 48]), rank 0 
2025-07-09 05:43:34.162618: predicting BraTS-PED-00248-000 
2025-07-09 05:43:34.167726: BraTS-PED-00248-000, shape torch.Size([4, 58, 58, 58]), rank 0 
2025-07-09 05:43:34.199726: predicting BraTS-PED-00249-000 
2025-07-09 05:43:34.207515: BraTS-PED-00249-000, shape torch.Size([4, 69, 69, 69]), rank 0 
2025-07-09 05:43:34.240484: predicting BraTS-PED-00250-000 
2025-07-09 05:43:34.247998: BraTS-PED-00250-000, shape torch.Size([4, 71, 71, 71]), rank 0 
2025-07-09 05:43:34.281182: predicting BraTS-PED-00251-000 
2025-07-09 05:43:34.286083: BraTS-PED-00251-000, shape torch.Size([4, 59, 59, 59]), rank 0 
2025-07-09 05:43:34.319130: predicting BraTS-PED-00252-000 
2025-07-09 05:43:34.326799: BraTS-PED-00252-000, shape torch.Size([4, 67, 67, 67]), rank 0 
2025-07-09 05:43:34.359550: predicting BraTS-PED-00253-000 
2025-07-09 05:43:34.364433: BraTS-PED-00253-000, shape torch.Size([4, 58, 58, 58]), rank 0 
2025-07-09 05:43:34.397399: predicting BraTS-PED-00254-000 
2025-07-09 05:43:34.404957: BraTS-PED-00254-000, shape torch.Size([4, 66, 66, 66]), rank 0 
2025-07-09 05:43:34.437865: predicting BraTS-PED-00255-000 
2025-07-09 05:43:34.453415: BraTS-PED-00255-000, shape torch.Size([4, 93, 93, 93]), rank 0 
2025-07-09 05:43:34.638703: predicting BraTS-PED-00256-000 
2025-07-09 05:43:34.647463: BraTS-PED-00256-000, shape torch.Size([4, 73, 73, 73]), rank 0 
2025-07-09 05:43:34.681478: predicting BraTS-PED-00257-000 
2025-07-09 05:43:34.686381: BraTS-PED-00257-000, shape torch.Size([4, 58, 58, 58]), rank 0 
2025-07-09 05:43:34.719221: predicting BraTS-PED-00258-000 
2025-07-09 05:43:34.727250: BraTS-PED-00258-000, shape torch.Size([4, 68, 68, 68]), rank 0 
2025-07-09 05:43:34.760816: predicting BraTS-PED-00259-000 
2025-07-09 05:43:34.764951: BraTS-PED-00259-000, shape torch.Size([4, 53, 53, 53]), rank 0 
2025-07-09 05:43:34.797852: predicting BraTS-PED-00260-000 
2025-07-09 05:43:34.803054: BraTS-PED-00260-000, shape torch.Size([4, 64, 64, 64]), rank 0 
2025-07-09 05:43:34.837665: predicting BraTS-PED-00261-000 
2025-07-09 05:43:34.846836: BraTS-PED-00261-000, shape torch.Size([4, 80, 80, 80]), rank 0 
2025-07-09 05:43:34.878385: predicting BraTS-PED-00262-000 
2025-07-09 05:43:34.885700: BraTS-PED-00262-000, shape torch.Size([4, 66, 66, 66]), rank 0 
2025-07-09 05:43:34.919052: predicting BraTS-PED-00263-000 
2025-07-09 05:43:34.928852: BraTS-PED-00263-000, shape torch.Size([4, 75, 75, 75]), rank 0 
2025-07-09 05:43:34.964175: predicting BraTS-PED-00264-000 
2025-07-09 05:43:34.969700: BraTS-PED-00264-000, shape torch.Size([4, 60, 60, 60]), rank 0 
2025-07-09 05:43:35.003630: predicting BraTS-PED-00265-000 
2025-07-09 05:43:35.007722: BraTS-PED-00265-000, shape torch.Size([4, 52, 52, 52]), rank 0 
2025-07-09 05:43:35.040125: predicting BraTS-PED-00266-000 
2025-07-09 05:43:35.047843: BraTS-PED-00266-000, shape torch.Size([4, 67, 67, 67]), rank 0 
2025-07-09 05:43:39.799527: Validation complete 
2025-07-09 05:43:39.799629: Mean Validation Dice:  0.7763339536510038 
