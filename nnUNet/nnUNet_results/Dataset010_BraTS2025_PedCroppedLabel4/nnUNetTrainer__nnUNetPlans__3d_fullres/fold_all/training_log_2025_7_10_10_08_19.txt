
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-07-10 10:08:19.733915: Using torch.compile... 
2025-07-10 10:08:21.108340: do_dummy_2d_data_aug: False 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 10, 'patch_size': [80, 80, 80], 'median_image_size_in_voxels': [73.0, 73.0, 73.0], 'spacing': [1.0, 1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization'], 'use_mask_for_norm': [False, False, False, False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 5, 'features_per_stage': [32, 64, 128, 256, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': False} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset010_BraTS2025_PedCroppedLabel4', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.0, 1.0, 1.0], 'original_median_shape_after_transp': [73, 73, 73], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 3569.61669921875, 'mean': 619.3331120851244, 'median': 419.62530517578125, 'min': 17.466230392456055, 'percentile_00_5': 77.24881744384766, 'percentile_99_5': 2854.41796875, 'std': 563.3833093020837}, '1': {'max': 12613.16015625, 'mean': 626.9736099822362, 'median': 364.6273193359375, 'min': 3.115943193435669, 'percentile_00_5': 30.64278793334961, 'percentile_99_5': 5344.75, 'std': 786.260330638529}, '2': {'max': 8601.6396484375, 'mean': 856.2387700915908, 'median': 654.79052734375, 'min': 0.5377194881439209, 'percentile_00_5': 61.33531951904297, 'percentile_99_5': 4792.1044921875, 'std': 758.5235901574508}, '3': {'max': 6537.60888671875, 'mean': 689.9587453587959, 'median': 505.0686340332031, 'min': 24.994007110595703, 'percentile_00_5': 105.51646423339844, 'percentile_99_5': 5367.23779296875, 'std': 710.5124549643075}}} 
 
2025-07-10 10:08:25.642802: Unable to plot network architecture: nnUNet_compile is enabled! 
2025-07-10 10:08:25.661822:  
2025-07-10 10:08:25.662435: Epoch 0 
2025-07-10 10:08:25.663029: Current learning rate: 0.01 
2025-07-10 10:09:19.641105: train_loss 0.0493 
2025-07-10 10:09:19.641370: val_loss 0.0171 
2025-07-10 10:09:19.641569: Pseudo dice [np.float32(0.0)] 
2025-07-10 10:09:19.641665: Epoch time: 53.98 s 
2025-07-10 10:09:19.641740: Yayy! New best EMA pseudo Dice: 0.0 
2025-07-10 10:09:21.034874:  
2025-07-10 10:09:21.035269: Epoch 1 
2025-07-10 10:09:21.035437: Current learning rate: 0.00999 
2025-07-10 10:10:07.302405: train_loss 0.0072 
2025-07-10 10:10:07.302821: val_loss -0.0097 
2025-07-10 10:10:07.302896: Pseudo dice [np.float32(0.186)] 
2025-07-10 10:10:07.302997: Epoch time: 46.27 s 
2025-07-10 10:10:07.303070: Yayy! New best EMA pseudo Dice: 0.01860000006854534 
2025-07-10 10:10:09.378078:  
2025-07-10 10:10:09.378348: Epoch 2 
2025-07-10 10:10:09.378550: Current learning rate: 0.00998 
2025-07-10 10:10:56.505090: train_loss -0.0133 
2025-07-10 10:10:56.505371: val_loss -0.0125 
2025-07-10 10:10:56.505445: Pseudo dice [np.float32(0.369)] 
2025-07-10 10:10:56.505547: Epoch time: 47.13 s 
2025-07-10 10:10:56.505620: Yayy! New best EMA pseudo Dice: 0.053599998354911804 
2025-07-10 10:10:58.505880:  
2025-07-10 10:10:58.506126: Epoch 3 
2025-07-10 10:10:58.506253: Current learning rate: 0.00997 
2025-07-10 10:11:45.177596: train_loss -0.0202 
2025-07-10 10:11:45.177955: val_loss -0.0291 
2025-07-10 10:11:45.178073: Pseudo dice [np.float32(0.3618)] 
2025-07-10 10:11:45.178164: Epoch time: 46.67 s 
2025-07-10 10:11:45.178233: Yayy! New best EMA pseudo Dice: 0.0843999981880188 
2025-07-10 10:11:47.179817:  
2025-07-10 10:11:47.180089: Epoch 4 
2025-07-10 10:11:47.180183: Current learning rate: 0.00996 
2025-07-10 10:12:33.400640: train_loss -0.0252 
2025-07-10 10:12:33.401066: val_loss -0.0276 
2025-07-10 10:12:33.401141: Pseudo dice [np.float32(0.4638)] 
2025-07-10 10:12:33.401238: Epoch time: 46.22 s 
2025-07-10 10:12:33.401313: Yayy! New best EMA pseudo Dice: 0.12240000069141388 
2025-07-10 10:12:35.512610:  
2025-07-10 10:12:35.512845: Epoch 5 
2025-07-10 10:12:35.513022: Current learning rate: 0.00995 
2025-07-10 10:13:21.653330: train_loss -0.0233 
2025-07-10 10:13:21.653818: val_loss -0.0276 
2025-07-10 10:13:21.653906: Pseudo dice [np.float32(0.3749)] 
2025-07-10 10:13:21.654016: Epoch time: 46.14 s 
2025-07-10 10:13:21.654099: Yayy! New best EMA pseudo Dice: 0.147599995136261 
2025-07-10 10:13:23.708927:  
2025-07-10 10:13:23.709215: Epoch 6 
2025-07-10 10:13:23.709346: Current learning rate: 0.00995 
2025-07-10 10:14:10.442321: train_loss -0.032 
2025-07-10 10:14:10.442691: val_loss -0.033 
2025-07-10 10:14:10.442769: Pseudo dice [np.float32(0.4127)] 
2025-07-10 10:14:10.442870: Epoch time: 46.73 s 
2025-07-10 10:14:10.442943: Yayy! New best EMA pseudo Dice: 0.17409999668598175 
2025-07-10 10:14:12.503179:  
2025-07-10 10:14:12.503428: Epoch 7 
2025-07-10 10:14:12.503606: Current learning rate: 0.00994 
2025-07-10 10:14:59.892125: train_loss -0.0464 
2025-07-10 10:14:59.892374: val_loss -0.0601 
2025-07-10 10:14:59.892498: Pseudo dice [np.float32(0.4819)] 
2025-07-10 10:14:59.892654: Epoch time: 47.39 s 
2025-07-10 10:14:59.892726: Yayy! New best EMA pseudo Dice: 0.20489999651908875 
2025-07-10 10:15:02.151084:  
2025-07-10 10:15:02.151192: Epoch 8 
2025-07-10 10:15:02.151281: Current learning rate: 0.00993 
2025-07-10 10:15:48.265131: train_loss -0.0371 
2025-07-10 10:15:48.265734: val_loss -0.0534 
2025-07-10 10:15:48.265829: Pseudo dice [np.float32(0.4868)] 
2025-07-10 10:15:48.265950: Epoch time: 46.11 s 
2025-07-10 10:15:48.266047: Yayy! New best EMA pseudo Dice: 0.23309999704360962 
2025-07-10 10:15:50.307015:  
2025-07-10 10:15:50.307324: Epoch 9 
2025-07-10 10:15:50.307579: Current learning rate: 0.00992 
2025-07-10 10:16:36.629096: train_loss -0.0546 
2025-07-10 10:16:36.629608: val_loss -0.0543 
2025-07-10 10:16:36.629886: Pseudo dice [np.float32(0.5184)] 
2025-07-10 10:16:36.629990: Epoch time: 46.32 s 
2025-07-10 10:16:36.630068: Yayy! New best EMA pseudo Dice: 0.26159998774528503 
2025-07-10 10:16:38.628921:  
2025-07-10 10:16:38.629462: Epoch 10 
2025-07-10 10:16:38.629652: Current learning rate: 0.00991 
2025-07-10 10:17:24.313241: train_loss -0.0512 
2025-07-10 10:17:24.313626: val_loss -0.0517 
2025-07-10 10:17:24.313700: Pseudo dice [np.float32(0.5272)] 
2025-07-10 10:17:24.313925: Epoch time: 45.69 s 
2025-07-10 10:17:24.314052: Yayy! New best EMA pseudo Dice: 0.2881999909877777 
2025-07-10 10:17:26.390440:  
2025-07-10 10:17:26.390641: Epoch 11 
2025-07-10 10:17:26.390785: Current learning rate: 0.0099 
2025-07-10 10:18:11.959750: train_loss -0.0556 
2025-07-10 10:18:11.960379: val_loss -0.0657 
2025-07-10 10:18:11.960468: Pseudo dice [np.float32(0.537)] 
2025-07-10 10:18:11.960613: Epoch time: 45.57 s 
2025-07-10 10:18:11.960705: Yayy! New best EMA pseudo Dice: 0.31310001015663147 
2025-07-10 10:18:14.536839:  
2025-07-10 10:18:14.537213: Epoch 12 
2025-07-10 10:18:14.537344: Current learning rate: 0.00989 
2025-07-10 10:19:00.780557: train_loss -0.0695 
2025-07-10 10:19:00.781079: val_loss -0.058 
2025-07-10 10:19:00.781162: Pseudo dice [np.float32(0.5877)] 
2025-07-10 10:19:00.781270: Epoch time: 46.24 s 
2025-07-10 10:19:00.781350: Yayy! New best EMA pseudo Dice: 0.34049999713897705 
2025-07-10 10:19:02.833662:  
2025-07-10 10:19:02.834196: Epoch 13 
2025-07-10 10:19:02.834454: Current learning rate: 0.00988 
2025-07-10 10:19:48.712675: train_loss -0.0573 
2025-07-10 10:19:48.713154: val_loss -0.0834 
2025-07-10 10:19:48.713237: Pseudo dice [np.float32(0.5961)] 
2025-07-10 10:19:48.713338: Epoch time: 45.88 s 
2025-07-10 10:19:48.713413: Yayy! New best EMA pseudo Dice: 0.366100013256073 
2025-07-10 10:19:50.876153:  
2025-07-10 10:19:50.876630: Epoch 14 
2025-07-10 10:19:50.876755: Current learning rate: 0.00987 
2025-07-10 10:20:36.125597: train_loss -0.0707 
2025-07-10 10:20:36.126030: val_loss -0.0599 
2025-07-10 10:20:36.126119: Pseudo dice [np.float32(0.5657)] 
2025-07-10 10:20:36.126222: Epoch time: 45.25 s 
2025-07-10 10:20:36.126309: Yayy! New best EMA pseudo Dice: 0.38609999418258667 
2025-07-10 10:20:38.239497:  
2025-07-10 10:20:38.239876: Epoch 15 
2025-07-10 10:20:38.240006: Current learning rate: 0.00986 
2025-07-10 10:21:23.915739: train_loss -0.0708 
2025-07-10 10:21:23.916294: val_loss -0.0746 
2025-07-10 10:21:23.916371: Pseudo dice [np.float32(0.5305)] 
2025-07-10 10:21:23.916471: Epoch time: 45.68 s 
2025-07-10 10:21:23.916560: Yayy! New best EMA pseudo Dice: 0.40049999952316284 
2025-07-10 10:21:25.983739:  
2025-07-10 10:21:25.984110: Epoch 16 
2025-07-10 10:21:25.984222: Current learning rate: 0.00986 
2025-07-10 10:22:11.156761: train_loss -0.0744 
2025-07-10 10:22:11.157159: val_loss -0.0847 
2025-07-10 10:22:11.157258: Pseudo dice [np.float32(0.669)] 
2025-07-10 10:22:11.157356: Epoch time: 45.17 s 
2025-07-10 10:22:11.157461: Yayy! New best EMA pseudo Dice: 0.42739999294281006 
2025-07-10 10:22:13.151318:  
2025-07-10 10:22:13.151764: Epoch 17 
2025-07-10 10:22:13.151903: Current learning rate: 0.00985 
2025-07-10 10:22:59.062439: train_loss -0.0707 
2025-07-10 10:22:59.062765: val_loss -0.0915 
2025-07-10 10:22:59.062864: Pseudo dice [np.float32(0.6867)] 
2025-07-10 10:22:59.063048: Epoch time: 45.91 s 
2025-07-10 10:22:59.063173: Yayy! New best EMA pseudo Dice: 0.45329999923706055 
2025-07-10 10:23:01.189056:  
2025-07-10 10:23:01.189283: Epoch 18 
2025-07-10 10:23:01.189443: Current learning rate: 0.00984 
2025-07-10 10:23:46.670032: train_loss -0.0891 
2025-07-10 10:23:46.670455: val_loss -0.076 
2025-07-10 10:23:46.670550: Pseudo dice [np.float32(0.6749)] 
2025-07-10 10:23:46.670658: Epoch time: 45.48 s 
2025-07-10 10:23:46.670794: Yayy! New best EMA pseudo Dice: 0.47540000081062317 
2025-07-10 10:23:48.808762:  
2025-07-10 10:23:48.809157: Epoch 19 
2025-07-10 10:23:48.809299: Current learning rate: 0.00983 
2025-07-10 10:24:34.581211: train_loss -0.0793 
2025-07-10 10:24:34.581536: val_loss -0.076 
2025-07-10 10:24:34.581630: Pseudo dice [np.float32(0.6093)] 
2025-07-10 10:24:34.581722: Epoch time: 45.77 s 
2025-07-10 10:24:34.581799: Yayy! New best EMA pseudo Dice: 0.4887999892234802 
2025-07-10 10:24:36.768955:  
2025-07-10 10:24:36.769311: Epoch 20 
2025-07-10 10:24:36.769448: Current learning rate: 0.00982 
2025-07-10 10:25:22.842813: train_loss -0.0806 
2025-07-10 10:25:22.843134: val_loss -0.0541 
2025-07-10 10:25:22.843210: Pseudo dice [np.float32(0.56)] 
2025-07-10 10:25:22.843469: Epoch time: 46.07 s 
2025-07-10 10:25:22.843567: Yayy! New best EMA pseudo Dice: 0.4959000051021576 
2025-07-10 10:25:24.829380:  
2025-07-10 10:25:24.829534: Epoch 21 
2025-07-10 10:25:24.829668: Current learning rate: 0.00981 
2025-07-10 10:26:10.055515: train_loss -0.0846 
2025-07-10 10:26:10.055888: val_loss -0.1018 
2025-07-10 10:26:10.055965: Pseudo dice [np.float32(0.7039)] 
2025-07-10 10:26:10.056082: Epoch time: 45.23 s 
2025-07-10 10:26:10.056160: Yayy! New best EMA pseudo Dice: 0.516700029373169 
2025-07-10 10:26:12.702179:  
2025-07-10 10:26:12.702384: Epoch 22 
2025-07-10 10:26:12.702504: Current learning rate: 0.0098 
2025-07-10 10:26:58.345553: train_loss -0.0927 
2025-07-10 10:26:58.346115: val_loss -0.0837 
2025-07-10 10:26:58.346276: Pseudo dice [np.float32(0.6992)] 
2025-07-10 10:26:58.346581: Epoch time: 45.64 s 
2025-07-10 10:26:58.346764: Yayy! New best EMA pseudo Dice: 0.5350000262260437 
2025-07-10 10:27:00.347505:  
2025-07-10 10:27:00.347851: Epoch 23 
2025-07-10 10:27:00.348052: Current learning rate: 0.00979 
2025-07-10 10:27:45.978971: train_loss -0.0871 
2025-07-10 10:27:45.979480: val_loss -0.0861 
2025-07-10 10:27:45.979650: Pseudo dice [np.float32(0.6057)] 
2025-07-10 10:27:45.979771: Epoch time: 45.63 s 
2025-07-10 10:27:45.979852: Yayy! New best EMA pseudo Dice: 0.5421000123023987 
2025-07-10 10:27:48.097169:  
2025-07-10 10:27:48.097663: Epoch 24 
2025-07-10 10:27:48.097848: Current learning rate: 0.00978 
2025-07-10 10:28:34.041344: train_loss -0.0912 
2025-07-10 10:28:34.041807: val_loss -0.0902 
2025-07-10 10:28:34.041926: Pseudo dice [np.float32(0.6871)] 
2025-07-10 10:28:34.042031: Epoch time: 45.95 s 
2025-07-10 10:28:34.042110: Yayy! New best EMA pseudo Dice: 0.5565999746322632 
2025-07-10 10:28:36.046579:  
2025-07-10 10:28:36.047070: Epoch 25 
2025-07-10 10:28:36.047295: Current learning rate: 0.00977 
2025-07-10 10:29:21.324749: train_loss -0.0925 
2025-07-10 10:29:21.325249: val_loss -0.1033 
2025-07-10 10:29:21.325334: Pseudo dice [np.float32(0.6967)] 
2025-07-10 10:29:21.325453: Epoch time: 45.28 s 
2025-07-10 10:29:21.325567: Yayy! New best EMA pseudo Dice: 0.5705999732017517 
2025-07-10 10:29:23.349747:  
2025-07-10 10:29:23.350096: Epoch 26 
2025-07-10 10:29:23.350199: Current learning rate: 0.00977 
2025-07-10 10:30:08.592950: train_loss -0.0858 
2025-07-10 10:30:08.593675: val_loss -0.0906 
2025-07-10 10:30:08.593789: Pseudo dice [np.float32(0.7152)] 
2025-07-10 10:30:08.593910: Epoch time: 45.24 s 
2025-07-10 10:30:08.593990: Yayy! New best EMA pseudo Dice: 0.5849999785423279 
2025-07-10 10:30:10.729529:  
2025-07-10 10:30:10.729769: Epoch 27 
2025-07-10 10:30:10.729973: Current learning rate: 0.00976 
2025-07-10 10:30:56.376989: train_loss -0.0952 
2025-07-10 10:30:56.377489: val_loss -0.0963 
2025-07-10 10:30:56.377595: Pseudo dice [np.float32(0.7371)] 
2025-07-10 10:30:56.377699: Epoch time: 45.65 s 
2025-07-10 10:30:56.377775: Yayy! New best EMA pseudo Dice: 0.6001999974250793 
2025-07-10 10:30:58.306185:  
2025-07-10 10:30:58.306314: Epoch 28 
2025-07-10 10:30:58.306410: Current learning rate: 0.00975 
2025-07-10 10:31:43.722083: train_loss -0.0934 
2025-07-10 10:31:43.722501: val_loss -0.111 
2025-07-10 10:31:43.722595: Pseudo dice [np.float32(0.7596)] 
2025-07-10 10:31:43.722688: Epoch time: 45.42 s 
2025-07-10 10:31:43.722778: Yayy! New best EMA pseudo Dice: 0.6161999702453613 
2025-07-10 10:31:45.629003:  
2025-07-10 10:31:45.629284: Epoch 29 
2025-07-10 10:31:45.629451: Current learning rate: 0.00974 
2025-07-10 10:32:31.536249: train_loss -0.1123 
2025-07-10 10:32:31.536695: val_loss -0.1052 
2025-07-10 10:32:31.536774: Pseudo dice [np.float32(0.7443)] 
2025-07-10 10:32:31.536873: Epoch time: 45.91 s 
2025-07-10 10:32:31.536949: Yayy! New best EMA pseudo Dice: 0.6290000081062317 
2025-07-10 10:32:33.631573:  
2025-07-10 10:32:33.631755: Epoch 30 
2025-07-10 10:32:33.631917: Current learning rate: 0.00973 
2025-07-10 10:33:19.715969: train_loss -0.1028 
2025-07-10 10:33:19.716325: val_loss -0.106 
2025-07-10 10:33:19.716446: Pseudo dice [np.float32(0.7261)] 
2025-07-10 10:33:19.716547: Epoch time: 46.09 s 
2025-07-10 10:33:19.716618: Yayy! New best EMA pseudo Dice: 0.638700008392334 
2025-07-10 10:33:21.766419:  
2025-07-10 10:33:21.766614: Epoch 31 
2025-07-10 10:33:21.766951: Current learning rate: 0.00972 
2025-07-10 10:34:07.998739: train_loss -0.0961 
2025-07-10 10:34:08.000749: val_loss -0.1007 
2025-07-10 10:34:08.002173: Pseudo dice [np.float32(0.7454)] 
2025-07-10 10:34:08.002419: Epoch time: 46.23 s 
2025-07-10 10:34:08.002628: Yayy! New best EMA pseudo Dice: 0.649399995803833 
2025-07-10 10:34:10.125806:  
2025-07-10 10:34:10.126071: Epoch 32 
2025-07-10 10:34:10.126198: Current learning rate: 0.00971 
2025-07-10 10:34:56.066957: train_loss -0.0919 
2025-07-10 10:34:56.067241: val_loss -0.112 
2025-07-10 10:34:56.067315: Pseudo dice [np.float32(0.7607)] 
2025-07-10 10:34:56.067408: Epoch time: 45.94 s 
2025-07-10 10:34:56.067479: Yayy! New best EMA pseudo Dice: 0.6604999899864197 
2025-07-10 10:34:58.433103:  
2025-07-10 10:34:58.433491: Epoch 33 
2025-07-10 10:34:58.433745: Current learning rate: 0.0097 
2025-07-10 10:35:44.551318: train_loss -0.1063 
2025-07-10 10:35:44.551772: val_loss -0.0951 
2025-07-10 10:35:44.551849: Pseudo dice [np.float32(0.7526)] 
2025-07-10 10:35:44.551952: Epoch time: 46.12 s 
2025-07-10 10:35:44.552025: Yayy! New best EMA pseudo Dice: 0.669700026512146 
2025-07-10 10:35:46.679203:  
2025-07-10 10:35:46.679684: Epoch 34 
2025-07-10 10:35:46.679813: Current learning rate: 0.00969 
2025-07-10 10:36:32.276376: train_loss -0.1077 
2025-07-10 10:36:32.276788: val_loss -0.1106 
2025-07-10 10:36:32.276944: Pseudo dice [np.float32(0.7855)] 
2025-07-10 10:36:32.277084: Epoch time: 45.6 s 
2025-07-10 10:36:32.277225: Yayy! New best EMA pseudo Dice: 0.6812999844551086 
2025-07-10 10:36:34.270774:  
2025-07-10 10:36:34.271121: Epoch 35 
2025-07-10 10:36:34.271343: Current learning rate: 0.00968 
2025-07-10 10:37:20.496232: train_loss -0.0988 
2025-07-10 10:37:20.496820: val_loss -0.1125 
2025-07-10 10:37:20.496935: Pseudo dice [np.float32(0.741)] 
2025-07-10 10:37:20.497061: Epoch time: 46.23 s 
2025-07-10 10:37:20.497144: Yayy! New best EMA pseudo Dice: 0.6873000264167786 
2025-07-10 10:37:22.590611:  
2025-07-10 10:37:22.590775: Epoch 36 
2025-07-10 10:37:22.590895: Current learning rate: 0.00968 
2025-07-10 10:38:09.425901: train_loss -0.0995 
2025-07-10 10:38:09.426232: val_loss -0.1328 
2025-07-10 10:38:09.426308: Pseudo dice [np.float32(0.7625)] 
2025-07-10 10:38:09.426405: Epoch time: 46.84 s 
2025-07-10 10:38:09.426479: Yayy! New best EMA pseudo Dice: 0.6948000192642212 
2025-07-10 10:38:11.502120:  
2025-07-10 10:38:11.502446: Epoch 37 
2025-07-10 10:38:11.502756: Current learning rate: 0.00967 
2025-07-10 10:38:58.284744: train_loss -0.105 
2025-07-10 10:38:58.285163: val_loss -0.109 
2025-07-10 10:38:58.285246: Pseudo dice [np.float32(0.7715)] 
2025-07-10 10:38:58.285348: Epoch time: 46.78 s 
2025-07-10 10:38:58.285424: Yayy! New best EMA pseudo Dice: 0.7024999856948853 
2025-07-10 10:39:00.509229:  
2025-07-10 10:39:00.509706: Epoch 38 
2025-07-10 10:39:00.509893: Current learning rate: 0.00966 
2025-07-10 10:39:47.228353: train_loss -0.1084 
2025-07-10 10:39:47.229148: val_loss -0.1047 
2025-07-10 10:39:47.229255: Pseudo dice [np.float32(0.7949)] 
2025-07-10 10:39:47.229403: Epoch time: 46.72 s 
2025-07-10 10:39:47.229500: Yayy! New best EMA pseudo Dice: 0.7117000222206116 
2025-07-10 10:39:49.452738:  
2025-07-10 10:39:49.453133: Epoch 39 
2025-07-10 10:39:49.453323: Current learning rate: 0.00965 
2025-07-10 10:40:36.335977: train_loss -0.1074 
2025-07-10 10:40:36.336592: val_loss -0.1122 
2025-07-10 10:40:36.336863: Pseudo dice [np.float32(0.7927)] 
2025-07-10 10:40:36.337075: Epoch time: 46.88 s 
2025-07-10 10:40:36.337169: Yayy! New best EMA pseudo Dice: 0.7197999954223633 
2025-07-10 10:40:38.421918:  
2025-07-10 10:40:38.422282: Epoch 40 
2025-07-10 10:40:38.422412: Current learning rate: 0.00964 
2025-07-10 10:41:24.846470: train_loss -0.1255 
2025-07-10 10:41:24.847368: val_loss -0.1007 
2025-07-10 10:41:24.847483: Pseudo dice [np.float32(0.754)] 
2025-07-10 10:41:24.847665: Epoch time: 46.43 s 
2025-07-10 10:41:24.847775: Yayy! New best EMA pseudo Dice: 0.7232000231742859 
2025-07-10 10:41:27.027570:  
2025-07-10 10:41:27.028333: Epoch 41 
2025-07-10 10:41:27.028563: Current learning rate: 0.00963 
2025-07-10 10:42:13.381482: train_loss -0.121 
2025-07-10 10:42:13.382283: val_loss -0.1133 
2025-07-10 10:42:13.382401: Pseudo dice [np.float32(0.7912)] 
2025-07-10 10:42:13.382586: Epoch time: 46.36 s 
2025-07-10 10:42:13.382699: Yayy! New best EMA pseudo Dice: 0.7300000190734863 
2025-07-10 10:42:15.519569:  
2025-07-10 10:42:15.519865: Epoch 42 
2025-07-10 10:42:15.520017: Current learning rate: 0.00962 
2025-07-10 10:43:01.314660: train_loss -0.097 
2025-07-10 10:43:01.315084: val_loss -0.1137 
2025-07-10 10:43:01.315202: Pseudo dice [np.float32(0.769)] 
2025-07-10 10:43:01.315310: Epoch time: 45.8 s 
2025-07-10 10:43:01.315395: Yayy! New best EMA pseudo Dice: 0.7339000105857849 
2025-07-10 10:43:03.401910:  
2025-07-10 10:43:03.402488: Epoch 43 
2025-07-10 10:43:03.402638: Current learning rate: 0.00961 
2025-07-10 10:43:48.701580: train_loss -0.1039 
2025-07-10 10:43:48.702045: val_loss -0.1197 
2025-07-10 10:43:48.702211: Pseudo dice [np.float32(0.7836)] 
2025-07-10 10:43:48.702317: Epoch time: 45.3 s 
2025-07-10 10:43:48.702390: Yayy! New best EMA pseudo Dice: 0.7389000058174133 
2025-07-10 10:43:51.327819:  
2025-07-10 10:43:51.328341: Epoch 44 
2025-07-10 10:43:51.328509: Current learning rate: 0.0096 
2025-07-10 10:44:36.634394: train_loss -0.1134 
2025-07-10 10:44:36.635224: val_loss -0.1176 
2025-07-10 10:44:36.635311: Pseudo dice [np.float32(0.7585)] 
2025-07-10 10:44:36.635508: Epoch time: 45.31 s 
2025-07-10 10:44:36.635610: Yayy! New best EMA pseudo Dice: 0.7408000230789185 
2025-07-10 10:44:38.736177:  
2025-07-10 10:44:38.736498: Epoch 45 
2025-07-10 10:44:38.736606: Current learning rate: 0.00959 
2025-07-10 10:45:24.496793: train_loss -0.114 
2025-07-10 10:45:24.497354: val_loss -0.1237 
2025-07-10 10:45:24.497432: Pseudo dice [np.float32(0.7859)] 
2025-07-10 10:45:24.497550: Epoch time: 45.76 s 
2025-07-10 10:45:24.497627: Yayy! New best EMA pseudo Dice: 0.7454000115394592 
2025-07-10 10:45:26.636202:  
2025-07-10 10:45:26.636527: Epoch 46 
2025-07-10 10:45:26.636829: Current learning rate: 0.00959 
2025-07-10 10:46:12.436939: train_loss -0.1039 
2025-07-10 10:46:12.437568: val_loss -0.1431 
2025-07-10 10:46:12.437665: Pseudo dice [np.float32(0.7906)] 
2025-07-10 10:46:12.437787: Epoch time: 45.8 s 
2025-07-10 10:46:12.437865: Yayy! New best EMA pseudo Dice: 0.7498999834060669 
2025-07-10 10:46:14.622600:  
2025-07-10 10:46:14.623072: Epoch 47 
2025-07-10 10:46:14.623235: Current learning rate: 0.00958 
2025-07-10 10:46:59.535228: train_loss -0.1133 
2025-07-10 10:46:59.535650: val_loss -0.1176 
2025-07-10 10:46:59.535725: Pseudo dice [np.float32(0.79)] 
2025-07-10 10:46:59.535832: Epoch time: 44.91 s 
2025-07-10 10:46:59.535903: Yayy! New best EMA pseudo Dice: 0.7538999915122986 
2025-07-10 10:47:01.583949:  
2025-07-10 10:47:01.584399: Epoch 48 
2025-07-10 10:47:01.584536: Current learning rate: 0.00957 
2025-07-10 10:47:46.770237: train_loss -0.1024 
2025-07-10 10:47:46.770836: val_loss -0.1102 
2025-07-10 10:47:46.771039: Pseudo dice [np.float32(0.7598)] 
2025-07-10 10:47:46.771199: Epoch time: 45.19 s 
2025-07-10 10:47:46.771293: Yayy! New best EMA pseudo Dice: 0.7544999718666077 
2025-07-10 10:47:48.917491:  
2025-07-10 10:47:48.918322: Epoch 49 
2025-07-10 10:47:48.918598: Current learning rate: 0.00956 
2025-07-10 10:48:34.372749: train_loss -0.1114 
2025-07-10 10:48:34.373238: val_loss -0.11 
2025-07-10 10:48:34.373315: Pseudo dice [np.float32(0.751)] 
2025-07-10 10:48:34.373428: Epoch time: 45.46 s 
2025-07-10 10:48:35.764108:  
2025-07-10 10:48:35.764409: Epoch 50 
2025-07-10 10:48:35.764686: Current learning rate: 0.00955 
2025-07-10 10:49:21.342472: train_loss -0.1121 
2025-07-10 10:49:21.343324: val_loss -0.1249 
2025-07-10 10:49:21.343470: Pseudo dice [np.float32(0.8173)] 
2025-07-10 10:49:21.343647: Epoch time: 45.58 s 
2025-07-10 10:49:21.343748: Yayy! New best EMA pseudo Dice: 0.7603999972343445 
2025-07-10 10:49:23.459987:  
2025-07-10 10:49:23.460399: Epoch 51 
2025-07-10 10:49:23.460739: Current learning rate: 0.00954 
2025-07-10 10:50:09.295949: train_loss -0.1252 
2025-07-10 10:50:09.296668: val_loss -0.0935 
2025-07-10 10:50:09.296852: Pseudo dice [np.float32(0.7779)] 
2025-07-10 10:50:09.296972: Epoch time: 45.84 s 
2025-07-10 10:50:09.297051: Yayy! New best EMA pseudo Dice: 0.7621999979019165 
2025-07-10 10:50:11.305568:  
2025-07-10 10:50:11.305963: Epoch 52 
2025-07-10 10:50:11.306212: Current learning rate: 0.00953 
2025-07-10 10:50:57.331085: train_loss -0.1187 
2025-07-10 10:50:57.331527: val_loss -0.0978 
2025-07-10 10:50:57.331616: Pseudo dice [np.float32(0.8034)] 
2025-07-10 10:50:57.331713: Epoch time: 46.03 s 
2025-07-10 10:50:57.331789: Yayy! New best EMA pseudo Dice: 0.7663000226020813 
2025-07-10 10:50:59.459126:  
2025-07-10 10:50:59.459604: Epoch 53 
2025-07-10 10:50:59.459893: Current learning rate: 0.00952 
2025-07-10 10:51:45.772228: train_loss -0.1062 
2025-07-10 10:51:45.772711: val_loss -0.1306 
2025-07-10 10:51:45.772865: Pseudo dice [np.float32(0.7731)] 
2025-07-10 10:51:45.772980: Epoch time: 46.31 s 
2025-07-10 10:51:45.773064: Yayy! New best EMA pseudo Dice: 0.7670000195503235 
2025-07-10 10:51:48.417738:  
2025-07-10 10:51:48.418022: Epoch 54 
2025-07-10 10:51:48.418147: Current learning rate: 0.00951 
2025-07-10 10:52:34.653048: train_loss -0.1136 
2025-07-10 10:52:34.653557: val_loss -0.1325 
2025-07-10 10:52:34.653692: Pseudo dice [np.float32(0.8241)] 
2025-07-10 10:52:34.653836: Epoch time: 46.24 s 
2025-07-10 10:52:34.653924: Yayy! New best EMA pseudo Dice: 0.7727000117301941 
2025-07-10 10:52:36.709220:  
2025-07-10 10:52:36.709474: Epoch 55 
2025-07-10 10:52:36.709620: Current learning rate: 0.0095 
2025-07-10 10:53:22.330257: train_loss -0.1169 
2025-07-10 10:53:22.330719: val_loss -0.1312 
2025-07-10 10:53:22.330803: Pseudo dice [np.float32(0.8123)] 
2025-07-10 10:53:22.330929: Epoch time: 45.62 s 
2025-07-10 10:53:22.331287: Yayy! New best EMA pseudo Dice: 0.7767000198364258 
2025-07-10 10:53:24.309004:  
2025-07-10 10:53:24.309406: Epoch 56 
2025-07-10 10:53:24.309618: Current learning rate: 0.00949 
2025-07-10 10:54:10.364871: train_loss -0.1125 
2025-07-10 10:54:10.365517: val_loss -0.1148 
2025-07-10 10:54:10.365630: Pseudo dice [np.float32(0.7812)] 
2025-07-10 10:54:10.365749: Epoch time: 46.06 s 
2025-07-10 10:54:10.365835: Yayy! New best EMA pseudo Dice: 0.7771000266075134 
2025-07-10 10:54:12.485228:  
2025-07-10 10:54:12.485653: Epoch 57 
2025-07-10 10:54:12.485826: Current learning rate: 0.00949 
2025-07-10 10:54:58.764776: train_loss -0.1163 
2025-07-10 10:54:58.765422: val_loss -0.1203 
2025-07-10 10:54:58.765518: Pseudo dice [np.float32(0.8242)] 
2025-07-10 10:54:58.765650: Epoch time: 46.28 s 
2025-07-10 10:54:58.765730: Yayy! New best EMA pseudo Dice: 0.7817999720573425 
2025-07-10 10:55:00.948838:  
2025-07-10 10:55:00.949155: Epoch 58 
2025-07-10 10:55:00.949511: Current learning rate: 0.00948 
2025-07-10 10:55:47.520169: train_loss -0.1101 
2025-07-10 10:55:47.520640: val_loss -0.1378 
2025-07-10 10:55:47.520724: Pseudo dice [np.float32(0.824)] 
2025-07-10 10:55:47.520833: Epoch time: 46.57 s 
2025-07-10 10:55:47.520908: Yayy! New best EMA pseudo Dice: 0.7860000133514404 
2025-07-10 10:55:49.601389:  
2025-07-10 10:55:49.601565: Epoch 59 
2025-07-10 10:55:49.601693: Current learning rate: 0.00947 
2025-07-10 10:56:36.112710: train_loss -0.1258 
2025-07-10 10:56:36.113183: val_loss -0.1257 
2025-07-10 10:56:36.113263: Pseudo dice [np.float32(0.7869)] 
2025-07-10 10:56:36.113370: Epoch time: 46.51 s 
2025-07-10 10:56:36.113447: Yayy! New best EMA pseudo Dice: 0.7860999703407288 
2025-07-10 10:56:38.182293:  
2025-07-10 10:56:38.182652: Epoch 60 
2025-07-10 10:56:38.182828: Current learning rate: 0.00946 
2025-07-10 10:57:24.192072: train_loss -0.1167 
2025-07-10 10:57:24.192576: val_loss -0.145 
2025-07-10 10:57:24.192674: Pseudo dice [np.float32(0.8422)] 
2025-07-10 10:57:24.192792: Epoch time: 46.01 s 
2025-07-10 10:57:24.192871: Yayy! New best EMA pseudo Dice: 0.791700005531311 
2025-07-10 10:57:26.349959:  
2025-07-10 10:57:26.350523: Epoch 61 
2025-07-10 10:57:26.350784: Current learning rate: 0.00945 
2025-07-10 10:58:13.072408: train_loss -0.1203 
2025-07-10 10:58:13.072998: val_loss -0.0911 
2025-07-10 10:58:13.073159: Pseudo dice [np.float32(0.8143)] 
2025-07-10 10:58:13.073256: Epoch time: 46.72 s 
2025-07-10 10:58:13.073327: Yayy! New best EMA pseudo Dice: 0.7940000295639038 
2025-07-10 10:58:15.129648:  
2025-07-10 10:58:15.129924: Epoch 62 
2025-07-10 10:58:15.130094: Current learning rate: 0.00944 
2025-07-10 10:59:01.895411: train_loss -0.1115 
2025-07-10 10:59:01.895793: val_loss -0.1212 
2025-07-10 10:59:01.895868: Pseudo dice [np.float32(0.7941)] 
2025-07-10 10:59:01.895969: Epoch time: 46.77 s 
2025-07-10 10:59:01.896038: Yayy! New best EMA pseudo Dice: 0.7940000295639038 
2025-07-10 10:59:03.962381:  
2025-07-10 10:59:03.962636: Epoch 63 
2025-07-10 10:59:03.962806: Current learning rate: 0.00943 
2025-07-10 10:59:50.586931: train_loss -0.1188 
2025-07-10 10:59:50.587318: val_loss -0.1187 
2025-07-10 10:59:50.587397: Pseudo dice [np.float32(0.8261)] 
2025-07-10 10:59:50.587500: Epoch time: 46.63 s 
2025-07-10 10:59:50.587583: Yayy! New best EMA pseudo Dice: 0.7972000241279602 
2025-07-10 10:59:52.578380:  
2025-07-10 10:59:52.578774: Epoch 64 
2025-07-10 10:59:52.579183: Current learning rate: 0.00942 
2025-07-10 11:00:39.496267: train_loss -0.1072 
2025-07-10 11:00:39.496899: val_loss -0.1109 
2025-07-10 11:00:39.496979: Pseudo dice [np.float32(0.8147)] 
2025-07-10 11:00:39.497091: Epoch time: 46.92 s 
2025-07-10 11:00:39.497163: Yayy! New best EMA pseudo Dice: 0.7990000247955322 
2025-07-10 11:00:42.235203:  
2025-07-10 11:00:42.235874: Epoch 65 
2025-07-10 11:00:42.236108: Current learning rate: 0.00941 
2025-07-10 11:01:28.895386: train_loss -0.1162 
2025-07-10 11:01:28.896003: val_loss -0.0992 
2025-07-10 11:01:28.896092: Pseudo dice [np.float32(0.8327)] 
2025-07-10 11:01:28.896205: Epoch time: 46.66 s 
2025-07-10 11:01:28.896279: Yayy! New best EMA pseudo Dice: 0.802299976348877 
2025-07-10 11:01:31.028801:  
2025-07-10 11:01:31.029347: Epoch 66 
2025-07-10 11:01:31.029592: Current learning rate: 0.0094 
2025-07-10 11:02:17.649040: train_loss -0.1242 
2025-07-10 11:02:17.649494: val_loss -0.114 
2025-07-10 11:02:17.649581: Pseudo dice [np.float32(0.8337)] 
2025-07-10 11:02:17.649695: Epoch time: 46.62 s 
2025-07-10 11:02:17.649772: Yayy! New best EMA pseudo Dice: 0.8054999709129333 
2025-07-10 11:02:19.825583:  
2025-07-10 11:02:19.825996: Epoch 67 
2025-07-10 11:02:19.826129: Current learning rate: 0.00939 
2025-07-10 11:03:06.257833: train_loss -0.1264 
2025-07-10 11:03:06.258240: val_loss -0.1072 
2025-07-10 11:03:06.258317: Pseudo dice [np.float32(0.8157)] 
2025-07-10 11:03:06.258425: Epoch time: 46.43 s 
2025-07-10 11:03:06.258497: Yayy! New best EMA pseudo Dice: 0.8065000176429749 
2025-07-10 11:03:08.247575:  
2025-07-10 11:03:08.247987: Epoch 68 
2025-07-10 11:03:08.248118: Current learning rate: 0.00939 
2025-07-10 11:03:53.950222: train_loss -0.1201 
2025-07-10 11:03:53.950831: val_loss -0.1369 
2025-07-10 11:03:53.950914: Pseudo dice [np.float32(0.8253)] 
2025-07-10 11:03:53.951025: Epoch time: 45.7 s 
2025-07-10 11:03:53.951101: Yayy! New best EMA pseudo Dice: 0.8083999752998352 
2025-07-10 11:03:56.154788:  
2025-07-10 11:03:56.155027: Epoch 69 
2025-07-10 11:03:56.155149: Current learning rate: 0.00938 
2025-07-10 11:04:42.341964: train_loss -0.1221 
2025-07-10 11:04:42.342288: val_loss -0.1535 
2025-07-10 11:04:42.342368: Pseudo dice [np.float32(0.8204)] 
2025-07-10 11:04:42.342458: Epoch time: 46.19 s 
2025-07-10 11:04:42.342526: Yayy! New best EMA pseudo Dice: 0.8095999956130981 
2025-07-10 11:04:44.421617:  
2025-07-10 11:04:44.421866: Epoch 70 
2025-07-10 11:04:44.422184: Current learning rate: 0.00937 
2025-07-10 11:05:31.640253: train_loss -0.1136 
2025-07-10 11:05:31.640855: val_loss -0.1302 
2025-07-10 11:05:31.640951: Pseudo dice [np.float32(0.8054)] 
2025-07-10 11:05:31.641067: Epoch time: 47.22 s 
2025-07-10 11:05:32.770722:  
2025-07-10 11:05:32.770932: Epoch 71 
2025-07-10 11:05:32.771055: Current learning rate: 0.00936 
2025-07-10 11:06:19.889629: train_loss -0.1208 
2025-07-10 11:06:19.890137: val_loss -0.1247 
2025-07-10 11:06:19.890221: Pseudo dice [np.float32(0.8203)] 
2025-07-10 11:06:19.890331: Epoch time: 47.12 s 
2025-07-10 11:06:19.890410: Yayy! New best EMA pseudo Dice: 0.8102999925613403 
2025-07-10 11:06:22.278506:  
2025-07-10 11:06:22.279094: Epoch 72 
2025-07-10 11:06:22.279305: Current learning rate: 0.00935 
2025-07-10 11:07:08.641822: train_loss -0.1214 
2025-07-10 11:07:08.642249: val_loss -0.1347 
2025-07-10 11:07:08.642332: Pseudo dice [np.float32(0.8246)] 
2025-07-10 11:07:08.642422: Epoch time: 46.36 s 
2025-07-10 11:07:08.642494: Yayy! New best EMA pseudo Dice: 0.8116999864578247 
2025-07-10 11:07:10.683964:  
2025-07-10 11:07:10.684284: Epoch 73 
2025-07-10 11:07:10.684414: Current learning rate: 0.00934 
2025-07-10 11:07:56.527249: train_loss -0.1138 
2025-07-10 11:07:56.527679: val_loss -0.1177 
2025-07-10 11:07:56.527761: Pseudo dice [np.float32(0.8148)] 
2025-07-10 11:07:56.527868: Epoch time: 45.84 s 
2025-07-10 11:07:56.527947: Yayy! New best EMA pseudo Dice: 0.8119999766349792 
2025-07-10 11:07:58.754550:  
2025-07-10 11:07:58.754976: Epoch 74 
2025-07-10 11:07:58.755104: Current learning rate: 0.00933 
2025-07-10 11:08:44.549438: train_loss -0.1125 
2025-07-10 11:08:44.550455: val_loss -0.1147 
2025-07-10 11:08:44.550642: Pseudo dice [np.float32(0.8179)] 
2025-07-10 11:08:44.550774: Epoch time: 45.8 s 
2025-07-10 11:08:44.550865: Yayy! New best EMA pseudo Dice: 0.8126000165939331 
2025-07-10 11:08:46.590074:  
2025-07-10 11:08:46.590469: Epoch 75 
2025-07-10 11:08:46.590659: Current learning rate: 0.00932 
2025-07-10 11:09:32.669734: train_loss -0.1298 
2025-07-10 11:09:32.670259: val_loss -0.1395 
2025-07-10 11:09:32.670341: Pseudo dice [np.float32(0.8216)] 
2025-07-10 11:09:32.670447: Epoch time: 46.08 s 
2025-07-10 11:09:32.670523: Yayy! New best EMA pseudo Dice: 0.8134999871253967 
2025-07-10 11:09:35.392392:  
2025-07-10 11:09:35.392799: Epoch 76 
2025-07-10 11:09:35.393115: Current learning rate: 0.00931 
2025-07-10 11:10:20.679373: train_loss -0.1228 
2025-07-10 11:10:20.680347: val_loss -0.1355 
2025-07-10 11:10:20.680444: Pseudo dice [np.float32(0.8338)] 
2025-07-10 11:10:20.680595: Epoch time: 45.29 s 
2025-07-10 11:10:20.680685: Yayy! New best EMA pseudo Dice: 0.815500020980835 
2025-07-10 11:10:22.643903:  
2025-07-10 11:10:22.644320: Epoch 77 
2025-07-10 11:10:22.644496: Current learning rate: 0.0093 
2025-07-10 11:11:08.342250: train_loss -0.1239 
2025-07-10 11:11:08.343250: val_loss -0.1279 
2025-07-10 11:11:08.343483: Pseudo dice [np.float32(0.8275)] 
2025-07-10 11:11:08.343738: Epoch time: 45.7 s 
2025-07-10 11:11:08.343922: Yayy! New best EMA pseudo Dice: 0.8166999816894531 
2025-07-10 11:11:10.490484:  
2025-07-10 11:11:10.491021: Epoch 78 
2025-07-10 11:11:10.491147: Current learning rate: 0.0093 
2025-07-10 11:11:56.365757: train_loss -0.1211 
2025-07-10 11:11:56.366240: val_loss -0.1213 
2025-07-10 11:11:56.366328: Pseudo dice [np.float32(0.8157)] 
2025-07-10 11:11:56.366446: Epoch time: 45.88 s 
2025-07-10 11:11:57.507599:  
2025-07-10 11:11:57.507997: Epoch 79 
2025-07-10 11:11:57.508126: Current learning rate: 0.00929 
2025-07-10 11:12:43.721420: train_loss -0.1197 
2025-07-10 11:12:43.721764: val_loss -0.1198 
2025-07-10 11:12:43.721835: Pseudo dice [np.float32(0.8025)] 
2025-07-10 11:12:43.721938: Epoch time: 46.21 s 
2025-07-10 11:12:44.941791:  
2025-07-10 11:12:44.942090: Epoch 80 
2025-07-10 11:12:44.942213: Current learning rate: 0.00928 
2025-07-10 11:13:31.404420: train_loss -0.1229 
2025-07-10 11:13:31.404801: val_loss -0.14 
2025-07-10 11:13:31.404944: Pseudo dice [np.float32(0.8411)] 
2025-07-10 11:13:31.405089: Epoch time: 46.46 s 
2025-07-10 11:13:31.405163: Yayy! New best EMA pseudo Dice: 0.817799985408783 
2025-07-10 11:13:33.481118:  
2025-07-10 11:13:33.481849: Epoch 81 
2025-07-10 11:13:33.482076: Current learning rate: 0.00927 
2025-07-10 11:14:19.599583: train_loss -0.1251 
2025-07-10 11:14:19.600036: val_loss -0.1272 
2025-07-10 11:14:19.600119: Pseudo dice [np.float32(0.8008)] 
2025-07-10 11:14:19.600266: Epoch time: 46.12 s 
2025-07-10 11:14:20.757974:  
2025-07-10 11:14:20.758272: Epoch 82 
2025-07-10 11:14:20.758389: Current learning rate: 0.00926 
2025-07-10 11:15:07.334112: train_loss -0.1245 
2025-07-10 11:15:07.334635: val_loss -0.1122 
2025-07-10 11:15:07.334738: Pseudo dice [np.float32(0.8317)] 
2025-07-10 11:15:07.334954: Epoch time: 46.58 s 
2025-07-10 11:15:08.414748:  
2025-07-10 11:15:08.415124: Epoch 83 
2025-07-10 11:15:08.415253: Current learning rate: 0.00925 
2025-07-10 11:15:53.576408: train_loss -0.1162 
2025-07-10 11:15:53.577589: val_loss -0.1489 
2025-07-10 11:15:53.577679: Pseudo dice [np.float32(0.795)] 
2025-07-10 11:15:53.577849: Epoch time: 45.16 s 
2025-07-10 11:15:54.743429:  
2025-07-10 11:15:54.743896: Epoch 84 
2025-07-10 11:15:54.744212: Current learning rate: 0.00924 
2025-07-10 11:16:40.345207: train_loss -0.1133 
2025-07-10 11:16:40.345667: val_loss -0.1444 
2025-07-10 11:16:40.345746: Pseudo dice [np.float32(0.8288)] 
2025-07-10 11:16:40.345847: Epoch time: 45.6 s 
2025-07-10 11:16:41.451104:  
2025-07-10 11:16:41.451349: Epoch 85 
2025-07-10 11:16:41.451536: Current learning rate: 0.00923 
2025-07-10 11:17:27.508764: train_loss -0.1311 
2025-07-10 11:17:27.509187: val_loss -0.1499 
2025-07-10 11:17:27.509281: Pseudo dice [np.float32(0.8496)] 
2025-07-10 11:17:27.509614: Epoch time: 46.06 s 
2025-07-10 11:17:27.509712: Yayy! New best EMA pseudo Dice: 0.8199999928474426 
2025-07-10 11:17:29.665600:  
2025-07-10 11:17:29.665999: Epoch 86 
2025-07-10 11:17:29.666138: Current learning rate: 0.00922 
2025-07-10 11:18:15.723581: train_loss -0.1286 
2025-07-10 11:18:15.724044: val_loss -0.1601 
2025-07-10 11:18:15.724122: Pseudo dice [np.float32(0.8213)] 
2025-07-10 11:18:15.724226: Epoch time: 46.06 s 
2025-07-10 11:18:15.724313: Yayy! New best EMA pseudo Dice: 0.8202000260353088 
2025-07-10 11:18:18.267967:  
2025-07-10 11:18:18.268214: Epoch 87 
2025-07-10 11:18:18.268350: Current learning rate: 0.00921 
2025-07-10 11:19:04.814759: train_loss -0.1316 
2025-07-10 11:19:04.815122: val_loss -0.1296 
2025-07-10 11:19:04.815267: Pseudo dice [np.float32(0.8124)] 
2025-07-10 11:19:04.815451: Epoch time: 46.55 s 
2025-07-10 11:19:05.926740:  
2025-07-10 11:19:05.927200: Epoch 88 
2025-07-10 11:19:05.927336: Current learning rate: 0.0092 
2025-07-10 11:19:51.815591: train_loss -0.1305 
2025-07-10 11:19:51.815967: val_loss -0.1456 
2025-07-10 11:19:51.816048: Pseudo dice [np.float32(0.8373)] 
2025-07-10 11:19:51.816159: Epoch time: 45.89 s 
2025-07-10 11:19:51.816239: Yayy! New best EMA pseudo Dice: 0.8212000131607056 
2025-07-10 11:19:54.038584:  
2025-07-10 11:19:54.039241: Epoch 89 
2025-07-10 11:19:54.039510: Current learning rate: 0.0092 
2025-07-10 11:20:40.364035: train_loss -0.1192 
2025-07-10 11:20:40.364462: val_loss -0.1158 
2025-07-10 11:20:40.364632: Pseudo dice [np.float32(0.7915)] 
2025-07-10 11:20:40.364789: Epoch time: 46.33 s 
2025-07-10 11:20:41.567282:  
2025-07-10 11:20:41.567686: Epoch 90 
2025-07-10 11:20:41.567837: Current learning rate: 0.00919 
2025-07-10 11:21:28.000174: train_loss -0.1297 
2025-07-10 11:21:28.000494: val_loss -0.1516 
2025-07-10 11:21:28.000694: Pseudo dice [np.float32(0.8297)] 
2025-07-10 11:21:28.000819: Epoch time: 46.43 s 
2025-07-10 11:21:29.090048:  
2025-07-10 11:21:29.090389: Epoch 91 
2025-07-10 11:21:29.090521: Current learning rate: 0.00918 
2025-07-10 11:22:15.742960: train_loss -0.1414 
2025-07-10 11:22:15.743324: val_loss -0.1406 
2025-07-10 11:22:15.743397: Pseudo dice [np.float32(0.8374)] 
2025-07-10 11:22:15.743487: Epoch time: 46.65 s 
2025-07-10 11:22:16.853972:  
2025-07-10 11:22:16.854234: Epoch 92 
2025-07-10 11:22:16.854400: Current learning rate: 0.00917 
2025-07-10 11:23:02.569585: train_loss -0.1226 
2025-07-10 11:23:02.570139: val_loss -0.1239 
2025-07-10 11:23:02.570364: Pseudo dice [np.float32(0.8266)] 
2025-07-10 11:23:02.570532: Epoch time: 45.72 s 
2025-07-10 11:23:02.570661: Yayy! New best EMA pseudo Dice: 0.8216999769210815 
2025-07-10 11:23:04.689863:  
2025-07-10 11:23:04.690493: Epoch 93 
2025-07-10 11:23:04.690645: Current learning rate: 0.00916 
2025-07-10 11:23:50.655887: train_loss -0.1241 
2025-07-10 11:23:50.656195: val_loss -0.1425 
2025-07-10 11:23:50.656267: Pseudo dice [np.float32(0.8353)] 
2025-07-10 11:23:50.656363: Epoch time: 45.97 s 
2025-07-10 11:23:50.656434: Yayy! New best EMA pseudo Dice: 0.8230999708175659 
2025-07-10 11:23:52.719762:  
2025-07-10 11:23:52.720104: Epoch 94 
2025-07-10 11:23:52.720409: Current learning rate: 0.00915 
2025-07-10 11:24:38.003715: train_loss -0.1281 
2025-07-10 11:24:38.004417: val_loss -0.1413 
2025-07-10 11:24:38.004500: Pseudo dice [np.float32(0.8331)] 
2025-07-10 11:24:38.004651: Epoch time: 45.29 s 
2025-07-10 11:24:38.004776: Yayy! New best EMA pseudo Dice: 0.8241000175476074 
2025-07-10 11:24:40.081195:  
2025-07-10 11:24:40.081617: Epoch 95 
2025-07-10 11:24:40.081770: Current learning rate: 0.00914 
2025-07-10 11:25:25.682500: train_loss -0.1232 
2025-07-10 11:25:25.682995: val_loss -0.1485 
2025-07-10 11:25:25.683082: Pseudo dice [np.float32(0.8419)] 
2025-07-10 11:25:25.683200: Epoch time: 45.6 s 
2025-07-10 11:25:25.683284: Yayy! New best EMA pseudo Dice: 0.8259000182151794 
2025-07-10 11:25:27.809796:  
2025-07-10 11:25:27.809972: Epoch 96 
2025-07-10 11:25:27.810175: Current learning rate: 0.00913 
2025-07-10 11:26:13.571246: train_loss -0.1181 
2025-07-10 11:26:13.571713: val_loss -0.1218 
2025-07-10 11:26:13.571791: Pseudo dice [np.float32(0.8311)] 
2025-07-10 11:26:13.571899: Epoch time: 45.76 s 
2025-07-10 11:26:13.571978: Yayy! New best EMA pseudo Dice: 0.8263999819755554 
2025-07-10 11:26:15.581055:  
2025-07-10 11:26:15.581412: Epoch 97 
2025-07-10 11:26:15.581609: Current learning rate: 0.00912 
2025-07-10 11:27:01.301439: train_loss -0.1295 
2025-07-10 11:27:01.301908: val_loss -0.1423 
2025-07-10 11:27:01.301989: Pseudo dice [np.float32(0.837)] 
2025-07-10 11:27:01.302091: Epoch time: 45.72 s 
2025-07-10 11:27:01.302164: Yayy! New best EMA pseudo Dice: 0.8274000287055969 
2025-07-10 11:27:03.228706:  
2025-07-10 11:27:03.228939: Epoch 98 
2025-07-10 11:27:03.229093: Current learning rate: 0.00911 
2025-07-10 11:27:49.776706: train_loss -0.1343 
2025-07-10 11:27:49.777196: val_loss -0.1259 
2025-07-10 11:27:49.777276: Pseudo dice [np.float32(0.8305)] 
2025-07-10 11:27:49.777417: Epoch time: 46.55 s 
2025-07-10 11:27:49.777499: Yayy! New best EMA pseudo Dice: 0.8277000188827515 
2025-07-10 11:27:52.388917:  
2025-07-10 11:27:52.389280: Epoch 99 
2025-07-10 11:27:52.389386: Current learning rate: 0.0091 
2025-07-10 11:28:38.505652: train_loss -0.1244 
2025-07-10 11:28:38.506021: val_loss -0.1308 
2025-07-10 11:28:38.506103: Pseudo dice [np.float32(0.8236)] 
2025-07-10 11:28:38.506206: Epoch time: 46.12 s 
2025-07-10 11:28:40.581227:  
2025-07-10 11:28:40.581828: Epoch 100 
2025-07-10 11:28:40.582004: Current learning rate: 0.0091 
2025-07-10 11:29:26.988849: train_loss -0.1262 
2025-07-10 11:29:26.989331: val_loss -0.1315 
2025-07-10 11:29:26.989402: Pseudo dice [np.float32(0.82)] 
2025-07-10 11:29:26.989502: Epoch time: 46.41 s 
2025-07-10 11:29:28.078871:  
2025-07-10 11:29:28.079219: Epoch 101 
2025-07-10 11:29:28.079408: Current learning rate: 0.00909 
2025-07-10 11:30:15.142497: train_loss -0.1292 
2025-07-10 11:30:15.142939: val_loss -0.1427 
2025-07-10 11:30:15.143015: Pseudo dice [np.float32(0.8287)] 
2025-07-10 11:30:15.143119: Epoch time: 47.06 s 
2025-07-10 11:30:16.221075:  
2025-07-10 11:30:16.221523: Epoch 102 
2025-07-10 11:30:16.221827: Current learning rate: 0.00908 
2025-07-10 11:31:01.603624: train_loss -0.1408 
2025-07-10 11:31:01.604229: val_loss -0.1264 
2025-07-10 11:31:01.604569: Pseudo dice [np.float32(0.8137)] 
2025-07-10 11:31:01.604733: Epoch time: 45.38 s 
2025-07-10 11:31:02.727645:  
2025-07-10 11:31:02.728089: Epoch 103 
2025-07-10 11:31:02.728218: Current learning rate: 0.00907 
2025-07-10 11:31:49.049998: train_loss -0.1316 
2025-07-10 11:31:49.050677: val_loss -0.1237 
2025-07-10 11:31:49.050803: Pseudo dice [np.float32(0.8185)] 
2025-07-10 11:31:49.050920: Epoch time: 46.32 s 
2025-07-10 11:31:50.160153:  
2025-07-10 11:31:50.160842: Epoch 104 
2025-07-10 11:31:50.161139: Current learning rate: 0.00906 
2025-07-10 11:32:37.012625: train_loss -0.1233 
2025-07-10 11:32:37.013016: val_loss -0.137 
2025-07-10 11:32:37.013089: Pseudo dice [np.float32(0.7963)] 
2025-07-10 11:32:37.013186: Epoch time: 46.85 s 
2025-07-10 11:32:38.112793:  
2025-07-10 11:32:38.113207: Epoch 105 
2025-07-10 11:32:38.113395: Current learning rate: 0.00905 
2025-07-10 11:33:24.188928: train_loss -0.1294 
2025-07-10 11:33:24.189687: val_loss -0.1288 
2025-07-10 11:33:24.189774: Pseudo dice [np.float32(0.8252)] 
2025-07-10 11:33:24.189913: Epoch time: 46.08 s 
2025-07-10 11:33:25.321785:  
2025-07-10 11:33:25.322307: Epoch 106 
2025-07-10 11:33:25.322523: Current learning rate: 0.00904 
2025-07-10 11:34:12.980454: train_loss -0.1353 
2025-07-10 11:34:12.980882: val_loss -0.141 
2025-07-10 11:34:12.980968: Pseudo dice [np.float32(0.8533)] 
2025-07-10 11:34:12.981078: Epoch time: 47.66 s 
2025-07-10 11:34:14.092373:  
2025-07-10 11:34:14.092591: Epoch 107 
2025-07-10 11:34:14.092742: Current learning rate: 0.00903 
2025-07-10 11:35:01.019936: train_loss -0.12 
2025-07-10 11:35:01.020376: val_loss -0.1329 
2025-07-10 11:35:01.020451: Pseudo dice [np.float32(0.8368)] 
2025-07-10 11:35:01.020554: Epoch time: 46.93 s 
2025-07-10 11:35:02.092795:  
2025-07-10 11:35:02.093351: Epoch 108 
2025-07-10 11:35:02.093479: Current learning rate: 0.00902 
2025-07-10 11:35:49.256055: train_loss -0.1266 
2025-07-10 11:35:49.256505: val_loss -0.1099 
2025-07-10 11:35:49.256609: Pseudo dice [np.float32(0.8273)] 
2025-07-10 11:35:49.256711: Epoch time: 47.16 s 
2025-07-10 11:35:50.319072:  
2025-07-10 11:35:50.319590: Epoch 109 
2025-07-10 11:35:50.319757: Current learning rate: 0.00901 
2025-07-10 11:36:39.002521: train_loss -0.1344 
2025-07-10 11:36:39.002827: val_loss -0.1461 
2025-07-10 11:36:39.002896: Pseudo dice [np.float32(0.8248)] 
2025-07-10 11:36:39.002995: Epoch time: 48.68 s 
2025-07-10 11:36:40.601996:  
2025-07-10 11:36:40.602437: Epoch 110 
2025-07-10 11:36:40.602551: Current learning rate: 0.009 
2025-07-10 11:37:29.181496: train_loss -0.1272 
2025-07-10 11:37:29.182032: val_loss -0.1516 
2025-07-10 11:37:29.182156: Pseudo dice [np.float32(0.8565)] 
2025-07-10 11:37:29.182310: Epoch time: 48.58 s 
2025-07-10 11:37:29.182409: Yayy! New best EMA pseudo Dice: 0.8294000029563904 
2025-07-10 11:37:31.390732:  
2025-07-10 11:37:31.391011: Epoch 111 
2025-07-10 11:37:31.391303: Current learning rate: 0.009 
2025-07-10 11:38:20.281796: train_loss -0.1335 
2025-07-10 11:38:20.282219: val_loss -0.1484 
2025-07-10 11:38:20.282370: Pseudo dice [np.float32(0.8224)] 
2025-07-10 11:38:20.282468: Epoch time: 48.89 s 
2025-07-10 11:38:21.369409:  
2025-07-10 11:38:21.369849: Epoch 112 
2025-07-10 11:38:21.369983: Current learning rate: 0.00899 
2025-07-10 11:39:08.585389: train_loss -0.1345 
2025-07-10 11:39:08.585893: val_loss -0.1457 
2025-07-10 11:39:08.586144: Pseudo dice [np.float32(0.834)] 
2025-07-10 11:39:08.586298: Epoch time: 47.22 s 
2025-07-10 11:39:09.748152:  
2025-07-10 11:39:09.748600: Epoch 113 
2025-07-10 11:39:09.748766: Current learning rate: 0.00898 
2025-07-10 11:39:57.358958: train_loss -0.1291 
2025-07-10 11:39:57.359633: val_loss -0.1358 
2025-07-10 11:39:57.359718: Pseudo dice [np.float32(0.8123)] 
2025-07-10 11:39:57.359831: Epoch time: 47.61 s 
2025-07-10 11:39:58.683928:  
2025-07-10 11:39:58.684496: Epoch 114 
2025-07-10 11:39:58.684647: Current learning rate: 0.00897 
2025-07-10 11:40:45.178166: train_loss -0.1291 
2025-07-10 11:40:45.179110: val_loss -0.1366 
2025-07-10 11:40:45.179279: Pseudo dice [np.float32(0.8444)] 
2025-07-10 11:40:45.179431: Epoch time: 46.5 s 
2025-07-10 11:40:46.469749:  
2025-07-10 11:40:46.470355: Epoch 115 
2025-07-10 11:40:46.470491: Current learning rate: 0.00896 
2025-07-10 11:41:32.605735: train_loss -0.1186 
2025-07-10 11:41:32.606385: val_loss -0.1295 
2025-07-10 11:41:32.606480: Pseudo dice [np.float32(0.8103)] 
2025-07-10 11:41:32.606682: Epoch time: 46.14 s 
2025-07-10 11:41:33.714788:  
2025-07-10 11:41:33.715182: Epoch 116 
2025-07-10 11:41:33.715335: Current learning rate: 0.00895 
2025-07-10 11:42:20.186251: train_loss -0.1371 
2025-07-10 11:42:20.187518: val_loss -0.1217 
2025-07-10 11:42:20.187690: Pseudo dice [np.float32(0.8397)] 
2025-07-10 11:42:20.187836: Epoch time: 46.47 s 
2025-07-10 11:42:21.359818:  
2025-07-10 11:42:21.360250: Epoch 117 
2025-07-10 11:42:21.360586: Current learning rate: 0.00894 
2025-07-10 11:43:07.774301: train_loss -0.1224 
2025-07-10 11:43:07.774911: val_loss -0.1147 
2025-07-10 11:43:07.774993: Pseudo dice [np.float32(0.8222)] 
2025-07-10 11:43:07.775121: Epoch time: 46.42 s 
2025-07-10 11:43:08.869056:  
2025-07-10 11:43:08.869397: Epoch 118 
2025-07-10 11:43:08.869633: Current learning rate: 0.00893 
2025-07-10 11:43:55.428498: train_loss -0.1258 
2025-07-10 11:43:55.429012: val_loss -0.1123 
2025-07-10 11:43:55.429098: Pseudo dice [np.float32(0.8324)] 
2025-07-10 11:43:55.429205: Epoch time: 46.56 s 
2025-07-10 11:43:56.569452:  
2025-07-10 11:43:56.569696: Epoch 119 
2025-07-10 11:43:56.569844: Current learning rate: 0.00892 
2025-07-10 11:44:41.890347: train_loss -0.1321 
2025-07-10 11:44:41.890792: val_loss -0.1279 
2025-07-10 11:44:41.890869: Pseudo dice [np.float32(0.8359)] 
2025-07-10 11:44:41.890969: Epoch time: 45.32 s 
2025-07-10 11:44:43.032603:  
2025-07-10 11:44:43.032984: Epoch 120 
2025-07-10 11:44:43.033265: Current learning rate: 0.00891 
2025-07-10 11:45:28.589907: train_loss -0.1345 
2025-07-10 11:45:28.590342: val_loss -0.1182 
2025-07-10 11:45:28.590459: Pseudo dice [np.float32(0.8333)] 
2025-07-10 11:45:28.590597: Epoch time: 45.56 s 
2025-07-10 11:45:28.590682: Yayy! New best EMA pseudo Dice: 0.8295999765396118 
2025-07-10 11:45:30.565707:  
2025-07-10 11:45:30.565959: Epoch 121 
2025-07-10 11:45:30.566081: Current learning rate: 0.0089 
2025-07-10 11:46:15.867178: train_loss -0.1352 
2025-07-10 11:46:15.867720: val_loss -0.1335 
2025-07-10 11:46:15.867806: Pseudo dice [np.float32(0.863)] 
2025-07-10 11:46:15.867916: Epoch time: 45.3 s 
2025-07-10 11:46:15.867991: Yayy! New best EMA pseudo Dice: 0.8328999876976013 
2025-07-10 11:46:18.565765:  
2025-07-10 11:46:18.566161: Epoch 122 
2025-07-10 11:46:18.566343: Current learning rate: 0.00889 
2025-07-10 11:47:04.479755: train_loss -0.1365 
2025-07-10 11:47:04.480412: val_loss -0.1633 
2025-07-10 11:47:04.480502: Pseudo dice [np.float32(0.8414)] 
2025-07-10 11:47:04.480653: Epoch time: 45.92 s 
2025-07-10 11:47:04.480739: Yayy! New best EMA pseudo Dice: 0.8338000178337097 
2025-07-10 11:47:06.539490:  
2025-07-10 11:47:06.539870: Epoch 123 
2025-07-10 11:47:06.539993: Current learning rate: 0.00889 
2025-07-10 11:47:52.999498: train_loss -0.1381 
2025-07-10 11:47:53.000125: val_loss -0.1309 
2025-07-10 11:47:53.000211: Pseudo dice [np.float32(0.8304)] 
2025-07-10 11:47:53.000325: Epoch time: 46.46 s 
2025-07-10 11:47:54.146138:  
2025-07-10 11:47:54.146672: Epoch 124 
2025-07-10 11:47:54.146802: Current learning rate: 0.00888 
2025-07-10 11:48:40.291585: train_loss -0.1317 
2025-07-10 11:48:40.291984: val_loss -0.1112 
2025-07-10 11:48:40.292063: Pseudo dice [np.float32(0.8489)] 
2025-07-10 11:48:40.292177: Epoch time: 46.15 s 
2025-07-10 11:48:40.292257: Yayy! New best EMA pseudo Dice: 0.8349999785423279 
2025-07-10 11:48:42.395396:  
2025-07-10 11:48:42.395905: Epoch 125 
2025-07-10 11:48:42.396184: Current learning rate: 0.00887 
2025-07-10 11:49:28.838769: train_loss -0.1209 
2025-07-10 11:49:28.839086: val_loss -0.1316 
2025-07-10 11:49:28.839157: Pseudo dice [np.float32(0.8332)] 
2025-07-10 11:49:28.839397: Epoch time: 46.44 s 
2025-07-10 11:49:30.008917:  
2025-07-10 11:49:30.009367: Epoch 126 
2025-07-10 11:49:30.009629: Current learning rate: 0.00886 
2025-07-10 11:50:15.262418: train_loss -0.1311 
2025-07-10 11:50:15.262978: val_loss -0.1462 
2025-07-10 11:50:15.263075: Pseudo dice [np.float32(0.8427)] 
2025-07-10 11:50:15.263211: Epoch time: 45.25 s 
2025-07-10 11:50:15.263297: Yayy! New best EMA pseudo Dice: 0.8356000185012817 
2025-07-10 11:50:17.274259:  
2025-07-10 11:50:17.274644: Epoch 127 
2025-07-10 11:50:17.274844: Current learning rate: 0.00885 
2025-07-10 11:51:03.104565: train_loss -0.1332 
2025-07-10 11:51:03.104948: val_loss -0.1379 
2025-07-10 11:51:03.105024: Pseudo dice [np.float32(0.8309)] 
2025-07-10 11:51:03.105124: Epoch time: 45.83 s 
2025-07-10 11:51:04.197639:  
2025-07-10 11:51:04.198084: Epoch 128 
2025-07-10 11:51:04.198344: Current learning rate: 0.00884 
2025-07-10 11:51:49.545496: train_loss -0.1333 
2025-07-10 11:51:49.546021: val_loss -0.1362 
2025-07-10 11:51:49.546106: Pseudo dice [np.float32(0.8379)] 
2025-07-10 11:51:49.546229: Epoch time: 45.35 s 
2025-07-10 11:51:50.722093:  
2025-07-10 11:51:50.722506: Epoch 129 
2025-07-10 11:51:50.722644: Current learning rate: 0.00883 
2025-07-10 11:52:37.809256: train_loss -0.1323 
2025-07-10 11:52:37.809634: val_loss -0.135 
2025-07-10 11:52:37.809737: Pseudo dice [np.float32(0.833)] 
2025-07-10 11:52:37.809883: Epoch time: 47.09 s 
2025-07-10 11:52:38.899827:  
2025-07-10 11:52:38.900183: Epoch 130 
2025-07-10 11:52:38.900397: Current learning rate: 0.00882 
2025-07-10 11:53:25.124620: train_loss -0.1339 
2025-07-10 11:53:25.125090: val_loss -0.1711 
2025-07-10 11:53:25.125191: Pseudo dice [np.float32(0.8338)] 
2025-07-10 11:53:25.125405: Epoch time: 46.23 s 
2025-07-10 11:53:26.248455:  
2025-07-10 11:53:26.248889: Epoch 131 
2025-07-10 11:53:26.249019: Current learning rate: 0.00881 
2025-07-10 11:54:13.987436: train_loss -0.1291 
2025-07-10 11:54:13.988487: val_loss -0.1237 
2025-07-10 11:54:13.988637: Pseudo dice [np.float32(0.8353)] 
2025-07-10 11:54:13.988794: Epoch time: 47.74 s 
2025-07-10 11:54:15.072851:  
2025-07-10 11:54:15.073328: Epoch 132 
2025-07-10 11:54:15.073504: Current learning rate: 0.0088 
2025-07-10 11:55:01.481452: train_loss -0.134 
2025-07-10 11:55:01.482046: val_loss -0.1585 
2025-07-10 11:55:01.482162: Pseudo dice [np.float32(0.8466)] 
2025-07-10 11:55:01.482312: Epoch time: 46.41 s 
2025-07-10 11:55:01.482488: Yayy! New best EMA pseudo Dice: 0.8361999988555908 
2025-07-10 11:55:04.056444:  
2025-07-10 11:55:04.056588: Epoch 133 
2025-07-10 11:55:04.056780: Current learning rate: 0.00879 
2025-07-10 11:55:51.746009: train_loss -0.1356 
2025-07-10 11:55:51.746399: val_loss -0.1435 
2025-07-10 11:55:51.746492: Pseudo dice [np.float32(0.8238)] 
2025-07-10 11:55:51.746607: Epoch time: 47.69 s 
2025-07-10 11:55:52.936923:  
2025-07-10 11:55:52.937230: Epoch 134 
2025-07-10 11:55:52.937364: Current learning rate: 0.00879 
2025-07-10 11:56:40.423490: train_loss -0.1204 
2025-07-10 11:56:40.423816: val_loss -0.1445 
2025-07-10 11:56:40.423889: Pseudo dice [np.float32(0.8162)] 
2025-07-10 11:56:40.423990: Epoch time: 47.49 s 
2025-07-10 11:56:41.543168:  
2025-07-10 11:56:41.543603: Epoch 135 
2025-07-10 11:56:41.543732: Current learning rate: 0.00878 
2025-07-10 11:57:29.674397: train_loss -0.1363 
2025-07-10 11:57:29.675322: val_loss -0.143 
2025-07-10 11:57:29.675419: Pseudo dice [np.float32(0.8292)] 
2025-07-10 11:57:29.675554: Epoch time: 48.13 s 
2025-07-10 11:57:30.838692:  
2025-07-10 11:57:30.838829: Epoch 136 
2025-07-10 11:57:30.838925: Current learning rate: 0.00877 
2025-07-10 11:58:18.874444: train_loss -0.1392 
2025-07-10 11:58:18.875480: val_loss -0.1303 
2025-07-10 11:58:18.875571: Pseudo dice [np.float32(0.8265)] 
2025-07-10 11:58:18.875694: Epoch time: 48.04 s 
2025-07-10 11:58:19.994622:  
2025-07-10 11:58:19.995101: Epoch 137 
2025-07-10 11:58:19.995262: Current learning rate: 0.00876 
2025-07-10 11:59:06.602378: train_loss -0.1278 
2025-07-10 11:59:06.602894: val_loss -0.1245 
2025-07-10 11:59:06.602975: Pseudo dice [np.float32(0.8395)] 
2025-07-10 11:59:06.603086: Epoch time: 46.61 s 
2025-07-10 11:59:07.737671:  
2025-07-10 11:59:07.738094: Epoch 138 
2025-07-10 11:59:07.738251: Current learning rate: 0.00875 
2025-07-10 11:59:54.092317: train_loss -0.1251 
2025-07-10 11:59:54.092847: val_loss -0.1261 
2025-07-10 11:59:54.092934: Pseudo dice [np.float32(0.8415)] 
2025-07-10 11:59:54.093091: Epoch time: 46.36 s 
2025-07-10 11:59:55.307289:  
2025-07-10 11:59:55.307712: Epoch 139 
2025-07-10 11:59:55.307840: Current learning rate: 0.00874 
2025-07-10 12:00:42.919827: train_loss -0.1218 
2025-07-10 12:00:42.920410: val_loss -0.1319 
2025-07-10 12:00:42.920512: Pseudo dice [np.float32(0.8262)] 
2025-07-10 12:00:42.920638: Epoch time: 47.61 s 
2025-07-10 12:00:44.091367:  
2025-07-10 12:00:44.091777: Epoch 140 
2025-07-10 12:00:44.091960: Current learning rate: 0.00873 
2025-07-10 12:01:30.712713: train_loss -0.1374 
2025-07-10 12:01:30.713335: val_loss -0.1363 
2025-07-10 12:01:30.713429: Pseudo dice [np.float32(0.845)] 
2025-07-10 12:01:30.713550: Epoch time: 46.62 s 
2025-07-10 12:01:31.857054:  
2025-07-10 12:01:31.857453: Epoch 141 
2025-07-10 12:01:31.857584: Current learning rate: 0.00872 
2025-07-10 12:02:19.209086: train_loss -0.1272 
2025-07-10 12:02:19.209450: val_loss -0.1466 
2025-07-10 12:02:19.209558: Pseudo dice [np.float32(0.8045)] 
2025-07-10 12:02:19.209669: Epoch time: 47.35 s 
2025-07-10 12:02:20.339723:  
2025-07-10 12:02:20.340274: Epoch 142 
2025-07-10 12:02:20.340418: Current learning rate: 0.00871 
2025-07-10 12:03:08.081127: train_loss -0.1308 
2025-07-10 12:03:08.081499: val_loss -0.1324 
2025-07-10 12:03:08.081593: Pseudo dice [np.float32(0.8392)] 
2025-07-10 12:03:08.081691: Epoch time: 47.74 s 
2025-07-10 12:03:09.197954:  
2025-07-10 12:03:09.198364: Epoch 143 
2025-07-10 12:03:09.198602: Current learning rate: 0.0087 
2025-07-10 12:03:56.054415: train_loss -0.1412 
2025-07-10 12:03:56.055152: val_loss -0.1439 
2025-07-10 12:03:56.055236: Pseudo dice [np.float32(0.84)] 
2025-07-10 12:03:56.055359: Epoch time: 46.86 s 
2025-07-10 12:03:57.785407:  
2025-07-10 12:03:57.785616: Epoch 144 
2025-07-10 12:03:57.785883: Current learning rate: 0.00869 
2025-07-10 12:04:44.991741: train_loss -0.127 
2025-07-10 12:04:44.992714: val_loss -0.1375 
2025-07-10 12:04:44.992799: Pseudo dice [np.float32(0.8468)] 
2025-07-10 12:04:44.992918: Epoch time: 47.21 s 
2025-07-10 12:04:46.065825:  
2025-07-10 12:04:46.066055: Epoch 145 
2025-07-10 12:04:46.066262: Current learning rate: 0.00868 
2025-07-10 12:05:32.090949: train_loss -0.1315 
2025-07-10 12:05:32.091563: val_loss -0.1386 
2025-07-10 12:05:32.091679: Pseudo dice [np.float32(0.8396)] 
2025-07-10 12:05:32.091799: Epoch time: 46.03 s 
2025-07-10 12:05:33.185867:  
2025-07-10 12:05:33.186082: Epoch 146 
2025-07-10 12:05:33.186273: Current learning rate: 0.00868 
2025-07-10 12:06:20.085391: train_loss -0.1351 
2025-07-10 12:06:20.086035: val_loss -0.1389 
2025-07-10 12:06:20.086113: Pseudo dice [np.float32(0.8614)] 
2025-07-10 12:06:20.086219: Epoch time: 46.9 s 
2025-07-10 12:06:20.086290: Yayy! New best EMA pseudo Dice: 0.8374000191688538 
2025-07-10 12:06:22.196973:  
2025-07-10 12:06:22.197331: Epoch 147 
2025-07-10 12:06:22.197633: Current learning rate: 0.00867 
2025-07-10 12:07:09.308726: train_loss -0.1294 
2025-07-10 12:07:09.309263: val_loss -0.1335 
2025-07-10 12:07:09.309354: Pseudo dice [np.float32(0.8352)] 
2025-07-10 12:07:09.309479: Epoch time: 47.11 s 
2025-07-10 12:07:10.454556:  
2025-07-10 12:07:10.454900: Epoch 148 
2025-07-10 12:07:10.455024: Current learning rate: 0.00866 
2025-07-10 12:07:56.880928: train_loss -0.1309 
2025-07-10 12:07:56.881436: val_loss -0.1537 
2025-07-10 12:07:56.881532: Pseudo dice [np.float32(0.858)] 
2025-07-10 12:07:56.881674: Epoch time: 46.43 s 
2025-07-10 12:07:56.881767: Yayy! New best EMA pseudo Dice: 0.8392999768257141 
2025-07-10 12:07:58.966887:  
2025-07-10 12:07:58.967212: Epoch 149 
2025-07-10 12:07:58.967507: Current learning rate: 0.00865 
2025-07-10 12:08:44.441449: train_loss -0.139 
2025-07-10 12:08:44.441878: val_loss -0.1372 
2025-07-10 12:08:44.441977: Pseudo dice [np.float32(0.8347)] 
2025-07-10 12:08:44.442187: Epoch time: 45.48 s 
2025-07-10 12:08:46.509380:  
2025-07-10 12:08:46.509593: Epoch 150 
2025-07-10 12:08:46.509696: Current learning rate: 0.00864 
2025-07-10 12:09:31.648970: train_loss -0.1274 
2025-07-10 12:09:31.649273: val_loss -0.146 
2025-07-10 12:09:31.649369: Pseudo dice [np.float32(0.8315)] 
2025-07-10 12:09:31.649463: Epoch time: 45.14 s 
2025-07-10 12:09:32.734521:  
2025-07-10 12:09:32.734756: Epoch 151 
2025-07-10 12:09:32.734943: Current learning rate: 0.00863 
2025-07-10 12:10:18.333372: train_loss -0.1322 
2025-07-10 12:10:18.333920: val_loss -0.1494 
2025-07-10 12:10:18.334021: Pseudo dice [np.float32(0.841)] 
2025-07-10 12:10:18.334191: Epoch time: 45.6 s 
2025-07-10 12:10:19.490534:  
2025-07-10 12:10:19.490726: Epoch 152 
2025-07-10 12:10:19.490830: Current learning rate: 0.00862 
2025-07-10 12:11:04.599499: train_loss -0.1322 
2025-07-10 12:11:04.599940: val_loss -0.1387 
2025-07-10 12:11:04.600022: Pseudo dice [np.float32(0.8364)] 
2025-07-10 12:11:04.600133: Epoch time: 45.11 s 
2025-07-10 12:11:05.831516:  
2025-07-10 12:11:05.832047: Epoch 153 
2025-07-10 12:11:05.832179: Current learning rate: 0.00861 
2025-07-10 12:11:51.372446: train_loss -0.1312 
2025-07-10 12:11:51.372958: val_loss -0.1641 
2025-07-10 12:11:51.373042: Pseudo dice [np.float32(0.836)] 
2025-07-10 12:11:51.373144: Epoch time: 45.54 s 
2025-07-10 12:11:52.476339:  
2025-07-10 12:11:52.476666: Epoch 154 
2025-07-10 12:11:52.476772: Current learning rate: 0.0086 
2025-07-10 12:12:37.276430: train_loss -0.1323 
2025-07-10 12:12:37.277020: val_loss -0.1225 
2025-07-10 12:12:37.277119: Pseudo dice [np.float32(0.8438)] 
2025-07-10 12:12:37.277254: Epoch time: 44.8 s 
2025-07-10 12:12:39.000412:  
2025-07-10 12:12:39.000755: Epoch 155 
2025-07-10 12:12:39.000932: Current learning rate: 0.00859 
2025-07-10 12:13:23.861867: train_loss -0.1363 
2025-07-10 12:13:23.862179: val_loss -0.1509 
2025-07-10 12:13:23.862260: Pseudo dice [np.float32(0.8422)] 
2025-07-10 12:13:23.862365: Epoch time: 44.86 s 
2025-07-10 12:13:24.911769:  
2025-07-10 12:13:24.911900: Epoch 156 
2025-07-10 12:13:24.912004: Current learning rate: 0.00858 
2025-07-10 12:14:10.091315: train_loss -0.1375 
2025-07-10 12:14:10.091744: val_loss -0.1467 
2025-07-10 12:14:10.091826: Pseudo dice [np.float32(0.8363)] 
2025-07-10 12:14:10.091931: Epoch time: 45.18 s 
2025-07-10 12:14:11.252374:  
2025-07-10 12:14:11.252799: Epoch 157 
2025-07-10 12:14:11.253009: Current learning rate: 0.00858 
2025-07-10 12:14:56.890249: train_loss -0.1389 
2025-07-10 12:14:56.890799: val_loss -0.1289 
2025-07-10 12:14:56.890877: Pseudo dice [np.float32(0.841)] 
2025-07-10 12:14:56.890976: Epoch time: 45.64 s 
2025-07-10 12:14:58.000964:  
2025-07-10 12:14:58.001203: Epoch 158 
2025-07-10 12:14:58.001407: Current learning rate: 0.00857 
2025-07-10 12:15:43.810533: train_loss -0.1366 
2025-07-10 12:15:43.810818: val_loss -0.1382 
2025-07-10 12:15:43.810897: Pseudo dice [np.float32(0.85)] 
2025-07-10 12:15:43.810986: Epoch time: 45.81 s 
2025-07-10 12:15:43.811060: Yayy! New best EMA pseudo Dice: 0.8399999737739563 
2025-07-10 12:15:45.950199:  
2025-07-10 12:15:45.950489: Epoch 159 
2025-07-10 12:15:45.950748: Current learning rate: 0.00856 
2025-07-10 12:16:32.237592: train_loss -0.1357 
2025-07-10 12:16:32.238133: val_loss -0.1389 
2025-07-10 12:16:32.238290: Pseudo dice [np.float32(0.842)] 
2025-07-10 12:16:32.238596: Epoch time: 46.29 s 
2025-07-10 12:16:32.239331: Yayy! New best EMA pseudo Dice: 0.8402000069618225 
2025-07-10 12:16:34.319048:  
2025-07-10 12:16:34.319190: Epoch 160 
2025-07-10 12:16:34.319412: Current learning rate: 0.00855 
2025-07-10 12:17:20.109287: train_loss -0.1382 
2025-07-10 12:17:20.109820: val_loss -0.1538 
2025-07-10 12:17:20.109900: Pseudo dice [np.float32(0.8522)] 
2025-07-10 12:17:20.110003: Epoch time: 45.79 s 
2025-07-10 12:17:20.110076: Yayy! New best EMA pseudo Dice: 0.8414000272750854 
2025-07-10 12:17:22.249923:  
2025-07-10 12:17:22.250175: Epoch 161 
2025-07-10 12:17:22.250452: Current learning rate: 0.00854 
2025-07-10 12:18:07.842000: train_loss -0.1365 
2025-07-10 12:18:07.842564: val_loss -0.1522 
2025-07-10 12:18:07.842661: Pseudo dice [np.float32(0.8575)] 
2025-07-10 12:18:07.842763: Epoch time: 45.59 s 
2025-07-10 12:18:07.842838: Yayy! New best EMA pseudo Dice: 0.8429999947547913 
2025-07-10 12:18:09.930699:  
2025-07-10 12:18:09.931186: Epoch 162 
2025-07-10 12:18:09.931462: Current learning rate: 0.00853 
2025-07-10 12:18:55.525839: train_loss -0.1329 
2025-07-10 12:18:55.526221: val_loss -0.1586 
2025-07-10 12:18:55.526308: Pseudo dice [np.float32(0.8548)] 
2025-07-10 12:18:55.526412: Epoch time: 45.6 s 
2025-07-10 12:18:55.526483: Yayy! New best EMA pseudo Dice: 0.8442000150680542 
2025-07-10 12:18:57.667986:  
2025-07-10 12:18:57.668411: Epoch 163 
2025-07-10 12:18:57.668598: Current learning rate: 0.00852 
2025-07-10 12:19:43.306829: train_loss -0.1351 
2025-07-10 12:19:43.307532: val_loss -0.1427 
2025-07-10 12:19:43.307748: Pseudo dice [np.float32(0.8598)] 
2025-07-10 12:19:43.307881: Epoch time: 45.64 s 
2025-07-10 12:19:43.308066: Yayy! New best EMA pseudo Dice: 0.8457000255584717 
2025-07-10 12:19:45.437261:  
2025-07-10 12:19:45.437771: Epoch 164 
2025-07-10 12:19:45.437897: Current learning rate: 0.00851 
2025-07-10 12:20:30.654035: train_loss -0.1353 
2025-07-10 12:20:30.654641: val_loss -0.1492 
2025-07-10 12:20:30.654730: Pseudo dice [np.float32(0.8484)] 
2025-07-10 12:20:30.654845: Epoch time: 45.22 s 
2025-07-10 12:20:30.654924: Yayy! New best EMA pseudo Dice: 0.8460000157356262 
2025-07-10 12:20:32.745584:  
2025-07-10 12:20:32.745863: Epoch 165 
2025-07-10 12:20:32.746095: Current learning rate: 0.0085 
2025-07-10 12:21:18.689638: train_loss -0.1409 
2025-07-10 12:21:18.690084: val_loss -0.146 
2025-07-10 12:21:18.690168: Pseudo dice [np.float32(0.8514)] 
2025-07-10 12:21:18.690278: Epoch time: 45.95 s 
2025-07-10 12:21:18.690357: Yayy! New best EMA pseudo Dice: 0.8464999794960022 
2025-07-10 12:21:21.396038:  
2025-07-10 12:21:21.396310: Epoch 166 
2025-07-10 12:21:21.396621: Current learning rate: 0.00849 
2025-07-10 12:22:07.712962: train_loss -0.1365 
2025-07-10 12:22:07.713335: val_loss -0.1399 
2025-07-10 12:22:07.713410: Pseudo dice [np.float32(0.8365)] 
2025-07-10 12:22:07.713508: Epoch time: 46.32 s 
2025-07-10 12:22:08.768392:  
2025-07-10 12:22:08.768535: Epoch 167 
2025-07-10 12:22:08.768650: Current learning rate: 0.00848 
2025-07-10 12:22:54.672423: train_loss -0.1347 
2025-07-10 12:22:54.672827: val_loss -0.1305 
2025-07-10 12:22:54.672922: Pseudo dice [np.float32(0.8518)] 
2025-07-10 12:22:54.673030: Epoch time: 45.91 s 
2025-07-10 12:22:55.814243:  
2025-07-10 12:22:55.814880: Epoch 168 
2025-07-10 12:22:55.815057: Current learning rate: 0.00847 
2025-07-10 12:23:41.876143: train_loss -0.1369 
2025-07-10 12:23:41.877031: val_loss -0.1462 
2025-07-10 12:23:41.877116: Pseudo dice [np.float32(0.8507)] 
2025-07-10 12:23:41.877235: Epoch time: 46.06 s 
2025-07-10 12:23:41.877315: Yayy! New best EMA pseudo Dice: 0.8465999960899353 
2025-07-10 12:23:43.945168:  
2025-07-10 12:23:43.945395: Epoch 169 
2025-07-10 12:23:43.945588: Current learning rate: 0.00847 
2025-07-10 12:24:30.216164: train_loss -0.152 
2025-07-10 12:24:30.217705: val_loss -0.1172 
2025-07-10 12:24:30.217863: Pseudo dice [np.float32(0.8434)] 
2025-07-10 12:24:30.218210: Epoch time: 46.27 s 
2025-07-10 12:24:31.363581:  
2025-07-10 12:24:31.363928: Epoch 170 
2025-07-10 12:24:31.364057: Current learning rate: 0.00846 
2025-07-10 12:25:17.164530: train_loss -0.122 
2025-07-10 12:25:17.164954: val_loss -0.1329 
2025-07-10 12:25:17.165030: Pseudo dice [np.float32(0.853)] 
2025-07-10 12:25:17.165138: Epoch time: 45.8 s 
2025-07-10 12:25:17.165208: Yayy! New best EMA pseudo Dice: 0.847000002861023 
2025-07-10 12:25:19.369760:  
2025-07-10 12:25:19.370146: Epoch 171 
2025-07-10 12:25:19.370309: Current learning rate: 0.00845 
2025-07-10 12:26:05.283774: train_loss -0.1409 
2025-07-10 12:26:05.284116: val_loss -0.1341 
2025-07-10 12:26:05.284323: Pseudo dice [np.float32(0.8615)] 
2025-07-10 12:26:05.284426: Epoch time: 45.92 s 
2025-07-10 12:26:05.284500: Yayy! New best EMA pseudo Dice: 0.8483999967575073 
2025-07-10 12:26:07.242520:  
2025-07-10 12:26:07.242912: Epoch 172 
2025-07-10 12:26:07.243056: Current learning rate: 0.00844 
2025-07-10 12:26:52.676109: train_loss -0.1493 
2025-07-10 12:26:52.676610: val_loss -0.1281 
2025-07-10 12:26:52.676717: Pseudo dice [np.float32(0.8277)] 
2025-07-10 12:26:52.676818: Epoch time: 45.43 s 
2025-07-10 12:26:53.833416:  
2025-07-10 12:26:53.833699: Epoch 173 
2025-07-10 12:26:53.833818: Current learning rate: 0.00843 
2025-07-10 12:27:39.389126: train_loss -0.1339 
2025-07-10 12:27:39.389547: val_loss -0.1423 
2025-07-10 12:27:39.389647: Pseudo dice [np.float32(0.8429)] 
2025-07-10 12:27:39.389762: Epoch time: 45.56 s 
2025-07-10 12:27:40.596985:  
2025-07-10 12:27:40.597178: Epoch 174 
2025-07-10 12:27:40.597310: Current learning rate: 0.00842 
2025-07-10 12:28:26.445012: train_loss -0.1285 
2025-07-10 12:28:26.445392: val_loss -0.1496 
2025-07-10 12:28:26.445465: Pseudo dice [np.float32(0.8347)] 
2025-07-10 12:28:26.445579: Epoch time: 45.85 s 
2025-07-10 12:28:27.839469:  
2025-07-10 12:28:27.840129: Epoch 175 
2025-07-10 12:28:27.840343: Current learning rate: 0.00841 
2025-07-10 12:29:13.162383: train_loss -0.1397 
2025-07-10 12:29:13.162862: val_loss -0.1348 
2025-07-10 12:29:13.162941: Pseudo dice [np.float32(0.8582)] 
2025-07-10 12:29:13.163043: Epoch time: 45.32 s 
2025-07-10 12:29:14.322547:  
2025-07-10 12:29:14.322789: Epoch 176 
2025-07-10 12:29:14.322942: Current learning rate: 0.0084 
2025-07-10 12:30:00.711914: train_loss -0.138 
2025-07-10 12:30:00.712175: val_loss -0.1413 
2025-07-10 12:30:00.712246: Pseudo dice [np.float32(0.8428)] 
2025-07-10 12:30:00.712343: Epoch time: 46.39 s 
2025-07-10 12:30:02.412639:  
2025-07-10 12:30:02.413068: Epoch 177 
2025-07-10 12:30:02.413304: Current learning rate: 0.00839 
2025-07-10 12:30:48.407366: train_loss -0.1431 
2025-07-10 12:30:48.407719: val_loss -0.1307 
2025-07-10 12:30:48.407814: Pseudo dice [np.float32(0.8265)] 
2025-07-10 12:30:48.407923: Epoch time: 46.0 s 
2025-07-10 12:30:49.577494:  
2025-07-10 12:30:49.577842: Epoch 178 
2025-07-10 12:30:49.578090: Current learning rate: 0.00838 
2025-07-10 12:31:35.203833: train_loss -0.1244 
2025-07-10 12:31:35.204497: val_loss -0.1425 
2025-07-10 12:31:35.204633: Pseudo dice [np.float32(0.8598)] 
2025-07-10 12:31:35.204777: Epoch time: 45.63 s 
2025-07-10 12:31:36.365861:  
2025-07-10 12:31:36.366423: Epoch 179 
2025-07-10 12:31:36.366567: Current learning rate: 0.00837 
2025-07-10 12:32:21.815346: train_loss -0.1375 
2025-07-10 12:32:21.815806: val_loss -0.1478 
2025-07-10 12:32:21.815892: Pseudo dice [np.float32(0.8535)] 
2025-07-10 12:32:21.816004: Epoch time: 45.45 s 
2025-07-10 12:32:22.949115:  
2025-07-10 12:32:22.949475: Epoch 180 
2025-07-10 12:32:22.949763: Current learning rate: 0.00836 
2025-07-10 12:33:08.531281: train_loss -0.1398 
2025-07-10 12:33:08.532027: val_loss -0.1513 
2025-07-10 12:33:08.532130: Pseudo dice [np.float32(0.8515)] 
2025-07-10 12:33:08.532266: Epoch time: 45.58 s 
2025-07-10 12:33:09.672049:  
2025-07-10 12:33:09.672505: Epoch 181 
2025-07-10 12:33:09.672644: Current learning rate: 0.00836 
2025-07-10 12:33:55.133385: train_loss -0.1312 
2025-07-10 12:33:55.133942: val_loss -0.1145 
2025-07-10 12:33:55.134036: Pseudo dice [np.float32(0.8163)] 
2025-07-10 12:33:55.134156: Epoch time: 45.46 s 
2025-07-10 12:33:56.275688:  
2025-07-10 12:33:56.276175: Epoch 182 
2025-07-10 12:33:56.276302: Current learning rate: 0.00835 
2025-07-10 12:34:41.813343: train_loss -0.1273 
2025-07-10 12:34:41.813695: val_loss -0.1291 
2025-07-10 12:34:41.813772: Pseudo dice [np.float32(0.8168)] 
2025-07-10 12:34:41.813876: Epoch time: 45.54 s 
2025-07-10 12:34:42.954142:  
2025-07-10 12:34:42.954479: Epoch 183 
2025-07-10 12:34:42.954617: Current learning rate: 0.00834 
2025-07-10 12:35:29.079801: train_loss -0.1451 
2025-07-10 12:35:29.080445: val_loss -0.1416 
2025-07-10 12:35:29.080527: Pseudo dice [np.float32(0.8396)] 
2025-07-10 12:35:29.080644: Epoch time: 46.13 s 
2025-07-10 12:35:30.222704:  
2025-07-10 12:35:30.222980: Epoch 184 
2025-07-10 12:35:30.223292: Current learning rate: 0.00833 
2025-07-10 12:36:15.985265: train_loss -0.1389 
2025-07-10 12:36:15.985749: val_loss -0.1305 
2025-07-10 12:36:15.989582: Pseudo dice [np.float32(0.8498)] 
2025-07-10 12:36:15.989810: Epoch time: 45.76 s 
2025-07-10 12:36:17.331042:  
2025-07-10 12:36:17.331634: Epoch 185 
2025-07-10 12:36:17.331798: Current learning rate: 0.00832 
2025-07-10 12:37:02.791868: train_loss -0.1347 
2025-07-10 12:37:02.792483: val_loss -0.1312 
2025-07-10 12:37:02.792585: Pseudo dice [np.float32(0.8458)] 
2025-07-10 12:37:02.792704: Epoch time: 45.46 s 
2025-07-10 12:37:03.969298:  
2025-07-10 12:37:03.969609: Epoch 186 
2025-07-10 12:37:03.969807: Current learning rate: 0.00831 
2025-07-10 12:37:50.525908: train_loss -0.1391 
2025-07-10 12:37:50.526486: val_loss -0.1517 
2025-07-10 12:37:50.526654: Pseudo dice [np.float32(0.8591)] 
2025-07-10 12:37:50.526799: Epoch time: 46.56 s 
2025-07-10 12:37:51.675467:  
2025-07-10 12:37:51.675896: Epoch 187 
2025-07-10 12:37:51.676068: Current learning rate: 0.0083 
2025-07-10 12:38:38.047074: train_loss -0.14 
2025-07-10 12:38:38.047855: val_loss -0.1362 
2025-07-10 12:38:38.047946: Pseudo dice [np.float32(0.8493)] 
2025-07-10 12:38:38.048064: Epoch time: 46.37 s 
2025-07-10 12:38:39.196379:  
2025-07-10 12:38:39.196836: Epoch 188 
2025-07-10 12:38:39.197011: Current learning rate: 0.00829 
2025-07-10 12:39:24.319454: train_loss -0.139 
2025-07-10 12:39:24.319924: val_loss -0.1539 
2025-07-10 12:39:24.320079: Pseudo dice [np.float32(0.8429)] 
2025-07-10 12:39:24.320196: Epoch time: 45.12 s 
2025-07-10 12:39:26.222973:  
2025-07-10 12:39:26.223627: Epoch 189 
2025-07-10 12:39:26.223915: Current learning rate: 0.00828 
2025-07-10 12:40:11.695055: train_loss -0.1375 
2025-07-10 12:40:11.695990: val_loss -0.1678 
2025-07-10 12:40:11.696113: Pseudo dice [np.float32(0.8609)] 
2025-07-10 12:40:11.696399: Epoch time: 45.47 s 
2025-07-10 12:40:12.848497:  
2025-07-10 12:40:12.849122: Epoch 190 
2025-07-10 12:40:12.849432: Current learning rate: 0.00827 
2025-07-10 12:40:58.673803: train_loss -0.1303 
2025-07-10 12:40:58.674208: val_loss -0.1579 
2025-07-10 12:40:58.674284: Pseudo dice [np.float32(0.847)] 
2025-07-10 12:40:58.674389: Epoch time: 45.83 s 
2025-07-10 12:40:59.813410:  
2025-07-10 12:40:59.814054: Epoch 191 
2025-07-10 12:40:59.814291: Current learning rate: 0.00826 
2025-07-10 12:41:46.016361: train_loss -0.1421 
2025-07-10 12:41:46.017016: val_loss -0.1489 
2025-07-10 12:41:46.017128: Pseudo dice [np.float32(0.8541)] 
2025-07-10 12:41:46.017255: Epoch time: 46.2 s 
2025-07-10 12:41:47.166585:  
2025-07-10 12:41:47.166865: Epoch 192 
2025-07-10 12:41:47.167002: Current learning rate: 0.00825 
2025-07-10 12:42:33.415456: train_loss -0.1473 
2025-07-10 12:42:33.415961: val_loss -0.1554 
2025-07-10 12:42:33.416049: Pseudo dice [np.float32(0.8478)] 
2025-07-10 12:42:33.416172: Epoch time: 46.25 s 
2025-07-10 12:42:34.548563:  
2025-07-10 12:42:34.548883: Epoch 193 
2025-07-10 12:42:34.549043: Current learning rate: 0.00824 
2025-07-10 12:43:21.030772: train_loss -0.1348 
2025-07-10 12:43:21.031706: val_loss -0.1537 
2025-07-10 12:43:21.031794: Pseudo dice [np.float32(0.843)] 
2025-07-10 12:43:21.031906: Epoch time: 46.48 s 
2025-07-10 12:43:22.136468:  
2025-07-10 12:43:22.136818: Epoch 194 
2025-07-10 12:43:22.137004: Current learning rate: 0.00824 
2025-07-10 12:44:07.807518: train_loss -0.1436 
2025-07-10 12:44:07.807965: val_loss -0.1726 
2025-07-10 12:44:07.808040: Pseudo dice [np.float32(0.8491)] 
2025-07-10 12:44:07.808136: Epoch time: 45.67 s 
2025-07-10 12:44:08.900268:  
2025-07-10 12:44:08.900621: Epoch 195 
2025-07-10 12:44:08.900754: Current learning rate: 0.00823 
2025-07-10 12:44:53.983952: train_loss -0.1434 
2025-07-10 12:44:53.984422: val_loss -0.1378 
2025-07-10 12:44:53.984498: Pseudo dice [np.float32(0.836)] 
2025-07-10 12:44:53.984609: Epoch time: 45.08 s 
2025-07-10 12:44:55.169936:  
2025-07-10 12:44:55.170307: Epoch 196 
2025-07-10 12:44:55.170481: Current learning rate: 0.00822 
2025-07-10 12:45:40.851963: train_loss -0.1409 
2025-07-10 12:45:40.852517: val_loss -0.1297 
2025-07-10 12:45:40.852618: Pseudo dice [np.float32(0.8306)] 
2025-07-10 12:45:40.852731: Epoch time: 45.68 s 
2025-07-10 12:45:42.081385:  
2025-07-10 12:45:42.081783: Epoch 197 
2025-07-10 12:45:42.081927: Current learning rate: 0.00821 
2025-07-10 12:46:28.292952: train_loss -0.1481 
2025-07-10 12:46:28.293291: val_loss -0.1618 
2025-07-10 12:46:28.293427: Pseudo dice [np.float32(0.8404)] 
2025-07-10 12:46:28.293571: Epoch time: 46.21 s 
2025-07-10 12:46:29.469466:  
2025-07-10 12:46:29.470019: Epoch 198 
2025-07-10 12:46:29.470346: Current learning rate: 0.0082 
2025-07-10 12:47:15.833328: train_loss -0.1335 
2025-07-10 12:47:15.833784: val_loss -0.1508 
2025-07-10 12:47:15.833868: Pseudo dice [np.float32(0.8338)] 
2025-07-10 12:47:15.833982: Epoch time: 46.36 s 
2025-07-10 12:47:17.084747:  
2025-07-10 12:47:17.085241: Epoch 199 
2025-07-10 12:47:17.085367: Current learning rate: 0.00819 
2025-07-10 12:48:05.009868: train_loss -0.1366 
2025-07-10 12:48:05.010238: val_loss -0.1342 
2025-07-10 12:48:05.010318: Pseudo dice [np.float32(0.8274)] 
2025-07-10 12:48:05.010412: Epoch time: 47.93 s 
2025-07-10 12:48:07.107081:  
2025-07-10 12:48:07.107284: Epoch 200 
2025-07-10 12:48:07.107381: Current learning rate: 0.00818 
2025-07-10 12:48:52.792216: train_loss -0.1337 
2025-07-10 12:48:52.792882: val_loss -0.145 
2025-07-10 12:48:52.792969: Pseudo dice [np.float32(0.8384)] 
2025-07-10 12:48:52.793085: Epoch time: 45.69 s 
2025-07-10 12:48:54.161670:  
2025-07-10 12:48:54.162134: Epoch 201 
2025-07-10 12:48:54.162261: Current learning rate: 0.00817 
2025-07-10 12:49:40.753938: train_loss -0.1359 
2025-07-10 12:49:40.754767: val_loss -0.1519 
2025-07-10 12:49:40.754903: Pseudo dice [np.float32(0.854)] 
2025-07-10 12:49:40.755042: Epoch time: 46.59 s 
2025-07-10 12:49:41.931815:  
2025-07-10 12:49:41.932282: Epoch 202 
2025-07-10 12:49:41.932410: Current learning rate: 0.00816 
2025-07-10 12:50:27.715497: train_loss -0.1427 
2025-07-10 12:50:27.716064: val_loss -0.1489 
2025-07-10 12:50:27.716142: Pseudo dice [np.float32(0.8616)] 
2025-07-10 12:50:27.716267: Epoch time: 45.78 s 
2025-07-10 12:50:28.916979:  
2025-07-10 12:50:28.917721: Epoch 203 
2025-07-10 12:50:28.917931: Current learning rate: 0.00815 
2025-07-10 12:51:15.210057: train_loss -0.1394 
2025-07-10 12:51:15.210438: val_loss -0.1465 
2025-07-10 12:51:15.210592: Pseudo dice [np.float32(0.8607)] 
2025-07-10 12:51:15.210700: Epoch time: 46.29 s 
2025-07-10 12:51:16.321939:  
2025-07-10 12:51:16.322173: Epoch 204 
2025-07-10 12:51:16.322299: Current learning rate: 0.00814 
2025-07-10 12:52:01.591431: train_loss -0.1492 
2025-07-10 12:52:01.591962: val_loss -0.1566 
2025-07-10 12:52:01.592114: Pseudo dice [np.float32(0.8508)] 
2025-07-10 12:52:01.592218: Epoch time: 45.27 s 
2025-07-10 12:52:02.746192:  
2025-07-10 12:52:02.746444: Epoch 205 
2025-07-10 12:52:02.746577: Current learning rate: 0.00813 
2025-07-10 12:52:48.573703: train_loss -0.2834 
2025-07-10 12:52:48.573996: val_loss -0.2221 
2025-07-10 12:52:48.574070: Pseudo dice [np.float32(0.0244)] 
2025-07-10 12:52:48.574171: Epoch time: 45.83 s 
2025-07-10 12:52:49.733335:  
2025-07-10 12:52:49.733580: Epoch 206 
2025-07-10 12:52:49.733748: Current learning rate: 0.00813 
2025-07-10 12:53:35.212063: train_loss -0.2795 
2025-07-10 12:53:35.212678: val_loss -0.2058 
2025-07-10 12:53:35.212772: Pseudo dice [np.float32(0.3483)] 
2025-07-10 12:53:35.212887: Epoch time: 45.48 s 
2025-07-10 12:53:36.332011:  
2025-07-10 12:53:36.332261: Epoch 207 
2025-07-10 12:53:36.332421: Current learning rate: 0.00812 
2025-07-10 12:54:22.344081: train_loss -0.2667 
2025-07-10 12:54:22.344711: val_loss -0.3396 
2025-07-10 12:54:22.344822: Pseudo dice [np.float32(0.4626)] 
2025-07-10 12:54:22.344943: Epoch time: 46.01 s 
2025-07-10 12:54:23.437448:  
2025-07-10 12:54:23.437934: Epoch 208 
2025-07-10 12:54:23.438213: Current learning rate: 0.00811 
2025-07-10 12:55:09.687749: train_loss -0.3185 
2025-07-10 12:55:09.688267: val_loss -0.3569 
2025-07-10 12:55:09.688346: Pseudo dice [np.float32(0.4255)] 
2025-07-10 12:55:09.688463: Epoch time: 46.25 s 
2025-07-10 12:55:10.899253:  
2025-07-10 12:55:10.899535: Epoch 209 
2025-07-10 12:55:10.899682: Current learning rate: 0.0081 
2025-07-10 12:55:57.774615: train_loss -0.3255 
2025-07-10 12:55:57.776049: val_loss -0.2417 
2025-07-10 12:55:57.776181: Pseudo dice [np.float32(0.2017)] 
2025-07-10 12:55:57.776357: Epoch time: 46.88 s 
2025-07-10 12:55:58.969337:  
2025-07-10 12:55:58.969651: Epoch 210 
2025-07-10 12:55:58.969777: Current learning rate: 0.00809 
2025-07-10 12:56:45.120941: train_loss -0.2757 
2025-07-10 12:56:45.121306: val_loss -0.2344 
2025-07-10 12:56:45.121383: Pseudo dice [np.float32(0.0)] 
2025-07-10 12:56:45.121492: Epoch time: 46.15 s 
2025-07-10 12:56:46.875809:  
2025-07-10 12:56:46.876103: Epoch 211 
2025-07-10 12:56:46.876228: Current learning rate: 0.00808 
2025-07-10 12:57:33.429807: train_loss -0.243 
2025-07-10 12:57:33.430773: val_loss -0.2502 
2025-07-10 12:57:33.430933: Pseudo dice [np.float32(0.0)] 
2025-07-10 12:57:33.431111: Epoch time: 46.55 s 
2025-07-10 12:57:34.605068:  
2025-07-10 12:57:34.605273: Epoch 212 
2025-07-10 12:57:34.605370: Current learning rate: 0.00807 
2025-07-10 12:58:21.525067: train_loss -0.265 
2025-07-10 12:58:21.525470: val_loss -0.2229 
2025-07-10 12:58:21.525562: Pseudo dice [np.float32(0.0)] 
2025-07-10 12:58:21.525662: Epoch time: 46.92 s 
2025-07-10 12:58:22.739184:  
2025-07-10 12:58:22.739794: Epoch 213 
2025-07-10 12:58:22.739995: Current learning rate: 0.00806 
2025-07-10 12:59:09.208379: train_loss -0.2497 
2025-07-10 12:59:09.208885: val_loss -0.2784 
2025-07-10 12:59:09.208982: Pseudo dice [np.float32(0.0)] 
2025-07-10 12:59:09.209099: Epoch time: 46.47 s 
2025-07-10 12:59:10.375940:  
2025-07-10 12:59:10.376392: Epoch 214 
2025-07-10 12:59:10.376523: Current learning rate: 0.00805 
2025-07-10 12:59:56.982120: train_loss -0.3023 
2025-07-10 12:59:56.982645: val_loss -0.3654 
2025-07-10 12:59:56.982728: Pseudo dice [np.float32(0.5566)] 
2025-07-10 12:59:56.982846: Epoch time: 46.61 s 
2025-07-10 12:59:58.145401:  
2025-07-10 12:59:58.146392: Epoch 215 
2025-07-10 12:59:58.146856: Current learning rate: 0.00804 
2025-07-10 13:00:44.945456: train_loss -0.331 
2025-07-10 13:00:44.945873: val_loss -0.3225 
2025-07-10 13:00:44.945949: Pseudo dice [np.float32(0.4807)] 
2025-07-10 13:00:44.946055: Epoch time: 46.8 s 
2025-07-10 13:00:46.086343:  
2025-07-10 13:00:46.086708: Epoch 216 
2025-07-10 13:00:46.086894: Current learning rate: 0.00803 
2025-07-10 13:01:32.119620: train_loss -0.3632 
2025-07-10 13:01:32.120100: val_loss -0.3663 
2025-07-10 13:01:32.120180: Pseudo dice [np.float32(0.5399)] 
2025-07-10 13:01:32.120358: Epoch time: 46.03 s 
2025-07-10 13:01:33.314766:  
2025-07-10 13:01:33.315144: Epoch 217 
2025-07-10 13:01:33.315289: Current learning rate: 0.00802 
2025-07-10 13:02:19.906373: train_loss -0.3359 
2025-07-10 13:02:19.907145: val_loss -0.349 
2025-07-10 13:02:19.907279: Pseudo dice [np.float32(0.5463)] 
2025-07-10 13:02:19.907432: Epoch time: 46.59 s 
2025-07-10 13:02:21.050746:  
2025-07-10 13:02:21.051091: Epoch 218 
2025-07-10 13:02:21.051244: Current learning rate: 0.00801 
2025-07-10 13:03:07.008265: train_loss -0.3267 
2025-07-10 13:03:07.008659: val_loss -0.2462 
2025-07-10 13:03:07.008741: Pseudo dice [np.float32(0.0)] 
2025-07-10 13:03:07.008845: Epoch time: 45.96 s 
2025-07-10 13:03:08.252923:  
2025-07-10 13:03:08.253572: Epoch 219 
2025-07-10 13:03:08.253752: Current learning rate: 0.00801 
2025-07-10 13:03:54.509946: train_loss -0.2707 
2025-07-10 13:03:54.510286: val_loss -0.1972 
2025-07-10 13:03:54.510370: Pseudo dice [np.float32(0.0)] 
2025-07-10 13:03:54.510482: Epoch time: 46.26 s 
2025-07-10 13:03:55.648425:  
2025-07-10 13:03:55.649086: Epoch 220 
2025-07-10 13:03:55.649213: Current learning rate: 0.008 
2025-07-10 13:04:41.565001: train_loss -0.2443 
2025-07-10 13:04:41.565444: val_loss -0.285 
2025-07-10 13:04:41.565520: Pseudo dice [np.float32(0.0)] 
2025-07-10 13:04:41.565626: Epoch time: 45.92 s 
2025-07-10 13:04:42.661478:  
2025-07-10 13:04:42.661740: Epoch 221 
2025-07-10 13:04:42.661847: Current learning rate: 0.00799 
2025-07-10 13:05:28.052345: train_loss -0.3143 
2025-07-10 13:05:28.052835: val_loss -0.3258 
2025-07-10 13:05:28.052909: Pseudo dice [np.float32(0.4438)] 
2025-07-10 13:05:28.053022: Epoch time: 45.39 s 
2025-07-10 13:05:29.200238:  
2025-07-10 13:05:29.200511: Epoch 222 
2025-07-10 13:05:29.200659: Current learning rate: 0.00798 
2025-07-10 13:06:15.770812: train_loss -0.3585 
2025-07-10 13:06:15.771247: val_loss -0.3699 
2025-07-10 13:06:15.771330: Pseudo dice [np.float32(0.5042)] 
2025-07-10 13:06:15.771433: Epoch time: 46.57 s 
2025-07-10 13:06:16.910603:  
2025-07-10 13:06:16.910784: Epoch 223 
2025-07-10 13:06:16.910908: Current learning rate: 0.00797 
2025-07-10 13:07:04.022307: train_loss -0.3474 
2025-07-10 13:07:04.022924: val_loss -0.3842 
2025-07-10 13:07:04.023075: Pseudo dice [np.float32(0.5006)] 
2025-07-10 13:07:04.023204: Epoch time: 47.11 s 
2025-07-10 13:07:05.185579:  
2025-07-10 13:07:05.185782: Epoch 224 
2025-07-10 13:07:05.186069: Current learning rate: 0.00796 
2025-07-10 13:07:52.550976: train_loss -0.3297 
2025-07-10 13:07:52.551425: val_loss -0.373 
2025-07-10 13:07:52.551529: Pseudo dice [np.float32(0.4685)] 
2025-07-10 13:07:52.551648: Epoch time: 47.37 s 
2025-07-10 13:07:53.646895:  
2025-07-10 13:07:53.647238: Epoch 225 
2025-07-10 13:07:53.647462: Current learning rate: 0.00795 
2025-07-10 13:08:41.061283: train_loss -0.3597 
2025-07-10 13:08:41.062199: val_loss -0.365 
2025-07-10 13:08:41.062331: Pseudo dice [np.float32(0.4063)] 
2025-07-10 13:08:41.062510: Epoch time: 47.42 s 
2025-07-10 13:08:42.260841:  
2025-07-10 13:08:42.261164: Epoch 226 
2025-07-10 13:08:42.261289: Current learning rate: 0.00794 
2025-07-10 13:09:29.760084: train_loss -0.3741 
2025-07-10 13:09:29.760645: val_loss -0.3717 
2025-07-10 13:09:29.760737: Pseudo dice [np.float32(0.4717)] 
2025-07-10 13:09:29.760864: Epoch time: 47.5 s 
2025-07-10 13:09:30.916293:  
2025-07-10 13:09:30.917016: Epoch 227 
2025-07-10 13:09:30.917140: Current learning rate: 0.00793 
2025-07-10 13:10:19.090252: train_loss -0.3552 
2025-07-10 13:10:19.091229: val_loss -0.3836 
2025-07-10 13:10:19.091362: Pseudo dice [np.float32(0.5552)] 
2025-07-10 13:10:19.091536: Epoch time: 48.18 s 
2025-07-10 13:10:20.239896:  
2025-07-10 13:10:20.240334: Epoch 228 
2025-07-10 13:10:20.240512: Current learning rate: 0.00792 
2025-07-10 13:11:08.141209: train_loss -0.3646 
2025-07-10 13:11:08.141907: val_loss -0.2906 
2025-07-10 13:11:08.142031: Pseudo dice [np.float32(0.3906)] 
2025-07-10 13:11:08.142184: Epoch time: 47.9 s 
2025-07-10 13:11:09.285809:  
2025-07-10 13:11:09.286240: Epoch 229 
2025-07-10 13:11:09.286373: Current learning rate: 0.00791 
2025-07-10 13:11:56.764234: train_loss -0.3408 
2025-07-10 13:11:56.764587: val_loss -0.2569 
2025-07-10 13:11:56.764669: Pseudo dice [np.float32(0.0843)] 
2025-07-10 13:11:56.764772: Epoch time: 47.48 s 
2025-07-10 13:11:57.953724:  
2025-07-10 13:11:57.954144: Epoch 230 
2025-07-10 13:11:57.954333: Current learning rate: 0.0079 
2025-07-10 13:12:46.524778: train_loss -0.3529 
2025-07-10 13:12:46.525116: val_loss -0.3427 
2025-07-10 13:12:46.525197: Pseudo dice [np.float32(0.5143)] 
2025-07-10 13:12:46.525356: Epoch time: 48.57 s 
2025-07-10 13:12:47.599133:  
2025-07-10 13:12:47.599590: Epoch 231 
2025-07-10 13:12:47.599718: Current learning rate: 0.00789 
2025-07-10 13:13:35.168726: train_loss -0.3362 
2025-07-10 13:13:35.169104: val_loss -0.2158 
2025-07-10 13:13:35.169177: Pseudo dice [np.float32(0.0)] 
2025-07-10 13:13:35.169273: Epoch time: 47.57 s 
2025-07-10 13:13:36.279836:  
2025-07-10 13:13:36.280126: Epoch 232 
2025-07-10 13:13:36.280259: Current learning rate: 0.00789 
2025-07-10 13:14:23.949751: train_loss -0.3494 
2025-07-10 13:14:23.950351: val_loss -0.3359 
2025-07-10 13:14:23.950427: Pseudo dice [np.float32(0.5086)] 
2025-07-10 13:14:23.950532: Epoch time: 47.67 s 
2025-07-10 13:14:25.044673:  
2025-07-10 13:14:25.044998: Epoch 233 
2025-07-10 13:14:25.045187: Current learning rate: 0.00788 
2025-07-10 13:15:11.160809: train_loss -0.3599 
2025-07-10 13:15:11.161450: val_loss -0.3654 
2025-07-10 13:15:11.161534: Pseudo dice [np.float32(0.4541)] 
2025-07-10 13:15:11.161698: Epoch time: 46.12 s 
2025-07-10 13:15:12.941894:  
2025-07-10 13:15:12.942784: Epoch 234 
2025-07-10 13:15:12.943181: Current learning rate: 0.00787 
2025-07-10 13:15:58.752612: train_loss -0.3669 
2025-07-10 13:15:58.753132: val_loss -0.3229 
2025-07-10 13:15:58.753235: Pseudo dice [np.float32(0.2716)] 
2025-07-10 13:15:58.753355: Epoch time: 45.81 s 
2025-07-10 13:15:59.899053:  
2025-07-10 13:15:59.899366: Epoch 235 
2025-07-10 13:15:59.899598: Current learning rate: 0.00786 
2025-07-10 13:16:46.639294: train_loss -0.3527 
2025-07-10 13:16:46.639976: val_loss -0.349 
2025-07-10 13:16:46.643517: Pseudo dice [np.float32(0.4282)] 
2025-07-10 13:16:46.643789: Epoch time: 46.74 s 
2025-07-10 13:16:47.708443:  
2025-07-10 13:16:47.708821: Epoch 236 
2025-07-10 13:16:47.708972: Current learning rate: 0.00785 
2025-07-10 13:17:35.288558: train_loss -0.3645 
2025-07-10 13:17:35.289115: val_loss -0.3416 
2025-07-10 13:17:35.289204: Pseudo dice [np.float32(0.427)] 
2025-07-10 13:17:35.289313: Epoch time: 47.58 s 
2025-07-10 13:17:36.400719:  
2025-07-10 13:17:36.401159: Epoch 237 
2025-07-10 13:17:36.401289: Current learning rate: 0.00784 
2025-07-10 13:18:23.755653: train_loss -0.3088 
2025-07-10 13:18:23.756201: val_loss -0.2217 
2025-07-10 13:18:23.756286: Pseudo dice [np.float32(0.0)] 
2025-07-10 13:18:23.756392: Epoch time: 47.36 s 
2025-07-10 13:18:24.817879:  
2025-07-10 13:18:24.818162: Epoch 238 
2025-07-10 13:18:24.818372: Current learning rate: 0.00783 
2025-07-10 13:19:13.131593: train_loss -0.2555 
2025-07-10 13:19:13.132978: val_loss -0.224 
2025-07-10 13:19:13.133261: Pseudo dice [np.float32(0.0)] 
2025-07-10 13:19:13.133523: Epoch time: 48.31 s 
2025-07-10 13:19:14.245679:  
2025-07-10 13:19:14.245879: Epoch 239 
2025-07-10 13:19:14.245986: Current learning rate: 0.00782 
2025-07-10 13:20:02.669021: train_loss -0.3145 
2025-07-10 13:20:02.669638: val_loss -0.3625 
2025-07-10 13:20:02.669744: Pseudo dice [np.float32(0.46)] 
2025-07-10 13:20:02.669886: Epoch time: 48.42 s 
2025-07-10 13:20:03.772640:  
2025-07-10 13:20:03.773077: Epoch 240 
2025-07-10 13:20:03.773403: Current learning rate: 0.00781 
2025-07-10 13:20:52.083694: train_loss -0.2589 
2025-07-10 13:20:52.084571: val_loss -0.1846 
2025-07-10 13:20:52.084706: Pseudo dice [np.float32(0.0)] 
2025-07-10 13:20:52.084846: Epoch time: 48.31 s 
2025-07-10 13:20:53.205022:  
2025-07-10 13:20:53.205473: Epoch 241 
2025-07-10 13:20:53.205609: Current learning rate: 0.0078 
2025-07-10 13:21:40.906381: train_loss -0.2188 
2025-07-10 13:21:40.906968: val_loss -0.2459 
2025-07-10 13:21:40.907084: Pseudo dice [np.float32(0.0)] 
2025-07-10 13:21:40.907202: Epoch time: 47.7 s 
2025-07-10 13:21:42.091607:  
2025-07-10 13:21:42.091897: Epoch 242 
2025-07-10 13:21:42.092054: Current learning rate: 0.00779 
2025-07-10 13:22:29.742381: train_loss -0.2569 
2025-07-10 13:22:29.742820: val_loss -0.2631 
2025-07-10 13:22:29.742920: Pseudo dice [np.float32(0.0)] 
2025-07-10 13:22:29.743011: Epoch time: 47.65 s 
2025-07-10 13:22:30.895421:  
2025-07-10 13:22:30.895706: Epoch 243 
2025-07-10 13:22:30.895926: Current learning rate: 0.00778 
2025-07-10 13:23:19.334426: train_loss -0.2564 
2025-07-10 13:23:19.334860: val_loss -0.2279 
2025-07-10 13:23:19.334934: Pseudo dice [np.float32(0.0)] 
2025-07-10 13:23:19.335031: Epoch time: 48.44 s 
2025-07-10 13:23:20.513205:  
2025-07-10 13:23:20.513368: Epoch 244 
2025-07-10 13:23:20.513488: Current learning rate: 0.00777 
2025-07-10 13:24:08.782985: train_loss -0.2894 
2025-07-10 13:24:08.783388: val_loss -0.2537 
2025-07-10 13:24:08.783477: Pseudo dice [np.float32(0.0)] 
2025-07-10 13:24:08.783623: Epoch time: 48.27 s 
2025-07-10 13:24:09.884421:  
2025-07-10 13:24:09.884790: Epoch 245 
2025-07-10 13:24:09.885013: Current learning rate: 0.00777 
2025-07-10 13:24:57.247654: train_loss -0.2731 
2025-07-10 13:24:57.248093: val_loss -0.2465 
2025-07-10 13:24:57.248177: Pseudo dice [np.float32(0.0)] 
2025-07-10 13:24:57.248286: Epoch time: 47.36 s 
2025-07-10 13:24:58.399930:  
2025-07-10 13:24:58.400089: Epoch 246 
2025-07-10 13:24:58.400211: Current learning rate: 0.00776 
2025-07-10 13:25:46.024290: train_loss -0.2724 
2025-07-10 13:25:46.025171: val_loss -0.2516 
2025-07-10 13:25:46.025286: Pseudo dice [np.float32(0.0)] 
2025-07-10 13:25:46.025426: Epoch time: 47.63 s 
2025-07-10 13:25:47.856585:  
2025-07-10 13:25:47.857128: Epoch 247 
2025-07-10 13:25:47.857819: Current learning rate: 0.00775 
2025-07-10 13:26:34.708326: train_loss -0.2931 
2025-07-10 13:26:34.709139: val_loss -0.3197 
2025-07-10 13:26:34.709259: Pseudo dice [np.float32(0.0021)] 
2025-07-10 13:26:34.709385: Epoch time: 46.85 s 
2025-07-10 13:26:35.858553:  
2025-07-10 13:26:35.858859: Epoch 248 
2025-07-10 13:26:35.858963: Current learning rate: 0.00774 
2025-07-10 13:27:23.460468: train_loss -0.3213 
2025-07-10 13:27:23.460867: val_loss -0.3543 
2025-07-10 13:27:23.460952: Pseudo dice [np.float32(0.2332)] 
2025-07-10 13:27:23.461056: Epoch time: 47.6 s 
2025-07-10 13:27:24.600238:  
2025-07-10 13:27:24.600463: Epoch 249 
2025-07-10 13:27:24.600599: Current learning rate: 0.00773 
2025-07-10 13:28:11.676309: train_loss -0.3586 
2025-07-10 13:28:11.677011: val_loss -0.3481 
2025-07-10 13:28:11.677113: Pseudo dice [np.float32(0.415)] 
2025-07-10 13:28:11.677247: Epoch time: 47.08 s 
2025-07-10 13:28:13.860726:  
2025-07-10 13:28:13.861188: Epoch 250 
2025-07-10 13:28:13.861597: Current learning rate: 0.00772 
2025-07-10 13:29:02.094718: train_loss -0.3717 
2025-07-10 13:29:02.095217: val_loss -0.3751 
2025-07-10 13:29:02.095309: Pseudo dice [np.float32(0.5003)] 
2025-07-10 13:29:02.095442: Epoch time: 48.24 s 
2025-07-10 13:29:03.392344:  
2025-07-10 13:29:03.393588: Epoch 251 
2025-07-10 13:29:03.394131: Current learning rate: 0.00771 
2025-07-10 13:29:51.753640: train_loss -0.3338 
2025-07-10 13:29:51.754093: val_loss -0.3319 
2025-07-10 13:29:51.754173: Pseudo dice [np.float32(0.4745)] 
2025-07-10 13:29:51.754279: Epoch time: 48.36 s 
2025-07-10 13:29:52.864474:  
2025-07-10 13:29:52.864891: Epoch 252 
2025-07-10 13:29:52.865128: Current learning rate: 0.0077 
2025-07-10 13:30:40.962008: train_loss -0.2806 
2025-07-10 13:30:40.962722: val_loss -0.1926 
2025-07-10 13:30:40.962824: Pseudo dice [np.float32(0.0)] 
2025-07-10 13:30:40.962949: Epoch time: 48.1 s 
2025-07-10 13:30:42.162286:  
2025-07-10 13:30:42.162740: Epoch 253 
2025-07-10 13:30:42.162882: Current learning rate: 0.00769 
2025-07-10 13:31:29.844319: train_loss -0.2554 
2025-07-10 13:31:29.845412: val_loss -0.2306 
2025-07-10 13:31:29.845582: Pseudo dice [np.float32(0.0)] 
2025-07-10 13:31:29.845922: Epoch time: 47.68 s 
2025-07-10 13:31:30.980090:  
2025-07-10 13:31:30.980362: Epoch 254 
2025-07-10 13:31:30.980536: Current learning rate: 0.00768 
2025-07-10 13:32:18.998939: train_loss -0.2468 
2025-07-10 13:32:18.999346: val_loss -0.2452 
2025-07-10 13:32:18.999431: Pseudo dice [np.float32(0.0)] 
2025-07-10 13:32:18.999533: Epoch time: 48.02 s 
2025-07-10 13:32:20.133103:  
2025-07-10 13:32:20.133648: Epoch 255 
2025-07-10 13:32:20.133785: Current learning rate: 0.00767 
2025-07-10 13:33:07.957180: train_loss -0.2672 
2025-07-10 13:33:07.957761: val_loss -0.2347 
2025-07-10 13:33:07.957845: Pseudo dice [np.float32(0.0)] 
2025-07-10 13:33:07.957957: Epoch time: 47.83 s 
2025-07-10 13:33:09.094010:  
2025-07-10 13:33:09.094387: Epoch 256 
2025-07-10 13:33:09.094618: Current learning rate: 0.00766 
2025-07-10 13:33:56.696826: train_loss -0.2827 
2025-07-10 13:33:56.698127: val_loss -0.2695 
2025-07-10 13:33:56.698236: Pseudo dice [np.float32(0.3305)] 
2025-07-10 13:33:56.698443: Epoch time: 47.6 s 
2025-07-10 13:33:57.891277:  
2025-07-10 13:33:57.891660: Epoch 257 
2025-07-10 13:33:57.891817: Current learning rate: 0.00765 
2025-07-10 13:34:46.233446: train_loss -0.3035 
2025-07-10 13:34:46.234516: val_loss -0.3257 
2025-07-10 13:34:46.234734: Pseudo dice [np.float32(0.4259)] 
2025-07-10 13:34:46.234968: Epoch time: 48.34 s 
2025-07-10 13:34:47.357840:  
2025-07-10 13:34:47.358051: Epoch 258 
2025-07-10 13:34:47.358156: Current learning rate: 0.00764 
2025-07-10 13:35:35.146149: train_loss -0.3469 
2025-07-10 13:35:35.146717: val_loss -0.3565 
2025-07-10 13:35:35.146802: Pseudo dice [np.float32(0.5063)] 
2025-07-10 13:35:35.146948: Epoch time: 47.79 s 
2025-07-10 13:35:36.944978:  
2025-07-10 13:35:36.945412: Epoch 259 
2025-07-10 13:35:36.945555: Current learning rate: 0.00764 
2025-07-10 13:36:23.759582: train_loss -0.3161 
2025-07-10 13:36:23.759945: val_loss -0.3289 
2025-07-10 13:36:23.760035: Pseudo dice [np.float32(0.4092)] 
2025-07-10 13:36:23.760276: Epoch time: 46.82 s 
2025-07-10 13:36:24.881353:  
2025-07-10 13:36:24.881651: Epoch 260 
2025-07-10 13:36:24.881945: Current learning rate: 0.00763 
2025-07-10 13:37:12.552565: train_loss -0.3593 
2025-07-10 13:37:12.553038: val_loss -0.3338 
2025-07-10 13:37:12.553128: Pseudo dice [np.float32(0.4541)] 
2025-07-10 13:37:12.553249: Epoch time: 47.67 s 
2025-07-10 13:37:13.744111:  
2025-07-10 13:37:13.744500: Epoch 261 
2025-07-10 13:37:13.744694: Current learning rate: 0.00762 
2025-07-10 13:38:01.209417: train_loss -0.3638 
2025-07-10 13:38:01.209701: val_loss -0.3734 
2025-07-10 13:38:01.209776: Pseudo dice [np.float32(0.4727)] 
2025-07-10 13:38:01.209879: Epoch time: 47.47 s 
2025-07-10 13:38:02.348211:  
2025-07-10 13:38:02.348397: Epoch 262 
2025-07-10 13:38:02.348875: Current learning rate: 0.00761 
2025-07-10 13:38:49.453217: train_loss -0.3493 
2025-07-10 13:38:49.453713: val_loss -0.3031 
2025-07-10 13:38:49.453865: Pseudo dice [np.float32(0.3754)] 
2025-07-10 13:38:49.453979: Epoch time: 47.11 s 
2025-07-10 13:38:50.631899:  
2025-07-10 13:38:50.632165: Epoch 263 
2025-07-10 13:38:50.632299: Current learning rate: 0.0076 
2025-07-10 13:39:38.377434: train_loss -0.3586 
2025-07-10 13:39:38.377747: val_loss -0.3693 
2025-07-10 13:39:38.377832: Pseudo dice [np.float32(0.4665)] 
2025-07-10 13:39:38.377944: Epoch time: 47.75 s 
2025-07-10 13:39:39.571599:  
2025-07-10 13:39:39.572018: Epoch 264 
2025-07-10 13:39:39.572209: Current learning rate: 0.00759 
2025-07-10 13:40:26.952420: train_loss -0.3711 
2025-07-10 13:40:26.952812: val_loss -0.3898 
2025-07-10 13:40:26.952889: Pseudo dice [np.float32(0.5209)] 
2025-07-10 13:40:26.953002: Epoch time: 47.38 s 
2025-07-10 13:40:28.161687:  
2025-07-10 13:40:28.162236: Epoch 265 
2025-07-10 13:40:28.162469: Current learning rate: 0.00758 
2025-07-10 13:41:15.657930: train_loss -0.3775 
2025-07-10 13:41:15.658188: val_loss -0.3654 
2025-07-10 13:41:15.658259: Pseudo dice [np.float32(0.4878)] 
2025-07-10 13:41:15.658355: Epoch time: 47.5 s 
2025-07-10 13:41:16.766806:  
2025-07-10 13:41:16.767139: Epoch 266 
2025-07-10 13:41:16.767319: Current learning rate: 0.00757 
2025-07-10 13:42:04.090965: train_loss -0.3842 
2025-07-10 13:42:04.091737: val_loss -0.3636 
2025-07-10 13:42:04.091824: Pseudo dice [np.float32(0.4629)] 
2025-07-10 13:42:04.091962: Epoch time: 47.33 s 
2025-07-10 13:42:05.310953:  
2025-07-10 13:42:05.311139: Epoch 267 
2025-07-10 13:42:05.311265: Current learning rate: 0.00756 
2025-07-10 13:42:52.270606: train_loss -0.37 
2025-07-10 13:42:52.271345: val_loss -0.3926 
2025-07-10 13:42:52.271436: Pseudo dice [np.float32(0.5319)] 
2025-07-10 13:42:52.271595: Epoch time: 46.96 s 
2025-07-10 13:42:53.444526:  
2025-07-10 13:42:53.445017: Epoch 268 
2025-07-10 13:42:53.445201: Current learning rate: 0.00755 
2025-07-10 13:43:41.057565: train_loss -0.39 
2025-07-10 13:43:41.057984: val_loss -0.4111 
2025-07-10 13:43:41.058065: Pseudo dice [np.float32(0.5363)] 
2025-07-10 13:43:41.058161: Epoch time: 47.61 s 
2025-07-10 13:43:42.273792:  
2025-07-10 13:43:42.274198: Epoch 269 
2025-07-10 13:43:42.274325: Current learning rate: 0.00754 
2025-07-10 13:44:29.482644: train_loss -0.3938 
2025-07-10 13:44:29.483390: val_loss -0.3804 
2025-07-10 13:44:29.483488: Pseudo dice [np.float32(0.5618)] 
2025-07-10 13:44:29.483639: Epoch time: 47.21 s 
2025-07-10 13:44:31.263783:  
2025-07-10 13:44:31.264204: Epoch 270 
2025-07-10 13:44:31.264302: Current learning rate: 0.00753 
2025-07-10 13:45:18.427858: train_loss -0.3916 
2025-07-10 13:45:18.428892: val_loss -0.3697 
2025-07-10 13:45:18.429089: Pseudo dice [np.float32(0.5514)] 
2025-07-10 13:45:18.429214: Epoch time: 47.16 s 
2025-07-10 13:45:19.591732:  
2025-07-10 13:45:19.592039: Epoch 271 
2025-07-10 13:45:19.592185: Current learning rate: 0.00752 
2025-07-10 13:46:07.025155: train_loss -0.3883 
2025-07-10 13:46:07.026004: val_loss -0.4059 
2025-07-10 13:46:07.026092: Pseudo dice [np.float32(0.6064)] 
2025-07-10 13:46:07.026212: Epoch time: 47.43 s 
2025-07-10 13:46:08.165413:  
2025-07-10 13:46:08.165708: Epoch 272 
2025-07-10 13:46:08.165896: Current learning rate: 0.00751 
2025-07-10 13:46:56.779806: train_loss -0.3532 
2025-07-10 13:46:56.780552: val_loss -0.1837 
2025-07-10 13:46:56.780640: Pseudo dice [np.float32(0.2883)] 
2025-07-10 13:46:56.780741: Epoch time: 48.62 s 
2025-07-10 13:46:57.998977:  
2025-07-10 13:46:57.999404: Epoch 273 
2025-07-10 13:46:57.999528: Current learning rate: 0.00751 
2025-07-10 13:47:48.557566: train_loss -0.3476 
2025-07-10 13:47:48.558433: val_loss -0.3517 
2025-07-10 13:47:48.558621: Pseudo dice [np.float32(0.4823)] 
2025-07-10 13:47:48.558803: Epoch time: 50.56 s 
2025-07-10 13:47:49.793924:  
2025-07-10 13:47:49.794566: Epoch 274 
2025-07-10 13:47:49.794747: Current learning rate: 0.0075 
2025-07-10 13:48:40.387084: train_loss -0.3484 
2025-07-10 13:48:40.387785: val_loss -0.3469 
2025-07-10 13:48:40.387881: Pseudo dice [np.float32(0.5199)] 
2025-07-10 13:48:40.388015: Epoch time: 50.59 s 
2025-07-10 13:48:41.560489:  
2025-07-10 13:48:41.560734: Epoch 275 
2025-07-10 13:48:41.560975: Current learning rate: 0.00749 
2025-07-10 13:49:30.791871: train_loss -0.3995 
2025-07-10 13:49:30.792526: val_loss -0.3945 
2025-07-10 13:49:30.792630: Pseudo dice [np.float32(0.5774)] 
2025-07-10 13:49:30.792752: Epoch time: 49.23 s 
2025-07-10 13:49:31.916635:  
2025-07-10 13:49:31.916908: Epoch 276 
2025-07-10 13:49:31.917039: Current learning rate: 0.00748 
2025-07-10 13:50:20.762035: train_loss -0.2929 
2025-07-10 13:50:20.762698: val_loss -0.2808 
2025-07-10 13:50:20.762788: Pseudo dice [np.float32(0.0466)] 
2025-07-10 13:50:20.762908: Epoch time: 48.85 s 
2025-07-10 13:50:21.988248:  
2025-07-10 13:50:21.988450: Epoch 277 
2025-07-10 13:50:21.988952: Current learning rate: 0.00747 
2025-07-10 13:51:10.793228: train_loss -0.3597 
2025-07-10 13:51:10.793706: val_loss -0.3784 
2025-07-10 13:51:10.793785: Pseudo dice [np.float32(0.514)] 
2025-07-10 13:51:10.793891: Epoch time: 48.81 s 
2025-07-10 13:51:11.949415:  
2025-07-10 13:51:11.949948: Epoch 278 
2025-07-10 13:51:11.950121: Current learning rate: 0.00746 
2025-07-10 13:52:00.217112: train_loss -0.3809 
2025-07-10 13:52:00.217575: val_loss -0.3778 
2025-07-10 13:52:00.217652: Pseudo dice [np.float32(0.5127)] 
2025-07-10 13:52:00.217760: Epoch time: 48.27 s 
2025-07-10 13:52:01.419963:  
2025-07-10 13:52:01.420260: Epoch 279 
2025-07-10 13:52:01.420461: Current learning rate: 0.00745 
2025-07-10 13:52:48.641179: train_loss -0.3776 
2025-07-10 13:52:48.641810: val_loss -0.3748 
2025-07-10 13:52:48.641890: Pseudo dice [np.float32(0.4822)] 
2025-07-10 13:52:48.642005: Epoch time: 47.22 s 
2025-07-10 13:52:49.755027:  
2025-07-10 13:52:49.755405: Epoch 280 
2025-07-10 13:52:49.755549: Current learning rate: 0.00744 
2025-07-10 13:53:36.534866: train_loss -0.3685 
2025-07-10 13:53:36.535880: val_loss -0.3986 
2025-07-10 13:53:36.535989: Pseudo dice [np.float32(0.4752)] 
2025-07-10 13:53:36.536144: Epoch time: 46.78 s 
2025-07-10 13:53:37.695481:  
2025-07-10 13:53:37.695828: Epoch 281 
2025-07-10 13:53:37.696005: Current learning rate: 0.00743 
2025-07-10 13:54:23.930006: train_loss -0.3997 
2025-07-10 13:54:23.930687: val_loss -0.3898 
2025-07-10 13:54:23.930791: Pseudo dice [np.float32(0.5997)] 
2025-07-10 13:54:23.930896: Epoch time: 46.24 s 
2025-07-10 13:54:25.542099:  
2025-07-10 13:54:25.542473: Epoch 282 
2025-07-10 13:54:25.542632: Current learning rate: 0.00742 
2025-07-10 13:55:12.790173: train_loss -0.3962 
2025-07-10 13:55:12.790715: val_loss -0.4005 
2025-07-10 13:55:12.790827: Pseudo dice [np.float32(0.6106)] 
2025-07-10 13:55:12.790955: Epoch time: 47.25 s 
2025-07-10 13:55:13.902980:  
2025-07-10 13:55:13.903449: Epoch 283 
2025-07-10 13:55:13.903685: Current learning rate: 0.00741 
2025-07-10 13:56:01.469899: train_loss -0.3897 
2025-07-10 13:56:01.470246: val_loss -0.3561 
2025-07-10 13:56:01.470417: Pseudo dice [np.float32(0.2558)] 
2025-07-10 13:56:01.470529: Epoch time: 47.57 s 
2025-07-10 13:56:02.692466:  
2025-07-10 13:56:02.692885: Epoch 284 
2025-07-10 13:56:02.693017: Current learning rate: 0.0074 
2025-07-10 13:56:49.919057: train_loss -0.3861 
2025-07-10 13:56:49.919671: val_loss -0.3891 
2025-07-10 13:56:49.919848: Pseudo dice [np.float32(0.5086)] 
2025-07-10 13:56:49.919979: Epoch time: 47.23 s 
2025-07-10 13:56:51.138891:  
2025-07-10 13:56:51.139078: Epoch 285 
2025-07-10 13:56:51.139598: Current learning rate: 0.00739 
2025-07-10 13:57:38.147598: train_loss -0.3938 
2025-07-10 13:57:38.147992: val_loss -0.397 
2025-07-10 13:57:38.148141: Pseudo dice [np.float32(0.5717)] 
2025-07-10 13:57:38.148247: Epoch time: 47.01 s 
2025-07-10 13:57:39.257878:  
2025-07-10 13:57:39.258125: Epoch 286 
2025-07-10 13:57:39.258228: Current learning rate: 0.00738 
2025-07-10 13:58:25.626146: train_loss -0.3722 
2025-07-10 13:58:25.626552: val_loss -0.3786 
2025-07-10 13:58:25.626695: Pseudo dice [np.float32(0.4277)] 
2025-07-10 13:58:25.626811: Epoch time: 46.37 s 
2025-07-10 13:58:26.786566:  
2025-07-10 13:58:26.786884: Epoch 287 
2025-07-10 13:58:26.786986: Current learning rate: 0.00738 
2025-07-10 13:59:14.275120: train_loss -0.3111 
2025-07-10 13:59:14.275615: val_loss -0.3604 
2025-07-10 13:59:14.275716: Pseudo dice [np.float32(0.4925)] 
2025-07-10 13:59:14.275826: Epoch time: 47.49 s 
2025-07-10 13:59:15.408332:  
2025-07-10 13:59:15.408464: Epoch 288 
2025-07-10 13:59:15.408574: Current learning rate: 0.00737 
2025-07-10 14:00:02.436985: train_loss -0.3497 
2025-07-10 14:00:02.437733: val_loss -0.3178 
2025-07-10 14:00:02.437828: Pseudo dice [np.float32(0.3255)] 
2025-07-10 14:00:02.437952: Epoch time: 47.03 s 
2025-07-10 14:00:03.559859:  
2025-07-10 14:00:03.560186: Epoch 289 
2025-07-10 14:00:03.560284: Current learning rate: 0.00736 
2025-07-10 14:00:49.364259: train_loss -0.3337 
2025-07-10 14:00:49.364631: val_loss -0.3523 
2025-07-10 14:00:49.364708: Pseudo dice [np.float32(0.5229)] 
2025-07-10 14:00:49.364829: Epoch time: 45.81 s 
2025-07-10 14:00:50.472475:  
2025-07-10 14:00:50.472767: Epoch 290 
2025-07-10 14:00:50.472962: Current learning rate: 0.00735 
2025-07-10 14:01:37.026671: train_loss -0.3836 
2025-07-10 14:01:37.027165: val_loss -0.3602 
2025-07-10 14:01:37.027251: Pseudo dice [np.float32(0.3956)] 
2025-07-10 14:01:37.027360: Epoch time: 46.56 s 
2025-07-10 14:01:38.185953:  
2025-07-10 14:01:38.186162: Epoch 291 
2025-07-10 14:01:38.186259: Current learning rate: 0.00734 
2025-07-10 14:02:24.595694: train_loss -0.2995 
2025-07-10 14:02:24.596078: val_loss -0.3924 
2025-07-10 14:02:24.596146: Pseudo dice [np.float32(0.5338)] 
2025-07-10 14:02:24.596241: Epoch time: 46.41 s 
2025-07-10 14:02:25.713950:  
2025-07-10 14:02:25.714430: Epoch 292 
2025-07-10 14:02:25.714576: Current learning rate: 0.00733 
2025-07-10 14:03:12.113082: train_loss -0.396 
2025-07-10 14:03:12.113464: val_loss -0.3783 
2025-07-10 14:03:12.113637: Pseudo dice [np.float32(0.5885)] 
2025-07-10 14:03:12.113745: Epoch time: 46.4 s 
2025-07-10 14:03:13.291459:  
2025-07-10 14:03:13.291782: Epoch 293 
2025-07-10 14:03:13.291990: Current learning rate: 0.00732 
2025-07-10 14:04:00.722317: train_loss -0.3849 
2025-07-10 14:04:00.722677: val_loss -0.3925 
2025-07-10 14:04:00.722758: Pseudo dice [np.float32(0.5792)] 
2025-07-10 14:04:00.722850: Epoch time: 47.43 s 
2025-07-10 14:04:02.477753:  
2025-07-10 14:04:02.478158: Epoch 294 
2025-07-10 14:04:02.478482: Current learning rate: 0.00731 
2025-07-10 14:04:49.567466: train_loss -0.3832 
2025-07-10 14:04:49.568122: val_loss -0.3973 
2025-07-10 14:04:49.568215: Pseudo dice [np.float32(0.5371)] 
2025-07-10 14:04:49.568351: Epoch time: 47.09 s 
2025-07-10 14:04:50.753878:  
2025-07-10 14:04:50.754366: Epoch 295 
2025-07-10 14:04:50.754501: Current learning rate: 0.0073 
2025-07-10 14:05:38.268707: train_loss -0.3701 
2025-07-10 14:05:38.269292: val_loss -0.3609 
2025-07-10 14:05:38.269413: Pseudo dice [np.float32(0.5033)] 
2025-07-10 14:05:38.269550: Epoch time: 47.52 s 
2025-07-10 14:05:39.445524:  
2025-07-10 14:05:39.446219: Epoch 296 
2025-07-10 14:05:39.446488: Current learning rate: 0.00729 
2025-07-10 14:06:26.026121: train_loss -0.3859 
2025-07-10 14:06:26.026489: val_loss -0.3578 
2025-07-10 14:06:26.026574: Pseudo dice [np.float32(0.4867)] 
2025-07-10 14:06:26.026687: Epoch time: 46.58 s 
2025-07-10 14:06:27.262059:  
2025-07-10 14:06:27.262608: Epoch 297 
2025-07-10 14:06:27.262814: Current learning rate: 0.00728 
2025-07-10 14:07:13.542378: train_loss -0.3692 
2025-07-10 14:07:13.543069: val_loss -0.292 
2025-07-10 14:07:13.543161: Pseudo dice [np.float32(0.1693)] 
2025-07-10 14:07:13.543290: Epoch time: 46.28 s 
2025-07-10 14:07:14.749219:  
2025-07-10 14:07:14.749661: Epoch 298 
2025-07-10 14:07:14.749858: Current learning rate: 0.00727 
2025-07-10 14:08:01.621009: train_loss -0.3493 
2025-07-10 14:08:01.621710: val_loss -0.3457 
2025-07-10 14:08:01.621788: Pseudo dice [np.float32(0.4541)] 
2025-07-10 14:08:01.621895: Epoch time: 46.87 s 
2025-07-10 14:08:02.740399:  
2025-07-10 14:08:02.740863: Epoch 299 
2025-07-10 14:08:02.741006: Current learning rate: 0.00726 
2025-07-10 14:08:49.580976: train_loss -0.3755 
2025-07-10 14:08:49.581387: val_loss -0.3865 
2025-07-10 14:08:49.581467: Pseudo dice [np.float32(0.5177)] 
2025-07-10 14:08:49.581578: Epoch time: 46.84 s 
2025-07-10 14:08:51.629275:  
2025-07-10 14:08:51.629591: Epoch 300 
2025-07-10 14:08:51.629800: Current learning rate: 0.00725 
2025-07-10 14:09:38.518455: train_loss -0.3713 
2025-07-10 14:09:38.519517: val_loss -0.3998 
2025-07-10 14:09:38.519689: Pseudo dice [np.float32(0.5518)] 
2025-07-10 14:09:38.519940: Epoch time: 46.89 s 
2025-07-10 14:09:39.701993:  
2025-07-10 14:09:39.702545: Epoch 301 
2025-07-10 14:09:39.702709: Current learning rate: 0.00724 
2025-07-10 14:10:26.740951: train_loss -0.4085 
2025-07-10 14:10:26.741939: val_loss -0.4229 
2025-07-10 14:10:26.742020: Pseudo dice [np.float32(0.5723)] 
2025-07-10 14:10:26.742177: Epoch time: 47.04 s 
2025-07-10 14:10:27.968146:  
2025-07-10 14:10:27.968739: Epoch 302 
2025-07-10 14:10:27.968890: Current learning rate: 0.00724 
2025-07-10 14:11:17.044931: train_loss -0.4044 
2025-07-10 14:11:17.045361: val_loss -0.397 
2025-07-10 14:11:17.045441: Pseudo dice [np.float32(0.558)] 
2025-07-10 14:11:17.045569: Epoch time: 49.08 s 
2025-07-10 14:11:18.176395:  
2025-07-10 14:11:18.176702: Epoch 303 
2025-07-10 14:11:18.176851: Current learning rate: 0.00723 
2025-07-10 14:12:06.368727: train_loss -0.3997 
2025-07-10 14:12:06.369180: val_loss -0.4006 
2025-07-10 14:12:06.369302: Pseudo dice [np.float32(0.5083)] 
2025-07-10 14:12:06.369410: Epoch time: 48.19 s 
2025-07-10 14:12:07.502275:  
2025-07-10 14:12:07.502612: Epoch 304 
2025-07-10 14:12:07.502911: Current learning rate: 0.00722 
2025-07-10 14:12:53.928881: train_loss -0.391 
2025-07-10 14:12:53.929258: val_loss -0.4011 
2025-07-10 14:12:53.929333: Pseudo dice [np.float32(0.59)] 
2025-07-10 14:12:53.929430: Epoch time: 46.43 s 
2025-07-10 14:12:55.631295:  
2025-07-10 14:12:55.631785: Epoch 305 
2025-07-10 14:12:55.632170: Current learning rate: 0.00721 
2025-07-10 14:13:42.736134: train_loss -0.4027 
2025-07-10 14:13:42.736492: val_loss -0.3783 
2025-07-10 14:13:42.736578: Pseudo dice [np.float32(0.5004)] 
2025-07-10 14:13:42.736677: Epoch time: 47.11 s 
2025-07-10 14:13:43.913003:  
2025-07-10 14:13:43.913371: Epoch 306 
2025-07-10 14:13:43.913598: Current learning rate: 0.0072 
2025-07-10 14:14:30.976023: train_loss -0.3646 
2025-07-10 14:14:30.977428: val_loss -0.3628 
2025-07-10 14:14:30.977696: Pseudo dice [np.float32(0.6143)] 
2025-07-10 14:14:30.977899: Epoch time: 47.06 s 
2025-07-10 14:14:32.189219:  
2025-07-10 14:14:32.189612: Epoch 307 
2025-07-10 14:14:32.189874: Current learning rate: 0.00719 
2025-07-10 14:15:18.918722: train_loss -0.3745 
2025-07-10 14:15:18.919279: val_loss -0.3759 
2025-07-10 14:15:18.919370: Pseudo dice [np.float32(0.5988)] 
2025-07-10 14:15:18.919588: Epoch time: 46.73 s 
2025-07-10 14:15:20.129934:  
2025-07-10 14:15:20.130137: Epoch 308 
2025-07-10 14:15:20.130263: Current learning rate: 0.00718 
2025-07-10 14:16:06.784718: train_loss -0.3349 
2025-07-10 14:16:06.785441: val_loss -0.3677 
2025-07-10 14:16:06.785531: Pseudo dice [np.float32(0.4555)] 
2025-07-10 14:16:06.785699: Epoch time: 46.66 s 
2025-07-10 14:16:07.921345:  
2025-07-10 14:16:07.921649: Epoch 309 
2025-07-10 14:16:07.921776: Current learning rate: 0.00717 
2025-07-10 14:16:55.788607: train_loss -0.3818 
2025-07-10 14:16:55.789057: val_loss -0.3824 
2025-07-10 14:16:55.789133: Pseudo dice [np.float32(0.4955)] 
2025-07-10 14:16:55.789242: Epoch time: 47.87 s 
2025-07-10 14:16:56.913485:  
2025-07-10 14:16:56.913971: Epoch 310 
2025-07-10 14:16:56.914096: Current learning rate: 0.00716 
2025-07-10 14:17:43.737165: train_loss -0.379 
2025-07-10 14:17:43.738384: val_loss -0.3729 
2025-07-10 14:17:43.738591: Pseudo dice [np.float32(0.5816)] 
2025-07-10 14:17:43.738805: Epoch time: 46.82 s 
2025-07-10 14:17:44.934164:  
2025-07-10 14:17:44.934722: Epoch 311 
2025-07-10 14:17:44.934868: Current learning rate: 0.00715 
2025-07-10 14:18:31.416759: train_loss -0.4035 
2025-07-10 14:18:31.417269: val_loss -0.4348 
2025-07-10 14:18:31.417344: Pseudo dice [np.float32(0.6822)] 
2025-07-10 14:18:31.417448: Epoch time: 46.48 s 
2025-07-10 14:18:32.575275:  
2025-07-10 14:18:32.575889: Epoch 312 
2025-07-10 14:18:32.576402: Current learning rate: 0.00714 
2025-07-10 14:19:19.329696: train_loss -0.4101 
2025-07-10 14:19:19.330153: val_loss -0.4176 
2025-07-10 14:19:19.330242: Pseudo dice [np.float32(0.6087)] 
2025-07-10 14:19:19.330351: Epoch time: 46.76 s 
2025-07-10 14:19:20.535015:  
2025-07-10 14:19:20.535336: Epoch 313 
2025-07-10 14:19:20.535499: Current learning rate: 0.00713 
2025-07-10 14:20:07.947936: train_loss -0.4095 
2025-07-10 14:20:07.948315: val_loss -0.3943 
2025-07-10 14:20:07.948389: Pseudo dice [np.float32(0.5597)] 
2025-07-10 14:20:07.948492: Epoch time: 47.41 s 
2025-07-10 14:20:09.074595:  
2025-07-10 14:20:09.074959: Epoch 314 
2025-07-10 14:20:09.075092: Current learning rate: 0.00712 
2025-07-10 14:20:56.066263: train_loss -0.4056 
2025-07-10 14:20:56.066635: val_loss -0.3773 
2025-07-10 14:20:56.066718: Pseudo dice [np.float32(0.5773)] 
2025-07-10 14:20:56.066863: Epoch time: 46.99 s 
2025-07-10 14:20:57.218264:  
2025-07-10 14:20:57.218514: Epoch 315 
2025-07-10 14:20:57.218674: Current learning rate: 0.00711 
2025-07-10 14:21:44.190431: train_loss -0.3773 
2025-07-10 14:21:44.190835: val_loss -0.3809 
2025-07-10 14:21:44.190914: Pseudo dice [np.float32(0.5401)] 
2025-07-10 14:21:44.191025: Epoch time: 46.97 s 
2025-07-10 14:21:45.435911:  
2025-07-10 14:21:45.436070: Epoch 316 
2025-07-10 14:21:45.436192: Current learning rate: 0.0071 
2025-07-10 14:22:32.496721: train_loss -0.3976 
2025-07-10 14:22:32.497102: val_loss -0.3964 
2025-07-10 14:22:32.497178: Pseudo dice [np.float32(0.5655)] 
2025-07-10 14:22:32.497275: Epoch time: 47.06 s 
2025-07-10 14:22:34.292220:  
2025-07-10 14:22:34.292820: Epoch 317 
2025-07-10 14:22:34.293193: Current learning rate: 0.0071 
2025-07-10 14:23:21.059317: train_loss -0.3874 
2025-07-10 14:23:21.059729: val_loss -0.4264 
2025-07-10 14:23:21.059810: Pseudo dice [np.float32(0.6336)] 
2025-07-10 14:23:21.059909: Epoch time: 46.77 s 
2025-07-10 14:23:22.168193:  
2025-07-10 14:23:22.168478: Epoch 318 
2025-07-10 14:23:22.168635: Current learning rate: 0.00709 
2025-07-10 14:24:09.538388: train_loss -0.4093 
2025-07-10 14:24:09.538919: val_loss -0.4114 
2025-07-10 14:24:09.538999: Pseudo dice [np.float32(0.5903)] 
2025-07-10 14:24:09.539103: Epoch time: 47.37 s 
2025-07-10 14:24:10.692850:  
2025-07-10 14:24:10.693226: Epoch 319 
2025-07-10 14:24:10.693388: Current learning rate: 0.00708 
2025-07-10 14:24:56.981673: train_loss -0.36 
2025-07-10 14:24:56.982074: val_loss -0.4064 
2025-07-10 14:24:56.982151: Pseudo dice [np.float32(0.5705)] 
2025-07-10 14:24:56.982264: Epoch time: 46.29 s 
2025-07-10 14:24:58.139958:  
2025-07-10 14:24:58.140342: Epoch 320 
2025-07-10 14:24:58.140477: Current learning rate: 0.00707 
2025-07-10 14:25:45.805887: train_loss -0.3973 
2025-07-10 14:25:45.806420: val_loss -0.4013 
2025-07-10 14:25:45.806499: Pseudo dice [np.float32(0.5596)] 
2025-07-10 14:25:45.806635: Epoch time: 47.67 s 
2025-07-10 14:25:47.062297:  
2025-07-10 14:25:47.062759: Epoch 321 
2025-07-10 14:25:47.062891: Current learning rate: 0.00706 
2025-07-10 14:26:33.705185: train_loss -0.4149 
2025-07-10 14:26:33.706141: val_loss -0.4153 
2025-07-10 14:26:33.706270: Pseudo dice [np.float32(0.6391)] 
2025-07-10 14:26:33.706395: Epoch time: 46.64 s 
2025-07-10 14:26:34.836999:  
2025-07-10 14:26:34.837226: Epoch 322 
2025-07-10 14:26:34.837341: Current learning rate: 0.00705 
2025-07-10 14:27:21.600815: train_loss -0.4241 
2025-07-10 14:27:21.601320: val_loss -0.4365 
2025-07-10 14:27:21.601425: Pseudo dice [np.float32(0.6589)] 
2025-07-10 14:27:21.605196: Epoch time: 46.77 s 
2025-07-10 14:27:22.748203:  
2025-07-10 14:27:22.748803: Epoch 323 
2025-07-10 14:27:22.748935: Current learning rate: 0.00704 
2025-07-10 14:28:09.900305: train_loss -0.3983 
2025-07-10 14:28:09.900692: val_loss -0.3962 
2025-07-10 14:28:09.900776: Pseudo dice [np.float32(0.6009)] 
2025-07-10 14:28:09.900888: Epoch time: 47.15 s 
2025-07-10 14:28:11.015974:  
2025-07-10 14:28:11.016287: Epoch 324 
2025-07-10 14:28:11.016565: Current learning rate: 0.00703 
2025-07-10 14:28:58.284134: train_loss -0.3898 
2025-07-10 14:28:58.284775: val_loss -0.3952 
2025-07-10 14:28:58.284867: Pseudo dice [np.float32(0.5256)] 
2025-07-10 14:28:58.284979: Epoch time: 47.27 s 
2025-07-10 14:28:59.428409:  
2025-07-10 14:28:59.428821: Epoch 325 
2025-07-10 14:28:59.428947: Current learning rate: 0.00702 
2025-07-10 14:29:48.555825: train_loss -0.3748 
2025-07-10 14:29:48.556224: val_loss -0.3723 
2025-07-10 14:29:48.556303: Pseudo dice [np.float32(0.5274)] 
2025-07-10 14:29:48.556409: Epoch time: 49.13 s 
2025-07-10 14:29:49.708145:  
2025-07-10 14:29:49.708314: Epoch 326 
2025-07-10 14:29:49.708436: Current learning rate: 0.00701 
2025-07-10 14:30:38.383723: train_loss -0.3869 
2025-07-10 14:30:38.384158: val_loss -0.3744 
2025-07-10 14:30:38.384243: Pseudo dice [np.float32(0.5349)] 
2025-07-10 14:30:38.384357: Epoch time: 48.68 s 
2025-07-10 14:30:39.495337:  
2025-07-10 14:30:39.495874: Epoch 327 
2025-07-10 14:30:39.496018: Current learning rate: 0.007 
2025-07-10 14:31:26.529858: train_loss -0.3977 
2025-07-10 14:31:26.530746: val_loss -0.3777 
2025-07-10 14:31:26.530907: Pseudo dice [np.float32(0.6061)] 
2025-07-10 14:31:26.531036: Epoch time: 47.04 s 
2025-07-10 14:31:27.669411:  
2025-07-10 14:31:27.669871: Epoch 328 
2025-07-10 14:31:27.670012: Current learning rate: 0.00699 
2025-07-10 14:32:14.544651: train_loss -0.3855 
2025-07-10 14:32:14.545055: val_loss -0.2992 
2025-07-10 14:32:14.545131: Pseudo dice [np.float32(0.3244)] 
2025-07-10 14:32:14.545230: Epoch time: 46.88 s 
2025-07-10 14:32:15.629560:  
2025-07-10 14:32:15.629888: Epoch 329 
2025-07-10 14:32:15.630070: Current learning rate: 0.00698 
2025-07-10 14:33:03.003364: train_loss -0.2957 
2025-07-10 14:33:03.004022: val_loss -0.2632 
2025-07-10 14:33:03.004115: Pseudo dice [np.float32(0.0)] 
2025-07-10 14:33:03.004241: Epoch time: 47.37 s 
2025-07-10 14:33:04.128969:  
2025-07-10 14:33:04.129293: Epoch 330 
2025-07-10 14:33:04.129457: Current learning rate: 0.00697 
2025-07-10 14:33:51.468270: train_loss -0.3295 
2025-07-10 14:33:51.468726: val_loss -0.4187 
2025-07-10 14:33:51.468801: Pseudo dice [np.float32(0.6135)] 
2025-07-10 14:33:51.468895: Epoch time: 47.34 s 
2025-07-10 14:33:52.605043:  
2025-07-10 14:33:52.605456: Epoch 331 
2025-07-10 14:33:52.605734: Current learning rate: 0.00696 
2025-07-10 14:34:39.057747: train_loss -0.3834 
2025-07-10 14:34:39.058347: val_loss -0.3774 
2025-07-10 14:34:39.058465: Pseudo dice [np.float32(0.4967)] 
2025-07-10 14:34:39.058618: Epoch time: 46.45 s 
2025-07-10 14:34:40.220517:  
2025-07-10 14:34:40.220949: Epoch 332 
2025-07-10 14:34:40.221074: Current learning rate: 0.00696 
2025-07-10 14:35:27.044053: train_loss -0.4004 
2025-07-10 14:35:27.045269: val_loss -0.406 
2025-07-10 14:35:27.045467: Pseudo dice [np.float32(0.5656)] 
2025-07-10 14:35:27.045646: Epoch time: 46.82 s 
2025-07-10 14:35:28.244511:  
2025-07-10 14:35:28.244917: Epoch 333 
2025-07-10 14:35:28.245137: Current learning rate: 0.00695 
2025-07-10 14:36:15.897032: train_loss -0.4066 
2025-07-10 14:36:15.897375: val_loss -0.419 
2025-07-10 14:36:15.897621: Pseudo dice [np.float32(0.5756)] 
2025-07-10 14:36:15.897727: Epoch time: 47.65 s 
2025-07-10 14:36:16.995216:  
2025-07-10 14:36:16.995525: Epoch 334 
2025-07-10 14:36:16.995682: Current learning rate: 0.00694 
2025-07-10 14:37:03.947047: train_loss -0.4134 
2025-07-10 14:37:03.947571: val_loss -0.3863 
2025-07-10 14:37:03.947650: Pseudo dice [np.float32(0.4941)] 
2025-07-10 14:37:03.947759: Epoch time: 46.95 s 
2025-07-10 14:37:05.086386:  
2025-07-10 14:37:05.086690: Epoch 335 
2025-07-10 14:37:05.086813: Current learning rate: 0.00693 
2025-07-10 14:37:52.928522: train_loss -0.3999 
2025-07-10 14:37:52.928891: val_loss -0.41 
2025-07-10 14:37:52.928964: Pseudo dice [np.float32(0.4879)] 
2025-07-10 14:37:52.929071: Epoch time: 47.84 s 
2025-07-10 14:37:54.161782:  
2025-07-10 14:37:54.162040: Epoch 336 
2025-07-10 14:37:54.162218: Current learning rate: 0.00692 
2025-07-10 14:38:42.250797: train_loss -0.4163 
2025-07-10 14:38:42.251349: val_loss -0.4082 
2025-07-10 14:38:42.251428: Pseudo dice [np.float32(0.5977)] 
2025-07-10 14:38:42.251534: Epoch time: 48.09 s 
2025-07-10 14:38:43.384570:  
2025-07-10 14:38:43.384902: Epoch 337 
2025-07-10 14:38:43.385019: Current learning rate: 0.00691 
2025-07-10 14:39:32.749891: train_loss -0.4092 
2025-07-10 14:39:32.750237: val_loss -0.4139 
2025-07-10 14:39:32.750313: Pseudo dice [np.float32(0.618)] 
2025-07-10 14:39:32.750422: Epoch time: 49.37 s 
2025-07-10 14:39:33.885327:  
2025-07-10 14:39:33.885782: Epoch 338 
2025-07-10 14:39:33.885915: Current learning rate: 0.0069 
2025-07-10 14:40:23.241287: train_loss -0.4094 
2025-07-10 14:40:23.241680: val_loss -0.4083 
2025-07-10 14:40:23.241759: Pseudo dice [np.float32(0.5786)] 
2025-07-10 14:40:23.241874: Epoch time: 49.36 s 
2025-07-10 14:40:24.377652:  
2025-07-10 14:40:24.377979: Epoch 339 
2025-07-10 14:40:24.378139: Current learning rate: 0.00689 
2025-07-10 14:41:13.423401: train_loss -0.4159 
2025-07-10 14:41:13.424170: val_loss -0.4148 
2025-07-10 14:41:13.424264: Pseudo dice [np.float32(0.6212)] 
2025-07-10 14:41:13.424400: Epoch time: 49.05 s 
2025-07-10 14:41:15.219806:  
2025-07-10 14:41:15.220149: Epoch 340 
2025-07-10 14:41:15.220332: Current learning rate: 0.00688 
2025-07-10 14:42:02.736563: train_loss -0.4302 
2025-07-10 14:42:02.737261: val_loss -0.446 
2025-07-10 14:42:02.737396: Pseudo dice [np.float32(0.6725)] 
2025-07-10 14:42:02.737562: Epoch time: 47.52 s 
2025-07-10 14:42:03.881841:  
2025-07-10 14:42:03.882252: Epoch 341 
2025-07-10 14:42:03.882371: Current learning rate: 0.00687 
2025-07-10 14:42:51.767638: train_loss -0.4322 
2025-07-10 14:42:51.768111: val_loss -0.4314 
2025-07-10 14:42:51.768188: Pseudo dice [np.float32(0.6549)] 
2025-07-10 14:42:51.768312: Epoch time: 47.89 s 
2025-07-10 14:42:52.950669:  
2025-07-10 14:42:52.951136: Epoch 342 
2025-07-10 14:42:52.951389: Current learning rate: 0.00686 
2025-07-10 14:43:41.199857: train_loss -0.4233 
2025-07-10 14:43:41.200826: val_loss -0.4333 
2025-07-10 14:43:41.200935: Pseudo dice [np.float32(0.6149)] 
2025-07-10 14:43:41.201220: Epoch time: 48.25 s 
2025-07-10 14:43:42.396764:  
2025-07-10 14:43:42.397224: Epoch 343 
2025-07-10 14:43:42.397669: Current learning rate: 0.00685 
2025-07-10 14:44:32.252671: train_loss -0.4149 
2025-07-10 14:44:32.253169: val_loss -0.4082 
2025-07-10 14:44:32.253265: Pseudo dice [np.float32(0.5759)] 
2025-07-10 14:44:32.253392: Epoch time: 49.86 s 
2025-07-10 14:44:33.395482:  
2025-07-10 14:44:33.395740: Epoch 344 
2025-07-10 14:44:33.395919: Current learning rate: 0.00684 
2025-07-10 14:45:23.236648: train_loss -0.4131 
2025-07-10 14:45:23.237527: val_loss -0.4196 
2025-07-10 14:45:23.241054: Pseudo dice [np.float32(0.6345)] 
2025-07-10 14:45:23.241322: Epoch time: 49.84 s 
2025-07-10 14:45:24.465461:  
2025-07-10 14:45:24.465627: Epoch 345 
2025-07-10 14:45:24.465746: Current learning rate: 0.00683 
2025-07-10 14:46:14.859354: train_loss -0.423 
2025-07-10 14:46:14.859795: val_loss -0.4365 
2025-07-10 14:46:14.859883: Pseudo dice [np.float32(0.6407)] 
2025-07-10 14:46:14.860016: Epoch time: 50.4 s 
2025-07-10 14:46:16.017574:  
2025-07-10 14:46:16.017763: Epoch 346 
2025-07-10 14:46:16.017891: Current learning rate: 0.00682 
2025-07-10 14:47:06.879976: train_loss -0.4388 
2025-07-10 14:47:06.880620: val_loss -0.428 
2025-07-10 14:47:06.880777: Pseudo dice [np.float32(0.6433)] 
2025-07-10 14:47:06.880955: Epoch time: 50.86 s 
2025-07-10 14:47:08.043854:  
2025-07-10 14:47:08.044028: Epoch 347 
2025-07-10 14:47:08.044164: Current learning rate: 0.00681 
2025-07-10 14:47:59.636358: train_loss -0.4291 
2025-07-10 14:47:59.636984: val_loss -0.4031 
2025-07-10 14:47:59.637089: Pseudo dice [np.float32(0.641)] 
2025-07-10 14:47:59.637209: Epoch time: 51.59 s 
2025-07-10 14:48:00.867099:  
2025-07-10 14:48:00.867549: Epoch 348 
2025-07-10 14:48:00.867679: Current learning rate: 0.0068 
2025-07-10 14:48:52.006765: train_loss -0.4073 
2025-07-10 14:48:52.007204: val_loss -0.3485 
2025-07-10 14:48:52.007287: Pseudo dice [np.float32(0.5055)] 
2025-07-10 14:48:52.007514: Epoch time: 51.14 s 
2025-07-10 14:48:53.139915:  
2025-07-10 14:48:53.140059: Epoch 349 
2025-07-10 14:48:53.140174: Current learning rate: 0.0068 
2025-07-10 14:49:44.759338: train_loss -0.403 
2025-07-10 14:49:44.759684: val_loss -0.3997 
2025-07-10 14:49:44.759759: Pseudo dice [np.float32(0.5659)] 
2025-07-10 14:49:44.759857: Epoch time: 51.62 s 
2025-07-10 14:49:46.396051:  
2025-07-10 14:49:46.396478: Epoch 350 
2025-07-10 14:49:46.396612: Current learning rate: 0.00679 
2025-07-10 14:50:36.907364: train_loss -0.3939 
2025-07-10 14:50:36.907912: val_loss -0.3258 
2025-07-10 14:50:36.907991: Pseudo dice [np.float32(0.351)] 
2025-07-10 14:50:36.908099: Epoch time: 50.51 s 
2025-07-10 14:50:38.688583:  
2025-07-10 14:50:38.689085: Epoch 351 
2025-07-10 14:50:38.689341: Current learning rate: 0.00678 
2025-07-10 14:51:27.780100: train_loss -0.382 
2025-07-10 14:51:27.780415: val_loss -0.3991 
2025-07-10 14:51:27.780499: Pseudo dice [np.float32(0.5925)] 
2025-07-10 14:51:27.780612: Epoch time: 49.09 s 
2025-07-10 14:51:28.910739:  
2025-07-10 14:51:28.910987: Epoch 352 
2025-07-10 14:51:28.911309: Current learning rate: 0.00677 
2025-07-10 14:52:17.249867: train_loss -0.4005 
2025-07-10 14:52:17.250335: val_loss -0.4076 
2025-07-10 14:52:17.250427: Pseudo dice [np.float32(0.6469)] 
2025-07-10 14:52:17.250617: Epoch time: 48.34 s 
2025-07-10 14:52:18.408812:  
2025-07-10 14:52:18.409069: Epoch 353 
2025-07-10 14:52:18.409199: Current learning rate: 0.00676 
2025-07-10 14:53:07.022003: train_loss -0.3961 
2025-07-10 14:53:07.022458: val_loss -0.4042 
2025-07-10 14:53:07.022558: Pseudo dice [np.float32(0.6149)] 
2025-07-10 14:53:07.022667: Epoch time: 48.61 s 
2025-07-10 14:53:08.175668:  
2025-07-10 14:53:08.176171: Epoch 354 
2025-07-10 14:53:08.176313: Current learning rate: 0.00675 
2025-07-10 14:53:56.799219: train_loss -0.414 
2025-07-10 14:53:56.799910: val_loss -0.3932 
2025-07-10 14:53:56.799992: Pseudo dice [np.float32(0.5311)] 
2025-07-10 14:53:56.800097: Epoch time: 48.62 s 
2025-07-10 14:53:58.030317:  
2025-07-10 14:53:58.030543: Epoch 355 
2025-07-10 14:53:58.030740: Current learning rate: 0.00674 
2025-07-10 14:54:46.447441: train_loss -0.4283 
2025-07-10 14:54:46.447956: val_loss -0.4186 
2025-07-10 14:54:46.448083: Pseudo dice [np.float32(0.5928)] 
2025-07-10 14:54:46.448189: Epoch time: 48.42 s 
2025-07-10 14:54:47.592587:  
2025-07-10 14:54:47.592763: Epoch 356 
2025-07-10 14:54:47.592889: Current learning rate: 0.00673 
2025-07-10 14:55:36.544350: train_loss -0.4256 
2025-07-10 14:55:36.545090: val_loss -0.4188 
2025-07-10 14:55:36.545194: Pseudo dice [np.float32(0.5429)] 
2025-07-10 14:55:36.545319: Epoch time: 48.95 s 
2025-07-10 14:55:37.691271:  
2025-07-10 14:55:37.691462: Epoch 357 
2025-07-10 14:55:37.691595: Current learning rate: 0.00672 
2025-07-10 14:56:27.637732: train_loss -0.311 
2025-07-10 14:56:27.638292: val_loss -0.2613 
2025-07-10 14:56:27.638384: Pseudo dice [np.float32(0.0)] 
2025-07-10 14:56:27.638533: Epoch time: 49.95 s 
2025-07-10 14:56:28.754645:  
2025-07-10 14:56:28.755006: Epoch 358 
2025-07-10 14:56:28.755129: Current learning rate: 0.00671 
2025-07-10 14:57:17.100757: train_loss -0.2722 
2025-07-10 14:57:17.101155: val_loss -0.3511 
2025-07-10 14:57:17.101230: Pseudo dice [np.float32(0.4378)] 
2025-07-10 14:57:17.101330: Epoch time: 48.35 s 
2025-07-10 14:57:18.244515:  
2025-07-10 14:57:18.244982: Epoch 359 
2025-07-10 14:57:18.245103: Current learning rate: 0.0067 
2025-07-10 14:58:04.649388: train_loss -0.3546 
2025-07-10 14:58:04.649675: val_loss -0.3768 
2025-07-10 14:58:04.649750: Pseudo dice [np.float32(0.5205)] 
2025-07-10 14:58:04.649841: Epoch time: 46.41 s 
2025-07-10 14:58:05.835163:  
2025-07-10 14:58:05.835477: Epoch 360 
2025-07-10 14:58:05.835605: Current learning rate: 0.00669 
2025-07-10 14:58:52.720081: train_loss -0.3698 
2025-07-10 14:58:52.720402: val_loss -0.3803 
2025-07-10 14:58:52.720478: Pseudo dice [np.float32(0.6178)] 
2025-07-10 14:58:52.720577: Epoch time: 46.89 s 
2025-07-10 14:58:53.825510:  
2025-07-10 14:58:53.825821: Epoch 361 
2025-07-10 14:58:53.825940: Current learning rate: 0.00668 
2025-07-10 14:59:40.770680: train_loss -0.3907 
2025-07-10 14:59:40.771112: val_loss -0.4031 
2025-07-10 14:59:40.771196: Pseudo dice [np.float32(0.6043)] 
2025-07-10 14:59:40.771306: Epoch time: 46.95 s 
2025-07-10 14:59:42.533562:  
2025-07-10 14:59:42.533945: Epoch 362 
2025-07-10 14:59:42.534196: Current learning rate: 0.00667 
2025-07-10 15:00:28.183595: train_loss -0.4109 
2025-07-10 15:00:28.184232: val_loss -0.3991 
2025-07-10 15:00:28.184350: Pseudo dice [np.float32(0.5685)] 
2025-07-10 15:00:28.184492: Epoch time: 45.65 s 
2025-07-10 15:00:29.392486:  
2025-07-10 15:00:29.393170: Epoch 363 
2025-07-10 15:00:29.393380: Current learning rate: 0.00666 
2025-07-10 15:01:16.446308: train_loss -0.4106 
2025-07-10 15:01:16.447185: val_loss -0.4183 
2025-07-10 15:01:16.447344: Pseudo dice [np.float32(0.6376)] 
2025-07-10 15:01:16.447578: Epoch time: 47.05 s 
2025-07-10 15:01:17.611180:  
2025-07-10 15:01:17.611675: Epoch 364 
2025-07-10 15:01:17.611800: Current learning rate: 0.00665 
2025-07-10 15:02:03.848399: train_loss -0.3907 
2025-07-10 15:02:03.848814: val_loss -0.397 
2025-07-10 15:02:03.848892: Pseudo dice [np.float32(0.5655)] 
2025-07-10 15:02:03.848997: Epoch time: 46.24 s 
2025-07-10 15:02:05.053678:  
2025-07-10 15:02:05.053976: Epoch 365 
2025-07-10 15:02:05.054112: Current learning rate: 0.00665 
2025-07-10 15:02:51.785883: train_loss -0.4179 
2025-07-10 15:02:51.786536: val_loss -0.4305 
2025-07-10 15:02:51.786632: Pseudo dice [np.float32(0.6425)] 
2025-07-10 15:02:51.786734: Epoch time: 46.73 s 
2025-07-10 15:02:52.953831:  
2025-07-10 15:02:52.954220: Epoch 366 
2025-07-10 15:02:52.954358: Current learning rate: 0.00664 
2025-07-10 15:03:39.574490: train_loss -0.41 
2025-07-10 15:03:39.574829: val_loss -0.4116 
2025-07-10 15:03:39.574905: Pseudo dice [np.float32(0.6495)] 
2025-07-10 15:03:39.575006: Epoch time: 46.62 s 
2025-07-10 15:03:40.742537:  
2025-07-10 15:03:40.742843: Epoch 367 
2025-07-10 15:03:40.742966: Current learning rate: 0.00663 
2025-07-10 15:04:27.238760: train_loss -0.3835 
2025-07-10 15:04:27.239697: val_loss -0.3735 
2025-07-10 15:04:27.239809: Pseudo dice [np.float32(0.5202)] 
2025-07-10 15:04:27.239956: Epoch time: 46.5 s 
2025-07-10 15:04:28.578350:  
2025-07-10 15:04:28.578758: Epoch 368 
2025-07-10 15:04:28.578897: Current learning rate: 0.00662 
2025-07-10 15:05:15.983898: train_loss -0.3928 
2025-07-10 15:05:15.984537: val_loss -0.4406 
2025-07-10 15:05:15.984625: Pseudo dice [np.float32(0.5748)] 
2025-07-10 15:05:15.984724: Epoch time: 47.41 s 
2025-07-10 15:05:17.143128:  
2025-07-10 15:05:17.143383: Epoch 369 
2025-07-10 15:05:17.143505: Current learning rate: 0.00661 
2025-07-10 15:06:05.010768: train_loss -0.4097 
2025-07-10 15:06:05.011249: val_loss -0.3955 
2025-07-10 15:06:05.011333: Pseudo dice [np.float32(0.6265)] 
2025-07-10 15:06:05.011445: Epoch time: 47.87 s 
2025-07-10 15:06:06.247733:  
2025-07-10 15:06:06.247947: Epoch 370 
2025-07-10 15:06:06.248064: Current learning rate: 0.0066 
2025-07-10 15:06:54.363315: train_loss -0.3887 
2025-07-10 15:06:54.363735: val_loss -0.4122 
2025-07-10 15:06:54.363815: Pseudo dice [np.float32(0.5983)] 
2025-07-10 15:06:54.363924: Epoch time: 48.12 s 
2025-07-10 15:06:55.487569:  
2025-07-10 15:06:55.487759: Epoch 371 
2025-07-10 15:06:55.487890: Current learning rate: 0.00659 
2025-07-10 15:07:43.149069: train_loss -0.416 
2025-07-10 15:07:43.149632: val_loss -0.4067 
2025-07-10 15:07:43.149718: Pseudo dice [np.float32(0.6274)] 
2025-07-10 15:07:43.149841: Epoch time: 47.66 s 
2025-07-10 15:07:44.290098:  
2025-07-10 15:07:44.290475: Epoch 372 
2025-07-10 15:07:44.290609: Current learning rate: 0.00658 
2025-07-10 15:08:32.183938: train_loss -0.4222 
2025-07-10 15:08:32.184557: val_loss -0.4258 
2025-07-10 15:08:32.184644: Pseudo dice [np.float32(0.6659)] 
2025-07-10 15:08:32.184760: Epoch time: 47.89 s 
2025-07-10 15:08:33.945333:  
2025-07-10 15:08:33.945574: Epoch 373 
2025-07-10 15:08:33.945864: Current learning rate: 0.00657 
2025-07-10 15:09:20.259315: train_loss -0.4195 
2025-07-10 15:09:20.259796: val_loss -0.4259 
2025-07-10 15:09:20.259902: Pseudo dice [np.float32(0.6487)] 
2025-07-10 15:09:20.260012: Epoch time: 46.31 s 
2025-07-10 15:09:21.419334:  
2025-07-10 15:09:21.419773: Epoch 374 
2025-07-10 15:09:21.419939: Current learning rate: 0.00656 
2025-07-10 15:10:08.043387: train_loss -0.4155 
2025-07-10 15:10:08.043891: val_loss -0.4104 
2025-07-10 15:10:08.044005: Pseudo dice [np.float32(0.6381)] 
2025-07-10 15:10:08.044110: Epoch time: 46.63 s 
2025-07-10 15:10:09.195704:  
2025-07-10 15:10:09.196356: Epoch 375 
2025-07-10 15:10:09.196515: Current learning rate: 0.00655 
2025-07-10 15:10:56.137105: train_loss -0.427 
2025-07-10 15:10:56.137529: val_loss -0.4222 
2025-07-10 15:10:56.137633: Pseudo dice [np.float32(0.6518)] 
2025-07-10 15:10:56.137749: Epoch time: 46.94 s 
2025-07-10 15:10:57.332009:  
2025-07-10 15:10:57.332425: Epoch 376 
2025-07-10 15:10:57.332564: Current learning rate: 0.00654 
2025-07-10 15:11:44.710037: train_loss -0.3951 
2025-07-10 15:11:44.710462: val_loss -0.3834 
2025-07-10 15:11:44.710593: Pseudo dice [np.float32(0.5085)] 
2025-07-10 15:11:44.710706: Epoch time: 47.38 s 
2025-07-10 15:11:45.819942:  
2025-07-10 15:11:45.820391: Epoch 377 
2025-07-10 15:11:45.820507: Current learning rate: 0.00653 
2025-07-10 15:12:32.513781: train_loss -0.3997 
2025-07-10 15:12:32.514309: val_loss -0.4161 
2025-07-10 15:12:32.514390: Pseudo dice [np.float32(0.5941)] 
2025-07-10 15:12:32.514517: Epoch time: 46.69 s 
2025-07-10 15:12:33.717474:  
2025-07-10 15:12:33.717999: Epoch 378 
2025-07-10 15:12:33.718204: Current learning rate: 0.00652 
2025-07-10 15:13:20.469638: train_loss -0.4288 
2025-07-10 15:13:20.469981: val_loss -0.427 
2025-07-10 15:13:20.470052: Pseudo dice [np.float32(0.6446)] 
2025-07-10 15:13:20.470149: Epoch time: 46.75 s 
2025-07-10 15:13:21.572922:  
2025-07-10 15:13:21.573220: Epoch 379 
2025-07-10 15:13:21.573520: Current learning rate: 0.00651 
2025-07-10 15:14:08.906685: train_loss -0.4191 
2025-07-10 15:14:08.907282: val_loss -0.4304 
2025-07-10 15:14:08.907395: Pseudo dice [np.float32(0.6001)] 
2025-07-10 15:14:08.907562: Epoch time: 47.33 s 
2025-07-10 15:14:10.104442:  
2025-07-10 15:14:10.104899: Epoch 380 
2025-07-10 15:14:10.105077: Current learning rate: 0.0065 
2025-07-10 15:14:56.924501: train_loss -0.4285 
2025-07-10 15:14:56.924970: val_loss -0.4019 
2025-07-10 15:14:56.925050: Pseudo dice [np.float32(0.6229)] 
2025-07-10 15:14:56.925151: Epoch time: 46.82 s 
2025-07-10 15:14:58.150051:  
2025-07-10 15:14:58.150290: Epoch 381 
2025-07-10 15:14:58.150420: Current learning rate: 0.00649 
2025-07-10 15:15:44.800287: train_loss -0.4213 
2025-07-10 15:15:44.800659: val_loss -0.4323 
2025-07-10 15:15:44.800776: Pseudo dice [np.float32(0.6602)] 
2025-07-10 15:15:44.800886: Epoch time: 46.65 s 
2025-07-10 15:15:45.958646:  
2025-07-10 15:15:45.958812: Epoch 382 
2025-07-10 15:15:45.958944: Current learning rate: 0.00648 
2025-07-10 15:16:32.708975: train_loss -0.4296 
2025-07-10 15:16:32.709416: val_loss -0.4328 
2025-07-10 15:16:32.709492: Pseudo dice [np.float32(0.6644)] 
2025-07-10 15:16:32.709609: Epoch time: 46.75 s 
2025-07-10 15:16:33.896599:  
2025-07-10 15:16:33.897077: Epoch 383 
2025-07-10 15:16:33.897231: Current learning rate: 0.00648 
2025-07-10 15:17:21.397668: train_loss -0.4283 
2025-07-10 15:17:21.398097: val_loss -0.4332 
2025-07-10 15:17:21.398181: Pseudo dice [np.float32(0.6523)] 
2025-07-10 15:17:21.398293: Epoch time: 47.5 s 
2025-07-10 15:17:22.586512:  
2025-07-10 15:17:22.586801: Epoch 384 
2025-07-10 15:17:22.587013: Current learning rate: 0.00647 
2025-07-10 15:18:09.637592: train_loss -0.4199 
2025-07-10 15:18:09.638020: val_loss -0.418 
2025-07-10 15:18:09.638200: Pseudo dice [np.float32(0.5858)] 
2025-07-10 15:18:09.638315: Epoch time: 47.05 s 
2025-07-10 15:18:10.791104:  
2025-07-10 15:18:10.791522: Epoch 385 
2025-07-10 15:18:10.791669: Current learning rate: 0.00646 
2025-07-10 15:18:58.125934: train_loss -0.4162 
2025-07-10 15:18:58.126621: val_loss -0.4317 
2025-07-10 15:18:58.126711: Pseudo dice [np.float32(0.6215)] 
2025-07-10 15:18:58.126829: Epoch time: 47.34 s 
2025-07-10 15:18:59.391528:  
2025-07-10 15:18:59.391729: Epoch 386 
2025-07-10 15:18:59.391902: Current learning rate: 0.00645 
2025-07-10 15:19:47.142066: train_loss -0.4157 
2025-07-10 15:19:47.142423: val_loss -0.4172 
2025-07-10 15:19:47.142492: Pseudo dice [np.float32(0.5791)] 
2025-07-10 15:19:47.142608: Epoch time: 47.75 s 
2025-07-10 15:19:48.306231:  
2025-07-10 15:19:48.306591: Epoch 387 
2025-07-10 15:19:48.306720: Current learning rate: 0.00644 
2025-07-10 15:20:34.913427: train_loss -0.4195 
2025-07-10 15:20:34.913964: val_loss -0.406 
2025-07-10 15:20:34.914052: Pseudo dice [np.float32(0.6531)] 
2025-07-10 15:20:34.914170: Epoch time: 46.61 s 
2025-07-10 15:20:36.093663:  
2025-07-10 15:20:36.094034: Epoch 388 
2025-07-10 15:20:36.094181: Current learning rate: 0.00643 
2025-07-10 15:21:23.122941: train_loss -0.4056 
2025-07-10 15:21:23.123779: val_loss -0.399 
2025-07-10 15:21:23.127651: Pseudo dice [np.float32(0.5667)] 
2025-07-10 15:21:23.128171: Epoch time: 47.03 s 
2025-07-10 15:21:24.362500:  
2025-07-10 15:21:24.363016: Epoch 389 
2025-07-10 15:21:24.363358: Current learning rate: 0.00642 
2025-07-10 15:22:11.958633: train_loss -0.4083 
2025-07-10 15:22:11.959131: val_loss -0.4081 
2025-07-10 15:22:11.959213: Pseudo dice [np.float32(0.6324)] 
2025-07-10 15:22:11.959327: Epoch time: 47.6 s 
2025-07-10 15:22:13.169391:  
2025-07-10 15:22:13.169856: Epoch 390 
2025-07-10 15:22:13.170024: Current learning rate: 0.00641 
2025-07-10 15:23:00.668067: train_loss -0.4157 
2025-07-10 15:23:00.668988: val_loss -0.3935 
2025-07-10 15:23:00.669124: Pseudo dice [np.float32(0.6248)] 
2025-07-10 15:23:00.669333: Epoch time: 47.5 s 
2025-07-10 15:23:01.849282:  
2025-07-10 15:23:01.849460: Epoch 391 
2025-07-10 15:23:01.849624: Current learning rate: 0.0064 
2025-07-10 15:23:49.021959: train_loss -0.4119 
2025-07-10 15:23:49.022658: val_loss -0.3959 
2025-07-10 15:23:49.022752: Pseudo dice [np.float32(0.6155)] 
2025-07-10 15:23:49.022860: Epoch time: 47.17 s 
2025-07-10 15:23:50.224974:  
2025-07-10 15:23:50.225409: Epoch 392 
2025-07-10 15:23:50.225593: Current learning rate: 0.00639 
2025-07-10 15:24:37.725476: train_loss -0.3946 
2025-07-10 15:24:37.726022: val_loss -0.3581 
2025-07-10 15:24:37.726099: Pseudo dice [np.float32(0.4518)] 
2025-07-10 15:24:37.726197: Epoch time: 47.5 s 
2025-07-10 15:24:38.933048:  
2025-07-10 15:24:38.933425: Epoch 393 
2025-07-10 15:24:38.933592: Current learning rate: 0.00638 
2025-07-10 15:25:26.243806: train_loss -0.4014 
2025-07-10 15:25:26.244352: val_loss -0.4329 
2025-07-10 15:25:26.244431: Pseudo dice [np.float32(0.627)] 
2025-07-10 15:25:26.244558: Epoch time: 47.31 s 
2025-07-10 15:25:27.401513:  
2025-07-10 15:25:27.401984: Epoch 394 
2025-07-10 15:25:27.402126: Current learning rate: 0.00637 
2025-07-10 15:26:13.753870: train_loss -0.4257 
2025-07-10 15:26:13.754304: val_loss -0.4288 
2025-07-10 15:26:13.754441: Pseudo dice [np.float32(0.6348)] 
2025-07-10 15:26:13.754592: Epoch time: 46.35 s 
2025-07-10 15:26:15.576846:  
2025-07-10 15:26:15.577133: Epoch 395 
2025-07-10 15:26:15.577263: Current learning rate: 0.00636 
2025-07-10 15:27:02.695774: train_loss -0.4226 
2025-07-10 15:27:02.696311: val_loss -0.4254 
2025-07-10 15:27:02.696414: Pseudo dice [np.float32(0.6292)] 
2025-07-10 15:27:02.696528: Epoch time: 47.12 s 
2025-07-10 15:27:03.943994:  
2025-07-10 15:27:03.944508: Epoch 396 
2025-07-10 15:27:03.944917: Current learning rate: 0.00635 
2025-07-10 15:27:50.959873: train_loss -0.4183 
2025-07-10 15:27:50.960470: val_loss -0.4254 
2025-07-10 15:27:50.960563: Pseudo dice [np.float32(0.6928)] 
2025-07-10 15:27:50.960679: Epoch time: 47.02 s 
2025-07-10 15:27:52.133505:  
2025-07-10 15:27:52.133915: Epoch 397 
2025-07-10 15:27:52.134161: Current learning rate: 0.00634 
2025-07-10 15:28:39.028720: train_loss -0.4314 
2025-07-10 15:28:39.029461: val_loss -0.4157 
2025-07-10 15:28:39.029588: Pseudo dice [np.float32(0.6422)] 
2025-07-10 15:28:39.029737: Epoch time: 46.9 s 
2025-07-10 15:28:40.259013:  
2025-07-10 15:28:40.259360: Epoch 398 
2025-07-10 15:28:40.259649: Current learning rate: 0.00633 
2025-07-10 15:29:27.019784: train_loss -0.4196 
2025-07-10 15:29:27.020289: val_loss -0.4273 
2025-07-10 15:29:27.020375: Pseudo dice [np.float32(0.6723)] 
2025-07-10 15:29:27.020479: Epoch time: 46.76 s 
2025-07-10 15:29:28.174018:  
2025-07-10 15:29:28.174324: Epoch 399 
2025-07-10 15:29:28.174490: Current learning rate: 0.00632 
2025-07-10 15:30:15.414920: train_loss -0.4182 
2025-07-10 15:30:15.415314: val_loss -0.4255 
2025-07-10 15:30:15.415392: Pseudo dice [np.float32(0.6068)] 
2025-07-10 15:30:15.415498: Epoch time: 47.24 s 
2025-07-10 15:30:17.099642:  
2025-07-10 15:30:17.099814: Epoch 400 
2025-07-10 15:30:17.099992: Current learning rate: 0.00631 
2025-07-10 15:31:04.364417: train_loss -0.4148 
2025-07-10 15:31:04.364831: val_loss -0.4263 
2025-07-10 15:31:04.364915: Pseudo dice [np.float32(0.5974)] 
2025-07-10 15:31:04.365017: Epoch time: 47.27 s 
2025-07-10 15:31:05.534741:  
2025-07-10 15:31:05.535468: Epoch 401 
2025-07-10 15:31:05.535645: Current learning rate: 0.0063 
2025-07-10 15:31:52.124816: train_loss -0.4069 
2025-07-10 15:31:52.125127: val_loss -0.4222 
2025-07-10 15:31:52.125200: Pseudo dice [np.float32(0.5698)] 
2025-07-10 15:31:52.125303: Epoch time: 46.59 s 
2025-07-10 15:31:53.305570:  
2025-07-10 15:31:53.306012: Epoch 402 
2025-07-10 15:31:53.306184: Current learning rate: 0.0063 
2025-07-10 15:32:39.746781: train_loss -0.4263 
2025-07-10 15:32:39.747603: val_loss -0.4133 
2025-07-10 15:32:39.747746: Pseudo dice [np.float32(0.5164)] 
2025-07-10 15:32:39.747910: Epoch time: 46.44 s 
2025-07-10 15:32:40.986739:  
2025-07-10 15:32:40.987047: Epoch 403 
2025-07-10 15:32:40.987258: Current learning rate: 0.00629 
2025-07-10 15:33:28.537387: train_loss -0.4376 
2025-07-10 15:33:28.538024: val_loss -0.4371 
2025-07-10 15:33:28.538112: Pseudo dice [np.float32(0.6991)] 
2025-07-10 15:33:28.538234: Epoch time: 47.55 s 
2025-07-10 15:33:29.781994:  
2025-07-10 15:33:29.782500: Epoch 404 
2025-07-10 15:33:29.782749: Current learning rate: 0.00628 
2025-07-10 15:34:17.598403: train_loss -0.4318 
2025-07-10 15:34:17.599298: val_loss -0.4037 
2025-07-10 15:34:17.599398: Pseudo dice [np.float32(0.6555)] 
2025-07-10 15:34:17.599550: Epoch time: 47.82 s 
2025-07-10 15:34:18.786988:  
2025-07-10 15:34:18.787321: Epoch 405 
2025-07-10 15:34:18.787600: Current learning rate: 0.00627 
2025-07-10 15:35:06.513604: train_loss -0.398 
2025-07-10 15:35:06.513995: val_loss -0.3609 
2025-07-10 15:35:06.514071: Pseudo dice [np.float32(0.4036)] 
2025-07-10 15:35:06.514178: Epoch time: 47.73 s 
2025-07-10 15:35:08.302883:  
2025-07-10 15:35:08.303203: Epoch 406 
2025-07-10 15:35:08.303416: Current learning rate: 0.00626 
2025-07-10 15:35:57.741716: train_loss -0.4029 
2025-07-10 15:35:57.742156: val_loss -0.4115 
2025-07-10 15:35:57.742245: Pseudo dice [np.float32(0.604)] 
2025-07-10 15:35:57.742364: Epoch time: 49.44 s 
2025-07-10 15:35:58.914293:  
2025-07-10 15:35:58.914479: Epoch 407 
2025-07-10 15:35:58.914620: Current learning rate: 0.00625 
2025-07-10 15:36:48.475628: train_loss -0.4212 
2025-07-10 15:36:48.475922: val_loss -0.432 
2025-07-10 15:36:48.475997: Pseudo dice [np.float32(0.6489)] 
2025-07-10 15:36:48.476094: Epoch time: 49.56 s 
2025-07-10 15:36:49.661148:  
2025-07-10 15:36:49.661755: Epoch 408 
2025-07-10 15:36:49.661889: Current learning rate: 0.00624 
2025-07-10 15:37:37.652307: train_loss -0.427 
2025-07-10 15:37:37.652781: val_loss -0.416 
2025-07-10 15:37:37.652870: Pseudo dice [np.float32(0.6125)] 
2025-07-10 15:37:37.652984: Epoch time: 47.99 s 
2025-07-10 15:37:38.834943:  
2025-07-10 15:37:38.835520: Epoch 409 
2025-07-10 15:37:38.835693: Current learning rate: 0.00623 
2025-07-10 15:38:26.538340: train_loss -0.4357 
2025-07-10 15:38:26.538858: val_loss -0.4263 
2025-07-10 15:38:26.538939: Pseudo dice [np.float32(0.7063)] 
2025-07-10 15:38:26.539047: Epoch time: 47.7 s 
2025-07-10 15:38:27.684707:  
2025-07-10 15:38:27.685087: Epoch 410 
2025-07-10 15:38:27.685313: Current learning rate: 0.00622 
2025-07-10 15:39:15.390390: train_loss -0.4386 
2025-07-10 15:39:15.390749: val_loss -0.4353 
2025-07-10 15:39:15.390835: Pseudo dice [np.float32(0.6539)] 
2025-07-10 15:39:15.390940: Epoch time: 47.71 s 
2025-07-10 15:39:16.514050:  
2025-07-10 15:39:16.514552: Epoch 411 
2025-07-10 15:39:16.514694: Current learning rate: 0.00621 
2025-07-10 15:40:03.776136: train_loss -0.4317 
2025-07-10 15:40:03.776781: val_loss -0.39 
2025-07-10 15:40:03.776901: Pseudo dice [np.float32(0.5347)] 
2025-07-10 15:40:03.777055: Epoch time: 47.26 s 
2025-07-10 15:40:04.912419:  
2025-07-10 15:40:04.912843: Epoch 412 
2025-07-10 15:40:04.912977: Current learning rate: 0.0062 
2025-07-10 15:40:51.816899: train_loss -0.424 
2025-07-10 15:40:51.817561: val_loss -0.4383 
2025-07-10 15:40:51.817724: Pseudo dice [np.float32(0.5925)] 
2025-07-10 15:40:51.817874: Epoch time: 46.91 s 
2025-07-10 15:40:53.033365:  
2025-07-10 15:40:53.033513: Epoch 413 
2025-07-10 15:40:53.033659: Current learning rate: 0.00619 
2025-07-10 15:41:40.114629: train_loss -0.4153 
2025-07-10 15:41:40.115249: val_loss -0.4123 
2025-07-10 15:41:40.115423: Pseudo dice [np.float32(0.6425)] 
2025-07-10 15:41:40.115572: Epoch time: 47.08 s 
2025-07-10 15:41:41.304157:  
2025-07-10 15:41:41.304612: Epoch 414 
2025-07-10 15:41:41.304907: Current learning rate: 0.00618 
2025-07-10 15:42:28.706432: train_loss -0.42 
2025-07-10 15:42:28.706863: val_loss -0.4302 
2025-07-10 15:42:28.706945: Pseudo dice [np.float32(0.6533)] 
2025-07-10 15:42:28.707055: Epoch time: 47.4 s 
2025-07-10 15:42:29.822699:  
2025-07-10 15:42:29.822872: Epoch 415 
2025-07-10 15:42:29.822996: Current learning rate: 0.00617 
2025-07-10 15:43:16.579239: train_loss -0.4121 
2025-07-10 15:43:16.579687: val_loss -0.434 
2025-07-10 15:43:16.583217: Pseudo dice [np.float32(0.6094)] 
2025-07-10 15:43:16.583353: Epoch time: 46.76 s 
2025-07-10 15:43:17.704419:  
2025-07-10 15:43:17.704776: Epoch 416 
2025-07-10 15:43:17.705048: Current learning rate: 0.00616 
2025-07-10 15:44:04.823156: train_loss -0.4227 
2025-07-10 15:44:04.823929: val_loss -0.4378 
2025-07-10 15:44:04.824060: Pseudo dice [np.float32(0.6701)] 
2025-07-10 15:44:04.824315: Epoch time: 47.12 s 
2025-07-10 15:44:06.649782:  
2025-07-10 15:44:06.650241: Epoch 417 
2025-07-10 15:44:06.650391: Current learning rate: 0.00615 
2025-07-10 15:44:53.364720: train_loss -0.4323 
2025-07-10 15:44:53.365128: val_loss -0.4426 
2025-07-10 15:44:53.365215: Pseudo dice [np.float32(0.7012)] 
2025-07-10 15:44:53.365332: Epoch time: 46.72 s 
2025-07-10 15:44:54.546405:  
2025-07-10 15:44:54.546804: Epoch 418 
2025-07-10 15:44:54.546946: Current learning rate: 0.00614 
2025-07-10 15:45:41.939364: train_loss -0.4366 
2025-07-10 15:45:41.939941: val_loss -0.4277 
2025-07-10 15:45:41.940030: Pseudo dice [np.float32(0.6164)] 
2025-07-10 15:45:41.940146: Epoch time: 47.39 s 
2025-07-10 15:45:43.081908:  
2025-07-10 15:45:43.082411: Epoch 419 
2025-07-10 15:45:43.082562: Current learning rate: 0.00613 
2025-07-10 15:46:30.904979: train_loss -0.4312 
2025-07-10 15:46:30.905430: val_loss -0.4336 
2025-07-10 15:46:30.905507: Pseudo dice [np.float32(0.7062)] 
2025-07-10 15:46:30.905632: Epoch time: 47.82 s 
2025-07-10 15:46:32.073765:  
2025-07-10 15:46:32.074179: Epoch 420 
2025-07-10 15:46:32.074371: Current learning rate: 0.00612 
2025-07-10 15:47:18.724804: train_loss -0.4344 
2025-07-10 15:47:18.725332: val_loss -0.4337 
2025-07-10 15:47:18.725411: Pseudo dice [np.float32(0.6728)] 
2025-07-10 15:47:18.725526: Epoch time: 46.65 s 
2025-07-10 15:47:19.850240:  
2025-07-10 15:47:19.850669: Epoch 421 
2025-07-10 15:47:19.850796: Current learning rate: 0.00612 
2025-07-10 15:48:06.951524: train_loss -0.4149 
2025-07-10 15:48:06.952038: val_loss -0.3853 
2025-07-10 15:48:06.952116: Pseudo dice [np.float32(0.442)] 
2025-07-10 15:48:06.952226: Epoch time: 47.1 s 
2025-07-10 15:48:08.162678:  
2025-07-10 15:48:08.163171: Epoch 422 
2025-07-10 15:48:08.163299: Current learning rate: 0.00611 
2025-07-10 15:48:54.892873: train_loss -0.3658 
2025-07-10 15:48:54.893418: val_loss -0.3426 
2025-07-10 15:48:54.893495: Pseudo dice [np.float32(0.4501)] 
2025-07-10 15:48:54.893616: Epoch time: 46.73 s 
2025-07-10 15:48:56.003077:  
2025-07-10 15:48:56.003320: Epoch 423 
2025-07-10 15:48:56.003445: Current learning rate: 0.0061 
2025-07-10 15:49:43.400441: train_loss -0.4073 
2025-07-10 15:49:43.400831: val_loss -0.4217 
2025-07-10 15:49:43.400910: Pseudo dice [np.float32(0.6293)] 
2025-07-10 15:49:43.401016: Epoch time: 47.4 s 
2025-07-10 15:49:44.529908:  
2025-07-10 15:49:44.530071: Epoch 424 
2025-07-10 15:49:44.530195: Current learning rate: 0.00609 
2025-07-10 15:50:31.946048: train_loss -0.4222 
2025-07-10 15:50:31.946361: val_loss -0.4341 
2025-07-10 15:50:31.946435: Pseudo dice [np.float32(0.6677)] 
2025-07-10 15:50:31.946529: Epoch time: 47.42 s 
2025-07-10 15:50:33.066742:  
2025-07-10 15:50:33.066983: Epoch 425 
2025-07-10 15:50:33.067253: Current learning rate: 0.00608 
2025-07-10 15:51:20.375425: train_loss -0.4239 
2025-07-10 15:51:20.375924: val_loss -0.4407 
2025-07-10 15:51:20.376052: Pseudo dice [np.float32(0.7027)] 
2025-07-10 15:51:20.376225: Epoch time: 47.31 s 
2025-07-10 15:51:21.535561:  
2025-07-10 15:51:21.535800: Epoch 426 
2025-07-10 15:51:21.536022: Current learning rate: 0.00607 
2025-07-10 15:52:09.224129: train_loss -0.4351 
2025-07-10 15:52:09.224651: val_loss -0.4548 
2025-07-10 15:52:09.224737: Pseudo dice [np.float32(0.6477)] 
2025-07-10 15:52:09.224848: Epoch time: 47.69 s 
2025-07-10 15:52:10.382359:  
2025-07-10 15:52:10.382740: Epoch 427 
2025-07-10 15:52:10.382970: Current learning rate: 0.00606 
2025-07-10 15:52:57.371208: train_loss -0.4405 
2025-07-10 15:52:57.371718: val_loss -0.4323 
2025-07-10 15:52:57.371804: Pseudo dice [np.float32(0.6941)] 
2025-07-10 15:52:57.371913: Epoch time: 46.99 s 
2025-07-10 15:52:58.492533:  
2025-07-10 15:52:58.493023: Epoch 428 
2025-07-10 15:52:58.493217: Current learning rate: 0.00605 
2025-07-10 15:53:45.901469: train_loss -0.425 
2025-07-10 15:53:45.901916: val_loss -0.4421 
2025-07-10 15:53:45.902045: Pseudo dice [np.float32(0.6886)] 
2025-07-10 15:53:45.902201: Epoch time: 47.41 s 
2025-07-10 15:53:47.658006:  
2025-07-10 15:53:47.658386: Epoch 429 
2025-07-10 15:53:47.658579: Current learning rate: 0.00604 
2025-07-10 15:54:35.153606: train_loss -0.4367 
2025-07-10 15:54:35.154152: val_loss -0.4179 
2025-07-10 15:54:35.154272: Pseudo dice [np.float32(0.6119)] 
2025-07-10 15:54:35.154400: Epoch time: 47.5 s 
2025-07-10 15:54:36.289656:  
2025-07-10 15:54:36.289949: Epoch 430 
2025-07-10 15:54:36.290077: Current learning rate: 0.00603 
2025-07-10 15:55:22.889614: train_loss -0.429 
2025-07-10 15:55:22.890084: val_loss -0.4324 
2025-07-10 15:55:22.890185: Pseudo dice [np.float32(0.6584)] 
2025-07-10 15:55:22.890298: Epoch time: 46.6 s 
2025-07-10 15:55:24.102295:  
2025-07-10 15:55:24.102659: Epoch 431 
2025-07-10 15:55:24.102830: Current learning rate: 0.00602 
2025-07-10 15:56:11.565012: train_loss -0.4114 
2025-07-10 15:56:11.565623: val_loss -0.2032 
2025-07-10 15:56:11.565712: Pseudo dice [np.float32(0.0)] 
2025-07-10 15:56:11.565825: Epoch time: 47.46 s 
2025-07-10 15:56:12.786366:  
2025-07-10 15:56:12.786743: Epoch 432 
2025-07-10 15:56:12.786879: Current learning rate: 0.00601 
2025-07-10 15:56:59.433892: train_loss -0.3495 
2025-07-10 15:56:59.434927: val_loss -0.3776 
2025-07-10 15:56:59.435020: Pseudo dice [np.float32(0.6375)] 
2025-07-10 15:56:59.435167: Epoch time: 46.65 s 
2025-07-10 15:57:00.618711:  
2025-07-10 15:57:00.619354: Epoch 433 
2025-07-10 15:57:00.619660: Current learning rate: 0.006 
2025-07-10 15:57:46.686139: train_loss -0.3923 
2025-07-10 15:57:46.686534: val_loss -0.3341 
2025-07-10 15:57:46.686698: Pseudo dice [np.float32(0.5875)] 
2025-07-10 15:57:46.686828: Epoch time: 46.07 s 
2025-07-10 15:57:47.809206:  
2025-07-10 15:57:47.809567: Epoch 434 
2025-07-10 15:57:47.809741: Current learning rate: 0.00599 
2025-07-10 15:58:35.033485: train_loss -0.2988 
2025-07-10 15:58:35.034029: val_loss -0.257 
2025-07-10 15:58:35.034187: Pseudo dice [np.float32(0.0)] 
2025-07-10 15:58:35.034371: Epoch time: 47.23 s 
2025-07-10 15:58:36.228888:  
2025-07-10 15:58:36.229263: Epoch 435 
2025-07-10 15:58:36.229390: Current learning rate: 0.00598 
2025-07-10 15:59:23.310683: train_loss -0.2939 
2025-07-10 15:59:23.311055: val_loss -0.3771 
2025-07-10 15:59:23.311350: Pseudo dice [np.float32(0.4837)] 
2025-07-10 15:59:23.311490: Epoch time: 47.08 s 
2025-07-10 15:59:24.598020:  
2025-07-10 15:59:24.598266: Epoch 436 
2025-07-10 15:59:24.598433: Current learning rate: 0.00597 
2025-07-10 16:00:11.335917: train_loss -0.3969 
2025-07-10 16:00:11.336505: val_loss -0.3792 
2025-07-10 16:00:11.336621: Pseudo dice [np.float32(0.5275)] 
2025-07-10 16:00:11.336755: Epoch time: 46.74 s 
2025-07-10 16:00:12.563991:  
2025-07-10 16:00:12.564268: Epoch 437 
2025-07-10 16:00:12.564404: Current learning rate: 0.00596 
2025-07-10 16:00:59.866952: train_loss -0.4006 
2025-07-10 16:00:59.867469: val_loss -0.4021 
2025-07-10 16:00:59.867560: Pseudo dice [np.float32(0.615)] 
2025-07-10 16:00:59.867673: Epoch time: 47.3 s 
2025-07-10 16:01:01.127086:  
2025-07-10 16:01:01.127315: Epoch 438 
2025-07-10 16:01:01.127453: Current learning rate: 0.00595 
2025-07-10 16:01:48.518584: train_loss -0.4139 
2025-07-10 16:01:48.519115: val_loss -0.4101 
2025-07-10 16:01:48.519198: Pseudo dice [np.float32(0.5921)] 
2025-07-10 16:01:48.519309: Epoch time: 47.39 s 
2025-07-10 16:01:49.670940:  
2025-07-10 16:01:49.671365: Epoch 439 
2025-07-10 16:01:49.671633: Current learning rate: 0.00594 
2025-07-10 16:02:36.831654: train_loss -0.4132 
2025-07-10 16:02:36.832352: val_loss -0.4013 
2025-07-10 16:02:36.832515: Pseudo dice [np.float32(0.6163)] 
2025-07-10 16:02:36.832733: Epoch time: 47.16 s 
2025-07-10 16:02:38.064234:  
2025-07-10 16:02:38.064650: Epoch 440 
2025-07-10 16:02:38.064839: Current learning rate: 0.00593 
2025-07-10 16:03:24.563508: train_loss -0.4245 
2025-07-10 16:03:24.563885: val_loss -0.389 
2025-07-10 16:03:24.563959: Pseudo dice [np.float32(0.6444)] 
2025-07-10 16:03:24.564062: Epoch time: 46.5 s 
2025-07-10 16:03:26.352132:  
2025-07-10 16:03:26.352407: Epoch 441 
2025-07-10 16:03:26.352529: Current learning rate: 0.00592 
2025-07-10 16:04:13.534092: train_loss -0.4211 
2025-07-10 16:04:13.534632: val_loss -0.4103 
2025-07-10 16:04:13.534756: Pseudo dice [np.float32(0.5658)] 
2025-07-10 16:04:13.534876: Epoch time: 47.18 s 
2025-07-10 16:04:14.721199:  
2025-07-10 16:04:14.721594: Epoch 442 
2025-07-10 16:04:14.721758: Current learning rate: 0.00592 
2025-07-10 16:05:01.253664: train_loss -0.3839 
2025-07-10 16:05:01.254359: val_loss -0.3787 
2025-07-10 16:05:01.254689: Pseudo dice [np.float32(0.5073)] 
2025-07-10 16:05:01.254844: Epoch time: 46.53 s 
2025-07-10 16:05:02.414457:  
2025-07-10 16:05:02.414857: Epoch 443 
2025-07-10 16:05:02.415024: Current learning rate: 0.00591 
2025-07-10 16:05:49.248462: train_loss -0.418 
2025-07-10 16:05:49.249006: val_loss -0.3762 
2025-07-10 16:05:49.249096: Pseudo dice [np.float32(0.5645)] 
2025-07-10 16:05:49.249207: Epoch time: 46.84 s 
2025-07-10 16:05:50.417135:  
2025-07-10 16:05:50.417474: Epoch 444 
2025-07-10 16:05:50.417652: Current learning rate: 0.0059 
2025-07-10 16:06:37.617952: train_loss -0.3785 
2025-07-10 16:06:37.619301: val_loss -0.4262 
2025-07-10 16:06:37.619514: Pseudo dice [np.float32(0.5886)] 
2025-07-10 16:06:37.619857: Epoch time: 47.2 s 
2025-07-10 16:06:38.767846:  
2025-07-10 16:06:38.768473: Epoch 445 
2025-07-10 16:06:38.768625: Current learning rate: 0.00589 
2025-07-10 16:07:25.092944: train_loss -0.4071 
2025-07-10 16:07:25.093603: val_loss -0.418 
2025-07-10 16:07:25.093681: Pseudo dice [np.float32(0.6063)] 
2025-07-10 16:07:25.093810: Epoch time: 46.33 s 
2025-07-10 16:07:26.256587:  
2025-07-10 16:07:26.257198: Epoch 446 
2025-07-10 16:07:26.257324: Current learning rate: 0.00588 
2025-07-10 16:08:12.566449: train_loss -0.4251 
2025-07-10 16:08:12.567690: val_loss -0.4468 
2025-07-10 16:08:12.568244: Pseudo dice [np.float32(0.6924)] 
2025-07-10 16:08:12.568438: Epoch time: 46.31 s 
2025-07-10 16:08:13.778080:  
2025-07-10 16:08:13.778458: Epoch 447 
2025-07-10 16:08:13.778667: Current learning rate: 0.00587 
2025-07-10 16:08:59.828512: train_loss -0.4202 
2025-07-10 16:08:59.828896: val_loss -0.4069 
2025-07-10 16:08:59.829067: Pseudo dice [np.float32(0.5973)] 
2025-07-10 16:08:59.829174: Epoch time: 46.05 s 
2025-07-10 16:09:01.030279:  
2025-07-10 16:09:01.030888: Epoch 448 
2025-07-10 16:09:01.031109: Current learning rate: 0.00586 
2025-07-10 16:09:47.649646: train_loss -0.4121 
2025-07-10 16:09:47.650121: val_loss -0.4191 
2025-07-10 16:09:47.650322: Pseudo dice [np.float32(0.6449)] 
2025-07-10 16:09:47.650476: Epoch time: 46.62 s 
2025-07-10 16:09:48.809962:  
2025-07-10 16:09:48.810260: Epoch 449 
2025-07-10 16:09:48.810413: Current learning rate: 0.00585 
2025-07-10 16:10:35.210636: train_loss -0.4175 
2025-07-10 16:10:35.211041: val_loss -0.4129 
2025-07-10 16:10:35.211116: Pseudo dice [np.float32(0.6427)] 
2025-07-10 16:10:35.211222: Epoch time: 46.4 s 
2025-07-10 16:10:36.943784:  
2025-07-10 16:10:36.944575: Epoch 450 
2025-07-10 16:10:36.944735: Current learning rate: 0.00584 
2025-07-10 16:11:23.716548: train_loss -0.4193 
2025-07-10 16:11:23.716913: val_loss -0.4157 
2025-07-10 16:11:23.716995: Pseudo dice [np.float32(0.6574)] 
2025-07-10 16:11:23.717116: Epoch time: 46.77 s 
2025-07-10 16:11:24.873225:  
2025-07-10 16:11:24.873616: Epoch 451 
2025-07-10 16:11:24.873882: Current learning rate: 0.00583 
2025-07-10 16:12:11.641310: train_loss -0.3118 
2025-07-10 16:12:11.642044: val_loss -0.3698 
2025-07-10 16:12:11.642145: Pseudo dice [np.float32(0.54)] 
2025-07-10 16:12:11.642288: Epoch time: 46.77 s 
2025-07-10 16:12:12.800726:  
2025-07-10 16:12:12.801202: Epoch 452 
2025-07-10 16:12:12.801482: Current learning rate: 0.00582 
2025-07-10 16:12:59.406165: train_loss -0.3706 
2025-07-10 16:12:59.406756: val_loss -0.3765 
2025-07-10 16:12:59.406840: Pseudo dice [np.float32(0.5351)] 
2025-07-10 16:12:59.406951: Epoch time: 46.61 s 
2025-07-10 16:13:01.138506:  
2025-07-10 16:13:01.138793: Epoch 453 
2025-07-10 16:13:01.138895: Current learning rate: 0.00581 
2025-07-10 16:13:48.356923: train_loss -0.4027 
2025-07-10 16:13:48.357435: val_loss -0.3777 
2025-07-10 16:13:48.357526: Pseudo dice [np.float32(0.591)] 
2025-07-10 16:13:48.357655: Epoch time: 47.22 s 
2025-07-10 16:13:49.538408:  
2025-07-10 16:13:49.538880: Epoch 454 
2025-07-10 16:13:49.539129: Current learning rate: 0.0058 
2025-07-10 16:14:37.379273: train_loss -0.4202 
2025-07-10 16:14:37.379648: val_loss -0.4216 
2025-07-10 16:14:37.379746: Pseudo dice [np.float32(0.6401)] 
2025-07-10 16:14:37.379887: Epoch time: 47.84 s 
2025-07-10 16:14:38.545233:  
2025-07-10 16:14:38.545796: Epoch 455 
2025-07-10 16:14:38.546072: Current learning rate: 0.00579 
2025-07-10 16:15:26.001006: train_loss -0.4288 
2025-07-10 16:15:26.001629: val_loss -0.4199 
2025-07-10 16:15:26.001725: Pseudo dice [np.float32(0.627)] 
2025-07-10 16:15:26.001834: Epoch time: 47.46 s 
2025-07-10 16:15:27.187068:  
2025-07-10 16:15:27.187459: Epoch 456 
2025-07-10 16:15:27.187604: Current learning rate: 0.00578 
2025-07-10 16:16:13.753511: train_loss -0.4271 
2025-07-10 16:16:13.754421: val_loss -0.419 
2025-07-10 16:16:13.754600: Pseudo dice [np.float32(0.6477)] 
2025-07-10 16:16:13.754744: Epoch time: 46.57 s 
2025-07-10 16:16:14.946738:  
2025-07-10 16:16:14.947218: Epoch 457 
2025-07-10 16:16:14.947363: Current learning rate: 0.00577 
2025-07-10 16:17:02.558205: train_loss -0.4143 
2025-07-10 16:17:02.559291: val_loss -0.4359 
2025-07-10 16:17:02.559398: Pseudo dice [np.float32(0.651)] 
2025-07-10 16:17:02.559526: Epoch time: 47.61 s 
2025-07-10 16:17:03.778649:  
2025-07-10 16:17:03.779225: Epoch 458 
2025-07-10 16:17:03.779420: Current learning rate: 0.00576 
2025-07-10 16:17:51.141534: train_loss -0.4309 
2025-07-10 16:17:51.142052: val_loss -0.4273 
2025-07-10 16:17:51.142141: Pseudo dice [np.float32(0.6437)] 
2025-07-10 16:17:51.142252: Epoch time: 47.36 s 
2025-07-10 16:17:52.282414:  
2025-07-10 16:17:52.282843: Epoch 459 
2025-07-10 16:17:52.283107: Current learning rate: 0.00575 
2025-07-10 16:18:38.879597: train_loss -0.4357 
2025-07-10 16:18:38.880022: val_loss -0.4395 
2025-07-10 16:18:38.880106: Pseudo dice [np.float32(0.7384)] 
2025-07-10 16:18:38.880213: Epoch time: 46.6 s 
2025-07-10 16:18:40.010197:  
2025-07-10 16:18:40.010516: Epoch 460 
2025-07-10 16:18:40.010628: Current learning rate: 0.00574 
2025-07-10 16:19:26.934488: train_loss -0.4311 
2025-07-10 16:19:26.934770: val_loss -0.4155 
2025-07-10 16:19:26.934850: Pseudo dice [np.float32(0.6216)] 
2025-07-10 16:19:26.934946: Epoch time: 46.93 s 
2025-07-10 16:19:28.054371:  
2025-07-10 16:19:28.054870: Epoch 461 
2025-07-10 16:19:28.055006: Current learning rate: 0.00573 
2025-07-10 16:20:14.578348: train_loss -0.427 
2025-07-10 16:20:14.578909: val_loss -0.4132 
2025-07-10 16:20:14.579000: Pseudo dice [np.float32(0.6373)] 
2025-07-10 16:20:14.579115: Epoch time: 46.52 s 
2025-07-10 16:20:15.770333:  
2025-07-10 16:20:15.770921: Epoch 462 
2025-07-10 16:20:15.771137: Current learning rate: 0.00572 
2025-07-10 16:21:02.238032: train_loss -0.4299 
2025-07-10 16:21:02.238497: val_loss -0.4398 
2025-07-10 16:21:02.238589: Pseudo dice [np.float32(0.6073)] 
2025-07-10 16:21:02.238696: Epoch time: 46.47 s 
2025-07-10 16:21:03.367092:  
2025-07-10 16:21:03.367615: Epoch 463 
2025-07-10 16:21:03.367742: Current learning rate: 0.00571 
2025-07-10 16:21:50.561446: train_loss -0.4235 
2025-07-10 16:21:50.561848: val_loss -0.4239 
2025-07-10 16:21:50.561925: Pseudo dice [np.float32(0.6393)] 
2025-07-10 16:21:50.562028: Epoch time: 47.2 s 
2025-07-10 16:21:51.677117:  
2025-07-10 16:21:51.677437: Epoch 464 
2025-07-10 16:21:51.677625: Current learning rate: 0.0057 
2025-07-10 16:22:39.082478: train_loss -0.42 
2025-07-10 16:22:39.083157: val_loss -0.4227 
2025-07-10 16:22:39.083245: Pseudo dice [np.float32(0.665)] 
2025-07-10 16:22:39.083364: Epoch time: 47.41 s 
2025-07-10 16:22:40.304440:  
2025-07-10 16:22:40.304973: Epoch 465 
2025-07-10 16:22:40.305153: Current learning rate: 0.0057 
2025-07-10 16:23:27.491191: train_loss -0.4346 
2025-07-10 16:23:27.491959: val_loss -0.4328 
2025-07-10 16:23:27.492058: Pseudo dice [np.float32(0.7169)] 
2025-07-10 16:23:27.492190: Epoch time: 47.19 s 
2025-07-10 16:23:29.503378:  
2025-07-10 16:23:29.503964: Epoch 466 
2025-07-10 16:23:29.504197: Current learning rate: 0.00569 
2025-07-10 16:24:17.022678: train_loss -0.441 
2025-07-10 16:24:17.023124: val_loss -0.4384 
2025-07-10 16:24:17.023216: Pseudo dice [np.float32(0.7292)] 
2025-07-10 16:24:17.023332: Epoch time: 47.52 s 
2025-07-10 16:24:18.151727:  
2025-07-10 16:24:18.152140: Epoch 467 
2025-07-10 16:24:18.152268: Current learning rate: 0.00568 
2025-07-10 16:25:05.840799: train_loss -0.4302 
2025-07-10 16:25:05.841530: val_loss -0.4361 
2025-07-10 16:25:05.841703: Pseudo dice [np.float32(0.6391)] 
2025-07-10 16:25:05.841859: Epoch time: 47.69 s 
2025-07-10 16:25:07.025802:  
2025-07-10 16:25:07.026023: Epoch 468 
2025-07-10 16:25:07.026175: Current learning rate: 0.00567 
2025-07-10 16:25:54.547247: train_loss -0.4086 
2025-07-10 16:25:54.547737: val_loss -0.4277 
2025-07-10 16:25:54.547813: Pseudo dice [np.float32(0.6288)] 
2025-07-10 16:25:54.547918: Epoch time: 47.52 s 
2025-07-10 16:25:55.699240:  
2025-07-10 16:25:55.699628: Epoch 469 
2025-07-10 16:25:55.699804: Current learning rate: 0.00566 
2025-07-10 16:26:42.822990: train_loss -0.4304 
2025-07-10 16:26:42.823395: val_loss -0.4343 
2025-07-10 16:26:42.823473: Pseudo dice [np.float32(0.7)] 
2025-07-10 16:26:42.823781: Epoch time: 47.12 s 
2025-07-10 16:26:43.960871:  
2025-07-10 16:26:43.961218: Epoch 470 
2025-07-10 16:26:43.961393: Current learning rate: 0.00565 
2025-07-10 16:27:31.406582: train_loss -0.4241 
2025-07-10 16:27:31.407031: val_loss -0.4199 
2025-07-10 16:27:31.407107: Pseudo dice [np.float32(0.6215)] 
2025-07-10 16:27:31.407203: Epoch time: 47.45 s 
2025-07-10 16:27:32.552732:  
2025-07-10 16:27:32.553180: Epoch 471 
2025-07-10 16:27:32.553311: Current learning rate: 0.00564 
2025-07-10 16:28:19.577448: train_loss -0.4317 
2025-07-10 16:28:19.577981: val_loss -0.4263 
2025-07-10 16:28:19.578066: Pseudo dice [np.float32(0.6905)] 
2025-07-10 16:28:19.578174: Epoch time: 47.03 s 
2025-07-10 16:28:20.751173:  
2025-07-10 16:28:20.751599: Epoch 472 
2025-07-10 16:28:20.751731: Current learning rate: 0.00563 
2025-07-10 16:29:07.388451: train_loss -0.4241 
2025-07-10 16:29:07.388948: val_loss -0.4338 
2025-07-10 16:29:07.389027: Pseudo dice [np.float32(0.7076)] 
2025-07-10 16:29:07.389127: Epoch time: 46.64 s 
2025-07-10 16:29:08.518458:  
2025-07-10 16:29:08.518878: Epoch 473 
2025-07-10 16:29:08.519083: Current learning rate: 0.00562 
2025-07-10 16:29:55.521191: train_loss -0.4267 
2025-07-10 16:29:55.521928: val_loss -0.4057 
2025-07-10 16:29:55.522127: Pseudo dice [np.float32(0.6932)] 
2025-07-10 16:29:55.522278: Epoch time: 47.0 s 
2025-07-10 16:29:56.677583:  
2025-07-10 16:29:56.678006: Epoch 474 
2025-07-10 16:29:56.678132: Current learning rate: 0.00561 
2025-07-10 16:30:43.365217: train_loss -0.4234 
2025-07-10 16:30:43.366235: val_loss -0.4262 
2025-07-10 16:30:43.366346: Pseudo dice [np.float32(0.6322)] 
2025-07-10 16:30:43.366491: Epoch time: 46.69 s 
2025-07-10 16:30:44.530793:  
2025-07-10 16:30:44.531170: Epoch 475 
2025-07-10 16:30:44.531309: Current learning rate: 0.0056 
2025-07-10 16:31:30.952152: train_loss -0.4254 
2025-07-10 16:31:30.952667: val_loss -0.4441 
2025-07-10 16:31:30.952755: Pseudo dice [np.float32(0.6661)] 
2025-07-10 16:31:30.952865: Epoch time: 46.42 s 
2025-07-10 16:31:32.179501:  
2025-07-10 16:31:32.179905: Epoch 476 
2025-07-10 16:31:32.180037: Current learning rate: 0.00559 
2025-07-10 16:32:19.571241: train_loss -0.4179 
2025-07-10 16:32:19.571853: val_loss -0.4185 
2025-07-10 16:32:19.571945: Pseudo dice [np.float32(0.5843)] 
2025-07-10 16:32:19.572056: Epoch time: 47.39 s 
2025-07-10 16:32:20.755529:  
2025-07-10 16:32:20.755796: Epoch 477 
2025-07-10 16:32:20.755924: Current learning rate: 0.00558 
2025-07-10 16:33:07.743933: train_loss -0.4215 
2025-07-10 16:33:07.744277: val_loss -0.421 
2025-07-10 16:33:07.744376: Pseudo dice [np.float32(0.6185)] 
2025-07-10 16:33:07.744575: Epoch time: 46.99 s 
2025-07-10 16:33:09.460367:  
2025-07-10 16:33:09.460901: Epoch 478 
2025-07-10 16:33:09.461242: Current learning rate: 0.00557 
2025-07-10 16:33:56.637359: train_loss -0.4429 
2025-07-10 16:33:56.637870: val_loss -0.4618 
2025-07-10 16:33:56.637951: Pseudo dice [np.float32(0.7253)] 
2025-07-10 16:33:56.638069: Epoch time: 47.18 s 
2025-07-10 16:33:57.805116:  
2025-07-10 16:33:57.805517: Epoch 479 
2025-07-10 16:33:57.806092: Current learning rate: 0.00556 
2025-07-10 16:34:45.395673: train_loss -0.4361 
2025-07-10 16:34:45.397718: val_loss -0.4369 
2025-07-10 16:34:45.401856: Pseudo dice [np.float32(0.6462)] 
2025-07-10 16:34:45.402857: Epoch time: 47.59 s 
2025-07-10 16:34:46.583468:  
2025-07-10 16:34:46.583785: Epoch 480 
2025-07-10 16:34:46.584008: Current learning rate: 0.00555 
2025-07-10 16:35:33.415219: train_loss -0.4473 
2025-07-10 16:35:33.415974: val_loss -0.4415 
2025-07-10 16:35:33.416075: Pseudo dice [np.float32(0.6817)] 
2025-07-10 16:35:33.416199: Epoch time: 46.83 s 
2025-07-10 16:35:34.584768:  
2025-07-10 16:35:34.585376: Epoch 481 
2025-07-10 16:35:34.585500: Current learning rate: 0.00554 
2025-07-10 16:36:21.069143: train_loss -0.4304 
2025-07-10 16:36:21.069875: val_loss -0.4304 
2025-07-10 16:36:21.070029: Pseudo dice [np.float32(0.6846)] 
2025-07-10 16:36:21.070212: Epoch time: 46.49 s 
2025-07-10 16:36:22.238794:  
2025-07-10 16:36:22.239058: Epoch 482 
2025-07-10 16:36:22.239396: Current learning rate: 0.00553 
2025-07-10 16:37:08.118131: train_loss -0.4201 
2025-07-10 16:37:08.119277: val_loss -0.3635 
2025-07-10 16:37:08.119467: Pseudo dice [np.float32(0.5818)] 
2025-07-10 16:37:08.119691: Epoch time: 45.88 s 
2025-07-10 16:37:09.281662:  
2025-07-10 16:37:09.281889: Epoch 483 
2025-07-10 16:37:09.282184: Current learning rate: 0.00552 
2025-07-10 16:37:55.854046: train_loss -0.3677 
2025-07-10 16:37:55.856030: val_loss -0.3973 
2025-07-10 16:37:55.856354: Pseudo dice [np.float32(0.5467)] 
2025-07-10 16:37:55.856708: Epoch time: 46.57 s 
2025-07-10 16:37:57.087872:  
2025-07-10 16:37:57.088102: Epoch 484 
2025-07-10 16:37:57.088302: Current learning rate: 0.00551 
2025-07-10 16:38:43.777723: train_loss -0.4145 
2025-07-10 16:38:43.778206: val_loss -0.4152 
2025-07-10 16:38:43.778311: Pseudo dice [np.float32(0.6602)] 
2025-07-10 16:38:43.778551: Epoch time: 46.69 s 
2025-07-10 16:38:44.916660:  
2025-07-10 16:38:44.917138: Epoch 485 
2025-07-10 16:38:44.917276: Current learning rate: 0.0055 
2025-07-10 16:39:31.597248: train_loss -0.43 
2025-07-10 16:39:31.597615: val_loss -0.4462 
2025-07-10 16:39:31.597692: Pseudo dice [np.float32(0.6679)] 
2025-07-10 16:39:31.597786: Epoch time: 46.68 s 
2025-07-10 16:39:32.724594:  
2025-07-10 16:39:32.724830: Epoch 486 
2025-07-10 16:39:32.724946: Current learning rate: 0.00549 
2025-07-10 16:40:19.341762: train_loss -0.4356 
2025-07-10 16:40:19.342297: val_loss -0.4343 
2025-07-10 16:40:19.342398: Pseudo dice [np.float32(0.7034)] 
2025-07-10 16:40:19.342511: Epoch time: 46.62 s 
2025-07-10 16:40:20.597546:  
2025-07-10 16:40:20.597949: Epoch 487 
2025-07-10 16:40:20.598096: Current learning rate: 0.00548 
2025-07-10 16:41:07.440657: train_loss -0.4259 
2025-07-10 16:41:07.441211: val_loss -0.4279 
2025-07-10 16:41:07.441351: Pseudo dice [np.float32(0.5972)] 
2025-07-10 16:41:07.441560: Epoch time: 46.84 s 
2025-07-10 16:41:08.681177:  
2025-07-10 16:41:08.681586: Epoch 488 
2025-07-10 16:41:08.681830: Current learning rate: 0.00547 
2025-07-10 16:41:54.949603: train_loss -0.4178 
2025-07-10 16:41:54.950478: val_loss -0.3105 
2025-07-10 16:41:54.950578: Pseudo dice [np.float32(0.4549)] 
2025-07-10 16:41:54.950783: Epoch time: 46.27 s 
2025-07-10 16:41:56.141668:  
2025-07-10 16:41:56.141803: Epoch 489 
2025-07-10 16:41:56.141905: Current learning rate: 0.00546 
2025-07-10 16:42:42.044889: train_loss -0.3889 
2025-07-10 16:42:42.045338: val_loss -0.3835 
2025-07-10 16:42:42.045532: Pseudo dice [np.float32(0.5899)] 
2025-07-10 16:42:42.045762: Epoch time: 45.9 s 
2025-07-10 16:42:43.822276:  
2025-07-10 16:42:43.822763: Epoch 490 
2025-07-10 16:42:43.822969: Current learning rate: 0.00546 
2025-07-10 16:43:29.705779: train_loss -0.4251 
2025-07-10 16:43:29.706309: val_loss -0.4445 
2025-07-10 16:43:29.706391: Pseudo dice [np.float32(0.6919)] 
2025-07-10 16:43:29.706500: Epoch time: 45.88 s 
2025-07-10 16:43:30.900086:  
2025-07-10 16:43:30.900552: Epoch 491 
2025-07-10 16:43:30.900748: Current learning rate: 0.00545 
2025-07-10 16:44:17.054139: train_loss -0.4276 
2025-07-10 16:44:17.054637: val_loss -0.423 
2025-07-10 16:44:17.054722: Pseudo dice [np.float32(0.6286)] 
2025-07-10 16:44:17.054830: Epoch time: 46.16 s 
2025-07-10 16:44:18.237344:  
2025-07-10 16:44:18.237521: Epoch 492 
2025-07-10 16:44:18.237667: Current learning rate: 0.00544 
2025-07-10 16:45:04.388117: train_loss -0.4383 
2025-07-10 16:45:04.388471: val_loss -0.4412 
2025-07-10 16:45:04.388565: Pseudo dice [np.float32(0.6775)] 
2025-07-10 16:45:04.388668: Epoch time: 46.15 s 
2025-07-10 16:45:05.588978:  
2025-07-10 16:45:05.589331: Epoch 493 
2025-07-10 16:45:05.589581: Current learning rate: 0.00543 
2025-07-10 16:45:52.090775: train_loss -0.4089 
2025-07-10 16:45:52.091207: val_loss -0.4063 
2025-07-10 16:45:52.091291: Pseudo dice [np.float32(0.4811)] 
2025-07-10 16:45:52.091399: Epoch time: 46.5 s 
2025-07-10 16:45:53.240357:  
2025-07-10 16:45:53.240875: Epoch 494 
2025-07-10 16:45:53.241062: Current learning rate: 0.00542 
2025-07-10 16:46:39.462276: train_loss -0.416 
2025-07-10 16:46:39.463392: val_loss -0.4297 
2025-07-10 16:46:39.463848: Pseudo dice [np.float32(0.6185)] 
2025-07-10 16:46:39.464133: Epoch time: 46.22 s 
2025-07-10 16:46:40.669744:  
2025-07-10 16:46:40.669980: Epoch 495 
2025-07-10 16:46:40.670102: Current learning rate: 0.00541 
2025-07-10 16:47:26.691552: train_loss -0.4092 
2025-07-10 16:47:26.691941: val_loss -0.4302 
2025-07-10 16:47:26.692015: Pseudo dice [np.float32(0.6825)] 
2025-07-10 16:47:26.692120: Epoch time: 46.02 s 
2025-07-10 16:47:27.836860:  
2025-07-10 16:47:27.837043: Epoch 496 
2025-07-10 16:47:27.837248: Current learning rate: 0.0054 
2025-07-10 16:48:14.265772: train_loss -0.4315 
2025-07-10 16:48:14.266480: val_loss -0.391 
2025-07-10 16:48:14.266576: Pseudo dice [np.float32(0.639)] 
2025-07-10 16:48:14.266752: Epoch time: 46.43 s 
2025-07-10 16:48:15.403291:  
2025-07-10 16:48:15.403600: Epoch 497 
2025-07-10 16:48:15.403835: Current learning rate: 0.00539 
2025-07-10 16:49:01.060783: train_loss -0.439 
2025-07-10 16:49:01.061199: val_loss -0.4394 
2025-07-10 16:49:01.061275: Pseudo dice [np.float32(0.655)] 
2025-07-10 16:49:01.061386: Epoch time: 45.66 s 
2025-07-10 16:49:02.230734:  
2025-07-10 16:49:02.231018: Epoch 498 
2025-07-10 16:49:02.231332: Current learning rate: 0.00538 
2025-07-10 16:49:48.809237: train_loss -0.4487 
2025-07-10 16:49:48.810123: val_loss -0.4351 
2025-07-10 16:49:48.810211: Pseudo dice [np.float32(0.7374)] 
2025-07-10 16:49:48.810345: Epoch time: 46.58 s 
2025-07-10 16:49:49.967779:  
2025-07-10 16:49:49.968057: Epoch 499 
2025-07-10 16:49:49.968193: Current learning rate: 0.00537 
2025-07-10 16:50:36.635090: train_loss -0.4496 
2025-07-10 16:50:36.635602: val_loss -0.4396 
2025-07-10 16:50:36.635689: Pseudo dice [np.float32(0.735)] 
2025-07-10 16:50:36.635789: Epoch time: 46.67 s 
2025-07-10 16:50:38.347784:  
2025-07-10 16:50:38.347958: Epoch 500 
2025-07-10 16:50:38.348083: Current learning rate: 0.00536 
2025-07-10 16:51:25.021323: train_loss -0.4531 
2025-07-10 16:51:25.022124: val_loss -0.432 
2025-07-10 16:51:25.022272: Pseudo dice [np.float32(0.7625)] 
2025-07-10 16:51:25.022395: Epoch time: 46.67 s 
2025-07-10 16:51:26.208436:  
2025-07-10 16:51:26.208671: Epoch 501 
2025-07-10 16:51:26.208815: Current learning rate: 0.00535 
2025-07-10 16:52:12.947425: train_loss -0.4416 
2025-07-10 16:52:12.948117: val_loss -0.4537 
2025-07-10 16:52:12.948243: Pseudo dice [np.float32(0.7259)] 
2025-07-10 16:52:12.948389: Epoch time: 46.74 s 
2025-07-10 16:52:14.856836:  
2025-07-10 16:52:14.857222: Epoch 502 
2025-07-10 16:52:14.857673: Current learning rate: 0.00534 
2025-07-10 16:53:02.086436: train_loss -0.4412 
2025-07-10 16:53:02.086979: val_loss -0.4453 
2025-07-10 16:53:02.087139: Pseudo dice [np.float32(0.7324)] 
2025-07-10 16:53:02.087283: Epoch time: 47.23 s 
2025-07-10 16:53:03.198179:  
2025-07-10 16:53:03.198698: Epoch 503 
2025-07-10 16:53:03.198884: Current learning rate: 0.00533 
2025-07-10 16:53:50.738157: train_loss -0.4375 
2025-07-10 16:53:50.738680: val_loss -0.4486 
2025-07-10 16:53:50.738776: Pseudo dice [np.float32(0.6988)] 
2025-07-10 16:53:50.739034: Epoch time: 47.54 s 
2025-07-10 16:53:51.934196:  
2025-07-10 16:53:51.934555: Epoch 504 
2025-07-10 16:53:51.934789: Current learning rate: 0.00532 
2025-07-10 16:54:38.685711: train_loss -0.4528 
2025-07-10 16:54:38.686181: val_loss -0.4399 
2025-07-10 16:54:38.686249: Pseudo dice [np.float32(0.7046)] 
2025-07-10 16:54:38.686335: Epoch time: 46.75 s 
2025-07-10 16:54:39.816135:  
2025-07-10 16:54:39.816556: Epoch 505 
2025-07-10 16:54:39.816774: Current learning rate: 0.00531 
2025-07-10 16:55:26.723879: train_loss -0.4549 
2025-07-10 16:55:26.725095: val_loss -0.4637 
2025-07-10 16:55:26.725295: Pseudo dice [np.float32(0.7257)] 
2025-07-10 16:55:26.725461: Epoch time: 46.91 s 
2025-07-10 16:55:27.928641:  
2025-07-10 16:55:27.929061: Epoch 506 
2025-07-10 16:55:27.929322: Current learning rate: 0.0053 
2025-07-10 16:56:14.856364: train_loss -0.4455 
2025-07-10 16:56:14.857034: val_loss -0.4257 
2025-07-10 16:56:14.857118: Pseudo dice [np.float32(0.6626)] 
2025-07-10 16:56:14.857239: Epoch time: 46.93 s 
2025-07-10 16:56:16.101095:  
2025-07-10 16:56:16.101581: Epoch 507 
2025-07-10 16:56:16.101831: Current learning rate: 0.00529 
2025-07-10 16:57:03.258922: train_loss -0.4268 
2025-07-10 16:57:03.259370: val_loss -0.4436 
2025-07-10 16:57:03.259529: Pseudo dice [np.float32(0.7018)] 
2025-07-10 16:57:03.259647: Epoch time: 47.16 s 
2025-07-10 16:57:04.435439:  
2025-07-10 16:57:04.436069: Epoch 508 
2025-07-10 16:57:04.436375: Current learning rate: 0.00528 
2025-07-10 16:57:50.848292: train_loss -0.4386 
2025-07-10 16:57:50.848873: val_loss -0.4482 
2025-07-10 16:57:50.848949: Pseudo dice [np.float32(0.696)] 
2025-07-10 16:57:50.849084: Epoch time: 46.41 s 
2025-07-10 16:57:51.965626:  
2025-07-10 16:57:51.965905: Epoch 509 
2025-07-10 16:57:51.966113: Current learning rate: 0.00527 
2025-07-10 16:58:38.524164: train_loss -0.4389 
2025-07-10 16:58:38.524695: val_loss -0.4294 
2025-07-10 16:58:38.524773: Pseudo dice [np.float32(0.6621)] 
2025-07-10 16:58:38.524881: Epoch time: 46.56 s 
2025-07-10 16:58:39.708809:  
2025-07-10 16:58:39.709241: Epoch 510 
2025-07-10 16:58:39.709369: Current learning rate: 0.00526 
2025-07-10 16:59:25.864153: train_loss -0.4212 
2025-07-10 16:59:25.864893: val_loss -0.4303 
2025-07-10 16:59:25.864990: Pseudo dice [np.float32(0.5721)] 
2025-07-10 16:59:25.865116: Epoch time: 46.16 s 
2025-07-10 16:59:27.041461:  
2025-07-10 16:59:27.041878: Epoch 511 
2025-07-10 16:59:27.042014: Current learning rate: 0.00525 
2025-07-10 17:00:13.963477: train_loss -0.4036 
2025-07-10 17:00:13.963908: val_loss -0.4224 
2025-07-10 17:00:13.963991: Pseudo dice [np.float32(0.6433)] 
2025-07-10 17:00:13.964098: Epoch time: 46.92 s 
2025-07-10 17:00:15.098366:  
2025-07-10 17:00:15.098714: Epoch 512 
2025-07-10 17:00:15.098890: Current learning rate: 0.00524 
2025-07-10 17:01:00.523483: train_loss -0.4165 
2025-07-10 17:01:00.524127: val_loss -0.4341 
2025-07-10 17:01:00.524216: Pseudo dice [np.float32(0.6189)] 
2025-07-10 17:01:00.524340: Epoch time: 45.43 s 
2025-07-10 17:01:01.703547:  
2025-07-10 17:01:01.703771: Epoch 513 
2025-07-10 17:01:01.703896: Current learning rate: 0.00523 
2025-07-10 17:01:48.112295: train_loss -0.4379 
2025-07-10 17:01:48.112775: val_loss -0.4053 
2025-07-10 17:01:48.112916: Pseudo dice [np.float32(0.6494)] 
2025-07-10 17:01:48.113040: Epoch time: 46.41 s 
2025-07-10 17:01:49.929202:  
2025-07-10 17:01:49.929663: Epoch 514 
2025-07-10 17:01:49.929847: Current learning rate: 0.00522 
2025-07-10 17:02:35.907131: train_loss -0.3594 
2025-07-10 17:02:35.907955: val_loss -0.4307 
2025-07-10 17:02:35.908124: Pseudo dice [np.float32(0.6336)] 
2025-07-10 17:02:35.908301: Epoch time: 45.98 s 
2025-07-10 17:02:37.151679:  
2025-07-10 17:02:37.152085: Epoch 515 
2025-07-10 17:02:37.152209: Current learning rate: 0.00521 
2025-07-10 17:03:24.907263: train_loss -0.4327 
2025-07-10 17:03:24.907659: val_loss -0.439 
2025-07-10 17:03:24.907738: Pseudo dice [np.float32(0.7395)] 
2025-07-10 17:03:24.907850: Epoch time: 47.76 s 
2025-07-10 17:03:26.059811:  
2025-07-10 17:03:26.060276: Epoch 516 
2025-07-10 17:03:26.060425: Current learning rate: 0.0052 
2025-07-10 17:04:12.895482: train_loss -0.4396 
2025-07-10 17:04:12.895864: val_loss -0.4461 
2025-07-10 17:04:12.895947: Pseudo dice [np.float32(0.6871)] 
2025-07-10 17:04:12.896071: Epoch time: 46.84 s 
2025-07-10 17:04:14.201896:  
2025-07-10 17:04:14.202524: Epoch 517 
2025-07-10 17:04:14.202674: Current learning rate: 0.00519 
2025-07-10 17:05:01.787067: train_loss -0.4124 
2025-07-10 17:05:01.787585: val_loss -0.4425 
2025-07-10 17:05:01.787704: Pseudo dice [np.float32(0.6387)] 
2025-07-10 17:05:01.787822: Epoch time: 47.59 s 
2025-07-10 17:05:03.018518:  
2025-07-10 17:05:03.018840: Epoch 518 
2025-07-10 17:05:03.019016: Current learning rate: 0.00518 
2025-07-10 17:05:50.667836: train_loss -0.4142 
2025-07-10 17:05:50.668285: val_loss -0.4452 
2025-07-10 17:05:50.668362: Pseudo dice [np.float32(0.6977)] 
2025-07-10 17:05:50.668468: Epoch time: 47.65 s 
2025-07-10 17:05:51.858576:  
2025-07-10 17:05:51.859378: Epoch 519 
2025-07-10 17:05:51.859729: Current learning rate: 0.00518 
2025-07-10 17:06:39.278468: train_loss -0.4295 
2025-07-10 17:06:39.279392: val_loss -0.43 
2025-07-10 17:06:39.279500: Pseudo dice [np.float32(0.6683)] 
2025-07-10 17:06:39.279639: Epoch time: 47.42 s 
2025-07-10 17:06:40.402329:  
2025-07-10 17:06:40.402781: Epoch 520 
2025-07-10 17:06:40.403050: Current learning rate: 0.00517 
2025-07-10 17:07:28.358711: train_loss -0.4058 
2025-07-10 17:07:28.359401: val_loss -0.4017 
2025-07-10 17:07:28.359492: Pseudo dice [np.float32(0.5409)] 
2025-07-10 17:07:28.359624: Epoch time: 47.96 s 
2025-07-10 17:07:29.511105:  
2025-07-10 17:07:29.511485: Epoch 521 
2025-07-10 17:07:29.511676: Current learning rate: 0.00516 
2025-07-10 17:08:16.806163: train_loss -0.4299 
2025-07-10 17:08:16.807408: val_loss -0.4676 
2025-07-10 17:08:16.807570: Pseudo dice [np.float32(0.7181)] 
2025-07-10 17:08:16.807713: Epoch time: 47.3 s 
2025-07-10 17:08:18.003095:  
2025-07-10 17:08:18.003335: Epoch 522 
2025-07-10 17:08:18.003471: Current learning rate: 0.00515 
2025-07-10 17:09:05.366787: train_loss -0.4335 
2025-07-10 17:09:05.367293: val_loss -0.4386 
2025-07-10 17:09:05.367388: Pseudo dice [np.float32(0.6518)] 
2025-07-10 17:09:05.367509: Epoch time: 47.36 s 
2025-07-10 17:09:06.494529:  
2025-07-10 17:09:06.494732: Epoch 523 
2025-07-10 17:09:06.494854: Current learning rate: 0.00514 
2025-07-10 17:09:53.988198: train_loss -0.4432 
2025-07-10 17:09:53.988796: val_loss -0.4328 
2025-07-10 17:09:53.988892: Pseudo dice [np.float32(0.6713)] 
2025-07-10 17:09:53.989020: Epoch time: 47.49 s 
2025-07-10 17:09:55.171436:  
2025-07-10 17:09:55.171845: Epoch 524 
2025-07-10 17:09:55.171970: Current learning rate: 0.00513 
2025-07-10 17:10:43.847137: train_loss -0.4357 
2025-07-10 17:10:43.847567: val_loss -0.4264 
2025-07-10 17:10:43.848496: Pseudo dice [np.float32(0.6969)] 
2025-07-10 17:10:43.848709: Epoch time: 48.68 s 
2025-07-10 17:10:45.019961:  
2025-07-10 17:10:45.020452: Epoch 525 
2025-07-10 17:10:45.020652: Current learning rate: 0.00512 
2025-07-10 17:11:33.383617: train_loss -0.4368 
2025-07-10 17:11:33.384134: val_loss -0.4465 
2025-07-10 17:11:33.384221: Pseudo dice [np.float32(0.7038)] 
2025-07-10 17:11:33.384338: Epoch time: 48.36 s 
2025-07-10 17:11:35.177466:  
2025-07-10 17:11:35.177947: Epoch 526 
2025-07-10 17:11:35.178150: Current learning rate: 0.00511 
2025-07-10 17:12:23.224773: train_loss -0.4507 
2025-07-10 17:12:23.225714: val_loss -0.4304 
2025-07-10 17:12:23.225819: Pseudo dice [np.float32(0.679)] 
2025-07-10 17:12:23.225966: Epoch time: 48.05 s 
2025-07-10 17:12:24.407925:  
2025-07-10 17:12:24.408092: Epoch 527 
2025-07-10 17:12:24.408217: Current learning rate: 0.0051 
2025-07-10 17:13:11.376774: train_loss -0.4486 
2025-07-10 17:13:11.377782: val_loss -0.4519 
2025-07-10 17:13:11.377911: Pseudo dice [np.float32(0.7172)] 
2025-07-10 17:13:11.378062: Epoch time: 46.97 s 
2025-07-10 17:13:12.606812:  
2025-07-10 17:13:12.607277: Epoch 528 
2025-07-10 17:13:12.607450: Current learning rate: 0.00509 
2025-07-10 17:13:59.343049: train_loss -0.3881 
2025-07-10 17:13:59.343444: val_loss -0.4038 
2025-07-10 17:13:59.343520: Pseudo dice [np.float32(0.5811)] 
2025-07-10 17:13:59.343639: Epoch time: 46.74 s 
2025-07-10 17:14:00.497314:  
2025-07-10 17:14:00.497783: Epoch 529 
2025-07-10 17:14:00.497984: Current learning rate: 0.00508 
2025-07-10 17:14:47.231925: train_loss -0.4208 
2025-07-10 17:14:47.232349: val_loss -0.4543 
2025-07-10 17:14:47.232428: Pseudo dice [np.float32(0.6834)] 
2025-07-10 17:14:47.232530: Epoch time: 46.74 s 
2025-07-10 17:14:48.372125:  
2025-07-10 17:14:48.372417: Epoch 530 
2025-07-10 17:14:48.372561: Current learning rate: 0.00507 
2025-07-10 17:15:34.381437: train_loss -0.384 
2025-07-10 17:15:34.382097: val_loss -0.3918 
2025-07-10 17:15:34.382191: Pseudo dice [np.float32(0.6275)] 
2025-07-10 17:15:34.382307: Epoch time: 46.01 s 
2025-07-10 17:15:35.583459:  
2025-07-10 17:15:35.583807: Epoch 531 
2025-07-10 17:15:35.583934: Current learning rate: 0.00506 
2025-07-10 17:16:23.266453: train_loss -0.41 
2025-07-10 17:16:23.266803: val_loss -0.4534 
2025-07-10 17:16:23.266869: Pseudo dice [np.float32(0.6368)] 
2025-07-10 17:16:23.266966: Epoch time: 47.68 s 
2025-07-10 17:16:24.407037:  
2025-07-10 17:16:24.407376: Epoch 532 
2025-07-10 17:16:24.407578: Current learning rate: 0.00505 
2025-07-10 17:17:12.157178: train_loss -0.4292 
2025-07-10 17:17:12.157735: val_loss -0.4439 
2025-07-10 17:17:12.157820: Pseudo dice [np.float32(0.6586)] 
2025-07-10 17:17:12.157931: Epoch time: 47.75 s 
2025-07-10 17:17:13.313421:  
2025-07-10 17:17:13.313713: Epoch 533 
2025-07-10 17:17:13.314025: Current learning rate: 0.00504 
2025-07-10 17:18:00.769043: train_loss -0.4361 
2025-07-10 17:18:00.769414: val_loss -0.4579 
2025-07-10 17:18:00.769498: Pseudo dice [np.float32(0.7197)] 
2025-07-10 17:18:00.769634: Epoch time: 47.46 s 
2025-07-10 17:18:01.889096:  
2025-07-10 17:18:01.889446: Epoch 534 
2025-07-10 17:18:01.889675: Current learning rate: 0.00503 
2025-07-10 17:18:49.850445: train_loss -0.4382 
2025-07-10 17:18:49.850876: val_loss -0.4212 
2025-07-10 17:18:49.850952: Pseudo dice [np.float32(0.6157)] 
2025-07-10 17:18:49.851057: Epoch time: 47.96 s 
2025-07-10 17:18:50.988642:  
2025-07-10 17:18:50.988891: Epoch 535 
2025-07-10 17:18:50.989017: Current learning rate: 0.00502 
2025-07-10 17:19:39.161439: train_loss -0.439 
2025-07-10 17:19:39.162298: val_loss -0.46 
2025-07-10 17:19:39.162479: Pseudo dice [np.float32(0.7111)] 
2025-07-10 17:19:39.162692: Epoch time: 48.17 s 
2025-07-10 17:19:40.382476:  
2025-07-10 17:19:40.383132: Epoch 536 
2025-07-10 17:19:40.383263: Current learning rate: 0.00501 
2025-07-10 17:20:28.209106: train_loss -0.4501 
2025-07-10 17:20:28.209614: val_loss -0.4324 
2025-07-10 17:20:28.209691: Pseudo dice [np.float32(0.7382)] 
2025-07-10 17:20:28.209805: Epoch time: 47.83 s 
2025-07-10 17:20:29.402089:  
2025-07-10 17:20:29.402246: Epoch 537 
2025-07-10 17:20:29.402396: Current learning rate: 0.005 
2025-07-10 17:21:16.500971: train_loss -0.4432 
2025-07-10 17:21:16.501894: val_loss -0.4526 
2025-07-10 17:21:16.505753: Pseudo dice [np.float32(0.6816)] 
2025-07-10 17:21:16.506296: Epoch time: 47.1 s 
2025-07-10 17:21:18.231987:  
2025-07-10 17:21:18.232236: Epoch 538 
2025-07-10 17:21:18.232350: Current learning rate: 0.00499 
2025-07-10 17:22:06.702972: train_loss -0.4561 
2025-07-10 17:22:06.703377: val_loss -0.4617 
2025-07-10 17:22:06.703457: Pseudo dice [np.float32(0.7318)] 
2025-07-10 17:22:06.703574: Epoch time: 48.47 s 
2025-07-10 17:22:07.882201:  
2025-07-10 17:22:07.882557: Epoch 539 
2025-07-10 17:22:07.882685: Current learning rate: 0.00498 
2025-07-10 17:22:54.863611: train_loss -0.4503 
2025-07-10 17:22:54.864304: val_loss -0.4398 
2025-07-10 17:22:54.864393: Pseudo dice [np.float32(0.704)] 
2025-07-10 17:22:54.864497: Epoch time: 46.98 s 
2025-07-10 17:22:56.026159:  
2025-07-10 17:22:56.026346: Epoch 540 
2025-07-10 17:22:56.026482: Current learning rate: 0.00497 
2025-07-10 17:23:43.132326: train_loss -0.4543 
2025-07-10 17:23:43.133500: val_loss -0.447 
2025-07-10 17:23:43.133672: Pseudo dice [np.float32(0.6923)] 
2025-07-10 17:23:43.133845: Epoch time: 47.11 s 
2025-07-10 17:23:44.367694:  
2025-07-10 17:23:44.368094: Epoch 541 
2025-07-10 17:23:44.368301: Current learning rate: 0.00496 
2025-07-10 17:24:31.367985: train_loss -0.4451 
2025-07-10 17:24:31.368395: val_loss -0.4552 
2025-07-10 17:24:31.368474: Pseudo dice [np.float32(0.664)] 
2025-07-10 17:24:31.368600: Epoch time: 47.0 s 
2025-07-10 17:24:32.572894:  
2025-07-10 17:24:32.573115: Epoch 542 
2025-07-10 17:24:32.573241: Current learning rate: 0.00495 
2025-07-10 17:25:21.528093: train_loss -0.4441 
2025-07-10 17:25:21.528562: val_loss -0.4333 
2025-07-10 17:25:21.528644: Pseudo dice [np.float32(0.7046)] 
2025-07-10 17:25:21.528755: Epoch time: 48.96 s 
2025-07-10 17:25:22.646572:  
2025-07-10 17:25:22.646976: Epoch 543 
2025-07-10 17:25:22.647213: Current learning rate: 0.00494 
2025-07-10 17:26:10.976717: train_loss -0.4462 
2025-07-10 17:26:10.977121: val_loss -0.4538 
2025-07-10 17:26:10.977200: Pseudo dice [np.float32(0.7101)] 
2025-07-10 17:26:10.977305: Epoch time: 48.33 s 
2025-07-10 17:26:12.107630:  
2025-07-10 17:26:12.108059: Epoch 544 
2025-07-10 17:26:12.108181: Current learning rate: 0.00493 
2025-07-10 17:26:59.405084: train_loss -0.4429 
2025-07-10 17:26:59.405602: val_loss -0.4394 
2025-07-10 17:26:59.405767: Pseudo dice [np.float32(0.6384)] 
2025-07-10 17:26:59.405880: Epoch time: 47.3 s 
2025-07-10 17:27:00.556203:  
2025-07-10 17:27:00.556636: Epoch 545 
2025-07-10 17:27:00.556774: Current learning rate: 0.00492 
2025-07-10 17:27:47.629089: train_loss -0.4438 
2025-07-10 17:27:47.629596: val_loss -0.4389 
2025-07-10 17:27:47.629692: Pseudo dice [np.float32(0.7303)] 
2025-07-10 17:27:47.629802: Epoch time: 47.07 s 
2025-07-10 17:27:48.756676:  
2025-07-10 17:27:48.757091: Epoch 546 
2025-07-10 17:27:48.757226: Current learning rate: 0.00491 
2025-07-10 17:28:36.308596: train_loss -0.4524 
2025-07-10 17:28:36.309167: val_loss -0.4476 
2025-07-10 17:28:36.309258: Pseudo dice [np.float32(0.7108)] 
2025-07-10 17:28:36.309368: Epoch time: 47.55 s 
2025-07-10 17:28:37.484796:  
2025-07-10 17:28:37.484971: Epoch 547 
2025-07-10 17:28:37.485094: Current learning rate: 0.0049 
2025-07-10 17:29:25.155956: train_loss -0.4524 
2025-07-10 17:29:25.156708: val_loss -0.4425 
2025-07-10 17:29:25.156902: Pseudo dice [np.float32(0.6848)] 
2025-07-10 17:29:25.157106: Epoch time: 47.67 s 
2025-07-10 17:29:26.333257:  
2025-07-10 17:29:26.333683: Epoch 548 
2025-07-10 17:29:26.334008: Current learning rate: 0.00489 
2025-07-10 17:30:13.363075: train_loss -0.455 
2025-07-10 17:30:13.363648: val_loss -0.43 
2025-07-10 17:30:13.363762: Pseudo dice [np.float32(0.6652)] 
2025-07-10 17:30:13.363896: Epoch time: 47.03 s 
2025-07-10 17:30:14.492987:  
2025-07-10 17:30:14.493521: Epoch 549 
2025-07-10 17:30:14.493812: Current learning rate: 0.00488 
2025-07-10 17:31:01.820162: train_loss -0.4502 
2025-07-10 17:31:01.820869: val_loss -0.4515 
2025-07-10 17:31:01.821036: Pseudo dice [np.float32(0.7568)] 
2025-07-10 17:31:01.821218: Epoch time: 47.33 s 
2025-07-10 17:31:04.079737:  
2025-07-10 17:31:04.080055: Epoch 550 
2025-07-10 17:31:04.080183: Current learning rate: 0.00487 
2025-07-10 17:31:51.347087: train_loss -0.4494 
2025-07-10 17:31:51.347681: val_loss -0.4327 
2025-07-10 17:31:51.347766: Pseudo dice [np.float32(0.6373)] 
2025-07-10 17:31:51.347891: Epoch time: 47.27 s 
2025-07-10 17:31:52.506988:  
2025-07-10 17:31:52.507303: Epoch 551 
2025-07-10 17:31:52.507628: Current learning rate: 0.00486 
2025-07-10 17:32:38.695497: train_loss -0.4348 
2025-07-10 17:32:38.695996: val_loss -0.3991 
2025-07-10 17:32:38.696077: Pseudo dice [np.float32(0.6671)] 
2025-07-10 17:32:38.696290: Epoch time: 46.19 s 
2025-07-10 17:32:39.829662:  
2025-07-10 17:32:39.829842: Epoch 552 
2025-07-10 17:32:39.829984: Current learning rate: 0.00485 
2025-07-10 17:33:26.749153: train_loss -0.4462 
2025-07-10 17:33:26.749850: val_loss -0.4508 
2025-07-10 17:33:26.749938: Pseudo dice [np.float32(0.7225)] 
2025-07-10 17:33:26.750128: Epoch time: 46.92 s 
2025-07-10 17:33:27.915150:  
2025-07-10 17:33:27.915431: Epoch 553 
2025-07-10 17:33:27.915560: Current learning rate: 0.00484 
2025-07-10 17:34:15.045359: train_loss -0.4596 
2025-07-10 17:34:15.045738: val_loss -0.443 
2025-07-10 17:34:15.045846: Pseudo dice [np.float32(0.7172)] 
2025-07-10 17:34:15.045989: Epoch time: 47.13 s 
2025-07-10 17:34:16.200092:  
2025-07-10 17:34:16.200332: Epoch 554 
2025-07-10 17:34:16.200532: Current learning rate: 0.00484 
2025-07-10 17:35:02.565714: train_loss -0.4401 
2025-07-10 17:35:02.566023: val_loss -0.4285 
2025-07-10 17:35:02.566097: Pseudo dice [np.float32(0.6706)] 
2025-07-10 17:35:02.566189: Epoch time: 46.37 s 
2025-07-10 17:35:03.703825:  
2025-07-10 17:35:03.704011: Epoch 555 
2025-07-10 17:35:03.704187: Current learning rate: 0.00483 
2025-07-10 17:35:50.591607: train_loss -0.4381 
2025-07-10 17:35:50.592634: val_loss -0.4519 
2025-07-10 17:35:50.592719: Pseudo dice [np.float32(0.7185)] 
2025-07-10 17:35:50.593011: Epoch time: 46.89 s 
2025-07-10 17:35:51.736215:  
2025-07-10 17:35:51.736383: Epoch 556 
2025-07-10 17:35:51.736522: Current learning rate: 0.00482 
2025-07-10 17:36:38.140918: train_loss -0.4322 
2025-07-10 17:36:38.141289: val_loss -0.4448 
2025-07-10 17:36:38.141363: Pseudo dice [np.float32(0.7191)] 
2025-07-10 17:36:38.141474: Epoch time: 46.41 s 
2025-07-10 17:36:39.265674:  
2025-07-10 17:36:39.265944: Epoch 557 
2025-07-10 17:36:39.266121: Current learning rate: 0.00481 
2025-07-10 17:37:26.921293: train_loss -0.4359 
2025-07-10 17:37:26.922845: val_loss -0.4235 
2025-07-10 17:37:26.923004: Pseudo dice [np.float32(0.7158)] 
2025-07-10 17:37:26.923231: Epoch time: 47.66 s 
2025-07-10 17:37:28.063674:  
2025-07-10 17:37:28.064056: Epoch 558 
2025-07-10 17:37:28.064273: Current learning rate: 0.0048 
2025-07-10 17:38:16.893311: train_loss -0.4518 
2025-07-10 17:38:16.893977: val_loss -0.4455 
2025-07-10 17:38:16.894132: Pseudo dice [np.float32(0.686)] 
2025-07-10 17:38:16.894321: Epoch time: 48.83 s 
2025-07-10 17:38:18.056733:  
2025-07-10 17:38:18.057135: Epoch 559 
2025-07-10 17:38:18.057266: Current learning rate: 0.00479 
2025-07-10 17:39:06.064948: train_loss -0.4427 
2025-07-10 17:39:06.065507: val_loss -0.437 
2025-07-10 17:39:06.065604: Pseudo dice [np.float32(0.6658)] 
2025-07-10 17:39:06.065710: Epoch time: 48.01 s 
2025-07-10 17:39:07.229254:  
2025-07-10 17:39:07.229527: Epoch 560 
2025-07-10 17:39:07.229706: Current learning rate: 0.00478 
2025-07-10 17:39:54.329253: train_loss -0.443 
2025-07-10 17:39:54.329712: val_loss -0.4462 
2025-07-10 17:39:54.329785: Pseudo dice [np.float32(0.6559)] 
2025-07-10 17:39:54.329887: Epoch time: 47.1 s 
2025-07-10 17:39:55.474158:  
2025-07-10 17:39:55.474370: Epoch 561 
2025-07-10 17:39:55.474580: Current learning rate: 0.00477 
2025-07-10 17:40:43.056033: train_loss -0.4425 
2025-07-10 17:40:43.056357: val_loss -0.4231 
2025-07-10 17:40:43.056432: Pseudo dice [np.float32(0.6576)] 
2025-07-10 17:40:43.056536: Epoch time: 47.58 s 
2025-07-10 17:40:44.803166:  
2025-07-10 17:40:44.803743: Epoch 562 
2025-07-10 17:40:44.803900: Current learning rate: 0.00476 
2025-07-10 17:41:32.985505: train_loss -0.4236 
2025-07-10 17:41:32.985946: val_loss -0.4415 
2025-07-10 17:41:32.986037: Pseudo dice [np.float32(0.57)] 
2025-07-10 17:41:32.986274: Epoch time: 48.18 s 
2025-07-10 17:41:34.140882:  
2025-07-10 17:41:34.141119: Epoch 563 
2025-07-10 17:41:34.141247: Current learning rate: 0.00475 
2025-07-10 17:42:21.871480: train_loss -0.4423 
2025-07-10 17:42:21.871996: val_loss -0.4366 
2025-07-10 17:42:21.872075: Pseudo dice [np.float32(0.7061)] 
2025-07-10 17:42:21.872182: Epoch time: 47.73 s 
2025-07-10 17:42:23.037685:  
2025-07-10 17:42:23.038268: Epoch 564 
2025-07-10 17:42:23.038408: Current learning rate: 0.00474 
2025-07-10 17:43:10.989422: train_loss -0.4397 
2025-07-10 17:43:10.989869: val_loss -0.446 
2025-07-10 17:43:10.989952: Pseudo dice [np.float32(0.6883)] 
2025-07-10 17:43:10.990056: Epoch time: 47.95 s 
2025-07-10 17:43:12.149201:  
2025-07-10 17:43:12.149664: Epoch 565 
2025-07-10 17:43:12.150003: Current learning rate: 0.00473 
2025-07-10 17:43:59.506691: train_loss -0.4499 
2025-07-10 17:43:59.507127: val_loss -0.4566 
2025-07-10 17:43:59.507208: Pseudo dice [np.float32(0.6737)] 
2025-07-10 17:43:59.507311: Epoch time: 47.36 s 
2025-07-10 17:44:00.750983:  
2025-07-10 17:44:00.751190: Epoch 566 
2025-07-10 17:44:00.751329: Current learning rate: 0.00472 
2025-07-10 17:44:48.551948: train_loss -0.4434 
2025-07-10 17:44:48.552598: val_loss -0.4398 
2025-07-10 17:44:48.552724: Pseudo dice [np.float32(0.6926)] 
2025-07-10 17:44:48.552933: Epoch time: 47.8 s 
2025-07-10 17:44:49.701855:  
2025-07-10 17:44:49.702199: Epoch 567 
2025-07-10 17:44:49.702417: Current learning rate: 0.00471 
2025-07-10 17:45:37.134935: train_loss -0.4403 
2025-07-10 17:45:37.135283: val_loss -0.4523 
2025-07-10 17:45:37.135359: Pseudo dice [np.float32(0.7231)] 
2025-07-10 17:45:37.135461: Epoch time: 47.43 s 
2025-07-10 17:45:38.374686:  
2025-07-10 17:45:38.374986: Epoch 568 
2025-07-10 17:45:38.375117: Current learning rate: 0.0047 
2025-07-10 17:46:25.360930: train_loss -0.4309 
2025-07-10 17:46:25.361233: val_loss -0.4196 
2025-07-10 17:46:25.361308: Pseudo dice [np.float32(0.624)] 
2025-07-10 17:46:25.361407: Epoch time: 46.99 s 
2025-07-10 17:46:26.485153:  
2025-07-10 17:46:26.485496: Epoch 569 
2025-07-10 17:46:26.485629: Current learning rate: 0.00469 
2025-07-10 17:47:13.098357: train_loss -0.3981 
2025-07-10 17:47:13.098803: val_loss -0.4419 
2025-07-10 17:47:13.098882: Pseudo dice [np.float32(0.6139)] 
2025-07-10 17:47:13.098990: Epoch time: 46.61 s 
2025-07-10 17:47:14.295169:  
2025-07-10 17:47:14.295441: Epoch 570 
2025-07-10 17:47:14.295675: Current learning rate: 0.00468 
2025-07-10 17:48:01.128461: train_loss -0.425 
2025-07-10 17:48:01.128832: val_loss -0.4367 
2025-07-10 17:48:01.129105: Pseudo dice [np.float32(0.6329)] 
2025-07-10 17:48:01.129212: Epoch time: 46.83 s 
2025-07-10 17:48:02.298808:  
2025-07-10 17:48:02.299209: Epoch 571 
2025-07-10 17:48:02.299330: Current learning rate: 0.00467 
2025-07-10 17:48:49.771150: train_loss -0.4321 
2025-07-10 17:48:49.771829: val_loss -0.4222 
2025-07-10 17:48:49.771928: Pseudo dice [np.float32(0.6411)] 
2025-07-10 17:48:49.772071: Epoch time: 47.47 s 
2025-07-10 17:48:51.082657:  
2025-07-10 17:48:51.083019: Epoch 572 
2025-07-10 17:48:51.083216: Current learning rate: 0.00466 
2025-07-10 17:49:38.530951: train_loss -0.4328 
2025-07-10 17:49:38.532214: val_loss -0.4228 
2025-07-10 17:49:38.532317: Pseudo dice [np.float32(0.6852)] 
2025-07-10 17:49:38.532436: Epoch time: 47.45 s 
2025-07-10 17:49:39.752412:  
2025-07-10 17:49:39.752691: Epoch 573 
2025-07-10 17:49:39.753177: Current learning rate: 0.00465 
2025-07-10 17:50:26.326460: train_loss -0.4196 
2025-07-10 17:50:26.327009: val_loss -0.3396 
2025-07-10 17:50:26.327127: Pseudo dice [np.float32(0.4561)] 
2025-07-10 17:50:26.327234: Epoch time: 46.58 s 
2025-07-10 17:50:27.961609:  
2025-07-10 17:50:27.961998: Epoch 574 
2025-07-10 17:50:27.962098: Current learning rate: 0.00464 
2025-07-10 17:51:15.203999: train_loss -0.3896 
2025-07-10 17:51:15.204554: val_loss -0.3835 
2025-07-10 17:51:15.204715: Pseudo dice [np.float32(0.5927)] 
2025-07-10 17:51:15.204867: Epoch time: 47.24 s 
2025-07-10 17:51:16.348485:  
2025-07-10 17:51:16.348714: Epoch 575 
2025-07-10 17:51:16.348812: Current learning rate: 0.00463 
2025-07-10 17:52:02.904469: train_loss -0.4267 
2025-07-10 17:52:02.905074: val_loss -0.4546 
2025-07-10 17:52:02.905174: Pseudo dice [np.float32(0.7136)] 
2025-07-10 17:52:02.905293: Epoch time: 46.56 s 
2025-07-10 17:52:04.062302:  
2025-07-10 17:52:04.062510: Epoch 576 
2025-07-10 17:52:04.062689: Current learning rate: 0.00462 
2025-07-10 17:52:50.780415: train_loss -0.4532 
2025-07-10 17:52:50.780999: val_loss -0.4436 
2025-07-10 17:52:50.781098: Pseudo dice [np.float32(0.6811)] 
2025-07-10 17:52:50.781216: Epoch time: 46.72 s 
2025-07-10 17:52:52.016315:  
2025-07-10 17:52:52.016787: Epoch 577 
2025-07-10 17:52:52.016935: Current learning rate: 0.00461 
2025-07-10 17:53:38.371526: train_loss -0.4425 
2025-07-10 17:53:38.371862: val_loss -0.4428 
2025-07-10 17:53:38.371938: Pseudo dice [np.float32(0.7068)] 
2025-07-10 17:53:38.372036: Epoch time: 46.36 s 
2025-07-10 17:53:39.584506:  
2025-07-10 17:53:39.585072: Epoch 578 
2025-07-10 17:53:39.585224: Current learning rate: 0.0046 
2025-07-10 17:54:26.913972: train_loss -0.4443 
2025-07-10 17:54:26.914332: val_loss -0.4502 
2025-07-10 17:54:26.914407: Pseudo dice [np.float32(0.6792)] 
2025-07-10 17:54:26.914633: Epoch time: 47.33 s 
2025-07-10 17:54:28.115294:  
2025-07-10 17:54:28.115714: Epoch 579 
2025-07-10 17:54:28.115846: Current learning rate: 0.00459 
2025-07-10 17:55:14.927969: train_loss -0.4417 
2025-07-10 17:55:14.929153: val_loss -0.4522 
2025-07-10 17:55:14.929320: Pseudo dice [np.float32(0.7068)] 
2025-07-10 17:55:14.929530: Epoch time: 46.81 s 
2025-07-10 17:55:16.151266:  
2025-07-10 17:55:16.151657: Epoch 580 
2025-07-10 17:55:16.151789: Current learning rate: 0.00458 
2025-07-10 17:56:02.667091: train_loss -0.4489 
2025-07-10 17:56:02.667803: val_loss -0.4515 
2025-07-10 17:56:02.667888: Pseudo dice [np.float32(0.7549)] 
2025-07-10 17:56:02.668031: Epoch time: 46.52 s 
2025-07-10 17:56:03.842083:  
2025-07-10 17:56:03.842677: Epoch 581 
2025-07-10 17:56:03.843022: Current learning rate: 0.00457 
2025-07-10 17:56:51.129050: train_loss -0.4411 
2025-07-10 17:56:51.129773: val_loss -0.4297 
2025-07-10 17:56:51.131274: Pseudo dice [np.float32(0.6765)] 
2025-07-10 17:56:51.131558: Epoch time: 47.29 s 
2025-07-10 17:56:52.292185:  
2025-07-10 17:56:52.292635: Epoch 582 
2025-07-10 17:56:52.292857: Current learning rate: 0.00456 
2025-07-10 17:57:40.099900: train_loss -0.4524 
2025-07-10 17:57:40.100374: val_loss -0.435 
2025-07-10 17:57:40.100456: Pseudo dice [np.float32(0.7091)] 
2025-07-10 17:57:40.100648: Epoch time: 47.81 s 
2025-07-10 17:57:41.240632:  
2025-07-10 17:57:41.240826: Epoch 583 
2025-07-10 17:57:41.241164: Current learning rate: 0.00455 
2025-07-10 17:58:28.008712: train_loss -0.4627 
2025-07-10 17:58:28.009181: val_loss -0.4257 
2025-07-10 17:58:28.009264: Pseudo dice [np.float32(0.656)] 
2025-07-10 17:58:28.009359: Epoch time: 46.77 s 
2025-07-10 17:58:29.166432:  
2025-07-10 17:58:29.166899: Epoch 584 
2025-07-10 17:58:29.167046: Current learning rate: 0.00454 
2025-07-10 17:59:16.361237: train_loss -0.4515 
2025-07-10 17:59:16.361583: val_loss -0.4415 
2025-07-10 17:59:16.361659: Pseudo dice [np.float32(0.6928)] 
2025-07-10 17:59:16.361760: Epoch time: 47.2 s 
2025-07-10 17:59:17.500449:  
2025-07-10 17:59:17.500827: Epoch 585 
2025-07-10 17:59:17.501166: Current learning rate: 0.00453 
2025-07-10 18:00:04.804491: train_loss -0.444 
2025-07-10 18:00:04.804969: val_loss -0.423 
2025-07-10 18:00:04.805053: Pseudo dice [np.float32(0.6452)] 
2025-07-10 18:00:04.805152: Epoch time: 47.31 s 
2025-07-10 18:00:06.601321:  
2025-07-10 18:00:06.601608: Epoch 586 
2025-07-10 18:00:06.601860: Current learning rate: 0.00452 
2025-07-10 18:00:53.332237: train_loss -0.4511 
2025-07-10 18:00:53.332707: val_loss -0.4494 
2025-07-10 18:00:53.332902: Pseudo dice [np.float32(0.6955)] 
2025-07-10 18:00:53.333013: Epoch time: 46.73 s 
2025-07-10 18:00:54.493166:  
2025-07-10 18:00:54.493607: Epoch 587 
2025-07-10 18:00:54.493789: Current learning rate: 0.00451 
2025-07-10 18:01:41.035238: train_loss -0.4512 
2025-07-10 18:01:41.035937: val_loss -0.4393 
2025-07-10 18:01:41.036034: Pseudo dice [np.float32(0.7527)] 
2025-07-10 18:01:41.036154: Epoch time: 46.54 s 
2025-07-10 18:01:42.201348:  
2025-07-10 18:01:42.201766: Epoch 588 
2025-07-10 18:01:42.202054: Current learning rate: 0.0045 
2025-07-10 18:02:28.699307: train_loss -0.4366 
2025-07-10 18:02:28.700098: val_loss -0.4187 
2025-07-10 18:02:28.700212: Pseudo dice [np.float32(0.6112)] 
2025-07-10 18:02:28.700357: Epoch time: 46.5 s 
2025-07-10 18:02:29.936143:  
2025-07-10 18:02:29.936511: Epoch 589 
2025-07-10 18:02:29.936743: Current learning rate: 0.00449 
2025-07-10 18:03:16.740153: train_loss -0.4299 
2025-07-10 18:03:16.740486: val_loss -0.4337 
2025-07-10 18:03:16.740583: Pseudo dice [np.float32(0.7207)] 
2025-07-10 18:03:16.740704: Epoch time: 46.81 s 
2025-07-10 18:03:17.976289:  
2025-07-10 18:03:17.976876: Epoch 590 
2025-07-10 18:03:17.977105: Current learning rate: 0.00448 
2025-07-10 18:04:05.389158: train_loss -0.4297 
2025-07-10 18:04:05.389454: val_loss -0.4224 
2025-07-10 18:04:05.389526: Pseudo dice [np.float32(0.634)] 
2025-07-10 18:04:05.389628: Epoch time: 47.41 s 
2025-07-10 18:04:06.552533:  
2025-07-10 18:04:06.552718: Epoch 591 
2025-07-10 18:04:06.552839: Current learning rate: 0.00447 
2025-07-10 18:04:53.811231: train_loss -0.4097 
2025-07-10 18:04:53.811728: val_loss -0.4274 
2025-07-10 18:04:53.811820: Pseudo dice [np.float32(0.616)] 
2025-07-10 18:04:53.811942: Epoch time: 47.26 s 
2025-07-10 18:04:55.020271:  
2025-07-10 18:04:55.020806: Epoch 592 
2025-07-10 18:04:55.020948: Current learning rate: 0.00446 
2025-07-10 18:05:42.044494: train_loss -0.4293 
2025-07-10 18:05:42.044749: val_loss -0.4231 
2025-07-10 18:05:42.044819: Pseudo dice [np.float32(0.6091)] 
2025-07-10 18:05:42.044909: Epoch time: 47.03 s 
2025-07-10 18:05:43.215085:  
2025-07-10 18:05:43.215358: Epoch 593 
2025-07-10 18:05:43.215613: Current learning rate: 0.00445 
2025-07-10 18:06:29.321194: train_loss -0.4481 
2025-07-10 18:06:29.321715: val_loss -0.4637 
2025-07-10 18:06:29.321820: Pseudo dice [np.float32(0.7388)] 
2025-07-10 18:06:29.322035: Epoch time: 46.11 s 
2025-07-10 18:06:30.469843:  
2025-07-10 18:06:30.470124: Epoch 594 
2025-07-10 18:06:30.470258: Current learning rate: 0.00444 
2025-07-10 18:07:17.979725: train_loss -0.4414 
2025-07-10 18:07:17.980215: val_loss -0.4296 
2025-07-10 18:07:17.980293: Pseudo dice [np.float32(0.6218)] 
2025-07-10 18:07:17.980402: Epoch time: 47.51 s 
2025-07-10 18:07:19.163184:  
2025-07-10 18:07:19.163553: Epoch 595 
2025-07-10 18:07:19.163687: Current learning rate: 0.00443 
2025-07-10 18:08:06.148734: train_loss -0.4328 
2025-07-10 18:08:06.149073: val_loss -0.4208 
2025-07-10 18:08:06.149147: Pseudo dice [np.float32(0.6948)] 
2025-07-10 18:08:06.149248: Epoch time: 46.99 s 
2025-07-10 18:08:07.324907:  
2025-07-10 18:08:07.325223: Epoch 596 
2025-07-10 18:08:07.325513: Current learning rate: 0.00442 
2025-07-10 18:08:54.514856: train_loss -0.4406 
2025-07-10 18:08:54.515226: val_loss -0.4432 
2025-07-10 18:08:54.515301: Pseudo dice [np.float32(0.6493)] 
2025-07-10 18:08:54.515398: Epoch time: 47.19 s 
2025-07-10 18:08:55.682118:  
2025-07-10 18:08:55.682716: Epoch 597 
2025-07-10 18:08:55.683101: Current learning rate: 0.00441 
2025-07-10 18:09:43.014760: train_loss -0.4369 
2025-07-10 18:09:43.015452: val_loss -0.4599 
2025-07-10 18:09:43.015552: Pseudo dice [np.float32(0.6918)] 
2025-07-10 18:09:43.015665: Epoch time: 47.33 s 
2025-07-10 18:09:44.224042:  
2025-07-10 18:09:44.224397: Epoch 598 
2025-07-10 18:09:44.224617: Current learning rate: 0.0044 
2025-07-10 18:10:31.583749: train_loss -0.4426 
2025-07-10 18:10:31.584517: val_loss -0.4705 
2025-07-10 18:10:31.584611: Pseudo dice [np.float32(0.7549)] 
2025-07-10 18:10:31.584754: Epoch time: 47.36 s 
2025-07-10 18:10:32.746599:  
2025-07-10 18:10:32.747042: Epoch 599 
2025-07-10 18:10:32.747177: Current learning rate: 0.00439 
2025-07-10 18:11:19.938061: train_loss -0.4311 
2025-07-10 18:11:19.938498: val_loss -0.4056 
2025-07-10 18:11:19.938592: Pseudo dice [np.float32(0.6219)] 
2025-07-10 18:11:19.938706: Epoch time: 47.19 s 
2025-07-10 18:11:21.659674:  
2025-07-10 18:11:21.660084: Epoch 600 
2025-07-10 18:11:21.660218: Current learning rate: 0.00438 
2025-07-10 18:12:08.810872: train_loss -0.429 
2025-07-10 18:12:08.811476: val_loss -0.4322 
2025-07-10 18:12:08.811577: Pseudo dice [np.float32(0.7149)] 
2025-07-10 18:12:08.811698: Epoch time: 47.15 s 
2025-07-10 18:12:10.025012:  
2025-07-10 18:12:10.025432: Epoch 601 
2025-07-10 18:12:10.025753: Current learning rate: 0.00437 
2025-07-10 18:12:57.360496: train_loss -0.4248 
2025-07-10 18:12:57.361005: val_loss -0.419 
2025-07-10 18:12:57.364574: Pseudo dice [np.float32(0.6758)] 
2025-07-10 18:12:57.364751: Epoch time: 47.34 s 
2025-07-10 18:12:58.588332:  
2025-07-10 18:12:58.588583: Epoch 602 
2025-07-10 18:12:58.588708: Current learning rate: 0.00436 
2025-07-10 18:13:45.377967: train_loss -0.4502 
2025-07-10 18:13:45.378387: val_loss -0.4343 
2025-07-10 18:13:45.378464: Pseudo dice [np.float32(0.7228)] 
2025-07-10 18:13:45.378589: Epoch time: 46.79 s 
2025-07-10 18:13:46.498344:  
2025-07-10 18:13:46.498616: Epoch 603 
2025-07-10 18:13:46.498865: Current learning rate: 0.00435 
2025-07-10 18:14:33.361348: train_loss -0.4269 
2025-07-10 18:14:33.361979: val_loss -0.3835 
2025-07-10 18:14:33.362065: Pseudo dice [np.float32(0.6628)] 
2025-07-10 18:14:33.362186: Epoch time: 46.86 s 
2025-07-10 18:14:34.538315:  
2025-07-10 18:14:34.538638: Epoch 604 
2025-07-10 18:14:34.538820: Current learning rate: 0.00434 
2025-07-10 18:15:20.725843: train_loss -0.4192 
2025-07-10 18:15:20.726417: val_loss -0.4409 
2025-07-10 18:15:20.727719: Pseudo dice [np.float32(0.7249)] 
2025-07-10 18:15:20.727844: Epoch time: 46.19 s 
2025-07-10 18:15:21.911489:  
2025-07-10 18:15:21.911861: Epoch 605 
2025-07-10 18:15:21.911989: Current learning rate: 0.00433 
2025-07-10 18:16:08.640349: train_loss -0.425 
2025-07-10 18:16:08.640827: val_loss -0.4027 
2025-07-10 18:16:08.640909: Pseudo dice [np.float32(0.7259)] 
2025-07-10 18:16:08.641025: Epoch time: 46.73 s 
2025-07-10 18:16:09.792972:  
2025-07-10 18:16:09.793634: Epoch 606 
2025-07-10 18:16:09.793841: Current learning rate: 0.00432 
2025-07-10 18:16:56.625508: train_loss -0.4294 
2025-07-10 18:16:56.626269: val_loss -0.4317 
2025-07-10 18:16:56.626361: Pseudo dice [np.float32(0.6753)] 
2025-07-10 18:16:56.626503: Epoch time: 46.83 s 
2025-07-10 18:16:57.788247:  
2025-07-10 18:16:57.788633: Epoch 607 
2025-07-10 18:16:57.788758: Current learning rate: 0.00431 
2025-07-10 18:17:44.259092: train_loss -0.4534 
2025-07-10 18:17:44.260105: val_loss -0.4307 
2025-07-10 18:17:44.260256: Pseudo dice [np.float32(0.7152)] 
2025-07-10 18:17:44.260475: Epoch time: 46.47 s 
2025-07-10 18:17:45.492765:  
2025-07-10 18:17:45.493514: Epoch 608 
2025-07-10 18:17:45.493736: Current learning rate: 0.0043 
2025-07-10 18:18:32.096719: train_loss -0.4354 
2025-07-10 18:18:32.097112: val_loss -0.4385 
2025-07-10 18:18:32.097189: Pseudo dice [np.float32(0.6008)] 
2025-07-10 18:18:32.097304: Epoch time: 46.61 s 
2025-07-10 18:18:33.871209:  
2025-07-10 18:18:33.871778: Epoch 609 
2025-07-10 18:18:33.871910: Current learning rate: 0.00429 
2025-07-10 18:19:21.030924: train_loss -0.4151 
2025-07-10 18:19:21.031291: val_loss -0.3717 
2025-07-10 18:19:21.031384: Pseudo dice [np.float32(0.5546)] 
2025-07-10 18:19:21.031497: Epoch time: 47.16 s 
2025-07-10 18:19:22.153568:  
2025-07-10 18:19:22.153956: Epoch 610 
2025-07-10 18:19:22.154095: Current learning rate: 0.00429 
2025-07-10 18:20:09.203133: train_loss -0.2918 
2025-07-10 18:20:09.203457: val_loss -0.2505 
2025-07-10 18:20:09.203548: Pseudo dice [np.float32(0.0)] 
2025-07-10 18:20:09.203647: Epoch time: 47.05 s 
2025-07-10 18:20:10.354717:  
2025-07-10 18:20:10.355108: Epoch 611 
2025-07-10 18:20:10.355284: Current learning rate: 0.00428 
2025-07-10 18:20:57.613025: train_loss -0.3314 
2025-07-10 18:20:57.613712: val_loss -0.3677 
2025-07-10 18:20:57.613812: Pseudo dice [np.float32(0.5083)] 
2025-07-10 18:20:57.613938: Epoch time: 47.26 s 
2025-07-10 18:20:58.826030:  
2025-07-10 18:20:58.826407: Epoch 612 
2025-07-10 18:20:58.826555: Current learning rate: 0.00427 
2025-07-10 18:21:45.581171: train_loss -0.4221 
2025-07-10 18:21:45.581683: val_loss -0.452 
2025-07-10 18:21:45.581767: Pseudo dice [np.float32(0.6558)] 
2025-07-10 18:21:45.581921: Epoch time: 46.76 s 
2025-07-10 18:21:46.790614:  
2025-07-10 18:21:46.790892: Epoch 613 
2025-07-10 18:21:46.791022: Current learning rate: 0.00426 
2025-07-10 18:22:34.014920: train_loss -0.4333 
2025-07-10 18:22:34.015720: val_loss -0.4311 
2025-07-10 18:22:34.015809: Pseudo dice [np.float32(0.6929)] 
2025-07-10 18:22:34.015913: Epoch time: 47.23 s 
2025-07-10 18:22:35.180461:  
2025-07-10 18:22:35.180651: Epoch 614 
2025-07-10 18:22:35.180771: Current learning rate: 0.00425 
2025-07-10 18:23:22.405238: train_loss -0.4373 
2025-07-10 18:23:22.405743: val_loss -0.4374 
2025-07-10 18:23:22.406007: Pseudo dice [np.float32(0.735)] 
2025-07-10 18:23:22.406292: Epoch time: 47.23 s 
2025-07-10 18:23:23.630964:  
2025-07-10 18:23:23.631399: Epoch 615 
2025-07-10 18:23:23.631525: Current learning rate: 0.00424 
2025-07-10 18:24:09.775368: train_loss -0.4532 
2025-07-10 18:24:09.776140: val_loss -0.4547 
2025-07-10 18:24:09.776242: Pseudo dice [np.float32(0.7163)] 
2025-07-10 18:24:09.776368: Epoch time: 46.15 s 
2025-07-10 18:24:11.002586:  
2025-07-10 18:24:11.003029: Epoch 616 
2025-07-10 18:24:11.003240: Current learning rate: 0.00423 
2025-07-10 18:24:57.715441: train_loss -0.4339 
2025-07-10 18:24:57.715935: val_loss -0.443 
2025-07-10 18:24:57.716016: Pseudo dice [np.float32(0.7306)] 
2025-07-10 18:24:57.716125: Epoch time: 46.71 s 
2025-07-10 18:24:58.876384:  
2025-07-10 18:24:58.876759: Epoch 617 
2025-07-10 18:24:58.876897: Current learning rate: 0.00422 
2025-07-10 18:25:45.693751: train_loss -0.4273 
2025-07-10 18:25:45.694120: val_loss -0.4257 
2025-07-10 18:25:45.694200: Pseudo dice [np.float32(0.6386)] 
2025-07-10 18:25:45.694377: Epoch time: 46.82 s 
2025-07-10 18:25:46.857354:  
2025-07-10 18:25:46.857592: Epoch 618 
2025-07-10 18:25:46.857719: Current learning rate: 0.00421 
2025-07-10 18:26:33.134645: train_loss -0.3996 
2025-07-10 18:26:33.135507: val_loss -0.418 
2025-07-10 18:26:33.135647: Pseudo dice [np.float32(0.6599)] 
2025-07-10 18:26:33.135801: Epoch time: 46.28 s 
2025-07-10 18:26:34.344716:  
2025-07-10 18:26:34.345196: Epoch 619 
2025-07-10 18:26:34.345353: Current learning rate: 0.0042 
2025-07-10 18:27:21.796537: train_loss -0.432 
2025-07-10 18:27:21.797002: val_loss -0.4355 
2025-07-10 18:27:21.797099: Pseudo dice [np.float32(0.7063)] 
2025-07-10 18:27:21.797273: Epoch time: 47.45 s 
2025-07-10 18:27:23.537567:  
2025-07-10 18:27:23.537988: Epoch 620 
2025-07-10 18:27:23.538109: Current learning rate: 0.00419 
2025-07-10 18:28:11.407818: train_loss -0.4403 
2025-07-10 18:28:11.408325: val_loss -0.4328 
2025-07-10 18:28:11.408441: Pseudo dice [np.float32(0.7143)] 
2025-07-10 18:28:11.408560: Epoch time: 47.87 s 
2025-07-10 18:28:12.640288:  
2025-07-10 18:28:12.640655: Epoch 621 
2025-07-10 18:28:12.640793: Current learning rate: 0.00418 
2025-07-10 18:28:58.479223: train_loss -0.4399 
2025-07-10 18:28:58.479879: val_loss -0.4473 
2025-07-10 18:28:58.479988: Pseudo dice [np.float32(0.7278)] 
2025-07-10 18:28:58.480112: Epoch time: 45.84 s 
2025-07-10 18:28:59.664305:  
2025-07-10 18:28:59.664616: Epoch 622 
2025-07-10 18:28:59.664800: Current learning rate: 0.00417 
2025-07-10 18:29:45.322366: train_loss -0.4362 
2025-07-10 18:29:45.323064: val_loss -0.4224 
2025-07-10 18:29:45.323182: Pseudo dice [np.float32(0.6729)] 
2025-07-10 18:29:45.323338: Epoch time: 45.66 s 
2025-07-10 18:29:46.587639:  
2025-07-10 18:29:46.588000: Epoch 623 
2025-07-10 18:29:46.588134: Current learning rate: 0.00416 
2025-07-10 18:30:33.363396: train_loss -0.4414 
2025-07-10 18:30:33.364220: val_loss -0.4506 
2025-07-10 18:30:33.364301: Pseudo dice [np.float32(0.714)] 
2025-07-10 18:30:33.364444: Epoch time: 46.78 s 
2025-07-10 18:30:34.529590:  
2025-07-10 18:30:34.529790: Epoch 624 
2025-07-10 18:30:34.530071: Current learning rate: 0.00415 
2025-07-10 18:31:21.474463: train_loss -0.431 
2025-07-10 18:31:21.475268: val_loss -0.4428 
2025-07-10 18:31:21.475360: Pseudo dice [np.float32(0.6996)] 
2025-07-10 18:31:21.475495: Epoch time: 46.95 s 
2025-07-10 18:31:22.645281:  
2025-07-10 18:31:22.645849: Epoch 625 
2025-07-10 18:31:22.646178: Current learning rate: 0.00414 
2025-07-10 18:32:09.827279: train_loss -0.4434 
2025-07-10 18:32:09.827903: val_loss -0.4238 
2025-07-10 18:32:09.827981: Pseudo dice [np.float32(0.5843)] 
2025-07-10 18:32:09.828089: Epoch time: 47.18 s 
2025-07-10 18:32:11.046692:  
2025-07-10 18:32:11.047166: Epoch 626 
2025-07-10 18:32:11.047309: Current learning rate: 0.00413 
2025-07-10 18:32:57.882702: train_loss -0.4148 
2025-07-10 18:32:57.883655: val_loss -0.4165 
2025-07-10 18:32:57.883748: Pseudo dice [np.float32(0.585)] 
2025-07-10 18:32:57.883912: Epoch time: 46.84 s 
2025-07-10 18:32:59.295810:  
2025-07-10 18:32:59.296261: Epoch 627 
2025-07-10 18:32:59.296383: Current learning rate: 0.00412 
2025-07-10 18:33:46.252821: train_loss -0.4303 
2025-07-10 18:33:46.253812: val_loss -0.4528 
2025-07-10 18:33:46.253967: Pseudo dice [np.float32(0.6832)] 
2025-07-10 18:33:46.254123: Epoch time: 46.96 s 
2025-07-10 18:33:47.600030:  
2025-07-10 18:33:47.600475: Epoch 628 
2025-07-10 18:33:47.600623: Current learning rate: 0.00411 
2025-07-10 18:34:34.633951: train_loss -0.4469 
2025-07-10 18:34:34.634630: val_loss -0.424 
2025-07-10 18:34:34.634737: Pseudo dice [np.float32(0.6996)] 
2025-07-10 18:34:34.634851: Epoch time: 47.03 s 
2025-07-10 18:34:35.801412:  
2025-07-10 18:34:35.801655: Epoch 629 
2025-07-10 18:34:35.801781: Current learning rate: 0.0041 
2025-07-10 18:35:23.092121: train_loss -0.4446 
2025-07-10 18:35:23.092968: val_loss -0.4556 
2025-07-10 18:35:23.093060: Pseudo dice [np.float32(0.6885)] 
2025-07-10 18:35:23.093165: Epoch time: 47.29 s 
2025-07-10 18:35:24.282056:  
2025-07-10 18:35:24.282389: Epoch 630 
2025-07-10 18:35:24.282554: Current learning rate: 0.00409 
2025-07-10 18:36:11.223827: train_loss -0.451 
2025-07-10 18:36:11.224391: val_loss -0.4512 
2025-07-10 18:36:11.224604: Pseudo dice [np.float32(0.7352)] 
2025-07-10 18:36:11.224739: Epoch time: 46.94 s 
2025-07-10 18:36:12.442048:  
2025-07-10 18:36:12.442383: Epoch 631 
2025-07-10 18:36:12.442551: Current learning rate: 0.00408 
2025-07-10 18:37:00.001318: train_loss -0.4465 
2025-07-10 18:37:00.001957: val_loss -0.4664 
2025-07-10 18:37:00.002045: Pseudo dice [np.float32(0.7245)] 
2025-07-10 18:37:00.002153: Epoch time: 47.56 s 
2025-07-10 18:37:01.844972:  
2025-07-10 18:37:01.845571: Epoch 632 
2025-07-10 18:37:01.845720: Current learning rate: 0.00407 
2025-07-10 18:37:49.198213: train_loss -0.4498 
2025-07-10 18:37:49.198580: val_loss -0.449 
2025-07-10 18:37:49.198663: Pseudo dice [np.float32(0.7043)] 
2025-07-10 18:37:49.198811: Epoch time: 47.35 s 
2025-07-10 18:37:50.416021:  
2025-07-10 18:37:50.416775: Epoch 633 
2025-07-10 18:37:50.417048: Current learning rate: 0.00406 
2025-07-10 18:38:37.650311: train_loss -0.4578 
2025-07-10 18:38:37.651000: val_loss -0.4443 
2025-07-10 18:38:37.651082: Pseudo dice [np.float32(0.7008)] 
2025-07-10 18:38:37.651231: Epoch time: 47.24 s 
2025-07-10 18:38:38.827518:  
2025-07-10 18:38:38.827768: Epoch 634 
2025-07-10 18:38:38.827887: Current learning rate: 0.00405 
2025-07-10 18:39:27.340212: train_loss -0.4598 
2025-07-10 18:39:27.340592: val_loss -0.4543 
2025-07-10 18:39:27.340669: Pseudo dice [np.float32(0.7461)] 
2025-07-10 18:39:27.340776: Epoch time: 48.51 s 
2025-07-10 18:39:28.704391:  
2025-07-10 18:39:28.704638: Epoch 635 
2025-07-10 18:39:28.704758: Current learning rate: 0.00404 
2025-07-10 18:40:15.469127: train_loss -0.3906 
2025-07-10 18:40:15.469876: val_loss -0.3799 
2025-07-10 18:40:15.470023: Pseudo dice [np.float32(0.4842)] 
2025-07-10 18:40:15.470187: Epoch time: 46.77 s 
2025-07-10 18:40:16.714634:  
2025-07-10 18:40:16.714871: Epoch 636 
2025-07-10 18:40:16.714995: Current learning rate: 0.00403 
2025-07-10 18:41:03.773333: train_loss -0.4229 
2025-07-10 18:41:03.773648: val_loss -0.4003 
2025-07-10 18:41:03.773727: Pseudo dice [np.float32(0.6149)] 
2025-07-10 18:41:03.773831: Epoch time: 47.06 s 
2025-07-10 18:41:04.928125:  
2025-07-10 18:41:04.928391: Epoch 637 
2025-07-10 18:41:04.928632: Current learning rate: 0.00402 
2025-07-10 18:41:51.502394: train_loss -0.4317 
2025-07-10 18:41:51.503007: val_loss -0.4267 
2025-07-10 18:41:51.503098: Pseudo dice [np.float32(0.6991)] 
2025-07-10 18:41:51.503229: Epoch time: 46.58 s 
2025-07-10 18:41:52.682184:  
2025-07-10 18:41:52.682558: Epoch 638 
2025-07-10 18:41:52.682692: Current learning rate: 0.00401 
2025-07-10 18:42:39.914465: train_loss -0.4299 
2025-07-10 18:42:39.914995: val_loss -0.4313 
2025-07-10 18:42:39.915075: Pseudo dice [np.float32(0.639)] 
2025-07-10 18:42:39.915204: Epoch time: 47.23 s 
2025-07-10 18:42:41.112137:  
2025-07-10 18:42:41.112669: Epoch 639 
2025-07-10 18:42:41.112880: Current learning rate: 0.004 
2025-07-10 18:43:28.562228: train_loss -0.4387 
2025-07-10 18:43:28.562794: val_loss -0.4191 
2025-07-10 18:43:28.562905: Pseudo dice [np.float32(0.6884)] 
2025-07-10 18:43:28.563008: Epoch time: 47.45 s 
2025-07-10 18:43:29.735495:  
2025-07-10 18:43:29.735834: Epoch 640 
2025-07-10 18:43:29.736143: Current learning rate: 0.00399 
2025-07-10 18:44:16.239654: train_loss -0.4506 
2025-07-10 18:44:16.239991: val_loss -0.4661 
2025-07-10 18:44:16.240164: Pseudo dice [np.float32(0.715)] 
2025-07-10 18:44:16.240264: Epoch time: 46.51 s 
2025-07-10 18:44:17.415087:  
2025-07-10 18:44:17.415349: Epoch 641 
2025-07-10 18:44:17.415549: Current learning rate: 0.00398 
2025-07-10 18:45:03.720573: train_loss -0.4612 
2025-07-10 18:45:03.721319: val_loss -0.4639 
2025-07-10 18:45:03.721414: Pseudo dice [np.float32(0.7399)] 
2025-07-10 18:45:03.721535: Epoch time: 46.31 s 
2025-07-10 18:45:04.882847:  
2025-07-10 18:45:04.883349: Epoch 642 
2025-07-10 18:45:04.883614: Current learning rate: 0.00397 
2025-07-10 18:45:52.424705: train_loss -0.4368 
2025-07-10 18:45:52.425155: val_loss -0.3717 
2025-07-10 18:45:52.425246: Pseudo dice [np.float32(0.5898)] 
2025-07-10 18:45:52.425357: Epoch time: 47.54 s 
2025-07-10 18:45:53.615880:  
2025-07-10 18:45:53.616199: Epoch 643 
2025-07-10 18:45:53.616323: Current learning rate: 0.00396 
2025-07-10 18:46:40.310363: train_loss -0.4039 
2025-07-10 18:46:40.311452: val_loss -0.4082 
2025-07-10 18:46:40.311558: Pseudo dice [np.float32(0.6396)] 
2025-07-10 18:46:40.311728: Epoch time: 46.7 s 
2025-07-10 18:46:42.337287:  
2025-07-10 18:46:42.337654: Epoch 644 
2025-07-10 18:46:42.337760: Current learning rate: 0.00395 
2025-07-10 18:47:29.959020: train_loss -0.4206 
2025-07-10 18:47:29.959494: val_loss -0.3634 
2025-07-10 18:47:29.959591: Pseudo dice [np.float32(0.5179)] 
2025-07-10 18:47:29.959695: Epoch time: 47.62 s 
2025-07-10 18:47:31.183845:  
2025-07-10 18:47:31.184177: Epoch 645 
2025-07-10 18:47:31.184348: Current learning rate: 0.00394 
2025-07-10 18:48:18.674365: train_loss -0.402 
2025-07-10 18:48:18.674885: val_loss -0.4179 
2025-07-10 18:48:18.674962: Pseudo dice [np.float32(0.5828)] 
2025-07-10 18:48:18.675071: Epoch time: 47.49 s 
2025-07-10 18:48:19.850003:  
2025-07-10 18:48:19.850330: Epoch 646 
2025-07-10 18:48:19.850574: Current learning rate: 0.00393 
2025-07-10 18:49:07.097898: train_loss -0.4206 
2025-07-10 18:49:07.098423: val_loss -0.4183 
2025-07-10 18:49:07.098502: Pseudo dice [np.float32(0.6543)] 
2025-07-10 18:49:07.098615: Epoch time: 47.25 s 
2025-07-10 18:49:08.253771:  
2025-07-10 18:49:08.254130: Epoch 647 
2025-07-10 18:49:08.254263: Current learning rate: 0.00392 
2025-07-10 18:49:55.032115: train_loss -0.444 
2025-07-10 18:49:55.032887: val_loss -0.4568 
2025-07-10 18:49:55.032989: Pseudo dice [np.float32(0.7368)] 
2025-07-10 18:49:55.033097: Epoch time: 46.78 s 
2025-07-10 18:49:56.330251:  
2025-07-10 18:49:56.330583: Epoch 648 
2025-07-10 18:49:56.330717: Current learning rate: 0.00391 
2025-07-10 18:50:42.646066: train_loss -0.4574 
2025-07-10 18:50:42.646524: val_loss -0.4471 
2025-07-10 18:50:42.646625: Pseudo dice [np.float32(0.7286)] 
2025-07-10 18:50:42.646737: Epoch time: 46.32 s 
2025-07-10 18:50:43.832092:  
2025-07-10 18:50:43.832465: Epoch 649 
2025-07-10 18:50:43.832603: Current learning rate: 0.0039 
2025-07-10 18:51:30.031254: train_loss -0.4477 
2025-07-10 18:51:30.031833: val_loss -0.4429 
2025-07-10 18:51:30.031915: Pseudo dice [np.float32(0.6976)] 
2025-07-10 18:51:30.032017: Epoch time: 46.2 s 
2025-07-10 18:51:31.683095:  
2025-07-10 18:51:31.683751: Epoch 650 
2025-07-10 18:51:31.683908: Current learning rate: 0.00389 
2025-07-10 18:52:18.054549: train_loss -0.4427 
2025-07-10 18:52:18.054959: val_loss -0.4414 
2025-07-10 18:52:18.055036: Pseudo dice [np.float32(0.7362)] 
2025-07-10 18:52:18.055135: Epoch time: 46.37 s 
2025-07-10 18:52:19.195470:  
2025-07-10 18:52:19.195959: Epoch 651 
2025-07-10 18:52:19.196089: Current learning rate: 0.00388 
2025-07-10 18:53:05.507289: train_loss -0.4564 
2025-07-10 18:53:05.507805: val_loss -0.4472 
2025-07-10 18:53:05.507890: Pseudo dice [np.float32(0.7492)] 
2025-07-10 18:53:05.507999: Epoch time: 46.31 s 
2025-07-10 18:53:06.728867:  
2025-07-10 18:53:06.729322: Epoch 652 
2025-07-10 18:53:06.729507: Current learning rate: 0.00387 
2025-07-10 18:53:53.614037: train_loss -0.4247 
2025-07-10 18:53:53.614791: val_loss -0.4286 
2025-07-10 18:53:53.614866: Pseudo dice [np.float32(0.6928)] 
2025-07-10 18:53:53.614970: Epoch time: 46.89 s 
2025-07-10 18:53:54.823775:  
2025-07-10 18:53:54.824362: Epoch 653 
2025-07-10 18:53:54.824581: Current learning rate: 0.00386 
2025-07-10 18:54:41.017192: train_loss -0.4461 
2025-07-10 18:54:41.018015: val_loss -0.4343 
2025-07-10 18:54:41.018140: Pseudo dice [np.float32(0.6659)] 
2025-07-10 18:54:41.018284: Epoch time: 46.19 s 
2025-07-10 18:54:42.205741:  
2025-07-10 18:54:42.206155: Epoch 654 
2025-07-10 18:54:42.206292: Current learning rate: 0.00385 
2025-07-10 18:55:29.096750: train_loss -0.4503 
2025-07-10 18:55:29.097339: val_loss -0.4423 
2025-07-10 18:55:29.097415: Pseudo dice [np.float32(0.7017)] 
2025-07-10 18:55:29.097533: Epoch time: 46.89 s 
2025-07-10 18:55:30.932927:  
2025-07-10 18:55:30.933408: Epoch 655 
2025-07-10 18:55:30.933633: Current learning rate: 0.00384 
2025-07-10 18:56:17.075674: train_loss -0.4445 
2025-07-10 18:56:17.076638: val_loss -0.3628 
2025-07-10 18:56:17.076728: Pseudo dice [np.float32(0.5784)] 
2025-07-10 18:56:17.076847: Epoch time: 46.14 s 
2025-07-10 18:56:18.291207:  
2025-07-10 18:56:18.291716: Epoch 656 
2025-07-10 18:56:18.291857: Current learning rate: 0.00383 
2025-07-10 18:57:04.542530: train_loss -0.4233 
2025-07-10 18:57:04.543150: val_loss -0.4186 
2025-07-10 18:57:04.543277: Pseudo dice [np.float32(0.6261)] 
2025-07-10 18:57:04.543418: Epoch time: 46.25 s 
2025-07-10 18:57:05.771736:  
2025-07-10 18:57:05.772243: Epoch 657 
2025-07-10 18:57:05.772372: Current learning rate: 0.00382 
2025-07-10 18:57:53.524885: train_loss -0.4384 
2025-07-10 18:57:53.525488: val_loss -0.4468 
2025-07-10 18:57:53.525595: Pseudo dice [np.float32(0.7166)] 
2025-07-10 18:57:53.525730: Epoch time: 47.75 s 
2025-07-10 18:57:54.759657:  
2025-07-10 18:57:54.760094: Epoch 658 
2025-07-10 18:57:54.760229: Current learning rate: 0.00381 
2025-07-10 18:58:42.786121: train_loss -0.4124 
2025-07-10 18:58:42.786818: val_loss -0.429 
2025-07-10 18:58:42.786906: Pseudo dice [np.float32(0.5566)] 
2025-07-10 18:58:42.787016: Epoch time: 48.03 s 
2025-07-10 18:58:44.023025:  
2025-07-10 18:58:44.023266: Epoch 659 
2025-07-10 18:58:44.023547: Current learning rate: 0.0038 
2025-07-10 18:59:31.165819: train_loss -0.4447 
2025-07-10 18:59:31.166207: val_loss -0.4474 
2025-07-10 18:59:31.166283: Pseudo dice [np.float32(0.6769)] 
2025-07-10 18:59:31.166387: Epoch time: 47.14 s 
2025-07-10 18:59:32.343314:  
2025-07-10 18:59:32.343725: Epoch 660 
2025-07-10 18:59:32.343886: Current learning rate: 0.00379 
2025-07-10 19:00:19.270422: train_loss -0.4447 
2025-07-10 19:00:19.270776: val_loss -0.4674 
2025-07-10 19:00:19.270851: Pseudo dice [np.float32(0.7475)] 
2025-07-10 19:00:19.270951: Epoch time: 46.93 s 
2025-07-10 19:00:20.448252:  
2025-07-10 19:00:20.448693: Epoch 661 
2025-07-10 19:00:20.448825: Current learning rate: 0.00378 
2025-07-10 19:01:07.976450: train_loss -0.4551 
2025-07-10 19:01:07.976859: val_loss -0.4671 
2025-07-10 19:01:07.976938: Pseudo dice [np.float32(0.7242)] 
2025-07-10 19:01:07.977044: Epoch time: 47.53 s 
2025-07-10 19:01:09.183655:  
2025-07-10 19:01:09.184184: Epoch 662 
2025-07-10 19:01:09.184382: Current learning rate: 0.00377 
2025-07-10 19:01:57.574923: train_loss -0.4656 
2025-07-10 19:01:57.575582: val_loss -0.4601 
2025-07-10 19:01:57.575662: Pseudo dice [np.float32(0.7296)] 
2025-07-10 19:01:57.575772: Epoch time: 48.39 s 
2025-07-10 19:01:58.726581:  
2025-07-10 19:01:58.726904: Epoch 663 
2025-07-10 19:01:58.727098: Current learning rate: 0.00376 
2025-07-10 19:02:46.712341: train_loss -0.4593 
2025-07-10 19:02:46.712786: val_loss -0.4357 
2025-07-10 19:02:46.712862: Pseudo dice [np.float32(0.7237)] 
2025-07-10 19:02:46.712963: Epoch time: 47.99 s 
2025-07-10 19:02:47.862768:  
2025-07-10 19:02:47.863236: Epoch 664 
2025-07-10 19:02:47.863571: Current learning rate: 0.00375 
2025-07-10 19:03:34.079743: train_loss -0.4297 
2025-07-10 19:03:34.080184: val_loss -0.4518 
2025-07-10 19:03:34.080266: Pseudo dice [np.float32(0.6953)] 
2025-07-10 19:03:34.080366: Epoch time: 46.22 s 
2025-07-10 19:03:35.240012:  
2025-07-10 19:03:35.240303: Epoch 665 
2025-07-10 19:03:35.240448: Current learning rate: 0.00374 
2025-07-10 19:04:21.992465: train_loss -0.4378 
2025-07-10 19:04:21.993046: val_loss -0.4224 
2025-07-10 19:04:21.993239: Pseudo dice [np.float32(0.6289)] 
2025-07-10 19:04:21.993418: Epoch time: 46.75 s 
2025-07-10 19:04:23.738406:  
2025-07-10 19:04:23.739178: Epoch 666 
2025-07-10 19:04:23.739746: Current learning rate: 0.00373 
2025-07-10 19:05:11.543798: train_loss -0.4489 
2025-07-10 19:05:11.544538: val_loss -0.4482 
2025-07-10 19:05:11.544654: Pseudo dice [np.float32(0.7257)] 
2025-07-10 19:05:11.544768: Epoch time: 47.81 s 
2025-07-10 19:05:12.831733:  
2025-07-10 19:05:12.832060: Epoch 667 
2025-07-10 19:05:12.832320: Current learning rate: 0.00372 
2025-07-10 19:06:00.582277: train_loss -0.4532 
2025-07-10 19:06:00.582715: val_loss -0.4391 
2025-07-10 19:06:00.582796: Pseudo dice [np.float32(0.7353)] 
2025-07-10 19:06:00.582893: Epoch time: 47.75 s 
2025-07-10 19:06:01.747147:  
2025-07-10 19:06:01.747563: Epoch 668 
2025-07-10 19:06:01.747695: Current learning rate: 0.00371 
2025-07-10 19:06:48.393159: train_loss -0.3966 
2025-07-10 19:06:48.393790: val_loss -0.3884 
2025-07-10 19:06:48.393877: Pseudo dice [np.float32(0.553)] 
2025-07-10 19:06:48.393995: Epoch time: 46.65 s 
2025-07-10 19:06:49.661405:  
2025-07-10 19:06:49.661772: Epoch 669 
2025-07-10 19:06:49.661961: Current learning rate: 0.0037 
2025-07-10 19:07:35.789029: train_loss -0.4259 
2025-07-10 19:07:35.789876: val_loss -0.4255 
2025-07-10 19:07:35.789978: Pseudo dice [np.float32(0.674)] 
2025-07-10 19:07:35.790125: Epoch time: 46.13 s 
2025-07-10 19:07:37.045326:  
2025-07-10 19:07:37.045631: Epoch 670 
2025-07-10 19:07:37.045773: Current learning rate: 0.00369 
2025-07-10 19:08:22.761149: train_loss -0.4501 
2025-07-10 19:08:22.761684: val_loss -0.4465 
2025-07-10 19:08:22.761762: Pseudo dice [np.float32(0.6816)] 
2025-07-10 19:08:22.761863: Epoch time: 45.72 s 
2025-07-10 19:08:23.938531:  
2025-07-10 19:08:23.939021: Epoch 671 
2025-07-10 19:08:23.939142: Current learning rate: 0.00368 
2025-07-10 19:09:10.413764: train_loss -0.4612 
2025-07-10 19:09:10.414161: val_loss -0.4647 
2025-07-10 19:09:10.414244: Pseudo dice [np.float32(0.7595)] 
2025-07-10 19:09:10.414362: Epoch time: 46.48 s 
2025-07-10 19:09:11.645289:  
2025-07-10 19:09:11.645684: Epoch 672 
2025-07-10 19:09:11.645827: Current learning rate: 0.00367 
2025-07-10 19:09:58.341907: train_loss -0.4432 
2025-07-10 19:09:58.342945: val_loss -0.4474 
2025-07-10 19:09:58.343055: Pseudo dice [np.float32(0.7309)] 
2025-07-10 19:09:58.343232: Epoch time: 46.7 s 
2025-07-10 19:09:59.657295:  
2025-07-10 19:09:59.657521: Epoch 673 
2025-07-10 19:09:59.657811: Current learning rate: 0.00366 
2025-07-10 19:10:46.270946: train_loss -0.4212 
2025-07-10 19:10:46.271523: val_loss -0.4312 
2025-07-10 19:10:46.271646: Pseudo dice [np.float32(0.6747)] 
2025-07-10 19:10:46.271769: Epoch time: 46.61 s 
2025-07-10 19:10:47.478830:  
2025-07-10 19:10:47.479002: Epoch 674 
2025-07-10 19:10:47.479251: Current learning rate: 0.00365 
2025-07-10 19:11:33.569933: train_loss -0.4322 
2025-07-10 19:11:33.570409: val_loss -0.4287 
2025-07-10 19:11:33.570493: Pseudo dice [np.float32(0.6025)] 
2025-07-10 19:11:33.570604: Epoch time: 46.09 s 
2025-07-10 19:11:34.781104:  
2025-07-10 19:11:34.781350: Epoch 675 
2025-07-10 19:11:34.781517: Current learning rate: 0.00364 
2025-07-10 19:12:20.621794: train_loss -0.446 
2025-07-10 19:12:20.622348: val_loss -0.4489 
2025-07-10 19:12:20.622430: Pseudo dice [np.float32(0.7135)] 
2025-07-10 19:12:20.622560: Epoch time: 45.84 s 
2025-07-10 19:12:21.811957:  
2025-07-10 19:12:21.812326: Epoch 676 
2025-07-10 19:12:21.812514: Current learning rate: 0.00363 
2025-07-10 19:13:08.628122: train_loss -0.4613 
2025-07-10 19:13:08.628986: val_loss -0.4513 
2025-07-10 19:13:08.629078: Pseudo dice [np.float32(0.7239)] 
2025-07-10 19:13:08.629206: Epoch time: 46.82 s 
2025-07-10 19:13:09.839415:  
2025-07-10 19:13:09.839590: Epoch 677 
2025-07-10 19:13:09.839866: Current learning rate: 0.00362 
2025-07-10 19:13:57.285117: train_loss -0.4483 
2025-07-10 19:13:57.285578: val_loss -0.4502 
2025-07-10 19:13:57.289804: Pseudo dice [np.float32(0.6818)] 
2025-07-10 19:13:57.290648: Epoch time: 47.45 s 
2025-07-10 19:13:59.025946:  
2025-07-10 19:13:59.026226: Epoch 678 
2025-07-10 19:13:59.026324: Current learning rate: 0.00361 
2025-07-10 19:14:45.856462: train_loss -0.4542 
2025-07-10 19:14:45.856889: val_loss -0.4605 
2025-07-10 19:14:45.856969: Pseudo dice [np.float32(0.7278)] 
2025-07-10 19:14:45.857066: Epoch time: 46.83 s 
2025-07-10 19:14:47.057110:  
2025-07-10 19:14:47.057506: Epoch 679 
2025-07-10 19:14:47.057642: Current learning rate: 0.0036 
2025-07-10 19:15:34.587940: train_loss -0.4565 
2025-07-10 19:15:34.588388: val_loss -0.4149 
2025-07-10 19:15:34.588473: Pseudo dice [np.float32(0.6175)] 
2025-07-10 19:15:34.588606: Epoch time: 47.53 s 
2025-07-10 19:15:35.767942:  
2025-07-10 19:15:35.768404: Epoch 680 
2025-07-10 19:15:35.768549: Current learning rate: 0.00359 
2025-07-10 19:16:23.317799: train_loss -0.4521 
2025-07-10 19:16:23.318377: val_loss -0.4811 
2025-07-10 19:16:23.318461: Pseudo dice [np.float32(0.7137)] 
2025-07-10 19:16:23.318580: Epoch time: 47.55 s 
2025-07-10 19:16:24.476109:  
2025-07-10 19:16:24.476317: Epoch 681 
2025-07-10 19:16:24.476644: Current learning rate: 0.00358 
2025-07-10 19:17:12.358752: train_loss -0.4523 
2025-07-10 19:17:12.359142: val_loss -0.453 
2025-07-10 19:17:12.359223: Pseudo dice [np.float32(0.7376)] 
2025-07-10 19:17:12.359352: Epoch time: 47.88 s 
2025-07-10 19:17:13.503793:  
2025-07-10 19:17:13.504089: Epoch 682 
2025-07-10 19:17:13.504205: Current learning rate: 0.00357 
2025-07-10 19:18:01.172489: train_loss -0.457 
2025-07-10 19:18:01.173083: val_loss -0.4337 
2025-07-10 19:18:01.173159: Pseudo dice [np.float32(0.7213)] 
2025-07-10 19:18:01.173272: Epoch time: 47.67 s 
2025-07-10 19:18:02.385126:  
2025-07-10 19:18:02.385683: Epoch 683 
2025-07-10 19:18:02.385956: Current learning rate: 0.00356 
2025-07-10 19:18:49.441356: train_loss -0.4406 
2025-07-10 19:18:49.442345: val_loss -0.4161 
2025-07-10 19:18:49.442429: Pseudo dice [np.float32(0.6536)] 
2025-07-10 19:18:49.442602: Epoch time: 47.06 s 
2025-07-10 19:18:50.629393:  
2025-07-10 19:18:50.629817: Epoch 684 
2025-07-10 19:18:50.629950: Current learning rate: 0.00355 
2025-07-10 19:19:38.258701: train_loss -0.4417 
2025-07-10 19:19:38.259250: val_loss -0.4447 
2025-07-10 19:19:38.260519: Pseudo dice [np.float32(0.7038)] 
2025-07-10 19:19:38.260635: Epoch time: 47.63 s 
2025-07-10 19:19:39.436477:  
2025-07-10 19:19:39.436926: Epoch 685 
2025-07-10 19:19:39.437194: Current learning rate: 0.00354 
2025-07-10 19:20:27.038234: train_loss -0.4437 
2025-07-10 19:20:27.038955: val_loss -0.4095 
2025-07-10 19:20:27.039037: Pseudo dice [np.float32(0.6439)] 
2025-07-10 19:20:27.039152: Epoch time: 47.6 s 
2025-07-10 19:20:28.239318:  
2025-07-10 19:20:28.239524: Epoch 686 
2025-07-10 19:20:28.239727: Current learning rate: 0.00353 
2025-07-10 19:21:16.033493: train_loss -0.4402 
2025-07-10 19:21:16.033814: val_loss -0.4601 
2025-07-10 19:21:16.033899: Pseudo dice [np.float32(0.7004)] 
2025-07-10 19:21:16.034006: Epoch time: 47.8 s 
2025-07-10 19:21:17.205975:  
2025-07-10 19:21:17.206520: Epoch 687 
2025-07-10 19:21:17.206675: Current learning rate: 0.00352 
2025-07-10 19:22:04.485276: train_loss -0.4629 
2025-07-10 19:22:04.486103: val_loss -0.4788 
2025-07-10 19:22:04.486218: Pseudo dice [np.float32(0.7668)] 
2025-07-10 19:22:04.486349: Epoch time: 47.28 s 
2025-07-10 19:22:05.746923:  
2025-07-10 19:22:05.747226: Epoch 688 
2025-07-10 19:22:05.747402: Current learning rate: 0.00351 
2025-07-10 19:22:52.636632: train_loss -0.458 
2025-07-10 19:22:52.637033: val_loss -0.4601 
2025-07-10 19:22:52.637168: Pseudo dice [np.float32(0.7197)] 
2025-07-10 19:22:52.637292: Epoch time: 46.89 s 
2025-07-10 19:22:54.452711:  
2025-07-10 19:22:54.453099: Epoch 689 
2025-07-10 19:22:54.453465: Current learning rate: 0.0035 
2025-07-10 19:23:41.426737: train_loss -0.4592 
2025-07-10 19:23:41.427205: val_loss -0.4665 
2025-07-10 19:23:41.427340: Pseudo dice [np.float32(0.79)] 
2025-07-10 19:23:41.427449: Epoch time: 46.98 s 
2025-07-10 19:23:42.611578:  
2025-07-10 19:23:42.611809: Epoch 690 
2025-07-10 19:23:42.612062: Current learning rate: 0.00349 
2025-07-10 19:24:29.085203: train_loss -0.4592 
2025-07-10 19:24:29.086103: val_loss -0.4556 
2025-07-10 19:24:29.086182: Pseudo dice [np.float32(0.6978)] 
2025-07-10 19:24:29.086304: Epoch time: 46.47 s 
2025-07-10 19:24:30.308107:  
2025-07-10 19:24:30.308563: Epoch 691 
2025-07-10 19:24:30.308885: Current learning rate: 0.00348 
2025-07-10 19:25:17.321830: train_loss -0.4523 
2025-07-10 19:25:17.322286: val_loss -0.4561 
2025-07-10 19:25:17.322377: Pseudo dice [np.float32(0.7435)] 
2025-07-10 19:25:17.322522: Epoch time: 47.01 s 
2025-07-10 19:25:18.531497:  
2025-07-10 19:25:18.531889: Epoch 692 
2025-07-10 19:25:18.532108: Current learning rate: 0.00346 
2025-07-10 19:26:04.815768: train_loss -0.4688 
2025-07-10 19:26:04.816772: val_loss -0.4616 
2025-07-10 19:26:04.816853: Pseudo dice [np.float32(0.7503)] 
2025-07-10 19:26:04.816990: Epoch time: 46.29 s 
2025-07-10 19:26:06.104756:  
2025-07-10 19:26:06.104918: Epoch 693 
2025-07-10 19:26:06.105014: Current learning rate: 0.00345 
2025-07-10 19:26:54.092574: train_loss -0.4375 
2025-07-10 19:26:54.096662: val_loss -0.4211 
2025-07-10 19:26:54.096830: Pseudo dice [np.float32(0.5882)] 
2025-07-10 19:26:54.096975: Epoch time: 47.99 s 
2025-07-10 19:26:55.303103:  
2025-07-10 19:26:55.303482: Epoch 694 
2025-07-10 19:26:55.303659: Current learning rate: 0.00344 
2025-07-10 19:27:42.696435: train_loss -0.4481 
2025-07-10 19:27:42.696841: val_loss -0.473 
2025-07-10 19:27:42.696922: Pseudo dice [np.float32(0.7273)] 
2025-07-10 19:27:42.697026: Epoch time: 47.39 s 
2025-07-10 19:27:43.909076:  
2025-07-10 19:27:43.909276: Epoch 695 
2025-07-10 19:27:43.909477: Current learning rate: 0.00343 
2025-07-10 19:28:31.517509: train_loss -0.4599 
2025-07-10 19:28:31.517886: val_loss -0.4708 
2025-07-10 19:28:31.517968: Pseudo dice [np.float32(0.757)] 
2025-07-10 19:28:31.518064: Epoch time: 47.61 s 
2025-07-10 19:28:32.690401:  
2025-07-10 19:28:32.690790: Epoch 696 
2025-07-10 19:28:32.690938: Current learning rate: 0.00342 
2025-07-10 19:29:19.198571: train_loss -0.4564 
2025-07-10 19:29:19.198979: val_loss -0.4499 
2025-07-10 19:29:19.199127: Pseudo dice [np.float32(0.7234)] 
2025-07-10 19:29:19.199242: Epoch time: 46.51 s 
2025-07-10 19:29:20.426035:  
2025-07-10 19:29:20.426420: Epoch 697 
2025-07-10 19:29:20.426572: Current learning rate: 0.00341 
2025-07-10 19:30:07.887365: train_loss -0.4714 
2025-07-10 19:30:07.887689: val_loss -0.4677 
2025-07-10 19:30:07.887786: Pseudo dice [np.float32(0.7583)] 
2025-07-10 19:30:07.887882: Epoch time: 47.46 s 
2025-07-10 19:30:09.067456:  
2025-07-10 19:30:09.067698: Epoch 698 
2025-07-10 19:30:09.067825: Current learning rate: 0.0034 
2025-07-10 19:30:55.512510: train_loss -0.4684 
2025-07-10 19:30:55.513115: val_loss -0.4922 
2025-07-10 19:30:55.513227: Pseudo dice [np.float32(0.7789)] 
2025-07-10 19:30:55.513355: Epoch time: 46.45 s 
2025-07-10 19:30:56.772086:  
2025-07-10 19:30:56.772258: Epoch 699 
2025-07-10 19:30:56.772390: Current learning rate: 0.00339 
2025-07-10 19:31:43.508882: train_loss -0.4687 
2025-07-10 19:31:43.509570: val_loss -0.4836 
2025-07-10 19:31:43.509648: Pseudo dice [np.float32(0.7604)] 
2025-07-10 19:31:43.509803: Epoch time: 46.74 s 
2025-07-10 19:31:46.021042:  
2025-07-10 19:31:46.022240: Epoch 700 
2025-07-10 19:31:46.022656: Current learning rate: 0.00338 
2025-07-10 19:32:33.362479: train_loss -0.4726 
2025-07-10 19:32:33.363102: val_loss -0.4727 
2025-07-10 19:32:33.363183: Pseudo dice [np.float32(0.7841)] 
2025-07-10 19:32:33.363294: Epoch time: 47.34 s 
2025-07-10 19:32:34.515952:  
2025-07-10 19:32:34.516351: Epoch 701 
2025-07-10 19:32:34.516476: Current learning rate: 0.00337 
2025-07-10 19:33:21.539228: train_loss -0.4727 
2025-07-10 19:33:21.540073: val_loss -0.4534 
2025-07-10 19:33:21.540495: Pseudo dice [np.float32(0.7494)] 
2025-07-10 19:33:21.541002: Epoch time: 47.02 s 
2025-07-10 19:33:22.743287:  
2025-07-10 19:33:22.743679: Epoch 702 
2025-07-10 19:33:22.743861: Current learning rate: 0.00336 
2025-07-10 19:34:09.246026: train_loss -0.4704 
2025-07-10 19:34:09.246468: val_loss -0.4783 
2025-07-10 19:34:09.246568: Pseudo dice [np.float32(0.7249)] 
2025-07-10 19:34:09.246711: Epoch time: 46.5 s 
2025-07-10 19:34:10.425909:  
2025-07-10 19:34:10.426418: Epoch 703 
2025-07-10 19:34:10.426646: Current learning rate: 0.00335 
2025-07-10 19:34:57.112680: train_loss -0.4692 
2025-07-10 19:34:57.113244: val_loss -0.4459 
2025-07-10 19:34:57.113325: Pseudo dice [np.float32(0.6826)] 
2025-07-10 19:34:57.113431: Epoch time: 46.69 s 
2025-07-10 19:34:58.295377:  
2025-07-10 19:34:58.295837: Epoch 704 
2025-07-10 19:34:58.295967: Current learning rate: 0.00334 
2025-07-10 19:35:44.746269: train_loss -0.4735 
2025-07-10 19:35:44.746565: val_loss -0.4549 
2025-07-10 19:35:44.746641: Pseudo dice [np.float32(0.7755)] 
2025-07-10 19:35:44.746735: Epoch time: 46.45 s 
2025-07-10 19:35:45.896343:  
2025-07-10 19:35:45.896776: Epoch 705 
2025-07-10 19:35:45.896928: Current learning rate: 0.00333 
2025-07-10 19:36:32.596807: train_loss -0.4553 
2025-07-10 19:36:32.597066: val_loss -0.4652 
2025-07-10 19:36:32.597135: Pseudo dice [np.float32(0.7557)] 
2025-07-10 19:36:32.597218: Epoch time: 46.7 s 
2025-07-10 19:36:33.783518:  
2025-07-10 19:36:33.783933: Epoch 706 
2025-07-10 19:36:33.784155: Current learning rate: 0.00332 
2025-07-10 19:37:21.591741: train_loss -0.4679 
2025-07-10 19:37:21.592321: val_loss -0.4672 
2025-07-10 19:37:21.592417: Pseudo dice [np.float32(0.7569)] 
2025-07-10 19:37:21.592553: Epoch time: 47.81 s 
2025-07-10 19:37:22.810618:  
2025-07-10 19:37:22.810900: Epoch 707 
2025-07-10 19:37:22.811028: Current learning rate: 0.00331 
2025-07-10 19:38:10.249430: train_loss -0.4744 
2025-07-10 19:38:10.250014: val_loss -0.4594 
2025-07-10 19:38:10.250107: Pseudo dice [np.float32(0.7565)] 
2025-07-10 19:38:10.250228: Epoch time: 47.44 s 
2025-07-10 19:38:11.563933:  
2025-07-10 19:38:11.564630: Epoch 708 
2025-07-10 19:38:11.564885: Current learning rate: 0.0033 
2025-07-10 19:38:58.267724: train_loss -0.4529 
2025-07-10 19:38:58.268146: val_loss -0.4723 
2025-07-10 19:38:58.268221: Pseudo dice [np.float32(0.7696)] 
2025-07-10 19:38:58.268324: Epoch time: 46.71 s 
2025-07-10 19:38:59.423766:  
2025-07-10 19:38:59.423907: Epoch 709 
2025-07-10 19:38:59.424026: Current learning rate: 0.00329 
2025-07-10 19:39:46.216160: train_loss -0.4652 
2025-07-10 19:39:46.216895: val_loss -0.4714 
2025-07-10 19:39:46.217000: Pseudo dice [np.float32(0.7687)] 
2025-07-10 19:39:46.217136: Epoch time: 46.79 s 
2025-07-10 19:39:47.386063:  
2025-07-10 19:39:47.386417: Epoch 710 
2025-07-10 19:39:47.386526: Current learning rate: 0.00328 
2025-07-10 19:40:33.928306: train_loss -0.4738 
2025-07-10 19:40:33.929470: val_loss -0.4604 
2025-07-10 19:40:33.929600: Pseudo dice [np.float32(0.7718)] 
2025-07-10 19:40:33.929736: Epoch time: 46.54 s 
2025-07-10 19:40:35.848117:  
2025-07-10 19:40:35.848998: Epoch 711 
2025-07-10 19:40:35.849529: Current learning rate: 0.00327 
2025-07-10 19:41:22.867455: train_loss -0.4747 
2025-07-10 19:41:22.867959: val_loss -0.4532 
2025-07-10 19:41:22.868042: Pseudo dice [np.float32(0.7282)] 
2025-07-10 19:41:22.868170: Epoch time: 47.02 s 
2025-07-10 19:41:24.046005:  
2025-07-10 19:41:24.046336: Epoch 712 
2025-07-10 19:41:24.046605: Current learning rate: 0.00326 
2025-07-10 19:42:10.462423: train_loss -0.4599 
2025-07-10 19:42:10.463110: val_loss -0.4601 
2025-07-10 19:42:10.463265: Pseudo dice [np.float32(0.7191)] 
2025-07-10 19:42:10.463419: Epoch time: 46.42 s 
2025-07-10 19:42:11.740044:  
2025-07-10 19:42:11.740404: Epoch 713 
2025-07-10 19:42:11.740515: Current learning rate: 0.00325 
2025-07-10 19:42:58.415095: train_loss -0.4643 
2025-07-10 19:42:58.415635: val_loss -0.4698 
2025-07-10 19:42:58.415800: Pseudo dice [np.float32(0.7573)] 
2025-07-10 19:42:58.416041: Epoch time: 46.68 s 
2025-07-10 19:42:59.626116:  
2025-07-10 19:42:59.626476: Epoch 714 
2025-07-10 19:42:59.626786: Current learning rate: 0.00324 
2025-07-10 19:43:46.351716: train_loss -0.4548 
2025-07-10 19:43:46.352268: val_loss -0.4416 
2025-07-10 19:43:46.352359: Pseudo dice [np.float32(0.6968)] 
2025-07-10 19:43:46.352474: Epoch time: 46.73 s 
2025-07-10 19:43:47.588401:  
2025-07-10 19:43:47.588770: Epoch 715 
2025-07-10 19:43:47.588900: Current learning rate: 0.00323 
2025-07-10 19:44:34.649168: train_loss -0.4486 
2025-07-10 19:44:34.649439: val_loss -0.461 
2025-07-10 19:44:34.649514: Pseudo dice [np.float32(0.7421)] 
2025-07-10 19:44:34.649629: Epoch time: 47.06 s 
2025-07-10 19:44:35.867185:  
2025-07-10 19:44:35.867560: Epoch 716 
2025-07-10 19:44:35.867696: Current learning rate: 0.00322 
2025-07-10 19:45:22.701441: train_loss -0.453 
2025-07-10 19:45:22.701861: val_loss -0.4517 
2025-07-10 19:45:22.701946: Pseudo dice [np.float32(0.7125)] 
2025-07-10 19:45:22.702048: Epoch time: 46.84 s 
2025-07-10 19:45:23.883781:  
2025-07-10 19:45:23.884338: Epoch 717 
2025-07-10 19:45:23.884471: Current learning rate: 0.00321 
2025-07-10 19:46:10.308138: train_loss -0.4581 
2025-07-10 19:46:10.308609: val_loss -0.4573 
2025-07-10 19:46:10.308694: Pseudo dice [np.float32(0.7575)] 
2025-07-10 19:46:10.308820: Epoch time: 46.43 s 
2025-07-10 19:46:11.546401:  
2025-07-10 19:46:11.546615: Epoch 718 
2025-07-10 19:46:11.546751: Current learning rate: 0.0032 
2025-07-10 19:46:58.279788: train_loss -0.4566 
2025-07-10 19:46:58.280454: val_loss -0.4571 
2025-07-10 19:46:58.280552: Pseudo dice [np.float32(0.7692)] 
2025-07-10 19:46:58.280679: Epoch time: 46.73 s 
2025-07-10 19:46:59.552591:  
2025-07-10 19:46:59.552936: Epoch 719 
2025-07-10 19:46:59.553063: Current learning rate: 0.00319 
2025-07-10 19:47:46.471647: train_loss -0.4466 
2025-07-10 19:47:46.472165: val_loss -0.4445 
2025-07-10 19:47:46.472249: Pseudo dice [np.float32(0.7068)] 
2025-07-10 19:47:46.472357: Epoch time: 46.92 s 
2025-07-10 19:47:47.757982:  
2025-07-10 19:47:47.758394: Epoch 720 
2025-07-10 19:47:47.758521: Current learning rate: 0.00318 
2025-07-10 19:48:34.126765: train_loss -0.4449 
2025-07-10 19:48:34.127267: val_loss -0.437 
2025-07-10 19:48:34.127344: Pseudo dice [np.float32(0.6446)] 
2025-07-10 19:48:34.127441: Epoch time: 46.37 s 
2025-07-10 19:48:35.304505:  
2025-07-10 19:48:35.304801: Epoch 721 
2025-07-10 19:48:35.304941: Current learning rate: 0.00317 
2025-07-10 19:49:21.812666: train_loss -0.4489 
2025-07-10 19:49:21.813083: val_loss -0.4482 
2025-07-10 19:49:21.813167: Pseudo dice [np.float32(0.7323)] 
2025-07-10 19:49:21.813289: Epoch time: 46.51 s 
2025-07-10 19:49:23.717008:  
2025-07-10 19:49:23.717466: Epoch 722 
2025-07-10 19:49:23.717619: Current learning rate: 0.00316 
2025-07-10 19:50:10.346524: train_loss -0.4482 
2025-07-10 19:50:10.347002: val_loss -0.4354 
2025-07-10 19:50:10.347077: Pseudo dice [np.float32(0.6986)] 
2025-07-10 19:50:10.347191: Epoch time: 46.63 s 
2025-07-10 19:50:11.600971:  
2025-07-10 19:50:11.601445: Epoch 723 
2025-07-10 19:50:11.601715: Current learning rate: 0.00315 
2025-07-10 19:50:58.559228: train_loss -0.4598 
2025-07-10 19:50:58.560059: val_loss -0.4593 
2025-07-10 19:50:58.560151: Pseudo dice [np.float32(0.6797)] 
2025-07-10 19:50:58.560277: Epoch time: 46.96 s 
2025-07-10 19:50:59.801238:  
2025-07-10 19:50:59.801439: Epoch 724 
2025-07-10 19:50:59.801574: Current learning rate: 0.00314 
2025-07-10 19:51:46.777500: train_loss -0.4645 
2025-07-10 19:51:46.778095: val_loss -0.4707 
2025-07-10 19:51:46.778224: Pseudo dice [np.float32(0.7351)] 
2025-07-10 19:51:46.778354: Epoch time: 46.98 s 
2025-07-10 19:51:48.036223:  
2025-07-10 19:51:48.036681: Epoch 725 
2025-07-10 19:51:48.036872: Current learning rate: 0.00313 
2025-07-10 19:52:35.421767: train_loss -0.4658 
2025-07-10 19:52:35.422494: val_loss -0.4637 
2025-07-10 19:52:35.422609: Pseudo dice [np.float32(0.7624)] 
2025-07-10 19:52:35.422716: Epoch time: 47.39 s 
2025-07-10 19:52:36.656022:  
2025-07-10 19:52:36.656405: Epoch 726 
2025-07-10 19:52:36.656518: Current learning rate: 0.00312 
2025-07-10 19:53:23.538306: train_loss -0.4656 
2025-07-10 19:53:23.538853: val_loss -0.4669 
2025-07-10 19:53:23.538953: Pseudo dice [np.float32(0.7576)] 
2025-07-10 19:53:23.539066: Epoch time: 46.88 s 
2025-07-10 19:53:24.734143:  
2025-07-10 19:53:24.734522: Epoch 727 
2025-07-10 19:53:24.734665: Current learning rate: 0.00311 
2025-07-10 19:54:12.128220: train_loss -0.4691 
2025-07-10 19:54:12.128621: val_loss -0.4691 
2025-07-10 19:54:12.128731: Pseudo dice [np.float32(0.7777)] 
2025-07-10 19:54:12.128833: Epoch time: 47.4 s 
2025-07-10 19:54:13.287854:  
2025-07-10 19:54:13.288227: Epoch 728 
2025-07-10 19:54:13.288348: Current learning rate: 0.0031 
2025-07-10 19:54:59.555763: train_loss -0.4528 
2025-07-10 19:54:59.556302: val_loss -0.4302 
2025-07-10 19:54:59.556389: Pseudo dice [np.float32(0.7215)] 
2025-07-10 19:54:59.556502: Epoch time: 46.27 s 
2025-07-10 19:55:00.800402:  
2025-07-10 19:55:00.801256: Epoch 729 
2025-07-10 19:55:00.801511: Current learning rate: 0.00309 
2025-07-10 19:55:47.129375: train_loss -0.4433 
2025-07-10 19:55:47.129828: val_loss -0.4567 
2025-07-10 19:55:47.129907: Pseudo dice [np.float32(0.6973)] 
2025-07-10 19:55:47.130015: Epoch time: 46.33 s 
2025-07-10 19:55:48.297227:  
2025-07-10 19:55:48.297647: Epoch 730 
2025-07-10 19:55:48.297775: Current learning rate: 0.00308 
2025-07-10 19:56:35.417308: train_loss -0.4674 
2025-07-10 19:56:35.417717: val_loss -0.4755 
2025-07-10 19:56:35.417999: Pseudo dice [np.float32(0.768)] 
2025-07-10 19:56:35.418175: Epoch time: 47.12 s 
2025-07-10 19:56:36.610394:  
2025-07-10 19:56:36.610567: Epoch 731 
2025-07-10 19:56:36.610784: Current learning rate: 0.00307 
2025-07-10 19:57:23.344530: train_loss -0.4599 
2025-07-10 19:57:23.345144: val_loss -0.4539 
2025-07-10 19:57:23.348130: Pseudo dice [np.float32(0.7377)] 
2025-07-10 19:57:23.348256: Epoch time: 46.74 s 
2025-07-10 19:57:24.592591:  
2025-07-10 19:57:24.592871: Epoch 732 
2025-07-10 19:57:24.593158: Current learning rate: 0.00306 
2025-07-10 19:58:11.003371: train_loss -0.4546 
2025-07-10 19:58:11.003945: val_loss -0.4588 
2025-07-10 19:58:11.004106: Pseudo dice [np.float32(0.7263)] 
2025-07-10 19:58:11.004268: Epoch time: 46.41 s 
2025-07-10 19:58:12.125884:  
2025-07-10 19:58:12.126143: Epoch 733 
2025-07-10 19:58:12.126297: Current learning rate: 0.00305 
2025-07-10 19:58:59.096221: train_loss -0.4732 
2025-07-10 19:58:59.096910: val_loss -0.4727 
2025-07-10 19:58:59.097014: Pseudo dice [np.float32(0.7572)] 
2025-07-10 19:58:59.097130: Epoch time: 46.97 s 
2025-07-10 19:59:00.296514:  
2025-07-10 19:59:00.297053: Epoch 734 
2025-07-10 19:59:00.297200: Current learning rate: 0.00304 
2025-07-10 19:59:46.943349: train_loss -0.4659 
2025-07-10 19:59:46.943981: val_loss -0.4756 
2025-07-10 19:59:46.944072: Pseudo dice [np.float32(0.7836)] 
2025-07-10 19:59:46.944232: Epoch time: 46.65 s 
2025-07-10 19:59:48.170421:  
2025-07-10 19:59:48.171143: Epoch 735 
2025-07-10 19:59:48.171273: Current learning rate: 0.00303 
2025-07-10 20:00:34.975723: train_loss -0.4807 
2025-07-10 20:00:34.977159: val_loss -0.472 
2025-07-10 20:00:34.977422: Pseudo dice [np.float32(0.731)] 
2025-07-10 20:00:34.977708: Epoch time: 46.81 s 
2025-07-10 20:00:36.341870:  
2025-07-10 20:00:36.342488: Epoch 736 
2025-07-10 20:00:36.342647: Current learning rate: 0.00302 
2025-07-10 20:01:23.237334: train_loss -0.4428 
2025-07-10 20:01:23.238013: val_loss -0.4669 
2025-07-10 20:01:23.238097: Pseudo dice [np.float32(0.7319)] 
2025-07-10 20:01:23.238210: Epoch time: 46.9 s 
2025-07-10 20:01:24.472275:  
2025-07-10 20:01:24.472707: Epoch 737 
2025-07-10 20:01:24.472908: Current learning rate: 0.00301 
2025-07-10 20:02:11.042159: train_loss -0.4668 
2025-07-10 20:02:11.042768: val_loss -0.4513 
2025-07-10 20:02:11.042857: Pseudo dice [np.float32(0.7609)] 
2025-07-10 20:02:11.042995: Epoch time: 46.57 s 
2025-07-10 20:02:12.505132:  
2025-07-10 20:02:12.505395: Epoch 738 
2025-07-10 20:02:12.505605: Current learning rate: 0.003 
2025-07-10 20:02:59.290768: train_loss -0.4575 
2025-07-10 20:02:59.291291: val_loss -0.4871 
2025-07-10 20:02:59.291375: Pseudo dice [np.float32(0.738)] 
2025-07-10 20:02:59.291476: Epoch time: 46.79 s 
2025-07-10 20:03:00.489898:  
2025-07-10 20:03:00.490176: Epoch 739 
2025-07-10 20:03:00.490432: Current learning rate: 0.00299 
2025-07-10 20:03:48.301694: train_loss -0.4794 
2025-07-10 20:03:48.302308: val_loss -0.4769 
2025-07-10 20:03:48.302428: Pseudo dice [np.float32(0.7875)] 
2025-07-10 20:03:48.302586: Epoch time: 47.81 s 
2025-07-10 20:03:49.597191:  
2025-07-10 20:03:49.597465: Epoch 740 
2025-07-10 20:03:49.597643: Current learning rate: 0.00297 
2025-07-10 20:04:36.637796: train_loss -0.4807 
2025-07-10 20:04:36.638517: val_loss -0.4587 
2025-07-10 20:04:36.638610: Pseudo dice [np.float32(0.742)] 
2025-07-10 20:04:36.638722: Epoch time: 47.04 s 
2025-07-10 20:04:37.895420:  
2025-07-10 20:04:37.895823: Epoch 741 
2025-07-10 20:04:37.895942: Current learning rate: 0.00296 
2025-07-10 20:05:24.302160: train_loss -0.4526 
2025-07-10 20:05:24.302582: val_loss -0.4552 
2025-07-10 20:05:24.302698: Pseudo dice [np.float32(0.707)] 
2025-07-10 20:05:24.302800: Epoch time: 46.41 s 
2025-07-10 20:05:25.507893:  
2025-07-10 20:05:25.508388: Epoch 742 
2025-07-10 20:05:25.508521: Current learning rate: 0.00295 
2025-07-10 20:06:12.738821: train_loss -0.4626 
2025-07-10 20:06:12.739264: val_loss -0.4895 
2025-07-10 20:06:12.739338: Pseudo dice [np.float32(0.7746)] 
2025-07-10 20:06:12.739531: Epoch time: 47.23 s 
2025-07-10 20:06:14.474081:  
2025-07-10 20:06:14.474515: Epoch 743 
2025-07-10 20:06:14.474678: Current learning rate: 0.00294 
2025-07-10 20:07:02.138607: train_loss -0.4533 
2025-07-10 20:07:02.139201: val_loss -0.427 
2025-07-10 20:07:02.139290: Pseudo dice [np.float32(0.6424)] 
2025-07-10 20:07:02.139409: Epoch time: 47.67 s 
2025-07-10 20:07:03.387636:  
2025-07-10 20:07:03.388042: Epoch 744 
2025-07-10 20:07:03.388283: Current learning rate: 0.00293 
2025-07-10 20:07:50.837456: train_loss -0.4457 
2025-07-10 20:07:50.837972: val_loss -0.4623 
2025-07-10 20:07:50.838058: Pseudo dice [np.float32(0.7153)] 
2025-07-10 20:07:50.838180: Epoch time: 47.45 s 
2025-07-10 20:07:52.154638:  
2025-07-10 20:07:52.155326: Epoch 745 
2025-07-10 20:07:52.155458: Current learning rate: 0.00292 
2025-07-10 20:08:39.879112: train_loss -0.4493 
2025-07-10 20:08:39.879925: val_loss -0.4333 
2025-07-10 20:08:39.880005: Pseudo dice [np.float32(0.6853)] 
2025-07-10 20:08:39.880121: Epoch time: 47.73 s 
2025-07-10 20:08:41.069005:  
2025-07-10 20:08:41.069328: Epoch 746 
2025-07-10 20:08:41.069556: Current learning rate: 0.00291 
2025-07-10 20:09:28.049840: train_loss -0.4452 
2025-07-10 20:09:28.050519: val_loss -0.4671 
2025-07-10 20:09:28.050635: Pseudo dice [np.float32(0.6723)] 
2025-07-10 20:09:28.050811: Epoch time: 46.98 s 
2025-07-10 20:09:29.345796:  
2025-07-10 20:09:29.346058: Epoch 747 
2025-07-10 20:09:29.346204: Current learning rate: 0.0029 
2025-07-10 20:10:16.852162: train_loss -0.4603 
2025-07-10 20:10:16.852744: val_loss -0.4567 
2025-07-10 20:10:16.852830: Pseudo dice [np.float32(0.7449)] 
2025-07-10 20:10:16.852946: Epoch time: 47.51 s 
2025-07-10 20:10:18.151710:  
2025-07-10 20:10:18.151989: Epoch 748 
2025-07-10 20:10:18.152173: Current learning rate: 0.00289 
2025-07-10 20:11:05.194270: train_loss -0.4618 
2025-07-10 20:11:05.195089: val_loss -0.4618 
2025-07-10 20:11:05.195214: Pseudo dice [np.float32(0.7466)] 
2025-07-10 20:11:05.195372: Epoch time: 47.04 s 
2025-07-10 20:11:06.442577:  
2025-07-10 20:11:06.442775: Epoch 749 
2025-07-10 20:11:06.442899: Current learning rate: 0.00288 
2025-07-10 20:11:52.654161: train_loss -0.4804 
2025-07-10 20:11:52.655193: val_loss -0.4745 
2025-07-10 20:11:52.655282: Pseudo dice [np.float32(0.7714)] 
2025-07-10 20:11:52.655505: Epoch time: 46.21 s 
2025-07-10 20:11:54.395751:  
2025-07-10 20:11:54.396176: Epoch 750 
2025-07-10 20:11:54.396352: Current learning rate: 0.00287 
2025-07-10 20:12:39.990831: train_loss -0.4644 
2025-07-10 20:12:39.991324: val_loss -0.4823 
2025-07-10 20:12:39.991493: Pseudo dice [np.float32(0.7713)] 
2025-07-10 20:12:39.991643: Epoch time: 45.6 s 
2025-07-10 20:12:41.228165:  
2025-07-10 20:12:41.228408: Epoch 751 
2025-07-10 20:12:41.228529: Current learning rate: 0.00286 
2025-07-10 20:13:27.467926: train_loss -0.4714 
2025-07-10 20:13:27.468428: val_loss -0.4642 
2025-07-10 20:13:27.468512: Pseudo dice [np.float32(0.7479)] 
2025-07-10 20:13:27.468639: Epoch time: 46.24 s 
2025-07-10 20:13:28.653052:  
2025-07-10 20:13:28.653409: Epoch 752 
2025-07-10 20:13:28.653534: Current learning rate: 0.00285 
2025-07-10 20:14:15.809147: train_loss -0.4704 
2025-07-10 20:14:15.809582: val_loss -0.4613 
2025-07-10 20:14:15.809664: Pseudo dice [np.float32(0.7458)] 
2025-07-10 20:14:15.809764: Epoch time: 47.16 s 
2025-07-10 20:14:16.988026:  
2025-07-10 20:14:16.988460: Epoch 753 
2025-07-10 20:14:16.988593: Current learning rate: 0.00284 
2025-07-10 20:15:05.045732: train_loss -0.4646 
2025-07-10 20:15:05.046089: val_loss -0.4591 
2025-07-10 20:15:05.046164: Pseudo dice [np.float32(0.7274)] 
2025-07-10 20:15:05.046264: Epoch time: 48.06 s 
2025-07-10 20:15:06.779257:  
2025-07-10 20:15:06.779521: Epoch 754 
2025-07-10 20:15:06.779699: Current learning rate: 0.00283 
2025-07-10 20:15:53.890873: train_loss -0.4654 
2025-07-10 20:15:53.891420: val_loss -0.4628 
2025-07-10 20:15:53.891575: Pseudo dice [np.float32(0.7743)] 
2025-07-10 20:15:53.891687: Epoch time: 47.11 s 
2025-07-10 20:15:55.106761:  
2025-07-10 20:15:55.106980: Epoch 755 
2025-07-10 20:15:55.107278: Current learning rate: 0.00282 
2025-07-10 20:16:41.754727: train_loss -0.4812 
2025-07-10 20:16:41.755312: val_loss -0.4711 
2025-07-10 20:16:41.755411: Pseudo dice [np.float32(0.7768)] 
2025-07-10 20:16:41.755573: Epoch time: 46.65 s 
2025-07-10 20:16:42.921294:  
2025-07-10 20:16:42.921546: Epoch 756 
2025-07-10 20:16:42.921684: Current learning rate: 0.00281 
2025-07-10 20:17:29.385712: train_loss -0.4724 
2025-07-10 20:17:29.386024: val_loss -0.4635 
2025-07-10 20:17:29.386100: Pseudo dice [np.float32(0.7217)] 
2025-07-10 20:17:29.386201: Epoch time: 46.47 s 
2025-07-10 20:17:30.635912:  
2025-07-10 20:17:30.636087: Epoch 757 
2025-07-10 20:17:30.636224: Current learning rate: 0.0028 
2025-07-10 20:18:16.886424: train_loss -0.4668 
2025-07-10 20:18:16.886827: val_loss -0.4767 
2025-07-10 20:18:16.886899: Pseudo dice [np.float32(0.7939)] 
2025-07-10 20:18:16.886983: Epoch time: 46.25 s 
2025-07-10 20:18:18.153311:  
2025-07-10 20:18:18.153498: Epoch 758 
2025-07-10 20:18:18.153802: Current learning rate: 0.00279 
2025-07-10 20:19:05.066600: train_loss -0.4761 
2025-07-10 20:19:05.066875: val_loss -0.4769 
2025-07-10 20:19:05.066948: Pseudo dice [np.float32(0.7862)] 
2025-07-10 20:19:05.067047: Epoch time: 46.91 s 
2025-07-10 20:19:06.250148:  
2025-07-10 20:19:06.250737: Epoch 759 
2025-07-10 20:19:06.250976: Current learning rate: 0.00278 
2025-07-10 20:19:52.958338: train_loss -0.4661 
2025-07-10 20:19:52.958759: val_loss -0.482 
2025-07-10 20:19:52.958843: Pseudo dice [np.float32(0.8027)] 
2025-07-10 20:19:52.958955: Epoch time: 46.71 s 
2025-07-10 20:19:54.193830:  
2025-07-10 20:19:54.194403: Epoch 760 
2025-07-10 20:19:54.194535: Current learning rate: 0.00277 
2025-07-10 20:20:40.976116: train_loss -0.4785 
2025-07-10 20:20:40.976807: val_loss -0.4801 
2025-07-10 20:20:40.976910: Pseudo dice [np.float32(0.7609)] 
2025-07-10 20:20:40.977036: Epoch time: 46.78 s 
2025-07-10 20:20:42.225244:  
2025-07-10 20:20:42.225873: Epoch 761 
2025-07-10 20:20:42.226020: Current learning rate: 0.00276 
2025-07-10 20:21:27.998930: train_loss -0.4626 
2025-07-10 20:21:27.999289: val_loss -0.4568 
2025-07-10 20:21:27.999462: Pseudo dice [np.float32(0.7392)] 
2025-07-10 20:21:27.999619: Epoch time: 45.78 s 
2025-07-10 20:21:29.200733:  
2025-07-10 20:21:29.200905: Epoch 762 
2025-07-10 20:21:29.201029: Current learning rate: 0.00275 
2025-07-10 20:22:15.987429: train_loss -0.4669 
2025-07-10 20:22:15.987978: val_loss -0.4711 
2025-07-10 20:22:15.988201: Pseudo dice [np.float32(0.761)] 
2025-07-10 20:22:15.988328: Epoch time: 46.79 s 
2025-07-10 20:22:17.179738:  
2025-07-10 20:22:17.180004: Epoch 763 
2025-07-10 20:22:17.180135: Current learning rate: 0.00274 
2025-07-10 20:23:03.306434: train_loss -0.4766 
2025-07-10 20:23:03.306807: val_loss -0.4784 
2025-07-10 20:23:03.306907: Pseudo dice [np.float32(0.7486)] 
2025-07-10 20:23:03.307005: Epoch time: 46.13 s 
2025-07-10 20:23:04.510249:  
2025-07-10 20:23:04.510625: Epoch 764 
2025-07-10 20:23:04.510728: Current learning rate: 0.00273 
2025-07-10 20:23:51.021840: train_loss -0.4714 
2025-07-10 20:23:51.022498: val_loss -0.4758 
2025-07-10 20:23:51.022608: Pseudo dice [np.float32(0.7493)] 
2025-07-10 20:23:51.022735: Epoch time: 46.51 s 
2025-07-10 20:23:52.744537:  
2025-07-10 20:23:52.744741: Epoch 765 
2025-07-10 20:23:52.744868: Current learning rate: 0.00272 
2025-07-10 20:24:39.123758: train_loss -0.4674 
2025-07-10 20:24:39.124661: val_loss -0.4696 
2025-07-10 20:24:39.124824: Pseudo dice [np.float32(0.7769)] 
2025-07-10 20:24:39.125016: Epoch time: 46.38 s 
2025-07-10 20:24:40.422681:  
2025-07-10 20:24:40.422960: Epoch 766 
2025-07-10 20:24:40.423083: Current learning rate: 0.00271 
2025-07-10 20:25:27.309056: train_loss -0.4547 
2025-07-10 20:25:27.309706: val_loss -0.4419 
2025-07-10 20:25:27.309820: Pseudo dice [np.float32(0.7206)] 
2025-07-10 20:25:27.309951: Epoch time: 46.89 s 
2025-07-10 20:25:28.514424:  
2025-07-10 20:25:28.514751: Epoch 767 
2025-07-10 20:25:28.514882: Current learning rate: 0.0027 
2025-07-10 20:26:15.586025: train_loss -0.4646 
2025-07-10 20:26:15.586570: val_loss -0.4593 
2025-07-10 20:26:15.586663: Pseudo dice [np.float32(0.7118)] 
2025-07-10 20:26:15.586809: Epoch time: 47.07 s 
2025-07-10 20:26:16.806440:  
2025-07-10 20:26:16.806756: Epoch 768 
2025-07-10 20:26:16.806885: Current learning rate: 0.00268 
2025-07-10 20:27:05.096305: train_loss -0.4638 
2025-07-10 20:27:05.096821: val_loss -0.4425 
2025-07-10 20:27:05.096898: Pseudo dice [np.float32(0.7311)] 
2025-07-10 20:27:05.097009: Epoch time: 48.29 s 
2025-07-10 20:27:06.284858:  
2025-07-10 20:27:06.285338: Epoch 769 
2025-07-10 20:27:06.285478: Current learning rate: 0.00267 
2025-07-10 20:27:53.820658: train_loss -0.4637 
2025-07-10 20:27:53.821320: val_loss -0.4512 
2025-07-10 20:27:53.821414: Pseudo dice [np.float32(0.757)] 
2025-07-10 20:27:53.821530: Epoch time: 47.54 s 
2025-07-10 20:27:55.086161:  
2025-07-10 20:27:55.086738: Epoch 770 
2025-07-10 20:27:55.086889: Current learning rate: 0.00266 
2025-07-10 20:28:42.331331: train_loss -0.479 
2025-07-10 20:28:42.331692: val_loss -0.4827 
2025-07-10 20:28:42.331764: Pseudo dice [np.float32(0.7697)] 
2025-07-10 20:28:42.331869: Epoch time: 47.25 s 
2025-07-10 20:28:43.515748:  
2025-07-10 20:28:43.516219: Epoch 771 
2025-07-10 20:28:43.516320: Current learning rate: 0.00265 
2025-07-10 20:29:31.837791: train_loss -0.4755 
2025-07-10 20:29:31.838319: val_loss -0.4855 
2025-07-10 20:29:31.838398: Pseudo dice [np.float32(0.7521)] 
2025-07-10 20:29:31.838500: Epoch time: 48.32 s 
2025-07-10 20:29:33.038969:  
2025-07-10 20:29:33.039347: Epoch 772 
2025-07-10 20:29:33.039484: Current learning rate: 0.00264 
2025-07-10 20:30:20.412850: train_loss -0.4734 
2025-07-10 20:30:20.413257: val_loss -0.4612 
2025-07-10 20:30:20.413334: Pseudo dice [np.float32(0.7112)] 
2025-07-10 20:30:20.413436: Epoch time: 47.37 s 
2025-07-10 20:30:21.640769:  
2025-07-10 20:30:21.641284: Epoch 773 
2025-07-10 20:30:21.641422: Current learning rate: 0.00263 
2025-07-10 20:31:08.930660: train_loss -0.4839 
2025-07-10 20:31:08.931210: val_loss -0.4566 
2025-07-10 20:31:08.931296: Pseudo dice [np.float32(0.7924)] 
2025-07-10 20:31:08.931400: Epoch time: 47.29 s 
2025-07-10 20:31:10.146323:  
2025-07-10 20:31:10.146526: Epoch 774 
2025-07-10 20:31:10.146666: Current learning rate: 0.00262 
2025-07-10 20:31:58.300231: train_loss -0.4583 
2025-07-10 20:31:58.301155: val_loss -0.4495 
2025-07-10 20:31:58.301286: Pseudo dice [np.float32(0.7318)] 
2025-07-10 20:31:58.301409: Epoch time: 48.15 s 
2025-07-10 20:31:59.515780:  
2025-07-10 20:31:59.516005: Epoch 775 
2025-07-10 20:31:59.516147: Current learning rate: 0.00261 
2025-07-10 20:32:47.015280: train_loss -0.4633 
2025-07-10 20:32:47.015696: val_loss -0.4412 
2025-07-10 20:32:47.015776: Pseudo dice [np.float32(0.6866)] 
2025-07-10 20:32:47.015869: Epoch time: 47.5 s 
2025-07-10 20:32:48.829680:  
2025-07-10 20:32:48.830104: Epoch 776 
2025-07-10 20:32:48.830254: Current learning rate: 0.0026 
2025-07-10 20:33:36.650247: train_loss -0.4612 
2025-07-10 20:33:36.650875: val_loss -0.4706 
2025-07-10 20:33:36.650965: Pseudo dice [np.float32(0.7582)] 
2025-07-10 20:33:36.651087: Epoch time: 47.82 s 
2025-07-10 20:33:37.875882:  
2025-07-10 20:33:37.876325: Epoch 777 
2025-07-10 20:33:37.876465: Current learning rate: 0.00259 
2025-07-10 20:34:28.251971: train_loss -0.4711 
2025-07-10 20:34:28.252589: val_loss -0.4713 
2025-07-10 20:34:28.252699: Pseudo dice [np.float32(0.7606)] 
2025-07-10 20:34:28.252863: Epoch time: 50.38 s 
2025-07-10 20:34:29.612380:  
2025-07-10 20:34:29.612770: Epoch 778 
2025-07-10 20:34:29.612931: Current learning rate: 0.00258 
2025-07-10 20:35:17.814515: train_loss -0.4794 
2025-07-10 20:35:17.815113: val_loss -0.4748 
2025-07-10 20:35:17.815198: Pseudo dice [np.float32(0.7488)] 
2025-07-10 20:35:17.815317: Epoch time: 48.2 s 
2025-07-10 20:35:19.027967:  
2025-07-10 20:35:19.028291: Epoch 779 
2025-07-10 20:35:19.028419: Current learning rate: 0.00257 
2025-07-10 20:36:06.246759: train_loss -0.4753 
2025-07-10 20:36:06.247428: val_loss -0.47 
2025-07-10 20:36:06.247607: Pseudo dice [np.float32(0.7744)] 
2025-07-10 20:36:06.247700: Epoch time: 47.22 s 
2025-07-10 20:36:07.412934:  
2025-07-10 20:36:07.413167: Epoch 780 
2025-07-10 20:36:07.413281: Current learning rate: 0.00256 
2025-07-10 20:36:55.240273: train_loss -0.4832 
2025-07-10 20:36:55.240634: val_loss -0.4915 
2025-07-10 20:36:55.240710: Pseudo dice [np.float32(0.8002)] 
2025-07-10 20:36:55.240798: Epoch time: 47.83 s 
2025-07-10 20:36:56.416187:  
2025-07-10 20:36:56.416390: Epoch 781 
2025-07-10 20:36:56.416599: Current learning rate: 0.00255 
2025-07-10 20:37:46.094844: train_loss -0.4748 
2025-07-10 20:37:46.095302: val_loss -0.4801 
2025-07-10 20:37:46.095382: Pseudo dice [np.float32(0.7502)] 
2025-07-10 20:37:46.095487: Epoch time: 49.68 s 
2025-07-10 20:37:47.286108:  
2025-07-10 20:37:47.286282: Epoch 782 
2025-07-10 20:37:47.286405: Current learning rate: 0.00254 
2025-07-10 20:38:35.017015: train_loss -0.4689 
2025-07-10 20:38:35.017600: val_loss -0.4637 
2025-07-10 20:38:35.017687: Pseudo dice [np.float32(0.7498)] 
2025-07-10 20:38:35.017792: Epoch time: 47.73 s 
2025-07-10 20:38:36.322940:  
2025-07-10 20:38:36.323432: Epoch 783 
2025-07-10 20:38:36.323612: Current learning rate: 0.00253 
2025-07-10 20:39:23.778266: train_loss -0.4564 
2025-07-10 20:39:23.778837: val_loss -0.4277 
2025-07-10 20:39:23.778927: Pseudo dice [np.float32(0.6948)] 
2025-07-10 20:39:23.779048: Epoch time: 47.46 s 
2025-07-10 20:39:24.993873:  
2025-07-10 20:39:24.994137: Epoch 784 
2025-07-10 20:39:24.994289: Current learning rate: 0.00252 
2025-07-10 20:40:11.122897: train_loss -0.4666 
2025-07-10 20:40:11.123270: val_loss -0.4847 
2025-07-10 20:40:11.123379: Pseudo dice [np.float32(0.7717)] 
2025-07-10 20:40:11.123466: Epoch time: 46.13 s 
2025-07-10 20:40:12.269451:  
2025-07-10 20:40:12.269816: Epoch 785 
2025-07-10 20:40:12.269961: Current learning rate: 0.00251 
2025-07-10 20:40:59.600944: train_loss -0.4706 
2025-07-10 20:40:59.601593: val_loss -0.4696 
2025-07-10 20:40:59.601688: Pseudo dice [np.float32(0.797)] 
2025-07-10 20:40:59.601811: Epoch time: 47.33 s 
2025-07-10 20:41:00.852399:  
2025-07-10 20:41:00.852848: Epoch 786 
2025-07-10 20:41:00.853010: Current learning rate: 0.0025 
2025-07-10 20:41:47.995786: train_loss -0.4735 
2025-07-10 20:41:47.996062: val_loss -0.4894 
2025-07-10 20:41:47.996137: Pseudo dice [np.float32(0.7836)] 
2025-07-10 20:41:47.996234: Epoch time: 47.14 s 
2025-07-10 20:41:49.648379:  
2025-07-10 20:41:49.648885: Epoch 787 
2025-07-10 20:41:49.649028: Current learning rate: 0.00249 
2025-07-10 20:42:36.570959: train_loss -0.4825 
2025-07-10 20:42:36.572395: val_loss -0.4788 
2025-07-10 20:42:36.572562: Pseudo dice [np.float32(0.7824)] 
2025-07-10 20:42:36.572781: Epoch time: 46.92 s 
2025-07-10 20:42:37.808157:  
2025-07-10 20:42:37.808404: Epoch 788 
2025-07-10 20:42:37.808586: Current learning rate: 0.00248 
2025-07-10 20:43:24.809190: train_loss -0.4602 
2025-07-10 20:43:24.809783: val_loss -0.458 
2025-07-10 20:43:24.809879: Pseudo dice [np.float32(0.7181)] 
2025-07-10 20:43:24.809980: Epoch time: 47.0 s 
2025-07-10 20:43:25.995065:  
2025-07-10 20:43:25.995253: Epoch 789 
2025-07-10 20:43:25.995488: Current learning rate: 0.00247 
2025-07-10 20:44:12.514827: train_loss -0.4656 
2025-07-10 20:44:12.515145: val_loss -0.4525 
2025-07-10 20:44:12.515230: Pseudo dice [np.float32(0.7568)] 
2025-07-10 20:44:12.515340: Epoch time: 46.52 s 
2025-07-10 20:44:13.720593:  
2025-07-10 20:44:13.720989: Epoch 790 
2025-07-10 20:44:13.721234: Current learning rate: 0.00245 
2025-07-10 20:45:00.241026: train_loss -0.4726 
2025-07-10 20:45:00.241643: val_loss -0.4798 
2025-07-10 20:45:00.241850: Pseudo dice [np.float32(0.7779)] 
2025-07-10 20:45:00.241963: Epoch time: 46.52 s 
2025-07-10 20:45:01.482949:  
2025-07-10 20:45:01.483536: Epoch 791 
2025-07-10 20:45:01.483747: Current learning rate: 0.00244 
2025-07-10 20:45:48.062819: train_loss -0.4884 
2025-07-10 20:45:48.063391: val_loss -0.4592 
2025-07-10 20:45:48.063534: Pseudo dice [np.float32(0.7428)] 
2025-07-10 20:45:48.063744: Epoch time: 46.58 s 
2025-07-10 20:45:49.319091:  
2025-07-10 20:45:49.319480: Epoch 792 
2025-07-10 20:45:49.319773: Current learning rate: 0.00243 
2025-07-10 20:46:36.360022: train_loss -0.4716 
2025-07-10 20:46:36.360574: val_loss -0.4783 
2025-07-10 20:46:36.360657: Pseudo dice [np.float32(0.7758)] 
2025-07-10 20:46:36.360769: Epoch time: 47.04 s 
2025-07-10 20:46:37.593727:  
2025-07-10 20:46:37.594121: Epoch 793 
2025-07-10 20:46:37.594440: Current learning rate: 0.00242 
2025-07-10 20:47:24.925835: train_loss -0.4701 
2025-07-10 20:47:24.926201: val_loss -0.4787 
2025-07-10 20:47:24.926279: Pseudo dice [np.float32(0.8154)] 
2025-07-10 20:47:24.926383: Epoch time: 47.33 s 
2025-07-10 20:47:26.232248:  
2025-07-10 20:47:26.232777: Epoch 794 
2025-07-10 20:47:26.233044: Current learning rate: 0.00241 
2025-07-10 20:48:14.893947: train_loss -0.472 
2025-07-10 20:48:14.894315: val_loss -0.4818 
2025-07-10 20:48:14.894391: Pseudo dice [np.float32(0.7664)] 
2025-07-10 20:48:14.894497: Epoch time: 48.66 s 
2025-07-10 20:48:16.080967:  
2025-07-10 20:48:16.081218: Epoch 795 
2025-07-10 20:48:16.081336: Current learning rate: 0.0024 
2025-07-10 20:49:04.250016: train_loss -0.4505 
2025-07-10 20:49:04.250463: val_loss -0.4426 
2025-07-10 20:49:04.250587: Pseudo dice [np.float32(0.7064)] 
2025-07-10 20:49:04.250707: Epoch time: 48.17 s 
2025-07-10 20:49:05.461404:  
2025-07-10 20:49:05.461656: Epoch 796 
2025-07-10 20:49:05.461781: Current learning rate: 0.00239 
2025-07-10 20:49:52.057307: train_loss -0.4573 
2025-07-10 20:49:52.057663: val_loss -0.462 
2025-07-10 20:49:52.057739: Pseudo dice [np.float32(0.7451)] 
2025-07-10 20:49:52.057839: Epoch time: 46.6 s 
2025-07-10 20:49:53.272409:  
2025-07-10 20:49:53.272899: Epoch 797 
2025-07-10 20:49:53.273036: Current learning rate: 0.00238 
2025-07-10 20:50:40.342353: train_loss -0.4783 
2025-07-10 20:50:40.342856: val_loss -0.4853 
2025-07-10 20:50:40.342951: Pseudo dice [np.float32(0.7722)] 
2025-07-10 20:50:40.343091: Epoch time: 47.07 s 
2025-07-10 20:50:42.158718:  
2025-07-10 20:50:42.158914: Epoch 798 
2025-07-10 20:50:42.159035: Current learning rate: 0.00237 
2025-07-10 20:51:29.089171: train_loss -0.4488 
2025-07-10 20:51:29.090244: val_loss -0.4754 
2025-07-10 20:51:29.090340: Pseudo dice [np.float32(0.7419)] 
2025-07-10 20:51:29.090563: Epoch time: 46.93 s 
2025-07-10 20:51:30.438289:  
2025-07-10 20:51:30.438552: Epoch 799 
2025-07-10 20:51:30.438755: Current learning rate: 0.00236 
2025-07-10 20:52:18.236281: train_loss -0.4662 
2025-07-10 20:52:18.236799: val_loss -0.4779 
2025-07-10 20:52:18.236929: Pseudo dice [np.float32(0.7356)] 
2025-07-10 20:52:18.237070: Epoch time: 47.8 s 
2025-07-10 20:52:19.969557:  
2025-07-10 20:52:19.969989: Epoch 800 
2025-07-10 20:52:19.970123: Current learning rate: 0.00235 
2025-07-10 20:53:07.349880: train_loss -0.4622 
2025-07-10 20:53:07.350767: val_loss -0.47 
2025-07-10 20:53:07.354501: Pseudo dice [np.float32(0.7808)] 
2025-07-10 20:53:07.354894: Epoch time: 47.38 s 
2025-07-10 20:53:08.598053:  
2025-07-10 20:53:08.598242: Epoch 801 
2025-07-10 20:53:08.598573: Current learning rate: 0.00234 
2025-07-10 20:53:56.569376: train_loss -0.4768 
2025-07-10 20:53:56.570090: val_loss -0.482 
2025-07-10 20:53:56.570191: Pseudo dice [np.float32(0.7853)] 
2025-07-10 20:53:56.570320: Epoch time: 47.97 s 
2025-07-10 20:53:57.864946:  
2025-07-10 20:53:57.865367: Epoch 802 
2025-07-10 20:53:57.865514: Current learning rate: 0.00233 
2025-07-10 20:54:44.570604: train_loss -0.4857 
2025-07-10 20:54:44.571065: val_loss -0.4877 
2025-07-10 20:54:44.571157: Pseudo dice [np.float32(0.7863)] 
2025-07-10 20:54:44.571261: Epoch time: 46.71 s 
2025-07-10 20:54:45.816213:  
2025-07-10 20:54:45.816616: Epoch 803 
2025-07-10 20:54:45.816748: Current learning rate: 0.00232 
2025-07-10 20:55:32.157664: train_loss -0.4842 
2025-07-10 20:55:32.158452: val_loss -0.4893 
2025-07-10 20:55:32.158527: Pseudo dice [np.float32(0.7834)] 
2025-07-10 20:55:32.158726: Epoch time: 46.34 s 
2025-07-10 20:55:33.350892:  
2025-07-10 20:55:33.351302: Epoch 804 
2025-07-10 20:55:33.351726: Current learning rate: 0.00231 
2025-07-10 20:56:19.729017: train_loss -0.4811 
2025-07-10 20:56:19.729633: val_loss -0.4914 
2025-07-10 20:56:19.729725: Pseudo dice [np.float32(0.791)] 
2025-07-10 20:56:19.729869: Epoch time: 46.38 s 
2025-07-10 20:56:20.926364:  
2025-07-10 20:56:20.926855: Epoch 805 
2025-07-10 20:56:20.926985: Current learning rate: 0.0023 
2025-07-10 20:57:07.150135: train_loss -0.4618 
2025-07-10 20:57:07.150653: val_loss -0.46 
2025-07-10 20:57:07.150751: Pseudo dice [np.float32(0.7424)] 
2025-07-10 20:57:07.150897: Epoch time: 46.22 s 
2025-07-10 20:57:08.359876:  
2025-07-10 20:57:08.360292: Epoch 806 
2025-07-10 20:57:08.360416: Current learning rate: 0.00229 
2025-07-10 20:57:54.578412: train_loss -0.4759 
2025-07-10 20:57:54.578745: val_loss -0.4605 
2025-07-10 20:57:54.578821: Pseudo dice [np.float32(0.7542)] 
2025-07-10 20:57:54.578932: Epoch time: 46.22 s 
2025-07-10 20:57:55.797517:  
2025-07-10 20:57:55.797759: Epoch 807 
2025-07-10 20:57:55.797931: Current learning rate: 0.00228 
2025-07-10 20:58:42.314047: train_loss -0.4737 
2025-07-10 20:58:42.314527: val_loss -0.4947 
2025-07-10 20:58:42.314642: Pseudo dice [np.float32(0.7708)] 
2025-07-10 20:58:42.314750: Epoch time: 46.52 s 
2025-07-10 20:58:44.161783:  
2025-07-10 20:58:44.162022: Epoch 808 
2025-07-10 20:58:44.162156: Current learning rate: 0.00226 
2025-07-10 20:59:31.200805: train_loss -0.4916 
2025-07-10 20:59:31.201267: val_loss -0.4814 
2025-07-10 20:59:31.201359: Pseudo dice [np.float32(0.7754)] 
2025-07-10 20:59:31.201464: Epoch time: 47.04 s 
2025-07-10 20:59:32.391675:  
2025-07-10 20:59:32.391833: Epoch 809 
2025-07-10 20:59:32.391946: Current learning rate: 0.00225 
2025-07-10 21:00:19.290483: train_loss -0.4746 
2025-07-10 21:00:19.291065: val_loss -0.4831 
2025-07-10 21:00:19.291175: Pseudo dice [np.float32(0.77)] 
2025-07-10 21:00:19.291311: Epoch time: 46.9 s 
2025-07-10 21:00:20.488827:  
2025-07-10 21:00:20.489207: Epoch 810 
2025-07-10 21:00:20.489360: Current learning rate: 0.00224 
2025-07-10 21:01:06.353841: train_loss -0.4617 
2025-07-10 21:01:06.354226: val_loss -0.4756 
2025-07-10 21:01:06.354301: Pseudo dice [np.float32(0.7546)] 
2025-07-10 21:01:06.354509: Epoch time: 45.87 s 
2025-07-10 21:01:07.518760:  
2025-07-10 21:01:07.519103: Epoch 811 
2025-07-10 21:01:07.519258: Current learning rate: 0.00223 
2025-07-10 21:01:54.522075: train_loss -0.4839 
2025-07-10 21:01:54.522697: val_loss -0.4994 
2025-07-10 21:01:54.522805: Pseudo dice [np.float32(0.7944)] 
2025-07-10 21:01:54.522932: Epoch time: 47.0 s 
2025-07-10 21:01:55.755638:  
2025-07-10 21:01:55.756008: Epoch 812 
2025-07-10 21:01:55.756220: Current learning rate: 0.00222 
2025-07-10 21:02:42.755326: train_loss -0.489 
2025-07-10 21:02:42.756611: val_loss -0.4891 
2025-07-10 21:02:42.760374: Pseudo dice [np.float32(0.77)] 
2025-07-10 21:02:42.761072: Epoch time: 47.0 s 
2025-07-10 21:02:44.011359:  
2025-07-10 21:02:44.011655: Epoch 813 
2025-07-10 21:02:44.011869: Current learning rate: 0.00221 
2025-07-10 21:03:31.118427: train_loss -0.485 
2025-07-10 21:03:31.119128: val_loss -0.5113 
2025-07-10 21:03:31.119272: Pseudo dice [np.float32(0.8242)] 
2025-07-10 21:03:31.119391: Epoch time: 47.11 s 
2025-07-10 21:03:32.345514:  
2025-07-10 21:03:32.345989: Epoch 814 
2025-07-10 21:03:32.346284: Current learning rate: 0.0022 
2025-07-10 21:04:19.480448: train_loss -0.4822 
2025-07-10 21:04:19.481589: val_loss -0.4697 
2025-07-10 21:04:19.481827: Pseudo dice [np.float32(0.7301)] 
2025-07-10 21:04:19.482121: Epoch time: 47.14 s 
2025-07-10 21:04:20.846645:  
2025-07-10 21:04:20.847031: Epoch 815 
2025-07-10 21:04:20.847171: Current learning rate: 0.00219 
2025-07-10 21:05:07.531481: train_loss -0.4684 
2025-07-10 21:05:07.532441: val_loss -0.4753 
2025-07-10 21:05:07.532566: Pseudo dice [np.float32(0.7815)] 
2025-07-10 21:05:07.532717: Epoch time: 46.69 s 
2025-07-10 21:05:08.758713:  
2025-07-10 21:05:08.759248: Epoch 816 
2025-07-10 21:05:08.759468: Current learning rate: 0.00218 
2025-07-10 21:05:54.923504: train_loss -0.48 
2025-07-10 21:05:54.923858: val_loss -0.4828 
2025-07-10 21:05:54.927741: Pseudo dice [np.float32(0.7916)] 
2025-07-10 21:05:54.928000: Epoch time: 46.17 s 
2025-07-10 21:05:56.131193:  
2025-07-10 21:05:56.131635: Epoch 817 
2025-07-10 21:05:56.131809: Current learning rate: 0.00217 
2025-07-10 21:06:43.546517: train_loss -0.4933 
2025-07-10 21:06:43.547070: val_loss -0.4728 
2025-07-10 21:06:43.547158: Pseudo dice [np.float32(0.7796)] 
2025-07-10 21:06:43.547268: Epoch time: 47.42 s 
2025-07-10 21:06:44.956615:  
2025-07-10 21:06:44.957311: Epoch 818 
2025-07-10 21:06:44.957703: Current learning rate: 0.00216 
2025-07-10 21:07:31.126948: train_loss -0.4799 
2025-07-10 21:07:31.127577: val_loss -0.4907 
2025-07-10 21:07:31.127682: Pseudo dice [np.float32(0.7979)] 
2025-07-10 21:07:31.127826: Epoch time: 46.17 s 
2025-07-10 21:07:32.942897:  
2025-07-10 21:07:32.943363: Epoch 819 
2025-07-10 21:07:32.943487: Current learning rate: 0.00215 
2025-07-10 21:08:19.619364: train_loss -0.4671 
2025-07-10 21:08:19.620026: val_loss -0.4575 
2025-07-10 21:08:19.620111: Pseudo dice [np.float32(0.7401)] 
2025-07-10 21:08:19.620216: Epoch time: 46.68 s 
2025-07-10 21:08:20.725472:  
2025-07-10 21:08:20.725636: Epoch 820 
2025-07-10 21:08:20.725837: Current learning rate: 0.00214 
2025-07-10 21:09:06.437970: train_loss -0.4827 
2025-07-10 21:09:06.438415: val_loss -0.4743 
2025-07-10 21:09:06.438502: Pseudo dice [np.float32(0.7882)] 
2025-07-10 21:09:06.438628: Epoch time: 45.71 s 
2025-07-10 21:09:07.615710:  
2025-07-10 21:09:07.615923: Epoch 821 
2025-07-10 21:09:07.616239: Current learning rate: 0.00213 
2025-07-10 21:09:54.423277: train_loss -0.4857 
2025-07-10 21:09:54.423880: val_loss -0.4678 
2025-07-10 21:09:54.423962: Pseudo dice [np.float32(0.7665)] 
2025-07-10 21:09:54.424076: Epoch time: 46.81 s 
2025-07-10 21:09:55.587264:  
2025-07-10 21:09:55.587422: Epoch 822 
2025-07-10 21:09:55.587537: Current learning rate: 0.00212 
2025-07-10 21:10:42.264918: train_loss -0.4733 
2025-07-10 21:10:42.265392: val_loss -0.4325 
2025-07-10 21:10:42.265475: Pseudo dice [np.float32(0.6622)] 
2025-07-10 21:10:42.265594: Epoch time: 46.68 s 
2025-07-10 21:10:43.447748:  
2025-07-10 21:10:43.448110: Epoch 823 
2025-07-10 21:10:43.448331: Current learning rate: 0.0021 
2025-07-10 21:11:30.387823: train_loss -0.4618 
2025-07-10 21:11:30.388684: val_loss -0.4584 
2025-07-10 21:11:30.388774: Pseudo dice [np.float32(0.7455)] 
2025-07-10 21:11:30.388914: Epoch time: 46.94 s 
2025-07-10 21:11:31.543704:  
2025-07-10 21:11:31.544019: Epoch 824 
2025-07-10 21:11:31.544307: Current learning rate: 0.00209 
2025-07-10 21:12:17.918938: train_loss -0.4727 
2025-07-10 21:12:17.919909: val_loss -0.4948 
2025-07-10 21:12:17.920068: Pseudo dice [np.float32(0.814)] 
2025-07-10 21:12:17.920376: Epoch time: 46.38 s 
2025-07-10 21:12:19.102623:  
2025-07-10 21:12:19.102917: Epoch 825 
2025-07-10 21:12:19.103105: Current learning rate: 0.00208 
2025-07-10 21:13:05.433776: train_loss -0.4809 
2025-07-10 21:13:05.434183: val_loss -0.4735 
2025-07-10 21:13:05.434259: Pseudo dice [np.float32(0.787)] 
2025-07-10 21:13:05.434361: Epoch time: 46.33 s 
2025-07-10 21:13:06.588947:  
2025-07-10 21:13:06.589220: Epoch 826 
2025-07-10 21:13:06.589466: Current learning rate: 0.00207 
2025-07-10 21:13:52.796351: train_loss -0.4811 
2025-07-10 21:13:52.796913: val_loss -0.4946 
2025-07-10 21:13:52.796994: Pseudo dice [np.float32(0.7959)] 
2025-07-10 21:13:52.797103: Epoch time: 46.21 s 
2025-07-10 21:13:53.972728:  
2025-07-10 21:13:53.973079: Epoch 827 
2025-07-10 21:13:53.973285: Current learning rate: 0.00206 
2025-07-10 21:14:40.667606: train_loss -0.4935 
2025-07-10 21:14:40.668316: val_loss -0.4827 
2025-07-10 21:14:40.668422: Pseudo dice [np.float32(0.7784)] 
2025-07-10 21:14:40.668566: Epoch time: 46.7 s 
2025-07-10 21:14:41.950767:  
2025-07-10 21:14:41.951020: Epoch 828 
2025-07-10 21:14:41.951149: Current learning rate: 0.00205 
2025-07-10 21:15:28.396842: train_loss -0.4907 
2025-07-10 21:15:28.397215: val_loss -0.4833 
2025-07-10 21:15:28.397293: Pseudo dice [np.float32(0.802)] 
2025-07-10 21:15:28.397398: Epoch time: 46.45 s 
2025-07-10 21:15:29.604844:  
2025-07-10 21:15:29.605069: Epoch 829 
2025-07-10 21:15:29.605189: Current learning rate: 0.00204 
2025-07-10 21:16:16.739483: train_loss -0.4941 
2025-07-10 21:16:16.740173: val_loss -0.4952 
2025-07-10 21:16:16.740277: Pseudo dice [np.float32(0.803)] 
2025-07-10 21:16:16.740402: Epoch time: 47.14 s 
2025-07-10 21:16:18.024308:  
2025-07-10 21:16:18.024737: Epoch 830 
2025-07-10 21:16:18.024974: Current learning rate: 0.00203 
2025-07-10 21:17:04.205008: train_loss -0.4784 
2025-07-10 21:17:04.205579: val_loss -0.4701 
2025-07-10 21:17:04.205669: Pseudo dice [np.float32(0.7764)] 
2025-07-10 21:17:04.205784: Epoch time: 46.18 s 
2025-07-10 21:17:05.978271:  
2025-07-10 21:17:05.978857: Epoch 831 
2025-07-10 21:17:05.979074: Current learning rate: 0.00202 
2025-07-10 21:17:52.999670: train_loss -0.4871 
2025-07-10 21:17:53.000173: val_loss -0.4858 
2025-07-10 21:17:53.000254: Pseudo dice [np.float32(0.7976)] 
2025-07-10 21:17:53.000366: Epoch time: 47.02 s 
2025-07-10 21:17:54.191867:  
2025-07-10 21:17:54.192396: Epoch 832 
2025-07-10 21:17:54.192580: Current learning rate: 0.00201 
2025-07-10 21:18:41.338607: train_loss -0.477 
2025-07-10 21:18:41.339332: val_loss -0.4645 
2025-07-10 21:18:41.339433: Pseudo dice [np.float32(0.7676)] 
2025-07-10 21:18:41.339583: Epoch time: 47.15 s 
2025-07-10 21:18:42.500772:  
2025-07-10 21:18:42.501020: Epoch 833 
2025-07-10 21:18:42.501142: Current learning rate: 0.002 
2025-07-10 21:19:30.136795: train_loss -0.4772 
2025-07-10 21:19:30.137311: val_loss -0.4813 
2025-07-10 21:19:30.137392: Pseudo dice [np.float32(0.7616)] 
2025-07-10 21:19:30.137508: Epoch time: 47.64 s 
2025-07-10 21:19:31.353420:  
2025-07-10 21:19:31.354044: Epoch 834 
2025-07-10 21:19:31.354402: Current learning rate: 0.00199 
2025-07-10 21:20:17.633090: train_loss -0.4793 
2025-07-10 21:20:17.634184: val_loss -0.4741 
2025-07-10 21:20:17.634323: Pseudo dice [np.float32(0.7986)] 
2025-07-10 21:20:17.634478: Epoch time: 46.28 s 
2025-07-10 21:20:18.954752:  
2025-07-10 21:20:18.955108: Epoch 835 
2025-07-10 21:20:18.955306: Current learning rate: 0.00198 
2025-07-10 21:21:06.077618: train_loss -0.4795 
2025-07-10 21:21:06.078881: val_loss -0.4914 
2025-07-10 21:21:06.079312: Pseudo dice [np.float32(0.7861)] 
2025-07-10 21:21:06.079497: Epoch time: 47.12 s 
2025-07-10 21:21:07.392333:  
2025-07-10 21:21:07.392927: Epoch 836 
2025-07-10 21:21:07.393057: Current learning rate: 0.00196 
2025-07-10 21:21:54.205091: train_loss -0.4823 
2025-07-10 21:21:54.205590: val_loss -0.4855 
2025-07-10 21:21:54.205671: Pseudo dice [np.float32(0.8144)] 
2025-07-10 21:21:54.205783: Epoch time: 46.81 s 
2025-07-10 21:21:55.411231:  
2025-07-10 21:21:55.411701: Epoch 837 
2025-07-10 21:21:55.411884: Current learning rate: 0.00195 
2025-07-10 21:22:41.206913: train_loss -0.4871 
2025-07-10 21:22:41.207604: val_loss -0.4896 
2025-07-10 21:22:41.207728: Pseudo dice [np.float32(0.837)] 
2025-07-10 21:22:41.207868: Epoch time: 45.8 s 
2025-07-10 21:22:42.518939:  
2025-07-10 21:22:42.519449: Epoch 838 
2025-07-10 21:22:42.519607: Current learning rate: 0.00194 
2025-07-10 21:23:29.110052: train_loss -0.4863 
2025-07-10 21:23:29.111105: val_loss -0.4693 
2025-07-10 21:23:29.111223: Pseudo dice [np.float32(0.7989)] 
2025-07-10 21:23:29.111413: Epoch time: 46.59 s 
2025-07-10 21:23:30.271611:  
2025-07-10 21:23:30.272009: Epoch 839 
2025-07-10 21:23:30.272133: Current learning rate: 0.00193 
2025-07-10 21:24:16.175102: train_loss -0.4891 
2025-07-10 21:24:16.175627: val_loss -0.483 
2025-07-10 21:24:16.175719: Pseudo dice [np.float32(0.7976)] 
2025-07-10 21:24:16.175840: Epoch time: 45.9 s 
2025-07-10 21:24:17.367103:  
2025-07-10 21:24:17.367371: Epoch 840 
2025-07-10 21:24:17.367498: Current learning rate: 0.00192 
2025-07-10 21:25:04.645681: train_loss -0.485 
2025-07-10 21:25:04.646322: val_loss -0.4744 
2025-07-10 21:25:04.646423: Pseudo dice [np.float32(0.7835)] 
2025-07-10 21:25:04.646562: Epoch time: 47.28 s 
2025-07-10 21:25:05.893018:  
2025-07-10 21:25:05.893694: Epoch 841 
2025-07-10 21:25:05.893887: Current learning rate: 0.00191 
2025-07-10 21:25:52.392447: train_loss -0.4872 
2025-07-10 21:25:52.392896: val_loss -0.4669 
2025-07-10 21:25:52.392977: Pseudo dice [np.float32(0.7746)] 
2025-07-10 21:25:52.393083: Epoch time: 46.5 s 
2025-07-10 21:25:53.549884:  
2025-07-10 21:25:53.550637: Epoch 842 
2025-07-10 21:25:53.550765: Current learning rate: 0.0019 
2025-07-10 21:26:40.211844: train_loss -0.4831 
2025-07-10 21:26:40.212497: val_loss -0.4871 
2025-07-10 21:26:40.212603: Pseudo dice [np.float32(0.8014)] 
2025-07-10 21:26:40.212730: Epoch time: 46.66 s 
2025-07-10 21:26:42.027432:  
2025-07-10 21:26:42.027930: Epoch 843 
2025-07-10 21:26:42.028192: Current learning rate: 0.00189 
2025-07-10 21:27:28.681820: train_loss -0.4845 
2025-07-10 21:27:28.682265: val_loss -0.4955 
2025-07-10 21:27:28.682343: Pseudo dice [np.float32(0.8229)] 
2025-07-10 21:27:28.682447: Epoch time: 46.66 s 
2025-07-10 21:27:29.797632:  
2025-07-10 21:27:29.797996: Epoch 844 
2025-07-10 21:27:29.798121: Current learning rate: 0.00188 
2025-07-10 21:28:16.839038: train_loss -0.4917 
2025-07-10 21:28:16.839360: val_loss -0.4773 
2025-07-10 21:28:16.839429: Pseudo dice [np.float32(0.8102)] 
2025-07-10 21:28:16.839524: Epoch time: 47.04 s 
2025-07-10 21:28:17.966481:  
2025-07-10 21:28:17.966856: Epoch 845 
2025-07-10 21:28:17.966982: Current learning rate: 0.00187 
2025-07-10 21:29:04.361686: train_loss -0.4955 
2025-07-10 21:29:04.362387: val_loss -0.4677 
2025-07-10 21:29:04.362554: Pseudo dice [np.float32(0.7966)] 
2025-07-10 21:29:04.362703: Epoch time: 46.4 s 
2025-07-10 21:29:05.547566:  
2025-07-10 21:29:05.547903: Epoch 846 
2025-07-10 21:29:05.548107: Current learning rate: 0.00186 
2025-07-10 21:29:51.783689: train_loss -0.4977 
2025-07-10 21:29:51.784266: val_loss -0.4924 
2025-07-10 21:29:51.784357: Pseudo dice [np.float32(0.8002)] 
2025-07-10 21:29:51.784557: Epoch time: 46.24 s 
2025-07-10 21:29:52.935503:  
2025-07-10 21:29:52.936061: Epoch 847 
2025-07-10 21:29:52.936226: Current learning rate: 0.00185 
2025-07-10 21:30:40.344398: train_loss -0.4904 
2025-07-10 21:30:40.344739: val_loss -0.4924 
2025-07-10 21:30:40.344899: Pseudo dice [np.float32(0.8166)] 
2025-07-10 21:30:40.345042: Epoch time: 47.41 s 
2025-07-10 21:30:41.494988:  
2025-07-10 21:30:41.495338: Epoch 848 
2025-07-10 21:30:41.495474: Current learning rate: 0.00184 
2025-07-10 21:31:28.857450: train_loss -0.4842 
2025-07-10 21:31:28.857875: val_loss -0.496 
2025-07-10 21:31:28.857951: Pseudo dice [np.float32(0.8313)] 
2025-07-10 21:31:28.858047: Epoch time: 47.36 s 
2025-07-10 21:31:30.019809:  
2025-07-10 21:31:30.019996: Epoch 849 
2025-07-10 21:31:30.020123: Current learning rate: 0.00182 
2025-07-10 21:32:17.606578: train_loss -0.493 
2025-07-10 21:32:17.606983: val_loss -0.4945 
2025-07-10 21:32:17.607228: Pseudo dice [np.float32(0.7872)] 
2025-07-10 21:32:17.607343: Epoch time: 47.59 s 
2025-07-10 21:32:19.367481:  
2025-07-10 21:32:19.368059: Epoch 850 
2025-07-10 21:32:19.368197: Current learning rate: 0.00181 
2025-07-10 21:33:05.618281: train_loss -0.4856 
2025-07-10 21:33:05.619148: val_loss -0.5097 
2025-07-10 21:33:05.619232: Pseudo dice [np.float32(0.8217)] 
2025-07-10 21:33:05.619440: Epoch time: 46.25 s 
2025-07-10 21:33:06.764915:  
2025-07-10 21:33:06.765131: Epoch 851 
2025-07-10 21:33:06.765316: Current learning rate: 0.0018 
2025-07-10 21:33:53.227111: train_loss -0.4867 
2025-07-10 21:33:53.227667: val_loss -0.4837 
2025-07-10 21:33:53.227755: Pseudo dice [np.float32(0.8293)] 
2025-07-10 21:33:53.227862: Epoch time: 46.46 s 
2025-07-10 21:33:54.386196:  
2025-07-10 21:33:54.386505: Epoch 852 
2025-07-10 21:33:54.386796: Current learning rate: 0.00179 
2025-07-10 21:34:41.110503: train_loss -0.4849 
2025-07-10 21:34:41.110906: val_loss -0.4892 
2025-07-10 21:34:41.110994: Pseudo dice [np.float32(0.7846)] 
2025-07-10 21:34:41.111100: Epoch time: 46.73 s 
2025-07-10 21:34:42.332067:  
2025-07-10 21:34:42.332624: Epoch 853 
2025-07-10 21:34:42.332808: Current learning rate: 0.00178 
2025-07-10 21:35:29.219012: train_loss -0.4847 
2025-07-10 21:35:29.219462: val_loss -0.501 
2025-07-10 21:35:29.219537: Pseudo dice [np.float32(0.7921)] 
2025-07-10 21:35:29.219650: Epoch time: 46.89 s 
2025-07-10 21:35:30.915863:  
2025-07-10 21:35:30.916448: Epoch 854 
2025-07-10 21:35:30.916646: Current learning rate: 0.00177 
2025-07-10 21:36:16.512132: train_loss -0.4852 
2025-07-10 21:36:16.513346: val_loss -0.4767 
2025-07-10 21:36:16.513483: Pseudo dice [np.float32(0.7853)] 
2025-07-10 21:36:16.513672: Epoch time: 45.6 s 
2025-07-10 21:36:17.728475:  
2025-07-10 21:36:17.728693: Epoch 855 
2025-07-10 21:36:17.728794: Current learning rate: 0.00176 
2025-07-10 21:37:03.709929: train_loss -0.4778 
2025-07-10 21:37:03.710307: val_loss -0.47 
2025-07-10 21:37:03.710399: Pseudo dice [np.float32(0.774)] 
2025-07-10 21:37:03.710495: Epoch time: 45.98 s 
2025-07-10 21:37:04.824068:  
2025-07-10 21:37:04.824321: Epoch 856 
2025-07-10 21:37:04.824642: Current learning rate: 0.00175 
2025-07-10 21:37:50.199732: train_loss -0.4819 
2025-07-10 21:37:50.200147: val_loss -0.4823 
2025-07-10 21:37:50.200223: Pseudo dice [np.float32(0.7935)] 
2025-07-10 21:37:50.200336: Epoch time: 45.38 s 
2025-07-10 21:37:51.365080:  
2025-07-10 21:37:51.365618: Epoch 857 
2025-07-10 21:37:51.365846: Current learning rate: 0.00174 
2025-07-10 21:38:37.972889: train_loss -0.481 
2025-07-10 21:38:37.973487: val_loss -0.4686 
2025-07-10 21:38:37.973600: Pseudo dice [np.float32(0.7732)] 
2025-07-10 21:38:37.973724: Epoch time: 46.61 s 
2025-07-10 21:38:39.104616:  
2025-07-10 21:38:39.104779: Epoch 858 
2025-07-10 21:38:39.104993: Current learning rate: 0.00173 
2025-07-10 21:39:25.646817: train_loss -0.4909 
2025-07-10 21:39:25.648072: val_loss -0.4987 
2025-07-10 21:39:25.648207: Pseudo dice [np.float32(0.8219)] 
2025-07-10 21:39:25.648381: Epoch time: 46.54 s 
2025-07-10 21:39:26.927042:  
2025-07-10 21:39:26.927360: Epoch 859 
2025-07-10 21:39:26.927489: Current learning rate: 0.00172 
2025-07-10 21:40:13.482941: train_loss -0.4952 
2025-07-10 21:40:13.483878: val_loss -0.4872 
2025-07-10 21:40:13.483966: Pseudo dice [np.float32(0.8182)] 
2025-07-10 21:40:13.484091: Epoch time: 46.56 s 
2025-07-10 21:40:14.790970:  
2025-07-10 21:40:14.791379: Epoch 860 
2025-07-10 21:40:14.791508: Current learning rate: 0.0017 
2025-07-10 21:41:01.925963: train_loss -0.4737 
2025-07-10 21:41:01.926348: val_loss -0.4826 
2025-07-10 21:41:01.926443: Pseudo dice [np.float32(0.8152)] 
2025-07-10 21:41:01.926562: Epoch time: 47.14 s 
2025-07-10 21:41:03.115593:  
2025-07-10 21:41:03.115890: Epoch 861 
2025-07-10 21:41:03.116022: Current learning rate: 0.00169 
2025-07-10 21:41:51.212303: train_loss -0.4878 
2025-07-10 21:41:51.213385: val_loss -0.4871 
2025-07-10 21:41:51.213508: Pseudo dice [np.float32(0.8176)] 
2025-07-10 21:41:51.213660: Epoch time: 48.1 s 
2025-07-10 21:41:52.351996:  
2025-07-10 21:41:52.352552: Epoch 862 
2025-07-10 21:41:52.352722: Current learning rate: 0.00168 
2025-07-10 21:42:39.780704: train_loss -0.5006 
2025-07-10 21:42:39.781165: val_loss -0.4751 
2025-07-10 21:42:39.781248: Pseudo dice [np.float32(0.8065)] 
2025-07-10 21:42:39.781348: Epoch time: 47.43 s 
2025-07-10 21:42:40.953491:  
2025-07-10 21:42:40.953893: Epoch 863 
2025-07-10 21:42:40.954071: Current learning rate: 0.00167 
2025-07-10 21:43:27.663621: train_loss -0.4915 
2025-07-10 21:43:27.664005: val_loss -0.4891 
2025-07-10 21:43:27.667975: Pseudo dice [np.float32(0.7449)] 
2025-07-10 21:43:27.668203: Epoch time: 46.71 s 
2025-07-10 21:43:28.820680:  
2025-07-10 21:43:28.820920: Epoch 864 
2025-07-10 21:43:28.821050: Current learning rate: 0.00166 
2025-07-10 21:44:16.518158: train_loss -0.4846 
2025-07-10 21:44:16.518589: val_loss -0.4925 
2025-07-10 21:44:16.518676: Pseudo dice [np.float32(0.8122)] 
2025-07-10 21:44:16.518773: Epoch time: 47.7 s 
2025-07-10 21:44:17.636528:  
2025-07-10 21:44:17.637069: Epoch 865 
2025-07-10 21:44:17.637187: Current learning rate: 0.00165 
2025-07-10 21:45:04.430211: train_loss -0.4906 
2025-07-10 21:45:04.430636: val_loss -0.4829 
2025-07-10 21:45:04.430721: Pseudo dice [np.float32(0.7682)] 
2025-07-10 21:45:04.430825: Epoch time: 46.79 s 
2025-07-10 21:45:06.215657:  
2025-07-10 21:45:06.215976: Epoch 866 
2025-07-10 21:45:06.216171: Current learning rate: 0.00164 
2025-07-10 21:45:53.851561: train_loss -0.48 
2025-07-10 21:45:53.852034: val_loss -0.4894 
2025-07-10 21:45:53.852119: Pseudo dice [np.float32(0.8132)] 
2025-07-10 21:45:53.852234: Epoch time: 47.64 s 
2025-07-10 21:45:54.997853:  
2025-07-10 21:45:54.998114: Epoch 867 
2025-07-10 21:45:54.998256: Current learning rate: 0.00163 
2025-07-10 21:46:41.113127: train_loss -0.4909 
2025-07-10 21:46:41.114024: val_loss -0.4829 
2025-07-10 21:46:41.114110: Pseudo dice [np.float32(0.7947)] 
2025-07-10 21:46:41.114263: Epoch time: 46.12 s 
2025-07-10 21:46:42.423998:  
2025-07-10 21:46:42.424238: Epoch 868 
2025-07-10 21:46:42.424428: Current learning rate: 0.00162 
2025-07-10 21:47:29.211097: train_loss -0.4928 
2025-07-10 21:47:29.211650: val_loss -0.4792 
2025-07-10 21:47:29.211731: Pseudo dice [np.float32(0.8047)] 
2025-07-10 21:47:29.211833: Epoch time: 46.79 s 
2025-07-10 21:47:30.369087:  
2025-07-10 21:47:30.369528: Epoch 869 
2025-07-10 21:47:30.369802: Current learning rate: 0.00161 
2025-07-10 21:48:15.624016: train_loss -0.4951 
2025-07-10 21:48:15.624969: val_loss -0.5042 
2025-07-10 21:48:15.625068: Pseudo dice [np.float32(0.806)] 
2025-07-10 21:48:15.625179: Epoch time: 45.26 s 
2025-07-10 21:48:16.803616:  
2025-07-10 21:48:16.803907: Epoch 870 
2025-07-10 21:48:16.804036: Current learning rate: 0.00159 
2025-07-10 21:49:02.803235: train_loss -0.4898 
2025-07-10 21:49:02.803645: val_loss -0.4687 
2025-07-10 21:49:02.803718: Pseudo dice [np.float32(0.7566)] 
2025-07-10 21:49:02.803819: Epoch time: 46.0 s 
2025-07-10 21:49:03.995635:  
2025-07-10 21:49:03.996109: Epoch 871 
2025-07-10 21:49:03.996239: Current learning rate: 0.00158 
2025-07-10 21:49:50.874390: train_loss -0.4755 
2025-07-10 21:49:50.875458: val_loss -0.4984 
2025-07-10 21:49:50.875595: Pseudo dice [np.float32(0.813)] 
2025-07-10 21:49:50.875732: Epoch time: 46.88 s 
2025-07-10 21:49:52.065215:  
2025-07-10 21:49:52.065629: Epoch 872 
2025-07-10 21:49:52.065797: Current learning rate: 0.00157 
2025-07-10 21:50:38.475025: train_loss -0.4887 
2025-07-10 21:50:38.476383: val_loss -0.4729 
2025-07-10 21:50:38.476480: Pseudo dice [np.float32(0.7785)] 
2025-07-10 21:50:38.476717: Epoch time: 46.41 s 
2025-07-10 21:50:39.692250:  
2025-07-10 21:50:39.692520: Epoch 873 
2025-07-10 21:50:39.692693: Current learning rate: 0.00156 
2025-07-10 21:51:25.280710: train_loss -0.5004 
2025-07-10 21:51:25.281480: val_loss -0.4852 
2025-07-10 21:51:25.281610: Pseudo dice [np.float32(0.802)] 
2025-07-10 21:51:25.281740: Epoch time: 45.59 s 
2025-07-10 21:51:26.450728:  
2025-07-10 21:51:26.451221: Epoch 874 
2025-07-10 21:51:26.451350: Current learning rate: 0.00155 
2025-07-10 21:52:12.424300: train_loss -0.4886 
2025-07-10 21:52:12.425085: val_loss -0.4701 
2025-07-10 21:52:12.425262: Pseudo dice [np.float32(0.7183)] 
2025-07-10 21:52:12.425419: Epoch time: 45.98 s 
2025-07-10 21:52:13.613496:  
2025-07-10 21:52:13.613757: Epoch 875 
2025-07-10 21:52:13.613909: Current learning rate: 0.00154 
2025-07-10 21:52:59.990015: train_loss -0.4826 
2025-07-10 21:52:59.990402: val_loss -0.4856 
2025-07-10 21:52:59.990481: Pseudo dice [np.float32(0.7716)] 
2025-07-10 21:52:59.990598: Epoch time: 46.38 s 
2025-07-10 21:53:01.152328:  
2025-07-10 21:53:01.152732: Epoch 876 
2025-07-10 21:53:01.152878: Current learning rate: 0.00153 
2025-07-10 21:53:47.685437: train_loss -0.4896 
2025-07-10 21:53:47.685790: val_loss -0.4898 
2025-07-10 21:53:47.685862: Pseudo dice [np.float32(0.7865)] 
2025-07-10 21:53:47.685965: Epoch time: 46.53 s 
2025-07-10 21:53:48.863421:  
2025-07-10 21:53:48.863641: Epoch 877 
2025-07-10 21:53:48.863741: Current learning rate: 0.00152 
2025-07-10 21:54:34.676535: train_loss -0.4966 
2025-07-10 21:54:34.677238: val_loss -0.5004 
2025-07-10 21:54:34.677346: Pseudo dice [np.float32(0.8015)] 
2025-07-10 21:54:34.677482: Epoch time: 45.81 s 
2025-07-10 21:54:36.462115:  
2025-07-10 21:54:36.462557: Epoch 878 
2025-07-10 21:54:36.462851: Current learning rate: 0.00151 
2025-07-10 21:55:22.464641: train_loss -0.4975 
2025-07-10 21:55:22.465285: val_loss -0.4787 
2025-07-10 21:55:22.465413: Pseudo dice [np.float32(0.8165)] 
2025-07-10 21:55:22.465524: Epoch time: 46.0 s 
2025-07-10 21:55:23.679388:  
2025-07-10 21:55:23.679971: Epoch 879 
2025-07-10 21:55:23.680097: Current learning rate: 0.00149 
2025-07-10 21:56:10.631225: train_loss -0.4799 
2025-07-10 21:56:10.631805: val_loss -0.467 
2025-07-10 21:56:10.631900: Pseudo dice [np.float32(0.7919)] 
2025-07-10 21:56:10.632011: Epoch time: 46.95 s 
2025-07-10 21:56:11.776971:  
2025-07-10 21:56:11.777341: Epoch 880 
2025-07-10 21:56:11.777518: Current learning rate: 0.00148 
2025-07-10 21:56:57.768386: train_loss -0.4857 
2025-07-10 21:56:57.768878: val_loss -0.4626 
2025-07-10 21:56:57.768955: Pseudo dice [np.float32(0.7799)] 
2025-07-10 21:56:57.769070: Epoch time: 45.99 s 
2025-07-10 21:56:58.906383:  
2025-07-10 21:56:58.906976: Epoch 881 
2025-07-10 21:56:58.907145: Current learning rate: 0.00147 
2025-07-10 21:57:45.803426: train_loss -0.4946 
2025-07-10 21:57:45.804148: val_loss -0.4901 
2025-07-10 21:57:45.804260: Pseudo dice [np.float32(0.8084)] 
2025-07-10 21:57:45.804394: Epoch time: 46.9 s 
2025-07-10 21:57:46.987471:  
2025-07-10 21:57:46.987659: Epoch 882 
2025-07-10 21:57:46.987843: Current learning rate: 0.00146 
2025-07-10 21:58:33.238754: train_loss -0.4837 
2025-07-10 21:58:33.239372: val_loss -0.4771 
2025-07-10 21:58:33.240824: Pseudo dice [np.float32(0.7851)] 
2025-07-10 21:58:33.240985: Epoch time: 46.25 s 
2025-07-10 21:58:34.481095:  
2025-07-10 21:58:34.481551: Epoch 883 
2025-07-10 21:58:34.481732: Current learning rate: 0.00145 
2025-07-10 21:59:21.229842: train_loss -0.4924 
2025-07-10 21:59:21.230406: val_loss -0.4854 
2025-07-10 21:59:21.230512: Pseudo dice [np.float32(0.7929)] 
2025-07-10 21:59:21.230649: Epoch time: 46.75 s 
2025-07-10 21:59:22.380511:  
2025-07-10 21:59:22.380950: Epoch 884 
2025-07-10 21:59:22.381080: Current learning rate: 0.00144 
2025-07-10 22:00:08.729554: train_loss -0.4842 
2025-07-10 22:00:08.730136: val_loss -0.4871 
2025-07-10 22:00:08.730368: Pseudo dice [np.float32(0.8116)] 
2025-07-10 22:00:08.730600: Epoch time: 46.35 s 
2025-07-10 22:00:09.907321:  
2025-07-10 22:00:09.907857: Epoch 885 
2025-07-10 22:00:09.907989: Current learning rate: 0.00143 
2025-07-10 22:00:56.902708: train_loss -0.4823 
2025-07-10 22:00:56.903302: val_loss -0.4697 
2025-07-10 22:00:56.903410: Pseudo dice [np.float32(0.7688)] 
2025-07-10 22:00:56.903547: Epoch time: 47.0 s 
2025-07-10 22:00:58.084023:  
2025-07-10 22:00:58.084620: Epoch 886 
2025-07-10 22:00:58.084796: Current learning rate: 0.00142 
2025-07-10 22:01:44.588679: train_loss -0.461 
2025-07-10 22:01:44.589473: val_loss -0.4947 
2025-07-10 22:01:44.589565: Pseudo dice [np.float32(0.7786)] 
2025-07-10 22:01:44.589677: Epoch time: 46.51 s 
2025-07-10 22:01:45.748004:  
2025-07-10 22:01:45.748266: Epoch 887 
2025-07-10 22:01:45.748385: Current learning rate: 0.00141 
2025-07-10 22:02:32.506136: train_loss -0.4817 
2025-07-10 22:02:32.507095: val_loss -0.5023 
2025-07-10 22:02:32.507174: Pseudo dice [np.float32(0.8058)] 
2025-07-10 22:02:32.507311: Epoch time: 46.76 s 
2025-07-10 22:02:33.641313:  
2025-07-10 22:02:33.641613: Epoch 888 
2025-07-10 22:02:33.641810: Current learning rate: 0.00139 
2025-07-10 22:03:20.680043: train_loss -0.4847 
2025-07-10 22:03:20.680361: val_loss -0.4986 
2025-07-10 22:03:20.683684: Pseudo dice [np.float32(0.8139)] 
2025-07-10 22:03:20.683791: Epoch time: 47.04 s 
2025-07-10 22:03:21.821015:  
2025-07-10 22:03:21.821637: Epoch 889 
2025-07-10 22:03:21.821839: Current learning rate: 0.00138 
2025-07-10 22:04:08.711235: train_loss -0.4877 
2025-07-10 22:04:08.711602: val_loss -0.4798 
2025-07-10 22:04:08.711729: Pseudo dice [np.float32(0.79)] 
2025-07-10 22:04:08.711821: Epoch time: 46.89 s 
2025-07-10 22:04:09.870291:  
2025-07-10 22:04:09.870508: Epoch 890 
2025-07-10 22:04:09.870643: Current learning rate: 0.00137 
2025-07-10 22:04:57.350657: train_loss -0.4902 
2025-07-10 22:04:57.350988: val_loss -0.4637 
2025-07-10 22:04:57.351063: Pseudo dice [np.float32(0.7422)] 
2025-07-10 22:04:57.351170: Epoch time: 47.48 s 
2025-07-10 22:04:59.123235:  
2025-07-10 22:04:59.123430: Epoch 891 
2025-07-10 22:04:59.123669: Current learning rate: 0.00136 
2025-07-10 22:05:45.882910: train_loss -0.4698 
2025-07-10 22:05:45.883392: val_loss -0.4767 
2025-07-10 22:05:45.883472: Pseudo dice [np.float32(0.7848)] 
2025-07-10 22:05:45.883594: Epoch time: 46.76 s 
2025-07-10 22:05:47.010428:  
2025-07-10 22:05:47.010693: Epoch 892 
2025-07-10 22:05:47.010816: Current learning rate: 0.00135 
2025-07-10 22:06:34.142241: train_loss -0.4853 
2025-07-10 22:06:34.142598: val_loss -0.4827 
2025-07-10 22:06:34.142729: Pseudo dice [np.float32(0.7946)] 
2025-07-10 22:06:34.142890: Epoch time: 47.13 s 
2025-07-10 22:06:35.309134:  
2025-07-10 22:06:35.309457: Epoch 893 
2025-07-10 22:06:35.309647: Current learning rate: 0.00134 
2025-07-10 22:07:23.092507: train_loss -0.4795 
2025-07-10 22:07:23.093161: val_loss -0.4832 
2025-07-10 22:07:23.094624: Pseudo dice [np.float32(0.8106)] 
2025-07-10 22:07:23.094770: Epoch time: 47.78 s 
2025-07-10 22:07:24.311316:  
2025-07-10 22:07:24.311665: Epoch 894 
2025-07-10 22:07:24.311839: Current learning rate: 0.00133 
2025-07-10 22:08:12.919071: train_loss -0.4638 
2025-07-10 22:08:12.919422: val_loss -0.487 
2025-07-10 22:08:12.919502: Pseudo dice [np.float32(0.8096)] 
2025-07-10 22:08:12.919624: Epoch time: 48.61 s 
2025-07-10 22:08:14.092362:  
2025-07-10 22:08:14.092900: Epoch 895 
2025-07-10 22:08:14.093238: Current learning rate: 0.00132 
2025-07-10 22:09:02.388224: train_loss -0.4882 
2025-07-10 22:09:02.388632: val_loss -0.4783 
2025-07-10 22:09:02.388747: Pseudo dice [np.float32(0.7859)] 
2025-07-10 22:09:02.388856: Epoch time: 48.3 s 
2025-07-10 22:09:03.514324:  
2025-07-10 22:09:03.514837: Epoch 896 
2025-07-10 22:09:03.515059: Current learning rate: 0.0013 
2025-07-10 22:09:50.529387: train_loss -0.4942 
2025-07-10 22:09:50.529769: val_loss -0.5068 
2025-07-10 22:09:50.529846: Pseudo dice [np.float32(0.8393)] 
2025-07-10 22:09:50.529953: Epoch time: 47.02 s 
2025-07-10 22:09:51.682033:  
2025-07-10 22:09:51.682612: Epoch 897 
2025-07-10 22:09:51.683885: Current learning rate: 0.00129 
2025-07-10 22:10:39.359152: train_loss -0.4982 
2025-07-10 22:10:39.359521: val_loss -0.4898 
2025-07-10 22:10:39.363251: Pseudo dice [np.float32(0.8192)] 
2025-07-10 22:10:39.363389: Epoch time: 47.68 s 
2025-07-10 22:10:40.517612:  
2025-07-10 22:10:40.517789: Epoch 898 
2025-07-10 22:10:40.517921: Current learning rate: 0.00128 
2025-07-10 22:11:27.808918: train_loss -0.4945 
2025-07-10 22:11:27.809354: val_loss -0.4981 
2025-07-10 22:11:27.810876: Pseudo dice [np.float32(0.8117)] 
2025-07-10 22:11:27.811005: Epoch time: 47.29 s 
2025-07-10 22:11:28.986448:  
2025-07-10 22:11:28.986871: Epoch 899 
2025-07-10 22:11:28.986995: Current learning rate: 0.00127 
2025-07-10 22:12:17.405035: train_loss -0.4877 
2025-07-10 22:12:17.405513: val_loss -0.4819 
2025-07-10 22:12:17.405666: Pseudo dice [np.float32(0.785)] 
2025-07-10 22:12:17.405788: Epoch time: 48.42 s 
2025-07-10 22:12:19.049605:  
2025-07-10 22:12:19.049966: Epoch 900 
2025-07-10 22:12:19.050092: Current learning rate: 0.00126 
2025-07-10 22:13:07.174990: train_loss -0.4976 
2025-07-10 22:13:07.175582: val_loss -0.5085 
2025-07-10 22:13:07.175671: Pseudo dice [np.float32(0.8059)] 
2025-07-10 22:13:07.175802: Epoch time: 48.13 s 
2025-07-10 22:13:08.398957:  
2025-07-10 22:13:08.399402: Epoch 901 
2025-07-10 22:13:08.399534: Current learning rate: 0.00125 
2025-07-10 22:13:55.633311: train_loss -0.4866 
2025-07-10 22:13:55.634375: val_loss -0.4921 
2025-07-10 22:13:55.634462: Pseudo dice [np.float32(0.7894)] 
2025-07-10 22:13:55.634611: Epoch time: 47.24 s 
2025-07-10 22:13:57.514232:  
2025-07-10 22:13:57.514559: Epoch 902 
2025-07-10 22:13:57.514822: Current learning rate: 0.00124 
2025-07-10 22:14:44.906317: train_loss -0.4925 
2025-07-10 22:14:44.906980: val_loss -0.4962 
2025-07-10 22:14:44.907092: Pseudo dice [np.float32(0.8111)] 
2025-07-10 22:14:44.907258: Epoch time: 47.39 s 
2025-07-10 22:14:46.137733:  
2025-07-10 22:14:46.138011: Epoch 903 
2025-07-10 22:14:46.138176: Current learning rate: 0.00122 
2025-07-10 22:15:33.309402: train_loss -0.4961 
2025-07-10 22:15:33.309902: val_loss -0.5079 
2025-07-10 22:15:33.309986: Pseudo dice [np.float32(0.831)] 
2025-07-10 22:15:33.310089: Epoch time: 47.17 s 
2025-07-10 22:15:34.470671:  
2025-07-10 22:15:34.471052: Epoch 904 
2025-07-10 22:15:34.471183: Current learning rate: 0.00121 
2025-07-10 22:16:21.546036: train_loss -0.5044 
2025-07-10 22:16:21.546591: val_loss -0.4997 
2025-07-10 22:16:21.546679: Pseudo dice [np.float32(0.7853)] 
2025-07-10 22:16:21.546781: Epoch time: 47.08 s 
2025-07-10 22:16:22.748991:  
2025-07-10 22:16:22.749700: Epoch 905 
2025-07-10 22:16:22.749912: Current learning rate: 0.0012 
2025-07-10 22:17:09.221035: train_loss -0.4997 
2025-07-10 22:17:09.221899: val_loss -0.4897 
2025-07-10 22:17:09.222058: Pseudo dice [np.float32(0.8059)] 
2025-07-10 22:17:09.222199: Epoch time: 46.47 s 
2025-07-10 22:17:10.421710:  
2025-07-10 22:17:10.422023: Epoch 906 
2025-07-10 22:17:10.422127: Current learning rate: 0.00119 
2025-07-10 22:17:56.550316: train_loss -0.49 
2025-07-10 22:17:56.550934: val_loss -0.5071 
2025-07-10 22:17:56.551023: Pseudo dice [np.float32(0.8114)] 
2025-07-10 22:17:56.551134: Epoch time: 46.13 s 
2025-07-10 22:17:57.779410:  
2025-07-10 22:17:57.779754: Epoch 907 
2025-07-10 22:17:57.779887: Current learning rate: 0.00118 
2025-07-10 22:18:44.583200: train_loss -0.4919 
2025-07-10 22:18:44.583518: val_loss -0.4859 
2025-07-10 22:18:44.583605: Pseudo dice [np.float32(0.8084)] 
2025-07-10 22:18:44.583696: Epoch time: 46.8 s 
2025-07-10 22:18:45.788682:  
2025-07-10 22:18:45.789167: Epoch 908 
2025-07-10 22:18:45.789317: Current learning rate: 0.00117 
2025-07-10 22:19:32.474804: train_loss -0.4915 
2025-07-10 22:19:32.475720: val_loss -0.4845 
2025-07-10 22:19:32.475828: Pseudo dice [np.float32(0.8068)] 
2025-07-10 22:19:32.475958: Epoch time: 46.69 s 
2025-07-10 22:19:33.719822:  
2025-07-10 22:19:33.720217: Epoch 909 
2025-07-10 22:19:33.720439: Current learning rate: 0.00116 
2025-07-10 22:20:21.052140: train_loss -0.4933 
2025-07-10 22:20:21.052600: val_loss -0.5016 
2025-07-10 22:20:21.052693: Pseudo dice [np.float32(0.8243)] 
2025-07-10 22:20:21.052847: Epoch time: 47.33 s 
2025-07-10 22:20:22.189253:  
2025-07-10 22:20:22.189691: Epoch 910 
2025-07-10 22:20:22.189974: Current learning rate: 0.00115 
2025-07-10 22:21:09.184768: train_loss -0.4999 
2025-07-10 22:21:09.185518: val_loss -0.4968 
2025-07-10 22:21:09.185648: Pseudo dice [np.float32(0.8158)] 
2025-07-10 22:21:09.185788: Epoch time: 47.0 s 
2025-07-10 22:21:10.375844:  
2025-07-10 22:21:10.376175: Epoch 911 
2025-07-10 22:21:10.376439: Current learning rate: 0.00113 
2025-07-10 22:21:58.687226: train_loss -0.5031 
2025-07-10 22:21:58.687679: val_loss -0.5038 
2025-07-10 22:21:58.687754: Pseudo dice [np.float32(0.8002)] 
2025-07-10 22:21:58.687853: Epoch time: 48.31 s 
2025-07-10 22:21:59.796287:  
2025-07-10 22:21:59.796557: Epoch 912 
2025-07-10 22:21:59.796738: Current learning rate: 0.00112 
2025-07-10 22:22:47.582768: train_loss -0.4962 
2025-07-10 22:22:47.583398: val_loss -0.4996 
2025-07-10 22:22:47.583752: Pseudo dice [np.float32(0.8111)] 
2025-07-10 22:22:47.583898: Epoch time: 47.79 s 
2025-07-10 22:22:48.761622:  
2025-07-10 22:22:48.762090: Epoch 913 
2025-07-10 22:22:48.762221: Current learning rate: 0.00111 
2025-07-10 22:23:36.645082: train_loss -0.5043 
2025-07-10 22:23:36.645491: val_loss -0.4905 
2025-07-10 22:23:36.645586: Pseudo dice [np.float32(0.8083)] 
2025-07-10 22:23:36.645689: Epoch time: 47.88 s 
2025-07-10 22:23:37.794979:  
2025-07-10 22:23:37.795650: Epoch 914 
2025-07-10 22:23:37.795828: Current learning rate: 0.0011 
2025-07-10 22:24:25.275933: train_loss -0.4907 
2025-07-10 22:24:25.277005: val_loss -0.4831 
2025-07-10 22:24:25.277164: Pseudo dice [np.float32(0.8018)] 
2025-07-10 22:24:25.277329: Epoch time: 47.48 s 
2025-07-10 22:24:27.185998:  
2025-07-10 22:24:27.186431: Epoch 915 
2025-07-10 22:24:27.186618: Current learning rate: 0.00109 
2025-07-10 22:25:13.989154: train_loss -0.4936 
2025-07-10 22:25:13.989966: val_loss -0.507 
2025-07-10 22:25:13.990066: Pseudo dice [np.float32(0.8063)] 
2025-07-10 22:25:13.990206: Epoch time: 46.8 s 
2025-07-10 22:25:15.179436:  
2025-07-10 22:25:15.179759: Epoch 916 
2025-07-10 22:25:15.179886: Current learning rate: 0.00108 
2025-07-10 22:26:02.233277: train_loss -0.5026 
2025-07-10 22:26:02.234209: val_loss -0.5117 
2025-07-10 22:26:02.234296: Pseudo dice [np.float32(0.8232)] 
2025-07-10 22:26:02.234412: Epoch time: 47.05 s 
2025-07-10 22:26:03.363203:  
2025-07-10 22:26:03.363568: Epoch 917 
2025-07-10 22:26:03.363811: Current learning rate: 0.00106 
2025-07-10 22:26:51.298391: train_loss -0.5058 
2025-07-10 22:26:51.298973: val_loss -0.5021 
2025-07-10 22:26:51.299049: Pseudo dice [np.float32(0.798)] 
2025-07-10 22:26:51.299160: Epoch time: 47.94 s 
2025-07-10 22:26:52.475989:  
2025-07-10 22:26:52.476302: Epoch 918 
2025-07-10 22:26:52.476428: Current learning rate: 0.00105 
2025-07-10 22:27:39.540900: train_loss -0.5089 
2025-07-10 22:27:39.541246: val_loss -0.511 
2025-07-10 22:27:39.541326: Pseudo dice [np.float32(0.8173)] 
2025-07-10 22:27:39.541482: Epoch time: 47.07 s 
2025-07-10 22:27:40.720982:  
2025-07-10 22:27:40.721318: Epoch 919 
2025-07-10 22:27:40.721486: Current learning rate: 0.00104 
2025-07-10 22:28:28.707766: train_loss -0.4943 
2025-07-10 22:28:28.708460: val_loss -0.496 
2025-07-10 22:28:28.708557: Pseudo dice [np.float32(0.7912)] 
2025-07-10 22:28:28.708737: Epoch time: 47.99 s 
2025-07-10 22:28:29.834409:  
2025-07-10 22:28:29.834830: Epoch 920 
2025-07-10 22:28:29.835016: Current learning rate: 0.00103 
2025-07-10 22:29:16.914583: train_loss -0.49 
2025-07-10 22:29:16.915203: val_loss -0.5014 
2025-07-10 22:29:16.915309: Pseudo dice [np.float32(0.8191)] 
2025-07-10 22:29:16.915443: Epoch time: 47.08 s 
2025-07-10 22:29:18.081751:  
2025-07-10 22:29:18.082002: Epoch 921 
2025-07-10 22:29:18.082124: Current learning rate: 0.00102 
2025-07-10 22:30:06.707549: train_loss -0.5042 
2025-07-10 22:30:06.707988: val_loss -0.4997 
2025-07-10 22:30:06.708068: Pseudo dice [np.float32(0.8129)] 
2025-07-10 22:30:06.708169: Epoch time: 48.63 s 
2025-07-10 22:30:07.890186:  
2025-07-10 22:30:07.890728: Epoch 922 
2025-07-10 22:30:07.890874: Current learning rate: 0.00101 
2025-07-10 22:30:56.457563: train_loss -0.4991 
2025-07-10 22:30:56.458506: val_loss -0.5085 
2025-07-10 22:30:56.458622: Pseudo dice [np.float32(0.8209)] 
2025-07-10 22:30:56.458780: Epoch time: 48.57 s 
2025-07-10 22:30:57.585803:  
2025-07-10 22:30:57.586259: Epoch 923 
2025-07-10 22:30:57.586383: Current learning rate: 0.001 
2025-07-10 22:31:47.125300: train_loss -0.5097 
2025-07-10 22:31:47.125750: val_loss -0.4974 
2025-07-10 22:31:47.125860: Pseudo dice [np.float32(0.8145)] 
2025-07-10 22:31:47.126127: Epoch time: 49.54 s 
2025-07-10 22:31:48.287158:  
2025-07-10 22:31:48.287509: Epoch 924 
2025-07-10 22:31:48.287652: Current learning rate: 0.00098 
2025-07-10 22:32:37.622783: train_loss -0.5021 
2025-07-10 22:32:37.623252: val_loss -0.4954 
2025-07-10 22:32:37.623332: Pseudo dice [np.float32(0.8067)] 
2025-07-10 22:32:37.623428: Epoch time: 49.34 s 
2025-07-10 22:32:38.754271:  
2025-07-10 22:32:38.754756: Epoch 925 
2025-07-10 22:32:38.755080: Current learning rate: 0.00097 
2025-07-10 22:33:27.770060: train_loss -0.4956 
2025-07-10 22:33:27.770574: val_loss -0.5108 
2025-07-10 22:33:27.770668: Pseudo dice [np.float32(0.8105)] 
2025-07-10 22:33:27.770795: Epoch time: 49.02 s 
2025-07-10 22:33:28.900238:  
2025-07-10 22:33:28.900643: Epoch 926 
2025-07-10 22:33:28.900815: Current learning rate: 0.00096 
2025-07-10 22:34:16.842190: train_loss -0.5077 
2025-07-10 22:34:16.842525: val_loss -0.4907 
2025-07-10 22:34:16.842616: Pseudo dice [np.float32(0.819)] 
2025-07-10 22:34:16.842715: Epoch time: 47.94 s 
2025-07-10 22:34:18.559666:  
2025-07-10 22:34:18.559979: Epoch 927 
2025-07-10 22:34:18.560147: Current learning rate: 0.00095 
2025-07-10 22:35:06.012923: train_loss -0.5018 
2025-07-10 22:35:06.013446: val_loss -0.5111 
2025-07-10 22:35:06.013558: Pseudo dice [np.float32(0.8023)] 
2025-07-10 22:35:06.013743: Epoch time: 47.45 s 
2025-07-10 22:35:07.167885:  
2025-07-10 22:35:07.168379: Epoch 928 
2025-07-10 22:35:07.168523: Current learning rate: 0.00094 
2025-07-10 22:35:55.623080: train_loss -0.5055 
2025-07-10 22:35:55.623464: val_loss -0.5101 
2025-07-10 22:35:55.626975: Pseudo dice [np.float32(0.8031)] 
2025-07-10 22:35:55.627199: Epoch time: 48.46 s 
2025-07-10 22:35:56.729780:  
2025-07-10 22:35:56.730146: Epoch 929 
2025-07-10 22:35:56.730277: Current learning rate: 0.00092 
2025-07-10 22:36:45.975194: train_loss -0.4981 
2025-07-10 22:36:45.975721: val_loss -0.5132 
2025-07-10 22:36:45.975814: Pseudo dice [np.float32(0.8159)] 
2025-07-10 22:36:45.975924: Epoch time: 49.25 s 
2025-07-10 22:36:47.109501:  
2025-07-10 22:36:47.109692: Epoch 930 
2025-07-10 22:36:47.109967: Current learning rate: 0.00091 
2025-07-10 22:37:36.362146: train_loss -0.4997 
2025-07-10 22:37:36.362572: val_loss -0.5026 
2025-07-10 22:37:36.362659: Pseudo dice [np.float32(0.8105)] 
2025-07-10 22:37:36.362757: Epoch time: 49.25 s 
2025-07-10 22:37:37.527224:  
2025-07-10 22:37:37.527565: Epoch 931 
2025-07-10 22:37:37.528036: Current learning rate: 0.0009 
2025-07-10 22:38:24.809645: train_loss -0.4982 
2025-07-10 22:38:24.810225: val_loss -0.5118 
2025-07-10 22:38:24.810322: Pseudo dice [np.float32(0.8279)] 
2025-07-10 22:38:24.810448: Epoch time: 47.28 s 
2025-07-10 22:38:26.036980:  
2025-07-10 22:38:26.037434: Epoch 932 
2025-07-10 22:38:26.037576: Current learning rate: 0.00089 
2025-07-10 22:39:13.754223: train_loss -0.4951 
2025-07-10 22:39:13.754569: val_loss -0.5009 
2025-07-10 22:39:13.754644: Pseudo dice [np.float32(0.7951)] 
2025-07-10 22:39:13.754747: Epoch time: 47.72 s 
2025-07-10 22:39:14.977554:  
2025-07-10 22:39:14.977973: Epoch 933 
2025-07-10 22:39:14.978104: Current learning rate: 0.00088 
2025-07-10 22:40:03.612219: train_loss -0.4979 
2025-07-10 22:40:03.612733: val_loss -0.4996 
2025-07-10 22:40:03.612879: Pseudo dice [np.float32(0.8224)] 
2025-07-10 22:40:03.612999: Epoch time: 48.64 s 
2025-07-10 22:40:04.742791:  
2025-07-10 22:40:04.743040: Epoch 934 
2025-07-10 22:40:04.743163: Current learning rate: 0.00087 
2025-07-10 22:40:51.998221: train_loss -0.5086 
2025-07-10 22:40:51.998879: val_loss -0.5178 
2025-07-10 22:40:51.998964: Pseudo dice [np.float32(0.8268)] 
2025-07-10 22:40:51.999082: Epoch time: 47.26 s 
2025-07-10 22:40:53.162868:  
2025-07-10 22:40:53.163165: Epoch 935 
2025-07-10 22:40:53.163305: Current learning rate: 0.00085 
2025-07-10 22:41:40.278623: train_loss -0.508 
2025-07-10 22:41:40.278974: val_loss -0.5209 
2025-07-10 22:41:40.279048: Pseudo dice [np.float32(0.8235)] 
2025-07-10 22:41:40.279157: Epoch time: 47.12 s 
2025-07-10 22:41:41.437789:  
2025-07-10 22:41:41.438105: Epoch 936 
2025-07-10 22:41:41.438382: Current learning rate: 0.00084 
2025-07-10 22:42:28.526956: train_loss -0.5111 
2025-07-10 22:42:28.527272: val_loss -0.517 
2025-07-10 22:42:28.527344: Pseudo dice [np.float32(0.8215)] 
2025-07-10 22:42:28.527447: Epoch time: 47.09 s 
2025-07-10 22:42:29.664346:  
2025-07-10 22:42:29.664665: Epoch 937 
2025-07-10 22:42:29.664951: Current learning rate: 0.00083 
2025-07-10 22:43:16.700715: train_loss -0.5039 
2025-07-10 22:43:16.701133: val_loss -0.5219 
2025-07-10 22:43:16.701291: Pseudo dice [np.float32(0.827)] 
2025-07-10 22:43:16.701400: Epoch time: 47.04 s 
2025-07-10 22:43:17.877502:  
2025-07-10 22:43:17.878145: Epoch 938 
2025-07-10 22:43:17.878278: Current learning rate: 0.00082 
2025-07-10 22:44:06.168083: train_loss -0.5019 
2025-07-10 22:44:06.168504: val_loss -0.5085 
2025-07-10 22:44:06.168784: Pseudo dice [np.float32(0.8083)] 
2025-07-10 22:44:06.168914: Epoch time: 48.29 s 
2025-07-10 22:44:07.966346:  
2025-07-10 22:44:07.966786: Epoch 939 
2025-07-10 22:44:07.967026: Current learning rate: 0.00081 
2025-07-10 22:44:55.634142: train_loss -0.5042 
2025-07-10 22:44:55.634500: val_loss -0.4918 
2025-07-10 22:44:55.634602: Pseudo dice [np.float32(0.8143)] 
2025-07-10 22:44:55.634709: Epoch time: 47.67 s 
2025-07-10 22:44:56.782193:  
2025-07-10 22:44:56.782861: Epoch 940 
2025-07-10 22:44:56.783105: Current learning rate: 0.00079 
2025-07-10 22:45:43.863551: train_loss -0.5069 
2025-07-10 22:45:43.863965: val_loss -0.498 
2025-07-10 22:45:43.864041: Pseudo dice [np.float32(0.83)] 
2025-07-10 22:45:43.864141: Epoch time: 47.08 s 
2025-07-10 22:45:45.028741:  
2025-07-10 22:45:45.029218: Epoch 941 
2025-07-10 22:45:45.029419: Current learning rate: 0.00078 
2025-07-10 22:46:32.458696: train_loss -0.5102 
2025-07-10 22:46:32.459229: val_loss -0.5179 
2025-07-10 22:46:32.459312: Pseudo dice [np.float32(0.822)] 
2025-07-10 22:46:32.459422: Epoch time: 47.43 s 
2025-07-10 22:46:33.676332:  
2025-07-10 22:46:33.676782: Epoch 942 
2025-07-10 22:46:33.676915: Current learning rate: 0.00077 
2025-07-10 22:47:22.459724: train_loss -0.5136 
2025-07-10 22:47:22.460104: val_loss -0.5279 
2025-07-10 22:47:22.460177: Pseudo dice [np.float32(0.8235)] 
2025-07-10 22:47:22.460279: Epoch time: 48.78 s 
2025-07-10 22:47:23.620552:  
2025-07-10 22:47:23.621029: Epoch 943 
2025-07-10 22:47:23.621294: Current learning rate: 0.00076 
2025-07-10 22:48:11.379242: train_loss -0.5079 
2025-07-10 22:48:11.379648: val_loss -0.5085 
2025-07-10 22:48:11.379737: Pseudo dice [np.float32(0.8085)] 
2025-07-10 22:48:11.379848: Epoch time: 47.76 s 
2025-07-10 22:48:12.557388:  
2025-07-10 22:48:12.557596: Epoch 944 
2025-07-10 22:48:12.557726: Current learning rate: 0.00075 
2025-07-10 22:48:59.570630: train_loss -0.5067 
2025-07-10 22:48:59.571078: val_loss -0.5107 
2025-07-10 22:48:59.571156: Pseudo dice [np.float32(0.83)] 
2025-07-10 22:48:59.571261: Epoch time: 47.01 s 
2025-07-10 22:49:00.725505:  
2025-07-10 22:49:00.725922: Epoch 945 
2025-07-10 22:49:00.726057: Current learning rate: 0.00074 
2025-07-10 22:49:47.904653: train_loss -0.5122 
2025-07-10 22:49:47.905119: val_loss -0.5108 
2025-07-10 22:49:47.905198: Pseudo dice [np.float32(0.8265)] 
2025-07-10 22:49:47.905308: Epoch time: 47.18 s 
2025-07-10 22:49:49.124384:  
2025-07-10 22:49:49.124773: Epoch 946 
2025-07-10 22:49:49.124906: Current learning rate: 0.00072 
2025-07-10 22:50:36.110537: train_loss -0.5056 
2025-07-10 22:50:36.110965: val_loss -0.4972 
2025-07-10 22:50:36.111066: Pseudo dice [np.float32(0.8363)] 
2025-07-10 22:50:36.111166: Epoch time: 46.99 s 
2025-07-10 22:50:37.269181:  
2025-07-10 22:50:37.269788: Epoch 947 
2025-07-10 22:50:37.270205: Current learning rate: 0.00071 
2025-07-10 22:51:24.776893: train_loss -0.5089 
2025-07-10 22:51:24.777648: val_loss -0.4939 
2025-07-10 22:51:24.777754: Pseudo dice [np.float32(0.8044)] 
2025-07-10 22:51:24.777897: Epoch time: 47.51 s 
2025-07-10 22:51:25.958692:  
2025-07-10 22:51:25.959097: Epoch 948 
2025-07-10 22:51:25.959347: Current learning rate: 0.0007 
2025-07-10 22:52:12.902296: train_loss -0.5133 
2025-07-10 22:52:12.902828: val_loss -0.4944 
2025-07-10 22:52:12.902932: Pseudo dice [np.float32(0.8181)] 
2025-07-10 22:52:12.903055: Epoch time: 46.94 s 
2025-07-10 22:52:14.055604:  
2025-07-10 22:52:14.055943: Epoch 949 
2025-07-10 22:52:14.056149: Current learning rate: 0.00069 
2025-07-10 22:53:01.279233: train_loss -0.5124 
2025-07-10 22:53:01.279696: val_loss -0.5044 
2025-07-10 22:53:01.279783: Pseudo dice [np.float32(0.8087)] 
2025-07-10 22:53:01.279890: Epoch time: 47.22 s 
2025-07-10 22:53:02.994053:  
2025-07-10 22:53:02.994679: Epoch 950 
2025-07-10 22:53:02.994809: Current learning rate: 0.00067 
2025-07-10 22:53:50.435185: train_loss -0.5117 
2025-07-10 22:53:50.435747: val_loss -0.5125 
2025-07-10 22:53:50.435824: Pseudo dice [np.float32(0.8156)] 
2025-07-10 22:53:50.435938: Epoch time: 47.44 s 
2025-07-10 22:53:52.276776:  
2025-07-10 22:53:52.277211: Epoch 951 
2025-07-10 22:53:52.277399: Current learning rate: 0.00066 
2025-07-10 22:54:39.704572: train_loss -0.5054 
2025-07-10 22:54:39.704963: val_loss -0.4973 
2025-07-10 22:54:39.705070: Pseudo dice [np.float32(0.8237)] 
2025-07-10 22:54:39.705166: Epoch time: 47.43 s 
2025-07-10 22:54:40.876880:  
2025-07-10 22:54:40.877120: Epoch 952 
2025-07-10 22:54:40.877243: Current learning rate: 0.00065 
2025-07-10 22:55:27.999598: train_loss -0.5103 
2025-07-10 22:55:28.000143: val_loss -0.5091 
2025-07-10 22:55:28.000230: Pseudo dice [np.float32(0.8228)] 
2025-07-10 22:55:28.000345: Epoch time: 47.12 s 
2025-07-10 22:55:29.204313:  
2025-07-10 22:55:29.204659: Epoch 953 
2025-07-10 22:55:29.204794: Current learning rate: 0.00064 
2025-07-10 22:56:16.645298: train_loss -0.5103 
2025-07-10 22:56:16.646057: val_loss -0.52 
2025-07-10 22:56:16.646143: Pseudo dice [np.float32(0.8153)] 
2025-07-10 22:56:16.646283: Epoch time: 47.44 s 
2025-07-10 22:56:17.849119:  
2025-07-10 22:56:17.849401: Epoch 954 
2025-07-10 22:56:17.849623: Current learning rate: 0.00063 
2025-07-10 22:57:05.388718: train_loss -0.5107 
2025-07-10 22:57:05.389092: val_loss -0.516 
2025-07-10 22:57:05.389177: Pseudo dice [np.float32(0.8106)] 
2025-07-10 22:57:05.389285: Epoch time: 47.54 s 
2025-07-10 22:57:06.541686:  
2025-07-10 22:57:06.541984: Epoch 955 
2025-07-10 22:57:06.542106: Current learning rate: 0.00061 
2025-07-10 22:57:53.946267: train_loss -0.5211 
2025-07-10 22:57:53.947308: val_loss -0.5003 
2025-07-10 22:57:53.947414: Pseudo dice [np.float32(0.8315)] 
2025-07-10 22:57:53.947625: Epoch time: 47.41 s 
2025-07-10 22:57:55.105999:  
2025-07-10 22:57:55.106319: Epoch 956 
2025-07-10 22:57:55.106470: Current learning rate: 0.0006 
2025-07-10 22:58:41.759692: train_loss -0.519 
2025-07-10 22:58:41.760266: val_loss -0.4943 
2025-07-10 22:58:41.760346: Pseudo dice [np.float32(0.8205)] 
2025-07-10 22:58:41.760469: Epoch time: 46.65 s 
2025-07-10 22:58:42.879234:  
2025-07-10 22:58:42.879532: Epoch 957 
2025-07-10 22:58:42.879702: Current learning rate: 0.00059 
2025-07-10 22:59:30.095108: train_loss -0.5077 
2025-07-10 22:59:30.095637: val_loss -0.5177 
2025-07-10 22:59:30.095716: Pseudo dice [np.float32(0.8405)] 
2025-07-10 22:59:30.095824: Epoch time: 47.22 s 
2025-07-10 22:59:31.315920:  
2025-07-10 22:59:31.316247: Epoch 958 
2025-07-10 22:59:31.316371: Current learning rate: 0.00058 
2025-07-10 23:00:18.636012: train_loss -0.5138 
2025-07-10 23:00:18.636602: val_loss -0.5212 
2025-07-10 23:00:18.636699: Pseudo dice [np.float32(0.8501)] 
2025-07-10 23:00:18.636824: Epoch time: 47.32 s 
2025-07-10 23:00:19.822344:  
2025-07-10 23:00:19.822607: Epoch 959 
2025-07-10 23:00:19.822735: Current learning rate: 0.00056 
2025-07-10 23:01:07.076775: train_loss -0.5138 
2025-07-10 23:01:07.077191: val_loss -0.5135 
2025-07-10 23:01:07.077269: Pseudo dice [np.float32(0.8321)] 
2025-07-10 23:01:07.077379: Epoch time: 47.26 s 
2025-07-10 23:01:08.277384:  
2025-07-10 23:01:08.277817: Epoch 960 
2025-07-10 23:01:08.277965: Current learning rate: 0.00055 
2025-07-10 23:01:55.861949: train_loss -0.5133 
2025-07-10 23:01:55.862333: val_loss -0.5092 
2025-07-10 23:01:55.862429: Pseudo dice [np.float32(0.837)] 
2025-07-10 23:01:55.862560: Epoch time: 47.59 s 
2025-07-10 23:01:57.036393:  
2025-07-10 23:01:57.036767: Epoch 961 
2025-07-10 23:01:57.036896: Current learning rate: 0.00054 
2025-07-10 23:02:44.323213: train_loss -0.5079 
2025-07-10 23:02:44.323921: val_loss -0.5145 
2025-07-10 23:02:44.324044: Pseudo dice [np.float32(0.8122)] 
2025-07-10 23:02:44.324208: Epoch time: 47.29 s 
2025-07-10 23:02:45.559495:  
2025-07-10 23:02:45.559809: Epoch 962 
2025-07-10 23:02:45.559945: Current learning rate: 0.00053 
2025-07-10 23:03:32.770035: train_loss -0.5128 
2025-07-10 23:03:32.770433: val_loss -0.5171 
2025-07-10 23:03:32.770690: Pseudo dice [np.float32(0.7979)] 
2025-07-10 23:03:32.770866: Epoch time: 47.21 s 
2025-07-10 23:03:34.862329:  
2025-07-10 23:03:34.863252: Epoch 963 
2025-07-10 23:03:34.864153: Current learning rate: 0.00051 
2025-07-10 23:04:23.065181: train_loss -0.5162 
2025-07-10 23:04:23.065615: val_loss -0.5094 
2025-07-10 23:04:23.065702: Pseudo dice [np.float32(0.8339)] 
2025-07-10 23:04:23.065821: Epoch time: 48.2 s 
2025-07-10 23:04:24.220652:  
2025-07-10 23:04:24.221076: Epoch 964 
2025-07-10 23:04:24.221358: Current learning rate: 0.0005 
2025-07-10 23:05:12.058559: train_loss -0.5071 
2025-07-10 23:05:12.059171: val_loss -0.506 
2025-07-10 23:05:12.059261: Pseudo dice [np.float32(0.8587)] 
2025-07-10 23:05:12.059376: Epoch time: 47.84 s 
2025-07-10 23:05:13.206424:  
2025-07-10 23:05:13.206816: Epoch 965 
2025-07-10 23:05:13.207013: Current learning rate: 0.00049 
2025-07-10 23:06:01.033126: train_loss -0.5083 
2025-07-10 23:06:01.033555: val_loss -0.5161 
2025-07-10 23:06:01.033640: Pseudo dice [np.float32(0.8445)] 
2025-07-10 23:06:01.033739: Epoch time: 47.83 s 
2025-07-10 23:06:02.214673:  
2025-07-10 23:06:02.215110: Epoch 966 
2025-07-10 23:06:02.215301: Current learning rate: 0.00048 
2025-07-10 23:06:49.636347: train_loss -0.5128 
2025-07-10 23:06:49.636827: val_loss -0.5061 
2025-07-10 23:06:49.636909: Pseudo dice [np.float32(0.8355)] 
2025-07-10 23:06:49.637016: Epoch time: 47.42 s 
2025-07-10 23:06:50.789159:  
2025-07-10 23:06:50.789466: Epoch 967 
2025-07-10 23:06:50.789607: Current learning rate: 0.00046 
2025-07-10 23:07:38.004060: train_loss -0.5162 
2025-07-10 23:07:38.004555: val_loss -0.5017 
2025-07-10 23:07:38.004634: Pseudo dice [np.float32(0.8451)] 
2025-07-10 23:07:38.004740: Epoch time: 47.22 s 
2025-07-10 23:07:39.147837:  
2025-07-10 23:07:39.148182: Epoch 968 
2025-07-10 23:07:39.148338: Current learning rate: 0.00045 
2025-07-10 23:08:26.689648: train_loss -0.5112 
2025-07-10 23:08:26.690735: val_loss -0.5219 
2025-07-10 23:08:26.690832: Pseudo dice [np.float32(0.8415)] 
2025-07-10 23:08:26.691032: Epoch time: 47.54 s 
2025-07-10 23:08:27.856082:  
2025-07-10 23:08:27.856697: Epoch 969 
2025-07-10 23:08:27.856896: Current learning rate: 0.00044 
2025-07-10 23:09:15.305275: train_loss -0.511 
2025-07-10 23:09:15.305719: val_loss -0.5074 
2025-07-10 23:09:15.305815: Pseudo dice [np.float32(0.8291)] 
2025-07-10 23:09:15.306097: Epoch time: 47.45 s 
2025-07-10 23:09:16.463620:  
2025-07-10 23:09:16.464015: Epoch 970 
2025-07-10 23:09:16.464186: Current learning rate: 0.00043 
2025-07-10 23:10:04.783491: train_loss -0.5144 
2025-07-10 23:10:04.783946: val_loss -0.5135 
2025-07-10 23:10:04.784026: Pseudo dice [np.float32(0.8427)] 
2025-07-10 23:10:04.784137: Epoch time: 48.32 s 
2025-07-10 23:10:05.940578:  
2025-07-10 23:10:05.941161: Epoch 971 
2025-07-10 23:10:05.941302: Current learning rate: 0.00041 
2025-07-10 23:10:53.850352: train_loss -0.5123 
2025-07-10 23:10:53.850954: val_loss -0.4956 
2025-07-10 23:10:53.851048: Pseudo dice [np.float32(0.8309)] 
2025-07-10 23:10:53.851157: Epoch time: 47.91 s 
2025-07-10 23:10:55.036639:  
2025-07-10 23:10:55.037137: Epoch 972 
2025-07-10 23:10:55.037357: Current learning rate: 0.0004 
2025-07-10 23:11:44.438554: train_loss -0.499 
2025-07-10 23:11:44.439144: val_loss -0.5075 
2025-07-10 23:11:44.439231: Pseudo dice [np.float32(0.8482)] 
2025-07-10 23:11:44.439349: Epoch time: 49.4 s 
2025-07-10 23:11:45.663741:  
2025-07-10 23:11:45.664057: Epoch 973 
2025-07-10 23:11:45.664217: Current learning rate: 0.00039 
2025-07-10 23:12:33.632379: train_loss -0.5168 
2025-07-10 23:12:33.633550: val_loss -0.5094 
2025-07-10 23:12:33.633708: Pseudo dice [np.float32(0.8092)] 
2025-07-10 23:12:33.633850: Epoch time: 47.97 s 
2025-07-10 23:12:34.821238:  
2025-07-10 23:12:34.821682: Epoch 974 
2025-07-10 23:12:34.821841: Current learning rate: 0.00037 
2025-07-10 23:13:22.668176: train_loss -0.5192 
2025-07-10 23:13:22.668530: val_loss -0.5247 
2025-07-10 23:13:22.668633: Pseudo dice [np.float32(0.8329)] 
2025-07-10 23:13:22.668739: Epoch time: 47.85 s 
2025-07-10 23:13:24.613437:  
2025-07-10 23:13:24.613865: Epoch 975 
2025-07-10 23:13:24.614003: Current learning rate: 0.00036 
2025-07-10 23:14:12.239560: train_loss -0.5109 
2025-07-10 23:14:12.240141: val_loss -0.5156 
2025-07-10 23:14:12.240223: Pseudo dice [np.float32(0.838)] 
2025-07-10 23:14:12.240328: Epoch time: 47.63 s 
2025-07-10 23:14:13.381820:  
2025-07-10 23:14:13.382232: Epoch 976 
2025-07-10 23:14:13.382385: Current learning rate: 0.00035 
2025-07-10 23:15:00.509789: train_loss -0.5042 
2025-07-10 23:15:00.510565: val_loss -0.5186 
2025-07-10 23:15:00.510647: Pseudo dice [np.float32(0.8263)] 
2025-07-10 23:15:00.510793: Epoch time: 47.13 s 
2025-07-10 23:15:01.685238:  
2025-07-10 23:15:01.685494: Epoch 977 
2025-07-10 23:15:01.685600: Current learning rate: 0.00034 
2025-07-10 23:15:48.696424: train_loss -0.5206 
2025-07-10 23:15:48.696785: val_loss -0.5128 
2025-07-10 23:15:48.696862: Pseudo dice [np.float32(0.8341)] 
2025-07-10 23:15:48.696962: Epoch time: 47.01 s 
2025-07-10 23:15:49.849515:  
2025-07-10 23:15:49.849926: Epoch 978 
2025-07-10 23:15:49.850170: Current learning rate: 0.00032 
2025-07-10 23:16:37.826128: train_loss -0.5057 
2025-07-10 23:16:37.827068: val_loss -0.5063 
2025-07-10 23:16:37.827151: Pseudo dice [np.float32(0.8507)] 
2025-07-10 23:16:37.827264: Epoch time: 47.98 s 
2025-07-10 23:16:38.986937:  
2025-07-10 23:16:38.987119: Epoch 979 
2025-07-10 23:16:38.987250: Current learning rate: 0.00031 
2025-07-10 23:17:26.321632: train_loss -0.5161 
2025-07-10 23:17:26.322031: val_loss -0.5082 
2025-07-10 23:17:26.322114: Pseudo dice [np.float32(0.8139)] 
2025-07-10 23:17:26.322214: Epoch time: 47.34 s 
2025-07-10 23:17:27.534897:  
2025-07-10 23:17:27.535438: Epoch 980 
2025-07-10 23:17:27.535578: Current learning rate: 0.0003 
2025-07-10 23:18:15.096316: train_loss -0.5153 
2025-07-10 23:18:15.096802: val_loss -0.4934 
2025-07-10 23:18:15.096880: Pseudo dice [np.float32(0.8397)] 
2025-07-10 23:18:15.096979: Epoch time: 47.56 s 
2025-07-10 23:18:16.285312:  
2025-07-10 23:18:16.285578: Epoch 981 
2025-07-10 23:18:16.285707: Current learning rate: 0.00028 
2025-07-10 23:19:04.021174: train_loss -0.5158 
2025-07-10 23:19:04.021599: val_loss -0.506 
2025-07-10 23:19:04.021678: Pseudo dice [np.float32(0.8297)] 
2025-07-10 23:19:04.021782: Epoch time: 47.74 s 
2025-07-10 23:19:05.166510:  
2025-07-10 23:19:05.166730: Epoch 982 
2025-07-10 23:19:05.166854: Current learning rate: 0.00027 
2025-07-10 23:19:52.358305: train_loss -0.5109 
2025-07-10 23:19:52.358778: val_loss -0.4906 
2025-07-10 23:19:52.358909: Pseudo dice [np.float32(0.8311)] 
2025-07-10 23:19:52.359103: Epoch time: 47.19 s 
2025-07-10 23:19:53.560169:  
2025-07-10 23:19:53.560619: Epoch 983 
2025-07-10 23:19:53.560766: Current learning rate: 0.00026 
2025-07-10 23:20:40.843158: train_loss -0.5111 
2025-07-10 23:20:40.843657: val_loss -0.4945 
2025-07-10 23:20:40.843736: Pseudo dice [np.float32(0.8463)] 
2025-07-10 23:20:40.843843: Epoch time: 47.28 s 
2025-07-10 23:20:42.111442:  
2025-07-10 23:20:42.112240: Epoch 984 
2025-07-10 23:20:42.112620: Current learning rate: 0.00024 
2025-07-10 23:21:28.918781: train_loss -0.517 
2025-07-10 23:21:28.919073: val_loss -0.5014 
2025-07-10 23:21:28.919163: Pseudo dice [np.float32(0.836)] 
2025-07-10 23:21:28.919256: Epoch time: 46.81 s 
2025-07-10 23:21:30.030180:  
2025-07-10 23:21:30.030457: Epoch 985 
2025-07-10 23:21:30.030576: Current learning rate: 0.00023 
2025-07-10 23:22:16.611276: train_loss -0.5187 
2025-07-10 23:22:16.612050: val_loss -0.5185 
2025-07-10 23:22:16.612144: Pseudo dice [np.float32(0.8549)] 
2025-07-10 23:22:16.612266: Epoch time: 46.58 s 
2025-07-10 23:22:17.827797:  
2025-07-10 23:22:17.828155: Epoch 986 
2025-07-10 23:22:17.828296: Current learning rate: 0.00021 
2025-07-10 23:23:04.642020: train_loss -0.5181 
2025-07-10 23:23:04.642517: val_loss -0.5078 
2025-07-10 23:23:04.642659: Pseudo dice [np.float32(0.8198)] 
2025-07-10 23:23:04.642782: Epoch time: 46.82 s 
2025-07-10 23:23:06.441577:  
2025-07-10 23:23:06.442202: Epoch 987 
2025-07-10 23:23:06.442338: Current learning rate: 0.0002 
2025-07-10 23:23:54.519798: train_loss -0.5134 
2025-07-10 23:23:54.520284: val_loss -0.5079 
2025-07-10 23:23:54.520395: Pseudo dice [np.float32(0.8288)] 
2025-07-10 23:23:54.520555: Epoch time: 48.08 s 
2025-07-10 23:23:55.710583:  
2025-07-10 23:23:55.710773: Epoch 988 
2025-07-10 23:23:55.710898: Current learning rate: 0.00019 
2025-07-10 23:24:42.847974: train_loss -0.516 
2025-07-10 23:24:42.848471: val_loss -0.5149 
2025-07-10 23:24:42.848583: Pseudo dice [np.float32(0.8396)] 
2025-07-10 23:24:42.848716: Epoch time: 47.14 s 
2025-07-10 23:24:44.096977:  
2025-07-10 23:24:44.097461: Epoch 989 
2025-07-10 23:24:44.097691: Current learning rate: 0.00017 
2025-07-10 23:25:31.979804: train_loss -0.5173 
2025-07-10 23:25:31.980810: val_loss -0.5205 
2025-07-10 23:25:31.980910: Pseudo dice [np.float32(0.8433)] 
2025-07-10 23:25:31.981173: Epoch time: 47.88 s 
2025-07-10 23:25:33.196715:  
2025-07-10 23:25:33.197081: Epoch 990 
2025-07-10 23:25:33.197214: Current learning rate: 0.00016 
2025-07-10 23:26:20.861379: train_loss -0.5106 
2025-07-10 23:26:20.862558: val_loss -0.5128 
2025-07-10 23:26:20.862741: Pseudo dice [np.float32(0.8332)] 
2025-07-10 23:26:20.862962: Epoch time: 47.67 s 
2025-07-10 23:26:22.057079:  
2025-07-10 23:26:22.057547: Epoch 991 
2025-07-10 23:26:22.057738: Current learning rate: 0.00014 
2025-07-10 23:27:09.901236: train_loss -0.5148 
2025-07-10 23:27:09.901844: val_loss -0.5048 
2025-07-10 23:27:09.901932: Pseudo dice [np.float32(0.8441)] 
2025-07-10 23:27:09.902043: Epoch time: 47.85 s 
2025-07-10 23:27:11.071258:  
2025-07-10 23:27:11.071511: Epoch 992 
2025-07-10 23:27:11.071654: Current learning rate: 0.00013 
2025-07-10 23:27:58.314808: train_loss -0.5147 
2025-07-10 23:27:58.315220: val_loss -0.5188 
2025-07-10 23:27:58.315300: Pseudo dice [np.float32(0.8224)] 
2025-07-10 23:27:58.315409: Epoch time: 47.24 s 
2025-07-10 23:27:59.479349:  
2025-07-10 23:27:59.479639: Epoch 993 
2025-07-10 23:27:59.479760: Current learning rate: 0.00011 
2025-07-10 23:28:46.476930: train_loss -0.5105 
2025-07-10 23:28:46.477523: val_loss -0.5211 
2025-07-10 23:28:46.477642: Pseudo dice [np.float32(0.8476)] 
2025-07-10 23:28:46.477775: Epoch time: 47.0 s 
2025-07-10 23:28:47.664600:  
2025-07-10 23:28:47.665043: Epoch 994 
2025-07-10 23:28:47.665219: Current learning rate: 0.0001 
2025-07-10 23:29:35.993144: train_loss -0.5199 
2025-07-10 23:29:35.993641: val_loss -0.5209 
2025-07-10 23:29:35.993760: Pseudo dice [np.float32(0.8246)] 
2025-07-10 23:29:35.993868: Epoch time: 48.33 s 
2025-07-10 23:29:37.224409:  
2025-07-10 23:29:37.224883: Epoch 995 
2025-07-10 23:29:37.225011: Current learning rate: 8e-05 
2025-07-10 23:30:24.555008: train_loss -0.5094 
2025-07-10 23:30:24.555652: val_loss -0.529 
2025-07-10 23:30:24.555742: Pseudo dice [np.float32(0.8439)] 
2025-07-10 23:30:24.555889: Epoch time: 47.33 s 
2025-07-10 23:30:25.800496:  
2025-07-10 23:30:25.801024: Epoch 996 
2025-07-10 23:30:25.801272: Current learning rate: 7e-05 
2025-07-10 23:31:14.198908: train_loss -0.5199 
2025-07-10 23:31:14.199477: val_loss -0.505 
2025-07-10 23:31:14.199575: Pseudo dice [np.float32(0.8474)] 
2025-07-10 23:31:14.199723: Epoch time: 48.4 s 
2025-07-10 23:31:15.350145:  
2025-07-10 23:31:15.350409: Epoch 997 
2025-07-10 23:31:15.350555: Current learning rate: 5e-05 
2025-07-10 23:32:02.958463: train_loss -0.5103 
2025-07-10 23:32:02.958786: val_loss -0.5304 
2025-07-10 23:32:02.958858: Pseudo dice [np.float32(0.8157)] 
2025-07-10 23:32:02.958954: Epoch time: 47.61 s 
2025-07-10 23:32:04.803881:  
2025-07-10 23:32:04.804956: Epoch 998 
2025-07-10 23:32:04.805148: Current learning rate: 4e-05 
2025-07-10 23:32:51.584634: train_loss -0.5188 
2025-07-10 23:32:51.585029: val_loss -0.5316 
2025-07-10 23:32:51.585119: Pseudo dice [np.float32(0.8593)] 
2025-07-10 23:32:51.585299: Epoch time: 46.78 s 
2025-07-10 23:32:52.767519:  
2025-07-10 23:32:52.768116: Epoch 999 
2025-07-10 23:32:52.768418: Current learning rate: 2e-05 
2025-07-10 23:33:40.122549: train_loss -0.5131 
2025-07-10 23:33:40.123139: val_loss -0.5189 
2025-07-10 23:33:40.123228: Pseudo dice [np.float32(0.8418)] 
2025-07-10 23:33:40.123355: Epoch time: 47.36 s 
2025-07-10 23:33:41.636783: Training done. 
2025-07-10 23:33:41.659276: predicting BraTS-PED-00001-000 
2025-07-10 23:33:41.718224: BraTS-PED-00001-000, shape torch.Size([4, 112, 112, 112]), rank 0 
2025-07-10 23:33:44.804086: predicting BraTS-PED-00002-000 
2025-07-10 23:33:44.812534: BraTS-PED-00002-000, shape torch.Size([4, 53, 53, 53]), rank 0 
2025-07-10 23:33:44.858146: predicting BraTS-PED-00003-000 
2025-07-10 23:33:44.908533: BraTS-PED-00003-000, shape torch.Size([4, 124, 124, 124]), rank 0 
2025-07-10 23:33:45.532830: predicting BraTS-PED-00004-000 
2025-07-10 23:33:45.571372: BraTS-PED-00004-000, shape torch.Size([4, 114, 114, 114]), rank 0 
2025-07-10 23:33:45.757099: predicting BraTS-PED-00005-000 
2025-07-10 23:33:45.762665: BraTS-PED-00005-000, shape torch.Size([4, 64, 64, 64]), rank 0 
2025-07-10 23:33:45.795547: predicting BraTS-PED-00006-000 
2025-07-10 23:33:45.801340: BraTS-PED-00006-000, shape torch.Size([4, 57, 57, 57]), rank 0 
2025-07-10 23:33:45.835428: predicting BraTS-PED-00008-000 
2025-07-10 23:33:45.856772: BraTS-PED-00008-000, shape torch.Size([4, 104, 104, 104]), rank 0 
2025-07-10 23:33:46.026654: predicting BraTS-PED-00009-000 
2025-07-10 23:33:46.053173: BraTS-PED-00009-000, shape torch.Size([4, 109, 109, 109]), rank 0 
2025-07-10 23:33:46.223791: predicting BraTS-PED-00010-000 
2025-07-10 23:33:46.238736: BraTS-PED-00010-000, shape torch.Size([4, 24, 179, 171]), rank 0 
2025-07-10 23:33:46.586029: predicting BraTS-PED-00013-000 
2025-07-10 23:33:46.598191: BraTS-PED-00013-000, shape torch.Size([4, 81, 81, 81]), rank 0 
2025-07-10 23:33:46.763337: predicting BraTS-PED-00014-000 
2025-07-10 23:33:46.771047: BraTS-PED-00014-000, shape torch.Size([4, 66, 66, 66]), rank 0 
2025-07-10 23:33:46.804084: predicting BraTS-PED-00015-000 
2025-07-10 23:33:46.819941: BraTS-PED-00015-000, shape torch.Size([4, 96, 96, 96]), rank 0 
2025-07-10 23:33:46.984953: predicting BraTS-PED-00016-000 
2025-07-10 23:33:46.999614: BraTS-PED-00016-000, shape torch.Size([4, 85, 85, 85]), rank 0 
2025-07-10 23:33:47.170033: predicting BraTS-PED-00017-000 
2025-07-10 23:33:47.225728: BraTS-PED-00017-000, shape torch.Size([4, 144, 144, 144]), rank 0 
2025-07-10 23:33:47.765077: predicting BraTS-PED-00018-000 
2025-07-10 23:33:47.790702: BraTS-PED-00018-000, shape torch.Size([4, 112, 112, 112]), rank 0 
2025-07-10 23:33:47.962767: predicting BraTS-PED-00019-000 
2025-07-10 23:33:48.023587: BraTS-PED-00019-000, shape torch.Size([4, 144, 144, 144]), rank 0 
2025-07-10 23:33:48.560414: predicting BraTS-PED-00020-000 
2025-07-10 23:33:48.568976: BraTS-PED-00020-000, shape torch.Size([4, 71, 71, 71]), rank 0 
2025-07-10 23:33:48.602072: predicting BraTS-PED-00021-000 
2025-07-10 23:33:48.639231: BraTS-PED-00021-000, shape torch.Size([4, 123, 123, 123]), rank 0 
2025-07-10 23:33:49.177986: predicting BraTS-PED-00022-000 
2025-07-10 23:33:49.204656: BraTS-PED-00022-000, shape torch.Size([4, 110, 110, 110]), rank 0 
2025-07-10 23:33:49.371396: predicting BraTS-PED-00023-000 
2025-07-10 23:33:49.397053: BraTS-PED-00023-000, shape torch.Size([4, 112, 112, 112]), rank 0 
2025-07-10 23:33:49.565161: predicting BraTS-PED-00024-000 
2025-07-10 23:33:49.583505: BraTS-PED-00024-000, shape torch.Size([4, 98, 102, 102]), rank 0 
2025-07-10 23:33:49.749820: predicting BraTS-PED-00025-000 
2025-07-10 23:33:49.759039: BraTS-PED-00025-000, shape torch.Size([4, 76, 76, 76]), rank 0 
2025-07-10 23:33:49.790586: predicting BraTS-PED-00026-000 
2025-07-10 23:33:49.796417: BraTS-PED-00026-000, shape torch.Size([4, 60, 60, 60]), rank 0 
2025-07-10 23:33:49.829286: predicting BraTS-PED-00027-000 
2025-07-10 23:33:49.835078: BraTS-PED-00027-000, shape torch.Size([4, 63, 63, 63]), rank 0 
2025-07-10 23:33:49.868445: predicting BraTS-PED-00028-000 
2025-07-10 23:33:49.902063: BraTS-PED-00028-000, shape torch.Size([4, 122, 122, 122]), rank 0 
2025-07-10 23:33:50.433224: predicting BraTS-PED-00029-000 
2025-07-10 23:33:50.436526: BraTS-PED-00029-000, shape torch.Size([4, 48, 48, 48]), rank 0 
2025-07-10 23:33:50.468418: predicting BraTS-PED-00030-000 
2025-07-10 23:33:50.498906: BraTS-PED-00030-000, shape torch.Size([4, 120, 120, 120]), rank 0 
2025-07-10 23:33:50.669469: predicting BraTS-PED-00031-000 
2025-07-10 23:33:50.696899: BraTS-PED-00031-000, shape torch.Size([4, 107, 107, 107]), rank 0 
2025-07-10 23:33:50.863848: predicting BraTS-PED-00032-000 
2025-07-10 23:33:50.880256: BraTS-PED-00032-000, shape torch.Size([4, 90, 90, 90]), rank 0 
2025-07-10 23:33:51.047359: predicting BraTS-PED-00033-000 
2025-07-10 23:33:51.074972: BraTS-PED-00033-000, shape torch.Size([4, 108, 108, 108]), rank 0 
2025-07-10 23:33:51.241879: predicting BraTS-PED-00034-000 
2025-07-10 23:33:51.264312: BraTS-PED-00034-000, shape torch.Size([4, 103, 103, 103]), rank 0 
2025-07-10 23:33:51.430595: predicting BraTS-PED-00035-000 
2025-07-10 23:33:51.464165: BraTS-PED-00035-000, shape torch.Size([4, 116, 116, 116]), rank 0 
2025-07-10 23:33:51.635717: predicting BraTS-PED-00036-000 
2025-07-10 23:33:51.646154: BraTS-PED-00036-000, shape torch.Size([4, 76, 76, 76]), rank 0 
2025-07-10 23:33:51.680479: predicting BraTS-PED-00037-000 
2025-07-10 23:33:51.687823: BraTS-PED-00037-000, shape torch.Size([4, 66, 66, 66]), rank 0 
2025-07-10 23:33:51.723514: predicting BraTS-PED-00038-000 
2025-07-10 23:33:51.727638: BraTS-PED-00038-000, shape torch.Size([4, 53, 53, 53]), rank 0 
2025-07-10 23:33:51.759815: predicting BraTS-PED-00039-000 
2025-07-10 23:33:51.769482: BraTS-PED-00039-000, shape torch.Size([4, 78, 78, 78]), rank 0 
2025-07-10 23:33:51.801298: predicting BraTS-PED-00040-000 
2025-07-10 23:33:51.812293: BraTS-PED-00040-000, shape torch.Size([4, 78, 78, 78]), rank 0 
2025-07-10 23:33:51.844825: predicting BraTS-PED-00041-000 
2025-07-10 23:33:51.858882: BraTS-PED-00041-000, shape torch.Size([4, 86, 86, 86]), rank 0 
2025-07-10 23:33:52.024329: predicting BraTS-PED-00042-000 
2025-07-10 23:33:52.078000: BraTS-PED-00042-000, shape torch.Size([4, 144, 144, 144]), rank 0 
2025-07-10 23:33:52.620299: predicting BraTS-PED-00043-000 
2025-07-10 23:33:52.651412: BraTS-PED-00043-000, shape torch.Size([4, 120, 120, 120]), rank 0 
2025-07-10 23:33:52.823629: predicting BraTS-PED-00044-000 
2025-07-10 23:33:52.831694: BraTS-PED-00044-000, shape torch.Size([4, 68, 68, 68]), rank 0 
2025-07-10 23:33:52.864198: predicting BraTS-PED-00045-000 
2025-07-10 23:33:52.875457: BraTS-PED-00045-000, shape torch.Size([4, 75, 75, 75]), rank 0 
2025-07-10 23:33:52.907527: predicting BraTS-PED-00046-000 
2025-07-10 23:33:52.915827: BraTS-PED-00046-000, shape torch.Size([4, 69, 69, 69]), rank 0 
2025-07-10 23:33:52.948317: predicting BraTS-PED-00047-000 
2025-07-10 23:33:52.954206: BraTS-PED-00047-000, shape torch.Size([4, 63, 63, 63]), rank 0 
2025-07-10 23:33:52.987388: predicting BraTS-PED-00048-000 
2025-07-10 23:33:53.044492: BraTS-PED-00048-000, shape torch.Size([4, 142, 142, 142]), rank 0 
2025-07-10 23:33:53.583786: predicting BraTS-PED-00049-000 
2025-07-10 23:33:53.622625: BraTS-PED-00049-000, shape torch.Size([4, 124, 124, 124]), rank 0 
2025-07-10 23:33:54.165878: predicting BraTS-PED-00050-000 
2025-07-10 23:33:54.181977: BraTS-PED-00050-000, shape torch.Size([4, 96, 96, 96]), rank 0 
2025-07-10 23:33:54.358204: predicting BraTS-PED-00051-000 
2025-07-10 23:33:54.405402: BraTS-PED-00051-000, shape torch.Size([4, 131, 131, 131]), rank 0 
2025-07-10 23:33:54.942649: predicting BraTS-PED-00052-000 
2025-07-10 23:33:54.950297: BraTS-PED-00052-000, shape torch.Size([4, 68, 68, 68]), rank 0 
2025-07-10 23:33:54.981927: predicting BraTS-PED-00053-000 
2025-07-10 23:33:54.987259: BraTS-PED-00053-000, shape torch.Size([4, 62, 62, 62]), rank 0 
2025-07-10 23:33:55.020247: predicting BraTS-PED-00054-000 
2025-07-10 23:33:55.044158: BraTS-PED-00054-000, shape torch.Size([4, 112, 112, 112]), rank 0 
2025-07-10 23:33:55.209626: predicting BraTS-PED-00055-000 
2025-07-10 23:33:55.212883: BraTS-PED-00055-000, shape torch.Size([4, 48, 48, 48]), rank 0 
2025-07-10 23:33:55.243366: predicting BraTS-PED-00056-000 
2025-07-10 23:33:55.259796: BraTS-PED-00056-000, shape torch.Size([4, 89, 89, 89]), rank 0 
2025-07-10 23:33:55.423816: predicting BraTS-PED-00057-000 
2025-07-10 23:33:55.434628: BraTS-PED-00057-000, shape torch.Size([4, 77, 77, 77]), rank 0 
2025-07-10 23:33:55.467358: predicting BraTS-PED-00058-000 
2025-07-10 23:33:55.488649: BraTS-PED-00058-000, shape torch.Size([4, 102, 102, 102]), rank 0 
2025-07-10 23:33:55.654585: predicting BraTS-PED-00059-000 
2025-07-10 23:33:55.668989: BraTS-PED-00059-000, shape torch.Size([4, 86, 86, 86]), rank 0 
2025-07-10 23:33:55.834581: predicting BraTS-PED-00060-000 
2025-07-10 23:33:55.867012: BraTS-PED-00060-000, shape torch.Size([4, 120, 120, 120]), rank 0 
2025-07-10 23:33:56.036733: predicting BraTS-PED-00061-000 
2025-07-10 23:33:56.045129: BraTS-PED-00061-000, shape torch.Size([4, 69, 69, 69]), rank 0 
2025-07-10 23:33:56.077458: predicting BraTS-PED-00062-000 
2025-07-10 23:33:56.094090: BraTS-PED-00062-000, shape torch.Size([4, 92, 92, 92]), rank 0 
2025-07-10 23:33:56.260073: predicting BraTS-PED-00063-000 
2025-07-10 23:33:56.293315: BraTS-PED-00063-000, shape torch.Size([4, 120, 120, 120]), rank 0 
2025-07-10 23:33:56.460552: predicting BraTS-PED-00064-000 
2025-07-10 23:33:56.491144: BraTS-PED-00064-000, shape torch.Size([4, 120, 120, 120]), rank 0 
2025-07-10 23:33:56.659321: predicting BraTS-PED-00065-000 
2025-07-10 23:33:56.691201: BraTS-PED-00065-000, shape torch.Size([4, 114, 114, 114]), rank 0 
2025-07-10 23:33:56.859395: predicting BraTS-PED-00066-000 
2025-07-10 23:33:56.915968: BraTS-PED-00066-000, shape torch.Size([4, 138, 138, 138]), rank 0 
2025-07-10 23:33:57.449408: predicting BraTS-PED-00067-000 
2025-07-10 23:33:57.457627: BraTS-PED-00067-000, shape torch.Size([4, 67, 67, 67]), rank 0 
2025-07-10 23:33:57.489429: predicting BraTS-PED-00068-000 
2025-07-10 23:33:57.493277: BraTS-PED-00068-000, shape torch.Size([4, 53, 53, 53]), rank 0 
2025-07-10 23:33:57.525201: predicting BraTS-PED-00069-000 
2025-07-10 23:33:57.540642: BraTS-PED-00069-000, shape torch.Size([4, 87, 87, 87]), rank 0 
2025-07-10 23:33:57.705058: predicting BraTS-PED-00070-000 
2025-07-10 23:33:57.710394: BraTS-PED-00070-000, shape torch.Size([4, 59, 59, 59]), rank 0 
2025-07-10 23:33:57.743259: predicting BraTS-PED-00071-000 
2025-07-10 23:33:57.750688: BraTS-PED-00071-000, shape torch.Size([4, 66, 66, 66]), rank 0 
2025-07-10 23:33:57.781571: predicting BraTS-PED-00072-000 
2025-07-10 23:33:57.786943: BraTS-PED-00072-000, shape torch.Size([4, 57, 57, 57]), rank 0 
2025-07-10 23:33:57.819391: predicting BraTS-PED-00073-000 
2025-07-10 23:33:57.849959: BraTS-PED-00073-000, shape torch.Size([4, 114, 114, 114]), rank 0 
2025-07-10 23:33:58.015557: predicting BraTS-PED-00074-000 
2025-07-10 23:33:58.019291: BraTS-PED-00074-000, shape torch.Size([4, 50, 50, 50]), rank 0 
2025-07-10 23:33:58.049895: predicting BraTS-PED-00075-000 
2025-07-10 23:33:58.053631: BraTS-PED-00075-000, shape torch.Size([4, 49, 49, 49]), rank 0 
2025-07-10 23:33:58.084818: predicting BraTS-PED-00076-000 
2025-07-10 23:33:58.102166: BraTS-PED-00076-000, shape torch.Size([4, 93, 93, 93]), rank 0 
2025-07-10 23:33:58.266736: predicting BraTS-PED-00077-000 
2025-07-10 23:33:58.270786: BraTS-PED-00077-000, shape torch.Size([4, 55, 55, 55]), rank 0 
2025-07-10 23:33:58.302489: predicting BraTS-PED-00078-000 
2025-07-10 23:33:58.312207: BraTS-PED-00078-000, shape torch.Size([4, 73, 73, 73]), rank 0 
2025-07-10 23:33:58.343549: predicting BraTS-PED-00079-000 
2025-07-10 23:33:58.370779: BraTS-PED-00079-000, shape torch.Size([4, 111, 111, 111]), rank 0 
2025-07-10 23:33:58.536666: predicting BraTS-PED-00080-000 
2025-07-10 23:33:58.543839: BraTS-PED-00080-000, shape torch.Size([4, 66, 66, 66]), rank 0 
2025-07-10 23:33:58.575682: predicting BraTS-PED-00081-000 
2025-07-10 23:33:58.584444: BraTS-PED-00081-000, shape torch.Size([4, 69, 69, 69]), rank 0 
2025-07-10 23:33:58.616606: predicting BraTS-PED-00082-000 
2025-07-10 23:33:58.626732: BraTS-PED-00082-000, shape torch.Size([4, 74, 74, 74]), rank 0 
2025-07-10 23:33:58.658307: predicting BraTS-PED-00083-000 
2025-07-10 23:33:58.667264: BraTS-PED-00083-000, shape torch.Size([4, 16, 171, 171]), rank 0 
2025-07-10 23:33:59.010411: predicting BraTS-PED-00084-000 
2025-07-10 23:33:59.017778: BraTS-PED-00084-000, shape torch.Size([4, 70, 70, 70]), rank 0 
2025-07-10 23:33:59.049977: predicting BraTS-PED-00085-000 
2025-07-10 23:33:59.055659: BraTS-PED-00085-000, shape torch.Size([4, 62, 62, 62]), rank 0 
2025-07-10 23:33:59.087691: predicting BraTS-PED-00086-000 
2025-07-10 23:33:59.095622: BraTS-PED-00086-000, shape torch.Size([4, 65, 65, 65]), rank 0 
2025-07-10 23:33:59.127057: predicting BraTS-PED-00087-000 
2025-07-10 23:33:59.132684: BraTS-PED-00087-000, shape torch.Size([4, 59, 59, 59]), rank 0 
2025-07-10 23:33:59.165002: predicting BraTS-PED-00088-000 
2025-07-10 23:33:59.182307: BraTS-PED-00088-000, shape torch.Size([4, 90, 90, 90]), rank 0 
2025-07-10 23:33:59.346620: predicting BraTS-PED-00089-000 
2025-07-10 23:33:59.363165: BraTS-PED-00089-000, shape torch.Size([4, 95, 95, 95]), rank 0 
2025-07-10 23:33:59.529234: predicting BraTS-PED-00091-000 
2025-07-10 23:33:59.584707: BraTS-PED-00091-000, shape torch.Size([4, 139, 139, 139]), rank 0 
2025-07-10 23:34:00.120554: predicting BraTS-PED-00092-000 
2025-07-10 23:34:00.134432: BraTS-PED-00092-000, shape torch.Size([4, 83, 83, 83]), rank 0 
2025-07-10 23:34:00.301513: predicting BraTS-PED-00093-000 
2025-07-10 23:34:00.328532: BraTS-PED-00093-000, shape torch.Size([4, 35, 190, 169]), rank 0 
2025-07-10 23:34:00.676234: predicting BraTS-PED-00094-000 
2025-07-10 23:34:00.680247: BraTS-PED-00094-000, shape torch.Size([4, 56, 56, 56]), rank 0 
2025-07-10 23:34:00.711789: predicting BraTS-PED-00095-000 
2025-07-10 23:34:00.717915: BraTS-PED-00095-000, shape torch.Size([4, 60, 60, 60]), rank 0 
2025-07-10 23:34:00.750203: predicting BraTS-PED-00096-000 
2025-07-10 23:34:00.768113: BraTS-PED-00096-000, shape torch.Size([4, 29, 184, 184]), rank 0 
2025-07-10 23:34:01.115202: predicting BraTS-PED-00097-000 
2025-07-10 23:34:01.136857: BraTS-PED-00097-000, shape torch.Size([4, 103, 103, 103]), rank 0 
2025-07-10 23:34:01.304216: predicting BraTS-PED-00098-000 
2025-07-10 23:34:01.314088: BraTS-PED-00098-000, shape torch.Size([4, 79, 79, 79]), rank 0 
2025-07-10 23:34:01.346317: predicting BraTS-PED-00099-000 
2025-07-10 23:34:01.353075: BraTS-PED-00099-000, shape torch.Size([4, 65, 65, 65]), rank 0 
2025-07-10 23:34:01.385641: predicting BraTS-PED-00100-000 
2025-07-10 23:34:01.442667: BraTS-PED-00100-000, shape torch.Size([4, 144, 144, 144]), rank 0 
2025-07-10 23:34:01.977763: predicting BraTS-PED-00101-000 
2025-07-10 23:34:01.999138: BraTS-PED-00101-000, shape torch.Size([4, 103, 103, 103]), rank 0 
2025-07-10 23:34:02.168089: predicting BraTS-PED-00102-000 
2025-07-10 23:34:02.170660: BraTS-PED-00102-000, shape torch.Size([4, 48, 48, 48]), rank 0 
2025-07-10 23:34:02.201027: predicting BraTS-PED-00103-000 
2025-07-10 23:34:02.235522: BraTS-PED-00103-000, shape torch.Size([4, 120, 120, 120]), rank 0 
2025-07-10 23:34:02.405761: predicting BraTS-PED-00104-000 
2025-07-10 23:34:02.483765: BraTS-PED-00104-000, shape torch.Size([4, 153, 153, 153]), rank 0 
2025-07-10 23:34:03.023155: predicting BraTS-PED-00105-000 
2025-07-10 23:34:03.033811: BraTS-PED-00105-000, shape torch.Size([4, 78, 78, 78]), rank 0 
2025-07-10 23:34:03.066388: predicting BraTS-PED-00106-000 
2025-07-10 23:34:03.075777: BraTS-PED-00106-000, shape torch.Size([4, 73, 73, 73]), rank 0 
2025-07-10 23:34:03.107628: predicting BraTS-PED-00107-000 
2025-07-10 23:34:03.124018: BraTS-PED-00107-000, shape torch.Size([4, 94, 94, 94]), rank 0 
2025-07-10 23:34:03.299264: predicting BraTS-PED-00108-000 
2025-07-10 23:34:03.321856: BraTS-PED-00108-000, shape torch.Size([4, 98, 98, 98]), rank 0 
2025-07-10 23:34:03.488668: predicting BraTS-PED-00109-000 
2025-07-10 23:34:03.506425: BraTS-PED-00109-000, shape torch.Size([4, 93, 93, 93]), rank 0 
2025-07-10 23:34:03.671759: predicting BraTS-PED-00110-000 
2025-07-10 23:34:03.685340: BraTS-PED-00110-000, shape torch.Size([4, 87, 87, 87]), rank 0 
2025-07-10 23:34:03.851712: predicting BraTS-PED-00112-000 
2025-07-10 23:34:03.860699: BraTS-PED-00112-000, shape torch.Size([4, 70, 70, 70]), rank 0 
2025-07-10 23:34:03.893993: predicting BraTS-PED-00113-000 
2025-07-10 23:34:03.898315: BraTS-PED-00113-000, shape torch.Size([4, 51, 51, 51]), rank 0 
2025-07-10 23:34:03.930428: predicting BraTS-PED-00114-000 
2025-07-10 23:34:03.938823: BraTS-PED-00114-000, shape torch.Size([4, 70, 70, 70]), rank 0 
2025-07-10 23:34:03.970314: predicting BraTS-PED-00115-000 
2025-07-10 23:34:03.980665: BraTS-PED-00115-000, shape torch.Size([4, 76, 76, 76]), rank 0 
2025-07-10 23:34:04.012119: predicting BraTS-PED-00116-000 
2025-07-10 23:34:04.029009: BraTS-PED-00116-000, shape torch.Size([4, 26, 181, 176]), rank 0 
2025-07-10 23:34:04.377893: predicting BraTS-PED-00117-000 
2025-07-10 23:34:04.403009: BraTS-PED-00117-000, shape torch.Size([4, 109, 109, 109]), rank 0 
2025-07-10 23:34:04.571182: predicting BraTS-PED-00118-000 
2025-07-10 23:34:04.581603: BraTS-PED-00118-000, shape torch.Size([4, 78, 78, 78]), rank 0 
2025-07-10 23:34:04.613489: predicting BraTS-PED-00119-000 
2025-07-10 23:34:04.639192: BraTS-PED-00119-000, shape torch.Size([4, 112, 112, 112]), rank 0 
2025-07-10 23:34:04.805423: predicting BraTS-PED-00120-000 
2025-07-10 23:34:04.813822: BraTS-PED-00120-000, shape torch.Size([4, 69, 69, 69]), rank 0 
2025-07-10 23:34:04.846766: predicting BraTS-PED-00121-000 
2025-07-10 23:34:04.890102: BraTS-PED-00121-000, shape torch.Size([4, 126, 126, 126]), rank 0 
2025-07-10 23:34:05.425348: predicting BraTS-PED-00122-000 
2025-07-10 23:34:05.470479: BraTS-PED-00122-000, shape torch.Size([4, 131, 131, 131]), rank 0 
2025-07-10 23:34:06.005029: predicting BraTS-PED-00123-000 
2025-07-10 23:34:06.013882: BraTS-PED-00123-000, shape torch.Size([4, 71, 71, 71]), rank 0 
2025-07-10 23:34:06.046242: predicting BraTS-PED-00124-000 
2025-07-10 23:34:06.060359: BraTS-PED-00124-000, shape torch.Size([4, 85, 85, 85]), rank 0 
2025-07-10 23:34:06.226915: predicting BraTS-PED-00125-000 
2025-07-10 23:34:06.243309: BraTS-PED-00125-000, shape torch.Size([4, 96, 96, 96]), rank 0 
2025-07-10 23:34:06.408194: predicting BraTS-PED-00126-000 
2025-07-10 23:34:06.421816: BraTS-PED-00126-000, shape torch.Size([4, 84, 84, 84]), rank 0 
2025-07-10 23:34:06.586345: predicting BraTS-PED-00127-000 
2025-07-10 23:34:06.603834: BraTS-PED-00127-000, shape torch.Size([4, 92, 92, 92]), rank 0 
2025-07-10 23:34:06.769224: predicting BraTS-PED-00128-000 
2025-07-10 23:34:06.773244: BraTS-PED-00128-000, shape torch.Size([4, 54, 54, 54]), rank 0 
2025-07-10 23:34:06.805502: predicting BraTS-PED-00129-000 
2025-07-10 23:34:06.815071: BraTS-PED-00129-000, shape torch.Size([4, 80, 80, 80]), rank 0 
2025-07-10 23:34:06.845469: predicting BraTS-PED-00130-000 
2025-07-10 23:34:06.872524: BraTS-PED-00130-000, shape torch.Size([4, 111, 111, 111]), rank 0 
2025-07-10 23:34:07.038746: predicting BraTS-PED-00131-000 
2025-07-10 23:34:07.051153: BraTS-PED-00131-000, shape torch.Size([4, 88, 88, 88]), rank 0 
2025-07-10 23:34:07.217407: predicting BraTS-PED-00132-000 
2025-07-10 23:34:07.221884: BraTS-PED-00132-000, shape torch.Size([4, 57, 57, 57]), rank 0 
2025-07-10 23:34:07.254138: predicting BraTS-PED-00133-000 
2025-07-10 23:34:07.278114: BraTS-PED-00133-000, shape torch.Size([4, 112, 112, 112]), rank 0 
2025-07-10 23:34:07.444600: predicting BraTS-PED-00134-000 
2025-07-10 23:34:07.451791: BraTS-PED-00134-000, shape torch.Size([4, 72, 72, 72]), rank 0 
2025-07-10 23:34:07.483768: predicting BraTS-PED-00135-000 
2025-07-10 23:34:07.521501: BraTS-PED-00135-000, shape torch.Size([4, 124, 124, 123]), rank 0 
2025-07-10 23:34:08.055021: predicting BraTS-PED-00136-000 
2025-07-10 23:34:08.079953: BraTS-PED-00136-000, shape torch.Size([4, 108, 108, 108]), rank 0 
2025-07-10 23:34:08.247245: predicting BraTS-PED-00137-000 
2025-07-10 23:34:08.259422: BraTS-PED-00137-000, shape torch.Size([4, 83, 83, 83]), rank 0 
2025-07-10 23:34:08.424842: predicting BraTS-PED-00138-000 
2025-07-10 23:34:08.444506: BraTS-PED-00138-000, shape torch.Size([4, 97, 97, 97]), rank 0 
2025-07-10 23:34:08.610573: predicting BraTS-PED-00139-000 
2025-07-10 23:34:08.620692: BraTS-PED-00139-000, shape torch.Size([4, 78, 78, 78]), rank 0 
2025-07-10 23:34:08.652809: predicting BraTS-PED-00140-000 
2025-07-10 23:34:08.657391: BraTS-PED-00140-000, shape torch.Size([4, 56, 56, 56]), rank 0 
2025-07-10 23:34:08.689587: predicting BraTS-PED-00141-000 
2025-07-10 23:34:08.710974: BraTS-PED-00141-000, shape torch.Size([4, 102, 102, 102]), rank 0 
2025-07-10 23:34:08.876110: predicting BraTS-PED-00142-000 
2025-07-10 23:34:08.889409: BraTS-PED-00142-000, shape torch.Size([4, 85, 85, 85]), rank 0 
2025-07-10 23:34:09.054173: predicting BraTS-PED-00143-000 
2025-07-10 23:34:09.071462: BraTS-PED-00143-000, shape torch.Size([4, 90, 90, 90]), rank 0 
2025-07-10 23:34:09.239925: predicting BraTS-PED-00144-000 
2025-07-10 23:34:09.266680: BraTS-PED-00144-000, shape torch.Size([4, 114, 114, 114]), rank 0 
2025-07-10 23:34:09.432832: predicting BraTS-PED-00145-000 
2025-07-10 23:34:09.441069: BraTS-PED-00145-000, shape torch.Size([4, 71, 71, 71]), rank 0 
2025-07-10 23:34:09.473798: predicting BraTS-PED-00146-000 
2025-07-10 23:34:09.491417: BraTS-PED-00146-000, shape torch.Size([4, 94, 94, 94]), rank 0 
2025-07-10 23:34:09.656511: predicting BraTS-PED-00147-000 
2025-07-10 23:34:09.660616: BraTS-PED-00147-000, shape torch.Size([4, 55, 55, 55]), rank 0 
2025-07-10 23:34:09.693241: predicting BraTS-PED-00148-000 
2025-07-10 23:34:09.714964: BraTS-PED-00148-000, shape torch.Size([4, 103, 103, 103]), rank 0 
2025-07-10 23:34:09.880924: predicting BraTS-PED-00149-000 
2025-07-10 23:34:09.888220: BraTS-PED-00149-000, shape torch.Size([4, 67, 67, 67]), rank 0 
2025-07-10 23:34:09.920748: predicting BraTS-PED-00150-000 
2025-07-10 23:34:09.933330: BraTS-PED-00150-000, shape torch.Size([4, 82, 82, 82]), rank 0 
2025-07-10 23:34:10.097145: predicting BraTS-PED-00151-000 
2025-07-10 23:34:10.104664: BraTS-PED-00151-000, shape torch.Size([4, 66, 66, 66]), rank 0 
2025-07-10 23:34:10.137149: predicting BraTS-PED-00152-000 
2025-07-10 23:34:10.145658: BraTS-PED-00152-000, shape torch.Size([4, 70, 70, 70]), rank 0 
2025-07-10 23:34:10.177604: predicting BraTS-PED-00153-000 
2025-07-10 23:34:10.213592: BraTS-PED-00153-000, shape torch.Size([4, 121, 121, 121]), rank 0 
2025-07-10 23:34:10.745595: predicting BraTS-PED-00154-000 
2025-07-10 23:34:10.782108: BraTS-PED-00154-000, shape torch.Size([4, 124, 124, 124]), rank 0 
2025-07-10 23:34:11.315114: predicting BraTS-PED-00155-000 
2025-07-10 23:34:11.331360: BraTS-PED-00155-000, shape torch.Size([4, 91, 91, 91]), rank 0 
2025-07-10 23:34:11.498584: predicting BraTS-PED-00156-000 
2025-07-10 23:34:11.544091: BraTS-PED-00156-000, shape torch.Size([4, 130, 130, 126]), rank 0 
2025-07-10 23:34:12.079781: predicting BraTS-PED-00157-000 
2025-07-10 23:34:12.085002: BraTS-PED-00157-000, shape torch.Size([4, 57, 57, 57]), rank 0 
2025-07-10 23:34:12.116838: predicting BraTS-PED-00158-000 
2025-07-10 23:34:12.125039: BraTS-PED-00158-000, shape torch.Size([4, 69, 69, 69]), rank 0 
2025-07-10 23:34:12.157215: predicting BraTS-PED-00159-000 
2025-07-10 23:34:12.167110: BraTS-PED-00159-000, shape torch.Size([4, 78, 78, 78]), rank 0 
2025-07-10 23:34:12.198911: predicting BraTS-PED-00160-000 
2025-07-10 23:34:12.204570: BraTS-PED-00160-000, shape torch.Size([4, 59, 59, 59]), rank 0 
2025-07-10 23:34:12.235989: predicting BraTS-PED-00161-000 
2025-07-10 23:34:12.241992: BraTS-PED-00161-000, shape torch.Size([4, 62, 62, 62]), rank 0 
2025-07-10 23:34:12.273640: predicting BraTS-PED-00162-000 
2025-07-10 23:34:12.279302: BraTS-PED-00162-000, shape torch.Size([4, 61, 61, 61]), rank 0 
2025-07-10 23:34:12.311485: predicting BraTS-PED-00163-000 
2025-07-10 23:34:12.353679: BraTS-PED-00163-000, shape torch.Size([4, 135, 135, 128]), rank 0 
2025-07-10 23:34:12.885622: predicting BraTS-PED-00164-000 
2025-07-10 23:34:12.889080: BraTS-PED-00164-000, shape torch.Size([4, 48, 48, 48]), rank 0 
2025-07-10 23:34:12.919760: predicting BraTS-PED-00165-000 
2025-07-10 23:34:12.925393: BraTS-PED-00165-000, shape torch.Size([4, 63, 63, 63]), rank 0 
2025-07-10 23:34:12.956889: predicting BraTS-PED-00166-000 
2025-07-10 23:34:12.964856: BraTS-PED-00166-000, shape torch.Size([4, 69, 69, 69]), rank 0 
2025-07-10 23:34:12.997051: predicting BraTS-PED-00167-000 
2025-07-10 23:34:13.026356: BraTS-PED-00167-000, shape torch.Size([4, 116, 116, 116]), rank 0 
2025-07-10 23:34:13.194331: predicting BraTS-PED-00168-000 
2025-07-10 23:34:13.202458: BraTS-PED-00168-000, shape torch.Size([4, 70, 70, 70]), rank 0 
2025-07-10 23:34:13.234353: predicting BraTS-PED-00169-000 
2025-07-10 23:34:13.240237: BraTS-PED-00169-000, shape torch.Size([4, 64, 64, 64]), rank 0 
2025-07-10 23:34:13.271932: predicting BraTS-PED-00170-000 
2025-07-10 23:34:13.320802: BraTS-PED-00170-000, shape torch.Size([4, 129, 129, 129]), rank 0 
2025-07-10 23:34:13.852916: predicting BraTS-PED-00171-000 
2025-07-10 23:34:13.865571: BraTS-PED-00171-000, shape torch.Size([4, 81, 81, 81]), rank 0 
2025-07-10 23:34:14.032830: predicting BraTS-PED-00172-000 
2025-07-10 23:34:14.049137: BraTS-PED-00172-000, shape torch.Size([4, 93, 93, 93]), rank 0 
2025-07-10 23:34:14.215066: predicting BraTS-PED-00173-000 
2025-07-10 23:34:14.222221: BraTS-PED-00173-000, shape torch.Size([4, 65, 65, 65]), rank 0 
2025-07-10 23:34:14.254296: predicting BraTS-PED-00174-000 
2025-07-10 23:34:14.275394: BraTS-PED-00174-000, shape torch.Size([4, 104, 104, 104]), rank 0 
2025-07-10 23:34:14.440976: predicting BraTS-PED-00175-000 
2025-07-10 23:34:14.446591: BraTS-PED-00175-000, shape torch.Size([4, 64, 64, 64]), rank 0 
2025-07-10 23:34:14.478738: predicting BraTS-PED-00176-000 
2025-07-10 23:34:14.525561: BraTS-PED-00176-000, shape torch.Size([4, 134, 134, 124]), rank 0 
2025-07-10 23:34:15.058669: predicting BraTS-PED-00177-000 
2025-07-10 23:34:15.071828: BraTS-PED-00177-000, shape torch.Size([4, 82, 82, 82]), rank 0 
2025-07-10 23:34:15.239037: predicting BraTS-PED-00178-000 
2025-07-10 23:34:15.248950: BraTS-PED-00178-000, shape torch.Size([4, 78, 78, 78]), rank 0 
2025-07-10 23:34:15.280621: predicting BraTS-PED-00179-000 
2025-07-10 23:34:15.312576: BraTS-PED-00179-000, shape torch.Size([4, 115, 115, 115]), rank 0 
2025-07-10 23:34:15.478982: predicting BraTS-PED-00180-000 
2025-07-10 23:34:15.483901: BraTS-PED-00180-000, shape torch.Size([4, 57, 57, 57]), rank 0 
2025-07-10 23:34:15.514624: predicting BraTS-PED-00181-000 
2025-07-10 23:34:15.519421: BraTS-PED-00181-000, shape torch.Size([4, 58, 58, 58]), rank 0 
2025-07-10 23:34:15.551765: predicting BraTS-PED-00182-000 
2025-07-10 23:34:15.607597: BraTS-PED-00182-000, shape torch.Size([4, 144, 144, 144]), rank 0 
2025-07-10 23:34:16.143335: predicting BraTS-PED-00183-000 
2025-07-10 23:34:16.151166: BraTS-PED-00183-000, shape torch.Size([4, 72, 72, 72]), rank 0 
2025-07-10 23:34:16.183728: predicting BraTS-PED-00184-000 
2025-07-10 23:34:16.191442: BraTS-PED-00184-000, shape torch.Size([4, 67, 67, 67]), rank 0 
2025-07-10 23:34:16.223321: predicting BraTS-PED-00185-000 
2025-07-10 23:34:16.255173: BraTS-PED-00185-000, shape torch.Size([4, 117, 117, 117]), rank 0 
2025-07-10 23:34:16.421963: predicting BraTS-PED-00186-000 
2025-07-10 23:34:16.479929: BraTS-PED-00186-000, shape torch.Size([4, 141, 141, 141]), rank 0 
2025-07-10 23:34:17.014991: predicting BraTS-PED-00187-000 
2025-07-10 23:34:17.020725: BraTS-PED-00187-000, shape torch.Size([4, 60, 60, 60]), rank 0 
2025-07-10 23:34:17.052788: predicting BraTS-PED-00188-000 
2025-07-10 23:34:17.069072: BraTS-PED-00188-000, shape torch.Size([4, 92, 92, 92]), rank 0 
2025-07-10 23:34:17.234850: predicting BraTS-PED-00189-000 
2025-07-10 23:34:17.238804: BraTS-PED-00189-000, shape torch.Size([4, 52, 52, 52]), rank 0 
2025-07-10 23:34:17.270575: predicting BraTS-PED-00190-000 
2025-07-10 23:34:17.284339: BraTS-PED-00190-000, shape torch.Size([4, 83, 83, 83]), rank 0 
2025-07-10 23:34:17.448308: predicting BraTS-PED-00191-000 
2025-07-10 23:34:17.458088: BraTS-PED-00191-000, shape torch.Size([4, 73, 73, 73]), rank 0 
2025-07-10 23:34:17.489985: predicting BraTS-PED-00192-000 
2025-07-10 23:34:17.497007: BraTS-PED-00192-000, shape torch.Size([4, 68, 68, 68]), rank 0 
2025-07-10 23:34:17.529365: predicting BraTS-PED-00193-000 
2025-07-10 23:34:17.540120: BraTS-PED-00193-000, shape torch.Size([4, 75, 75, 75]), rank 0 
2025-07-10 23:34:17.571800: predicting BraTS-PED-00194-000 
2025-07-10 23:34:17.575264: BraTS-PED-00194-000, shape torch.Size([4, 49, 49, 49]), rank 0 
2025-07-10 23:34:17.607428: predicting BraTS-PED-00195-000 
2025-07-10 23:34:17.614969: BraTS-PED-00195-000, shape torch.Size([4, 66, 66, 66]), rank 0 
2025-07-10 23:34:17.646583: predicting BraTS-PED-00196-000 
2025-07-10 23:34:17.650714: BraTS-PED-00196-000, shape torch.Size([4, 55, 55, 55]), rank 0 
2025-07-10 23:34:17.682734: predicting BraTS-PED-00197-000 
2025-07-10 23:34:17.690920: BraTS-PED-00197-000, shape torch.Size([4, 69, 69, 69]), rank 0 
2025-07-10 23:34:17.722933: predicting BraTS-PED-00198-000 
2025-07-10 23:34:17.728705: BraTS-PED-00198-000, shape torch.Size([4, 61, 61, 61]), rank 0 
2025-07-10 23:34:17.760963: predicting BraTS-PED-00199-000 
2025-07-10 23:34:17.766370: BraTS-PED-00199-000, shape torch.Size([4, 59, 59, 59]), rank 0 
2025-07-10 23:34:17.797599: predicting BraTS-PED-00200-000 
2025-07-10 23:34:17.803924: BraTS-PED-00200-000, shape torch.Size([4, 63, 63, 63]), rank 0 
2025-07-10 23:34:17.836105: predicting BraTS-PED-00201-000 
2025-07-10 23:34:17.846154: BraTS-PED-00201-000, shape torch.Size([4, 73, 73, 73]), rank 0 
2025-07-10 23:34:17.877128: predicting BraTS-PED-00202-000 
2025-07-10 23:34:17.883299: BraTS-PED-00202-000, shape torch.Size([4, 63, 63, 63]), rank 0 
2025-07-10 23:34:17.915902: predicting BraTS-PED-00203-000 
2025-07-10 23:34:17.926891: BraTS-PED-00203-000, shape torch.Size([4, 79, 79, 79]), rank 0 
2025-07-10 23:34:17.958316: predicting BraTS-PED-00204-000 
2025-07-10 23:34:17.961375: BraTS-PED-00204-000, shape torch.Size([4, 48, 48, 48]), rank 0 
2025-07-10 23:34:17.993479: predicting BraTS-PED-00205-000 
2025-07-10 23:34:18.001155: BraTS-PED-00205-000, shape torch.Size([4, 66, 66, 66]), rank 0 
2025-07-10 23:34:18.037457: predicting BraTS-PED-00206-000 
2025-07-10 23:34:18.043646: BraTS-PED-00206-000, shape torch.Size([4, 58, 58, 58]), rank 0 
2025-07-10 23:34:18.076073: predicting BraTS-PED-00207-000 
2025-07-10 23:34:18.086188: BraTS-PED-00207-000, shape torch.Size([4, 74, 74, 74]), rank 0 
2025-07-10 23:34:18.117366: predicting BraTS-PED-00208-000 
2025-07-10 23:34:18.123312: BraTS-PED-00208-000, shape torch.Size([4, 61, 61, 61]), rank 0 
2025-07-10 23:34:18.155807: predicting BraTS-PED-00209-000 
2025-07-10 23:34:18.163404: BraTS-PED-00209-000, shape torch.Size([4, 66, 66, 66]), rank 0 
2025-07-10 23:34:18.195072: predicting BraTS-PED-00210-000 
2025-07-10 23:34:18.201933: BraTS-PED-00210-000, shape torch.Size([4, 65, 65, 65]), rank 0 
2025-07-10 23:34:18.234455: predicting BraTS-PED-00211-000 
2025-07-10 23:34:18.305076: BraTS-PED-00211-000, shape torch.Size([4, 153, 153, 153]), rank 0 
2025-07-10 23:34:18.838572: predicting BraTS-PED-00212-000 
2025-07-10 23:34:18.848369: BraTS-PED-00212-000, shape torch.Size([4, 73, 73, 73]), rank 0 
2025-07-10 23:34:18.881814: predicting BraTS-PED-00213-000 
2025-07-10 23:34:18.889811: BraTS-PED-00213-000, shape torch.Size([4, 68, 68, 68]), rank 0 
2025-07-10 23:34:18.921051: predicting BraTS-PED-00214-000 
2025-07-10 23:34:18.929740: BraTS-PED-00214-000, shape torch.Size([4, 68, 68, 68]), rank 0 
2025-07-10 23:34:18.961338: predicting BraTS-PED-00215-000 
2025-07-10 23:34:18.969306: BraTS-PED-00215-000, shape torch.Size([4, 70, 70, 70]), rank 0 
2025-07-10 23:34:19.001421: predicting BraTS-PED-00216-000 
2025-07-10 23:34:19.009882: BraTS-PED-00216-000, shape torch.Size([4, 69, 69, 69]), rank 0 
2025-07-10 23:34:19.042376: predicting BraTS-PED-00217-000 
2025-07-10 23:34:19.050304: BraTS-PED-00217-000, shape torch.Size([4, 69, 69, 69]), rank 0 
2025-07-10 23:34:19.082085: predicting BraTS-PED-00218-000 
2025-07-10 23:34:19.084753: BraTS-PED-00218-000, shape torch.Size([4, 48, 48, 48]), rank 0 
2025-07-10 23:34:19.117830: predicting BraTS-PED-00219-000 
2025-07-10 23:34:19.122831: BraTS-PED-00219-000, shape torch.Size([4, 59, 59, 59]), rank 0 
2025-07-10 23:34:19.154357: predicting BraTS-PED-00220-000 
2025-07-10 23:34:19.158360: BraTS-PED-00220-000, shape torch.Size([4, 56, 56, 56]), rank 0 
2025-07-10 23:34:19.191875: predicting BraTS-PED-00221-000 
2025-07-10 23:34:19.199324: BraTS-PED-00221-000, shape torch.Size([4, 65, 65, 65]), rank 0 
2025-07-10 23:34:19.229975: predicting BraTS-PED-00222-000 
2025-07-10 23:34:19.237833: BraTS-PED-00222-000, shape torch.Size([4, 68, 68, 68]), rank 0 
2025-07-10 23:34:19.269759: predicting BraTS-PED-00223-000 
2025-07-10 23:34:19.273433: BraTS-PED-00223-000, shape torch.Size([4, 50, 50, 50]), rank 0 
2025-07-10 23:34:19.305195: predicting BraTS-PED-00224-000 
2025-07-10 23:34:19.332963: BraTS-PED-00224-000, shape torch.Size([4, 107, 107, 107]), rank 0 
2025-07-10 23:34:19.497641: predicting BraTS-PED-00225-000 
2025-07-10 23:34:19.501728: BraTS-PED-00225-000, shape torch.Size([4, 49, 49, 49]), rank 0 
2025-07-10 23:34:19.531815: predicting BraTS-PED-00226-000 
2025-07-10 23:34:19.537899: BraTS-PED-00226-000, shape torch.Size([4, 63, 63, 63]), rank 0 
2025-07-10 23:34:19.570226: predicting BraTS-PED-00227-000 
2025-07-10 23:34:19.574926: BraTS-PED-00227-000, shape torch.Size([4, 57, 57, 57]), rank 0 
2025-07-10 23:34:19.606751: predicting BraTS-PED-00228-000 
2025-07-10 23:34:19.614674: BraTS-PED-00228-000, shape torch.Size([4, 65, 65, 65]), rank 0 
2025-07-10 23:34:19.646789: predicting BraTS-PED-00229-000 
2025-07-10 23:34:19.652089: BraTS-PED-00229-000, shape torch.Size([4, 60, 60, 60]), rank 0 
2025-07-10 23:34:19.685565: predicting BraTS-PED-00230-000 
2025-07-10 23:34:19.695381: BraTS-PED-00230-000, shape torch.Size([4, 74, 74, 74]), rank 0 
2025-07-10 23:34:19.728220: predicting BraTS-PED-00231-000 
2025-07-10 23:34:19.736710: BraTS-PED-00231-000, shape torch.Size([4, 70, 70, 70]), rank 0 
2025-07-10 23:34:19.768592: predicting BraTS-PED-00232-000 
2025-07-10 23:34:19.778555: BraTS-PED-00232-000, shape torch.Size([4, 74, 74, 74]), rank 0 
2025-07-10 23:34:19.811364: predicting BraTS-PED-00233-000 
2025-07-10 23:34:19.818378: BraTS-PED-00233-000, shape torch.Size([4, 65, 65, 65]), rank 0 
2025-07-10 23:34:19.850771: predicting BraTS-PED-00234-000 
2025-07-10 23:34:19.860453: BraTS-PED-00234-000, shape torch.Size([4, 73, 73, 73]), rank 0 
2025-07-10 23:34:19.892481: predicting BraTS-PED-00235-000 
2025-07-10 23:34:19.903012: BraTS-PED-00235-000, shape torch.Size([4, 76, 76, 76]), rank 0 
2025-07-10 23:34:19.936739: predicting BraTS-PED-00236-000 
2025-07-10 23:34:19.988622: BraTS-PED-00236-000, shape torch.Size([4, 135, 135, 135]), rank 0 
2025-07-10 23:34:20.522242: predicting BraTS-PED-00237-000 
2025-07-10 23:34:20.530815: BraTS-PED-00237-000, shape torch.Size([4, 67, 67, 67]), rank 0 
2025-07-10 23:34:20.563051: predicting BraTS-PED-00238-000 
2025-07-10 23:34:20.568641: BraTS-PED-00238-000, shape torch.Size([4, 63, 63, 63]), rank 0 
2025-07-10 23:34:20.601373: predicting BraTS-PED-00239-000 
2025-07-10 23:34:20.612322: BraTS-PED-00239-000, shape torch.Size([4, 79, 79, 79]), rank 0 
2025-07-10 23:34:20.644369: predicting BraTS-PED-00240-000 
2025-07-10 23:34:20.653390: BraTS-PED-00240-000, shape torch.Size([4, 73, 73, 73]), rank 0 
2025-07-10 23:34:20.686338: predicting BraTS-PED-00241-000 
2025-07-10 23:34:20.694837: BraTS-PED-00241-000, shape torch.Size([4, 70, 70, 70]), rank 0 
2025-07-10 23:34:20.727770: predicting BraTS-PED-00242-000 
2025-07-10 23:34:20.733180: BraTS-PED-00242-000, shape torch.Size([4, 60, 60, 60]), rank 0 
2025-07-10 23:34:20.765793: predicting BraTS-PED-00243-000 
2025-07-10 23:34:20.776125: BraTS-PED-00243-000, shape torch.Size([4, 73, 73, 73]), rank 0 
2025-07-10 23:34:20.807629: predicting BraTS-PED-00244-000 
2025-07-10 23:34:20.816190: BraTS-PED-00244-000, shape torch.Size([4, 71, 71, 71]), rank 0 
2025-07-10 23:34:20.848063: predicting BraTS-PED-00245-000 
2025-07-10 23:34:20.856329: BraTS-PED-00245-000, shape torch.Size([4, 68, 68, 68]), rank 0 
2025-07-10 23:34:20.889089: predicting BraTS-PED-00246-000 
2025-07-10 23:34:20.897173: BraTS-PED-00246-000, shape torch.Size([4, 72, 72, 72]), rank 0 
2025-07-10 23:34:20.929736: predicting BraTS-PED-00247-000 
2025-07-10 23:34:20.932758: BraTS-PED-00247-000, shape torch.Size([4, 48, 48, 48]), rank 0 
2025-07-10 23:34:20.965393: predicting BraTS-PED-00248-000 
2025-07-10 23:34:20.970811: BraTS-PED-00248-000, shape torch.Size([4, 58, 58, 58]), rank 0 
2025-07-10 23:34:21.002728: predicting BraTS-PED-00249-000 
2025-07-10 23:34:21.010791: BraTS-PED-00249-000, shape torch.Size([4, 69, 69, 69]), rank 0 
2025-07-10 23:34:21.042914: predicting BraTS-PED-00250-000 
2025-07-10 23:34:21.051053: BraTS-PED-00250-000, shape torch.Size([4, 71, 71, 71]), rank 0 
2025-07-10 23:34:21.083590: predicting BraTS-PED-00251-000 
2025-07-10 23:34:21.088846: BraTS-PED-00251-000, shape torch.Size([4, 59, 59, 59]), rank 0 
2025-07-10 23:34:21.121452: predicting BraTS-PED-00252-000 
2025-07-10 23:34:21.129897: BraTS-PED-00252-000, shape torch.Size([4, 67, 67, 67]), rank 0 
2025-07-10 23:34:21.162132: predicting BraTS-PED-00253-000 
2025-07-10 23:34:21.167719: BraTS-PED-00253-000, shape torch.Size([4, 58, 58, 58]), rank 0 
2025-07-10 23:34:21.200578: predicting BraTS-PED-00254-000 
2025-07-10 23:34:21.207731: BraTS-PED-00254-000, shape torch.Size([4, 66, 66, 66]), rank 0 
2025-07-10 23:34:21.239306: predicting BraTS-PED-00255-000 
2025-07-10 23:34:21.256049: BraTS-PED-00255-000, shape torch.Size([4, 93, 93, 93]), rank 0 
2025-07-10 23:34:21.422872: predicting BraTS-PED-00256-000 
2025-07-10 23:34:21.432374: BraTS-PED-00256-000, shape torch.Size([4, 73, 73, 73]), rank 0 
2025-07-10 23:34:21.466414: predicting BraTS-PED-00257-000 
2025-07-10 23:34:21.471848: BraTS-PED-00257-000, shape torch.Size([4, 58, 58, 58]), rank 0 
2025-07-10 23:34:21.504130: predicting BraTS-PED-00258-000 
2025-07-10 23:34:21.512174: BraTS-PED-00258-000, shape torch.Size([4, 68, 68, 68]), rank 0 
2025-07-10 23:34:21.544127: predicting BraTS-PED-00259-000 
2025-07-10 23:34:21.548025: BraTS-PED-00259-000, shape torch.Size([4, 53, 53, 53]), rank 0 
2025-07-10 23:34:21.580385: predicting BraTS-PED-00260-000 
2025-07-10 23:34:21.585878: BraTS-PED-00260-000, shape torch.Size([4, 64, 64, 64]), rank 0 
2025-07-10 23:34:21.618073: predicting BraTS-PED-00261-000 
2025-07-10 23:34:21.628039: BraTS-PED-00261-000, shape torch.Size([4, 80, 80, 80]), rank 0 
2025-07-10 23:34:21.658932: predicting BraTS-PED-00262-000 
2025-07-10 23:34:21.666329: BraTS-PED-00262-000, shape torch.Size([4, 66, 66, 66]), rank 0 
2025-07-10 23:34:21.698896: predicting BraTS-PED-00263-000 
2025-07-10 23:34:21.709279: BraTS-PED-00263-000, shape torch.Size([4, 75, 75, 75]), rank 0 
2025-07-10 23:34:21.741297: predicting BraTS-PED-00264-000 
2025-07-10 23:34:21.746686: BraTS-PED-00264-000, shape torch.Size([4, 60, 60, 60]), rank 0 
2025-07-10 23:34:21.778746: predicting BraTS-PED-00265-000 
2025-07-10 23:34:21.782898: BraTS-PED-00265-000, shape torch.Size([4, 52, 52, 52]), rank 0 
2025-07-10 23:34:21.814583: predicting BraTS-PED-00266-000 
2025-07-10 23:34:21.822676: BraTS-PED-00266-000, shape torch.Size([4, 67, 67, 67]), rank 0 
2025-07-10 23:34:26.744925: Validation complete 
2025-07-10 23:34:26.745020: Mean Validation Dice:  0.4315768812630586 
