
#######################################################################
Please cite the following paper when using nnU-Net:
Isensee, F., Jaeger, P. F., Kohl, S. A., Petersen, J., & Maier-Hein, K. H. (2021). nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation. Nature methods, 18(2), 203-211.
#######################################################################
 
2025-07-09 20:50:08.115848: Using torch.compile... 
2025-07-09 20:50:09.438979: do_dummy_2d_data_aug: False 

This is the configuration used by this training:
Configuration name: 3d_fullres
 {'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 10, 'patch_size': [80, 80, 80], 'median_image_size_in_voxels': [73.0, 73.0, 73.0], 'spacing': [1.0, 1.0, 1.0], 'normalization_schemes': ['ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization', 'ZScoreNormalization'], 'use_mask_for_norm': [False, False, False, False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 5, 'features_per_stage': [32, 64, 128, 256, 320], 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': [[3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3], [3, 3, 3]], 'strides': [[1, 1, 1], [2, 2, 2], [2, 2, 2], [2, 2, 2], [2, 2, 2]], 'n_conv_per_stage': [2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2], 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ['conv_op', 'norm_op', 'dropout_op', 'nonlin']}, 'batch_dice': False} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset009_BraTS2025_PedCroppedLabel3', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [1.0, 1.0, 1.0], 'original_median_shape_after_transp': [73, 73, 73], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 3455.415771484375, 'mean': 472.0268231958261, 'median': 292.0391845703125, 'min': 0.0, 'percentile_00_5': 44.34764862060547, 'percentile_99_5': 2736.933837890625, 'std': 488.53236080460067}, '1': {'max': 10593.279296875, 'mean': 487.2744437640218, 'median': 282.50396728515625, 'min': 0.0, 'percentile_00_5': 24.600265502929688, 'percentile_99_5': 3545.998046875, 'std': 624.748188437947}, '2': {'max': 8873.6279296875, 'mean': 1197.5724986966297, 'median': 980.4761352539062, 'min': 4.2663044929504395, 'percentile_00_5': 67.33873748779297, 'percentile_99_5': 5343.71044921875, 'std': 918.9832846403094}, '3': {'max': 4854.6728515625, 'mean': 553.4773275417879, 'median': 415.9311218261719, 'min': 0.0, 'percentile_00_5': 24.041622161865234, 'percentile_99_5': 3584.040771484375, 'std': 522.0095715485086}}} 
 
2025-07-09 20:50:14.642891: Unable to plot network architecture: nnUNet_compile is enabled! 
2025-07-09 20:50:14.658933:  
2025-07-09 20:50:14.659084: Epoch 0 
2025-07-09 20:50:14.659451: Current learning rate: 0.01 
2025-07-09 20:51:08.046128: train_loss -0.0121 
2025-07-09 20:51:08.046683: val_loss -0.0663 
2025-07-09 20:51:08.046826: Pseudo dice [np.float32(0.3401)] 
2025-07-09 20:51:08.046992: Epoch time: 53.39 s 
2025-07-09 20:51:08.047071: Yayy! New best EMA pseudo Dice: 0.3400999903678894 
2025-07-09 20:51:09.525204:  
2025-07-09 20:51:09.525357: Epoch 1 
2025-07-09 20:51:09.525491: Current learning rate: 0.00999 
2025-07-09 20:51:57.002988: train_loss -0.0686 
2025-07-09 20:51:57.003377: val_loss -0.0706 
2025-07-09 20:51:57.003457: Pseudo dice [np.float32(0.2715)] 
2025-07-09 20:51:57.003574: Epoch time: 47.48 s 
2025-07-09 20:51:58.120067:  
2025-07-09 20:51:58.120418: Epoch 2 
2025-07-09 20:51:58.120557: Current learning rate: 0.00998 
2025-07-09 20:52:45.510615: train_loss -0.0972 
2025-07-09 20:52:45.511550: val_loss -0.0877 
2025-07-09 20:52:45.511649: Pseudo dice [np.float32(0.3563)] 
2025-07-09 20:52:45.511839: Epoch time: 47.39 s 
2025-07-09 20:52:46.749074:  
2025-07-09 20:52:46.749390: Epoch 3 
2025-07-09 20:52:46.749498: Current learning rate: 0.00997 
2025-07-09 20:53:34.397521: train_loss -0.0981 
2025-07-09 20:53:34.398116: val_loss -0.0998 
2025-07-09 20:53:34.398216: Pseudo dice [np.float32(0.4115)] 
2025-07-09 20:53:34.398348: Epoch time: 47.65 s 
2025-07-09 20:53:34.398437: Yayy! New best EMA pseudo Dice: 0.34310001134872437 
2025-07-09 20:53:36.416949:  
2025-07-09 20:53:36.417262: Epoch 4 
2025-07-09 20:53:36.417386: Current learning rate: 0.00996 
2025-07-09 20:54:24.377884: train_loss -0.1053 
2025-07-09 20:54:24.378307: val_loss -0.1129 
2025-07-09 20:54:24.378468: Pseudo dice [np.float32(0.5102)] 
2025-07-09 20:54:24.378590: Epoch time: 47.96 s 
2025-07-09 20:54:24.378672: Yayy! New best EMA pseudo Dice: 0.3598000109195709 
2025-07-09 20:54:26.420947:  
2025-07-09 20:54:26.421155: Epoch 5 
2025-07-09 20:54:26.421331: Current learning rate: 0.00995 
2025-07-09 20:55:14.169587: train_loss -0.126 
2025-07-09 20:55:14.170246: val_loss -0.1245 
2025-07-09 20:55:14.170344: Pseudo dice [np.float32(0.5438)] 
2025-07-09 20:55:14.170456: Epoch time: 47.75 s 
2025-07-09 20:55:14.170537: Yayy! New best EMA pseudo Dice: 0.3781999945640564 
2025-07-09 20:55:16.361414:  
2025-07-09 20:55:16.362026: Epoch 6 
2025-07-09 20:55:16.362235: Current learning rate: 0.00995 
2025-07-09 20:56:03.183772: train_loss -0.1182 
2025-07-09 20:56:03.184427: val_loss -0.1304 
2025-07-09 20:56:03.184527: Pseudo dice [np.float32(0.5463)] 
2025-07-09 20:56:03.184671: Epoch time: 46.82 s 
2025-07-09 20:56:03.184753: Yayy! New best EMA pseudo Dice: 0.39500001072883606 
2025-07-09 20:56:05.266625:  
2025-07-09 20:56:05.266903: Epoch 7 
2025-07-09 20:56:05.267031: Current learning rate: 0.00994 
2025-07-09 20:56:51.728689: train_loss -0.1406 
2025-07-09 20:56:51.729235: val_loss -0.1407 
2025-07-09 20:56:51.729337: Pseudo dice [np.float32(0.6144)] 
2025-07-09 20:56:51.729451: Epoch time: 46.46 s 
2025-07-09 20:56:51.729527: Yayy! New best EMA pseudo Dice: 0.4169999957084656 
2025-07-09 20:56:53.768311:  
2025-07-09 20:56:53.768619: Epoch 8 
2025-07-09 20:56:53.768885: Current learning rate: 0.00993 
2025-07-09 20:57:40.760561: train_loss -0.1368 
2025-07-09 20:57:40.761091: val_loss -0.155 
2025-07-09 20:57:40.761209: Pseudo dice [np.float32(0.6808)] 
2025-07-09 20:57:40.761328: Epoch time: 46.99 s 
2025-07-09 20:57:40.761480: Yayy! New best EMA pseudo Dice: 0.44339999556541443 
2025-07-09 20:57:42.954359:  
2025-07-09 20:57:42.954585: Epoch 9 
2025-07-09 20:57:42.954713: Current learning rate: 0.00992 
2025-07-09 20:58:29.797248: train_loss -0.1377 
2025-07-09 20:58:29.797900: val_loss -0.1296 
2025-07-09 20:58:29.797978: Pseudo dice [np.float32(0.4678)] 
2025-07-09 20:58:29.798127: Epoch time: 46.84 s 
2025-07-09 20:58:29.798203: Yayy! New best EMA pseudo Dice: 0.4458000063896179 
2025-07-09 20:58:31.808226:  
2025-07-09 20:58:31.808633: Epoch 10 
2025-07-09 20:58:31.808758: Current learning rate: 0.00991 
2025-07-09 20:59:18.512854: train_loss -0.1496 
2025-07-09 20:59:18.513154: val_loss -0.1395 
2025-07-09 20:59:18.513227: Pseudo dice [np.float32(0.6289)] 
2025-07-09 20:59:18.513412: Epoch time: 46.71 s 
2025-07-09 20:59:18.513616: Yayy! New best EMA pseudo Dice: 0.4641000032424927 
2025-07-09 20:59:20.616215:  
2025-07-09 20:59:20.616491: Epoch 11 
2025-07-09 20:59:20.616756: Current learning rate: 0.0099 
2025-07-09 21:00:07.281432: train_loss -0.1345 
2025-07-09 21:00:07.281819: val_loss -0.1554 
2025-07-09 21:00:07.281915: Pseudo dice [np.float32(0.7107)] 
2025-07-09 21:00:07.282011: Epoch time: 46.67 s 
2025-07-09 21:00:07.282078: Yayy! New best EMA pseudo Dice: 0.4887999892234802 
2025-07-09 21:00:09.859464:  
2025-07-09 21:00:09.859992: Epoch 12 
2025-07-09 21:00:09.860120: Current learning rate: 0.00989 
2025-07-09 21:00:55.635508: train_loss -0.1447 
2025-07-09 21:00:55.635991: val_loss -0.11 
2025-07-09 21:00:55.636086: Pseudo dice [np.float32(0.6514)] 
2025-07-09 21:00:55.636193: Epoch time: 45.78 s 
2025-07-09 21:00:55.636274: Yayy! New best EMA pseudo Dice: 0.5049999952316284 
2025-07-09 21:00:57.699798:  
2025-07-09 21:00:57.700187: Epoch 13 
2025-07-09 21:00:57.700312: Current learning rate: 0.00988 
2025-07-09 21:01:43.587499: train_loss -0.1485 
2025-07-09 21:01:43.587858: val_loss -0.1658 
2025-07-09 21:01:43.587933: Pseudo dice [np.float32(0.6799)] 
2025-07-09 21:01:43.588028: Epoch time: 45.89 s 
2025-07-09 21:01:43.588099: Yayy! New best EMA pseudo Dice: 0.5224999785423279 
2025-07-09 21:01:45.765018:  
2025-07-09 21:01:45.765257: Epoch 14 
2025-07-09 21:01:45.765383: Current learning rate: 0.00987 
2025-07-09 21:02:31.095991: train_loss -0.1487 
2025-07-09 21:02:31.098508: val_loss -0.1721 
2025-07-09 21:02:31.099734: Pseudo dice [np.float32(0.6251)] 
2025-07-09 21:02:31.100223: Epoch time: 45.33 s 
2025-07-09 21:02:31.101098: Yayy! New best EMA pseudo Dice: 0.532800018787384 
2025-07-09 21:02:33.297555:  
2025-07-09 21:02:33.297972: Epoch 15 
2025-07-09 21:02:33.298152: Current learning rate: 0.00986 
2025-07-09 21:03:18.898563: train_loss -0.1626 
2025-07-09 21:03:18.899724: val_loss -0.1751 
2025-07-09 21:03:18.900008: Pseudo dice [np.float32(0.7041)] 
2025-07-09 21:03:18.900219: Epoch time: 45.6 s 
2025-07-09 21:03:18.900319: Yayy! New best EMA pseudo Dice: 0.5498999953269958 
2025-07-09 21:03:20.908906:  
2025-07-09 21:03:20.909259: Epoch 16 
2025-07-09 21:03:20.909376: Current learning rate: 0.00986 
2025-07-09 21:04:06.997907: train_loss -0.1584 
2025-07-09 21:04:06.998333: val_loss -0.161 
2025-07-09 21:04:06.998492: Pseudo dice [np.float32(0.6837)] 
2025-07-09 21:04:06.998619: Epoch time: 46.09 s 
2025-07-09 21:04:06.998757: Yayy! New best EMA pseudo Dice: 0.5633000135421753 
2025-07-09 21:04:09.067147:  
2025-07-09 21:04:09.067309: Epoch 17 
2025-07-09 21:04:09.067427: Current learning rate: 0.00985 
2025-07-09 21:04:54.834109: train_loss -0.1595 
2025-07-09 21:04:54.834648: val_loss -0.1771 
2025-07-09 21:04:54.834747: Pseudo dice [np.float32(0.7367)] 
2025-07-09 21:04:54.834882: Epoch time: 45.77 s 
2025-07-09 21:04:54.834968: Yayy! New best EMA pseudo Dice: 0.5806000232696533 
2025-07-09 21:04:56.936624:  
2025-07-09 21:04:56.936902: Epoch 18 
2025-07-09 21:04:56.937147: Current learning rate: 0.00984 
2025-07-09 21:05:43.569795: train_loss -0.1823 
2025-07-09 21:05:43.570160: val_loss -0.1998 
2025-07-09 21:05:43.570317: Pseudo dice [np.float32(0.7442)] 
2025-07-09 21:05:43.570419: Epoch time: 46.63 s 
2025-07-09 21:05:43.570490: Yayy! New best EMA pseudo Dice: 0.597000002861023 
2025-07-09 21:05:45.708587:  
2025-07-09 21:05:45.708960: Epoch 19 
2025-07-09 21:05:45.709195: Current learning rate: 0.00983 
2025-07-09 21:06:33.461466: train_loss -0.1714 
2025-07-09 21:06:33.461968: val_loss -0.1973 
2025-07-09 21:06:33.462056: Pseudo dice [np.float32(0.7855)] 
2025-07-09 21:06:33.462173: Epoch time: 47.75 s 
2025-07-09 21:06:33.462253: Yayy! New best EMA pseudo Dice: 0.6158000230789185 
2025-07-09 21:06:35.435953:  
2025-07-09 21:06:35.436166: Epoch 20 
2025-07-09 21:06:35.436291: Current learning rate: 0.00982 
2025-07-09 21:07:22.604003: train_loss -0.1662 
2025-07-09 21:07:22.604465: val_loss -0.1988 
2025-07-09 21:07:22.604708: Pseudo dice [np.float32(0.7778)] 
2025-07-09 21:07:22.604890: Epoch time: 47.17 s 
2025-07-09 21:07:22.605107: Yayy! New best EMA pseudo Dice: 0.6320000290870667 
2025-07-09 21:07:24.720368:  
2025-07-09 21:07:24.720762: Epoch 21 
2025-07-09 21:07:24.720991: Current learning rate: 0.00981 
2025-07-09 21:08:12.942817: train_loss -0.1915 
2025-07-09 21:08:12.943331: val_loss -0.1729 
2025-07-09 21:08:12.943414: Pseudo dice [np.float32(0.7778)] 
2025-07-09 21:08:12.943521: Epoch time: 48.22 s 
2025-07-09 21:08:12.943615: Yayy! New best EMA pseudo Dice: 0.6466000080108643 
2025-07-09 21:08:14.998045:  
2025-07-09 21:08:14.998495: Epoch 22 
2025-07-09 21:08:14.998734: Current learning rate: 0.0098 
2025-07-09 21:09:01.612992: train_loss -0.1758 
2025-07-09 21:09:01.613912: val_loss -0.1818 
2025-07-09 21:09:01.614011: Pseudo dice [np.float32(0.6972)] 
2025-07-09 21:09:01.614163: Epoch time: 46.62 s 
2025-07-09 21:09:01.614241: Yayy! New best EMA pseudo Dice: 0.6517000198364258 
2025-07-09 21:09:04.448246:  
2025-07-09 21:09:04.448698: Epoch 23 
2025-07-09 21:09:04.448915: Current learning rate: 0.00979 
2025-07-09 21:09:51.071075: train_loss -0.1667 
2025-07-09 21:09:51.071807: val_loss -0.1857 
2025-07-09 21:09:51.071914: Pseudo dice [np.float32(0.729)] 
2025-07-09 21:09:51.072048: Epoch time: 46.62 s 
2025-07-09 21:09:51.072140: Yayy! New best EMA pseudo Dice: 0.6593999862670898 
2025-07-09 21:09:53.042033:  
2025-07-09 21:09:53.042408: Epoch 24 
2025-07-09 21:09:53.042532: Current learning rate: 0.00978 
2025-07-09 21:10:40.665653: train_loss -0.1911 
2025-07-09 21:10:40.666046: val_loss -0.1991 
2025-07-09 21:10:40.666129: Pseudo dice [np.float32(0.7734)] 
2025-07-09 21:10:40.666234: Epoch time: 47.62 s 
2025-07-09 21:10:40.666305: Yayy! New best EMA pseudo Dice: 0.670799970626831 
2025-07-09 21:10:42.734960:  
2025-07-09 21:10:42.735640: Epoch 25 
2025-07-09 21:10:42.735815: Current learning rate: 0.00977 
2025-07-09 21:11:29.917090: train_loss -0.1851 
2025-07-09 21:11:29.917658: val_loss -0.1776 
2025-07-09 21:11:29.917816: Pseudo dice [np.float32(0.7016)] 
2025-07-09 21:11:29.917957: Epoch time: 47.18 s 
2025-07-09 21:11:29.918048: Yayy! New best EMA pseudo Dice: 0.6739000082015991 
2025-07-09 21:11:32.093614:  
2025-07-09 21:11:32.093947: Epoch 26 
2025-07-09 21:11:32.094157: Current learning rate: 0.00977 
2025-07-09 21:12:18.967290: train_loss -0.1844 
2025-07-09 21:12:18.967793: val_loss -0.1693 
2025-07-09 21:12:18.967883: Pseudo dice [np.float32(0.7206)] 
2025-07-09 21:12:18.968016: Epoch time: 46.87 s 
2025-07-09 21:12:18.968104: Yayy! New best EMA pseudo Dice: 0.678600013256073 
2025-07-09 21:12:21.083850:  
2025-07-09 21:12:21.084217: Epoch 27 
2025-07-09 21:12:21.084455: Current learning rate: 0.00976 
2025-07-09 21:13:08.961321: train_loss -0.1804 
2025-07-09 21:13:08.961925: val_loss -0.1809 
2025-07-09 21:13:08.962016: Pseudo dice [np.float32(0.7594)] 
2025-07-09 21:13:08.962168: Epoch time: 47.88 s 
2025-07-09 21:13:08.962263: Yayy! New best EMA pseudo Dice: 0.6866000294685364 
2025-07-09 21:13:10.995381:  
2025-07-09 21:13:10.995566: Epoch 28 
2025-07-09 21:13:10.995745: Current learning rate: 0.00975 
2025-07-09 21:13:58.441500: train_loss -0.1773 
2025-07-09 21:13:58.441850: val_loss -0.171 
2025-07-09 21:13:58.441937: Pseudo dice [np.float32(0.748)] 
2025-07-09 21:13:58.442053: Epoch time: 47.45 s 
2025-07-09 21:13:58.442127: Yayy! New best EMA pseudo Dice: 0.692799985408783 
2025-07-09 21:14:00.496412:  
2025-07-09 21:14:00.496767: Epoch 29 
2025-07-09 21:14:00.496908: Current learning rate: 0.00974 
2025-07-09 21:14:47.950393: train_loss -0.1944 
2025-07-09 21:14:47.950895: val_loss -0.1813 
2025-07-09 21:14:47.950975: Pseudo dice [np.float32(0.7816)] 
2025-07-09 21:14:47.951082: Epoch time: 47.46 s 
2025-07-09 21:14:47.951159: Yayy! New best EMA pseudo Dice: 0.70169997215271 
2025-07-09 21:14:50.032303:  
2025-07-09 21:14:50.032683: Epoch 30 
2025-07-09 21:14:50.032831: Current learning rate: 0.00973 
2025-07-09 21:15:37.439597: train_loss -0.1829 
2025-07-09 21:15:37.440033: val_loss -0.1845 
2025-07-09 21:15:37.440112: Pseudo dice [np.float32(0.7546)] 
2025-07-09 21:15:37.440210: Epoch time: 47.41 s 
2025-07-09 21:15:37.440281: Yayy! New best EMA pseudo Dice: 0.7070000171661377 
2025-07-09 21:15:39.522364:  
2025-07-09 21:15:39.522599: Epoch 31 
2025-07-09 21:15:39.522730: Current learning rate: 0.00972 
2025-07-09 21:16:26.056116: train_loss -0.1974 
2025-07-09 21:16:26.056635: val_loss -0.1828 
2025-07-09 21:16:26.056716: Pseudo dice [np.float32(0.7367)] 
2025-07-09 21:16:26.056842: Epoch time: 46.53 s 
2025-07-09 21:16:26.056913: Yayy! New best EMA pseudo Dice: 0.7099000215530396 
2025-07-09 21:16:28.075323:  
2025-07-09 21:16:28.075439: Epoch 32 
2025-07-09 21:16:28.075530: Current learning rate: 0.00971 
2025-07-09 21:17:13.945842: train_loss -0.1943 
2025-07-09 21:17:13.946911: val_loss -0.1879 
2025-07-09 21:17:13.947006: Pseudo dice [np.float32(0.7875)] 
2025-07-09 21:17:13.947170: Epoch time: 45.87 s 
2025-07-09 21:17:13.947253: Yayy! New best EMA pseudo Dice: 0.7177000045776367 
2025-07-09 21:17:15.965734:  
2025-07-09 21:17:15.965929: Epoch 33 
2025-07-09 21:17:15.966072: Current learning rate: 0.0097 
2025-07-09 21:18:02.707734: train_loss -0.1886 
2025-07-09 21:18:02.708177: val_loss -0.1938 
2025-07-09 21:18:02.708256: Pseudo dice [np.float32(0.8013)] 
2025-07-09 21:18:02.708366: Epoch time: 46.74 s 
2025-07-09 21:18:02.708440: Yayy! New best EMA pseudo Dice: 0.7260000109672546 
2025-07-09 21:18:05.401710:  
2025-07-09 21:18:05.402022: Epoch 34 
2025-07-09 21:18:05.402275: Current learning rate: 0.00969 
2025-07-09 21:18:51.268423: train_loss -0.1957 
2025-07-09 21:18:51.269217: val_loss -0.1805 
2025-07-09 21:18:51.269321: Pseudo dice [np.float32(0.7799)] 
2025-07-09 21:18:51.269452: Epoch time: 45.87 s 
2025-07-09 21:18:51.269563: Yayy! New best EMA pseudo Dice: 0.7314000129699707 
2025-07-09 21:18:53.321816:  
2025-07-09 21:18:53.322283: Epoch 35 
2025-07-09 21:18:53.322460: Current learning rate: 0.00968 
2025-07-09 21:19:39.640679: train_loss -0.1944 
2025-07-09 21:19:39.641093: val_loss -0.1963 
2025-07-09 21:19:39.641168: Pseudo dice [np.float32(0.7891)] 
2025-07-09 21:19:39.641275: Epoch time: 46.32 s 
2025-07-09 21:19:39.641349: Yayy! New best EMA pseudo Dice: 0.7372000217437744 
2025-07-09 21:19:41.774224:  
2025-07-09 21:19:41.774459: Epoch 36 
2025-07-09 21:19:41.774598: Current learning rate: 0.00968 
2025-07-09 21:20:28.396451: train_loss -0.1851 
2025-07-09 21:20:28.396755: val_loss -0.2241 
2025-07-09 21:20:28.396837: Pseudo dice [np.float32(0.8278)] 
2025-07-09 21:20:28.396929: Epoch time: 46.62 s 
2025-07-09 21:20:28.397005: Yayy! New best EMA pseudo Dice: 0.7462999820709229 
2025-07-09 21:20:30.478037:  
2025-07-09 21:20:30.478228: Epoch 37 
2025-07-09 21:20:30.478356: Current learning rate: 0.00967 
2025-07-09 21:21:17.507702: train_loss -0.1952 
2025-07-09 21:21:17.508192: val_loss -0.1744 
2025-07-09 21:21:17.508279: Pseudo dice [np.float32(0.7984)] 
2025-07-09 21:21:17.508409: Epoch time: 47.03 s 
2025-07-09 21:21:17.508495: Yayy! New best EMA pseudo Dice: 0.7515000104904175 
2025-07-09 21:21:19.643786:  
2025-07-09 21:21:19.644104: Epoch 38 
2025-07-09 21:21:19.644245: Current learning rate: 0.00966 
2025-07-09 21:22:07.513577: train_loss -0.1973 
2025-07-09 21:22:07.514289: val_loss -0.2042 
2025-07-09 21:22:07.514412: Pseudo dice [np.float32(0.8173)] 
2025-07-09 21:22:07.514663: Epoch time: 47.87 s 
2025-07-09 21:22:07.514776: Yayy! New best EMA pseudo Dice: 0.7580999732017517 
2025-07-09 21:22:09.646373:  
2025-07-09 21:22:09.646685: Epoch 39 
2025-07-09 21:22:09.646817: Current learning rate: 0.00965 
2025-07-09 21:22:58.722664: train_loss -0.1998 
2025-07-09 21:22:58.723958: val_loss -0.183 
2025-07-09 21:22:58.724095: Pseudo dice [np.float32(0.8062)] 
2025-07-09 21:22:58.724292: Epoch time: 49.08 s 
2025-07-09 21:22:58.724373: Yayy! New best EMA pseudo Dice: 0.7628999948501587 
2025-07-09 21:23:00.816422:  
2025-07-09 21:23:00.816998: Epoch 40 
2025-07-09 21:23:00.817198: Current learning rate: 0.00964 
2025-07-09 21:23:48.652916: train_loss -0.1912 
2025-07-09 21:23:48.653615: val_loss -0.1912 
2025-07-09 21:23:48.653700: Pseudo dice [np.float32(0.8137)] 
2025-07-09 21:23:48.653853: Epoch time: 47.84 s 
2025-07-09 21:23:48.653929: Yayy! New best EMA pseudo Dice: 0.7678999900817871 
2025-07-09 21:23:50.747479:  
2025-07-09 21:23:50.747675: Epoch 41 
2025-07-09 21:23:50.747773: Current learning rate: 0.00963 
2025-07-09 21:24:37.862155: train_loss -0.1964 
2025-07-09 21:24:37.862537: val_loss -0.1853 
2025-07-09 21:24:37.862720: Pseudo dice [np.float32(0.8005)] 
2025-07-09 21:24:37.862852: Epoch time: 47.12 s 
2025-07-09 21:24:37.862981: Yayy! New best EMA pseudo Dice: 0.7712000012397766 
2025-07-09 21:24:39.913165:  
2025-07-09 21:24:39.913402: Epoch 42 
2025-07-09 21:24:39.913582: Current learning rate: 0.00962 
2025-07-09 21:25:28.152990: train_loss -0.1982 
2025-07-09 21:25:28.153475: val_loss -0.1959 
2025-07-09 21:25:28.153577: Pseudo dice [np.float32(0.7779)] 
2025-07-09 21:25:28.153697: Epoch time: 48.24 s 
2025-07-09 21:25:28.153781: Yayy! New best EMA pseudo Dice: 0.7718999981880188 
2025-07-09 21:25:30.162711:  
2025-07-09 21:25:30.163235: Epoch 43 
2025-07-09 21:25:30.163598: Current learning rate: 0.00961 
2025-07-09 21:26:17.638553: train_loss -0.1869 
2025-07-09 21:26:17.638938: val_loss -0.176 
2025-07-09 21:26:17.639007: Pseudo dice [np.float32(0.7829)] 
2025-07-09 21:26:17.639112: Epoch time: 47.48 s 
2025-07-09 21:26:17.639188: Yayy! New best EMA pseudo Dice: 0.7730000019073486 
2025-07-09 21:26:19.670772:  
2025-07-09 21:26:19.671287: Epoch 44 
2025-07-09 21:26:19.671753: Current learning rate: 0.0096 
2025-07-09 21:27:08.018809: train_loss -0.2036 
2025-07-09 21:27:08.019449: val_loss -0.1998 
2025-07-09 21:27:08.019534: Pseudo dice [np.float32(0.7784)] 
2025-07-09 21:27:08.019664: Epoch time: 48.35 s 
2025-07-09 21:27:08.019744: Yayy! New best EMA pseudo Dice: 0.7735000252723694 
2025-07-09 21:27:10.659193:  
2025-07-09 21:27:10.659648: Epoch 45 
2025-07-09 21:27:10.659853: Current learning rate: 0.00959 
2025-07-09 21:27:56.835612: train_loss -0.1815 
2025-07-09 21:27:56.836181: val_loss -0.2059 
2025-07-09 21:27:56.836388: Pseudo dice [np.float32(0.8266)] 
2025-07-09 21:27:56.836609: Epoch time: 46.18 s 
2025-07-09 21:27:56.836727: Yayy! New best EMA pseudo Dice: 0.7788000106811523 
2025-07-09 21:27:58.913525:  
2025-07-09 21:27:58.913773: Epoch 46 
2025-07-09 21:27:58.913895: Current learning rate: 0.00959 
2025-07-09 21:28:47.675476: train_loss -0.1962 
2025-07-09 21:28:47.675920: val_loss -0.1944 
2025-07-09 21:28:47.675998: Pseudo dice [np.float32(0.7689)] 
2025-07-09 21:28:47.676111: Epoch time: 48.76 s 
2025-07-09 21:28:48.779464:  
2025-07-09 21:28:48.779758: Epoch 47 
2025-07-09 21:28:48.779921: Current learning rate: 0.00958 
2025-07-09 21:29:35.445823: train_loss -0.1969 
2025-07-09 21:29:35.446350: val_loss -0.2002 
2025-07-09 21:29:35.446446: Pseudo dice [np.float32(0.8317)] 
2025-07-09 21:29:35.446632: Epoch time: 46.67 s 
2025-07-09 21:29:35.446723: Yayy! New best EMA pseudo Dice: 0.7832000255584717 
2025-07-09 21:29:37.410704:  
2025-07-09 21:29:37.410933: Epoch 48 
2025-07-09 21:29:37.411094: Current learning rate: 0.00957 
2025-07-09 21:30:25.302734: train_loss -0.1924 
2025-07-09 21:30:25.303158: val_loss -0.2134 
2025-07-09 21:30:25.303238: Pseudo dice [np.float32(0.7834)] 
2025-07-09 21:30:25.303335: Epoch time: 47.89 s 
2025-07-09 21:30:25.303413: Yayy! New best EMA pseudo Dice: 0.7832000255584717 
2025-07-09 21:30:27.349208:  
2025-07-09 21:30:27.349699: Epoch 49 
2025-07-09 21:30:27.349894: Current learning rate: 0.00956 
2025-07-09 21:31:14.367197: train_loss -0.1942 
2025-07-09 21:31:14.367573: val_loss -0.1749 
2025-07-09 21:31:14.367656: Pseudo dice [np.float32(0.8064)] 
2025-07-09 21:31:14.367757: Epoch time: 47.02 s 
2025-07-09 21:31:14.625391: Yayy! New best EMA pseudo Dice: 0.7856000065803528 
2025-07-09 21:31:16.631286:  
2025-07-09 21:31:16.631829: Epoch 50 
2025-07-09 21:31:16.631959: Current learning rate: 0.00955 
2025-07-09 21:32:03.467618: train_loss -0.1987 
2025-07-09 21:32:03.468054: val_loss -0.2065 
2025-07-09 21:32:03.468146: Pseudo dice [np.float32(0.8012)] 
2025-07-09 21:32:03.468246: Epoch time: 46.84 s 
2025-07-09 21:32:03.468323: Yayy! New best EMA pseudo Dice: 0.7871000170707703 
2025-07-09 21:32:05.501963:  
2025-07-09 21:32:05.502202: Epoch 51 
2025-07-09 21:32:05.502300: Current learning rate: 0.00954 
2025-07-09 21:32:52.032997: train_loss -0.2033 
2025-07-09 21:32:52.033385: val_loss -0.2013 
2025-07-09 21:32:52.033456: Pseudo dice [np.float32(0.8172)] 
2025-07-09 21:32:52.033566: Epoch time: 46.53 s 
2025-07-09 21:32:52.033641: Yayy! New best EMA pseudo Dice: 0.7900999784469604 
2025-07-09 21:32:54.077034:  
2025-07-09 21:32:54.077269: Epoch 52 
2025-07-09 21:32:54.077391: Current learning rate: 0.00953 
2025-07-09 21:33:40.332873: train_loss -0.2159 
2025-07-09 21:33:40.333629: val_loss -0.219 
2025-07-09 21:33:40.333728: Pseudo dice [np.float32(0.796)] 
2025-07-09 21:33:40.333854: Epoch time: 46.26 s 
2025-07-09 21:33:40.333948: Yayy! New best EMA pseudo Dice: 0.7907000184059143 
2025-07-09 21:33:42.412680:  
2025-07-09 21:33:42.413316: Epoch 53 
2025-07-09 21:33:42.413538: Current learning rate: 0.00952 
2025-07-09 21:34:28.832353: train_loss -0.2007 
2025-07-09 21:34:28.832708: val_loss -0.1929 
2025-07-09 21:34:28.832791: Pseudo dice [np.float32(0.806)] 
2025-07-09 21:34:28.832889: Epoch time: 46.42 s 
2025-07-09 21:34:28.833095: Yayy! New best EMA pseudo Dice: 0.7922000288963318 
2025-07-09 21:34:30.903203:  
2025-07-09 21:34:30.903524: Epoch 54 
2025-07-09 21:34:30.903684: Current learning rate: 0.00951 
2025-07-09 21:35:17.716529: train_loss -0.1948 
2025-07-09 21:35:17.716992: val_loss -0.1849 
2025-07-09 21:35:17.717148: Pseudo dice [np.float32(0.7962)] 
2025-07-09 21:35:17.717366: Epoch time: 46.81 s 
2025-07-09 21:35:17.717449: Yayy! New best EMA pseudo Dice: 0.7925999760627747 
2025-07-09 21:35:19.678527:  
2025-07-09 21:35:19.678847: Epoch 55 
2025-07-09 21:35:19.679158: Current learning rate: 0.0095 
2025-07-09 21:36:05.863654: train_loss -0.2131 
2025-07-09 21:36:05.864153: val_loss -0.214 
2025-07-09 21:36:05.864228: Pseudo dice [np.float32(0.839)] 
2025-07-09 21:36:05.864337: Epoch time: 46.19 s 
2025-07-09 21:36:05.864409: Yayy! New best EMA pseudo Dice: 0.7972999811172485 
2025-07-09 21:36:08.119592:  
2025-07-09 21:36:08.119979: Epoch 56 
2025-07-09 21:36:08.120234: Current learning rate: 0.00949 
2025-07-09 21:36:54.675408: train_loss -0.2062 
2025-07-09 21:36:54.675992: val_loss -0.2338 
2025-07-09 21:36:54.676076: Pseudo dice [np.float32(0.8204)] 
2025-07-09 21:36:54.676184: Epoch time: 46.56 s 
2025-07-09 21:36:54.676261: Yayy! New best EMA pseudo Dice: 0.7996000051498413 
2025-07-09 21:36:57.656754:  
2025-07-09 21:36:57.657381: Epoch 57 
2025-07-09 21:36:57.657853: Current learning rate: 0.00949 
2025-07-09 21:37:43.759751: train_loss -0.1916 
2025-07-09 21:37:43.760308: val_loss -0.203 
2025-07-09 21:37:43.760391: Pseudo dice [np.float32(0.8122)] 
2025-07-09 21:37:43.760498: Epoch time: 46.1 s 
2025-07-09 21:37:43.760592: Yayy! New best EMA pseudo Dice: 0.8008000254631042 
2025-07-09 21:37:45.835829:  
2025-07-09 21:37:45.836319: Epoch 58 
2025-07-09 21:37:45.836583: Current learning rate: 0.00948 
2025-07-09 21:38:32.690633: train_loss -0.1933 
2025-07-09 21:38:32.691761: val_loss -0.2 
2025-07-09 21:38:32.691958: Pseudo dice [np.float32(0.8248)] 
2025-07-09 21:38:32.692207: Epoch time: 46.86 s 
2025-07-09 21:38:32.692321: Yayy! New best EMA pseudo Dice: 0.8032000064849854 
2025-07-09 21:38:34.615274:  
2025-07-09 21:38:34.615531: Epoch 59 
2025-07-09 21:38:34.615670: Current learning rate: 0.00947 
2025-07-09 21:39:21.161214: train_loss -0.1927 
2025-07-09 21:39:21.161603: val_loss -0.2014 
2025-07-09 21:39:21.165105: Pseudo dice [np.float32(0.7855)] 
2025-07-09 21:39:21.165241: Epoch time: 46.55 s 
2025-07-09 21:39:22.251981:  
2025-07-09 21:39:22.252492: Epoch 60 
2025-07-09 21:39:22.252783: Current learning rate: 0.00946 
2025-07-09 21:40:08.789258: train_loss -0.202 
2025-07-09 21:40:08.789700: val_loss -0.2162 
2025-07-09 21:40:08.789791: Pseudo dice [np.float32(0.805)] 
2025-07-09 21:40:08.789905: Epoch time: 46.54 s 
2025-07-09 21:40:09.913405:  
2025-07-09 21:40:09.913795: Epoch 61 
2025-07-09 21:40:09.913959: Current learning rate: 0.00945 
2025-07-09 21:40:56.302281: train_loss -0.2099 
2025-07-09 21:40:56.302678: val_loss -0.2055 
2025-07-09 21:40:56.302763: Pseudo dice [np.float32(0.8181)] 
2025-07-09 21:40:56.302866: Epoch time: 46.39 s 
2025-07-09 21:40:56.302962: Yayy! New best EMA pseudo Dice: 0.8033999800682068 
2025-07-09 21:40:58.328928:  
2025-07-09 21:40:58.329386: Epoch 62 
2025-07-09 21:40:58.329569: Current learning rate: 0.00944 
2025-07-09 21:41:44.053876: train_loss -0.2098 
2025-07-09 21:41:44.054492: val_loss -0.2208 
2025-07-09 21:41:44.054607: Pseudo dice [np.float32(0.816)] 
2025-07-09 21:41:44.054724: Epoch time: 45.73 s 
2025-07-09 21:41:44.054801: Yayy! New best EMA pseudo Dice: 0.8047000169754028 
2025-07-09 21:41:46.045666:  
2025-07-09 21:41:46.046076: Epoch 63 
2025-07-09 21:41:46.046206: Current learning rate: 0.00943 
2025-07-09 21:42:32.357423: train_loss -0.2124 
2025-07-09 21:42:32.358156: val_loss -0.2308 
2025-07-09 21:42:32.358280: Pseudo dice [np.float32(0.843)] 
2025-07-09 21:42:32.358509: Epoch time: 46.31 s 
2025-07-09 21:42:32.358637: Yayy! New best EMA pseudo Dice: 0.8084999918937683 
2025-07-09 21:42:34.527251:  
2025-07-09 21:42:34.527568: Epoch 64 
2025-07-09 21:42:34.527703: Current learning rate: 0.00942 
2025-07-09 21:43:21.333338: train_loss -0.2078 
2025-07-09 21:43:21.333808: val_loss -0.2539 
2025-07-09 21:43:21.333891: Pseudo dice [np.float32(0.8267)] 
2025-07-09 21:43:21.333999: Epoch time: 46.81 s 
2025-07-09 21:43:21.334077: Yayy! New best EMA pseudo Dice: 0.8104000091552734 
2025-07-09 21:43:23.277050:  
2025-07-09 21:43:23.277195: Epoch 65 
2025-07-09 21:43:23.277313: Current learning rate: 0.00941 
2025-07-09 21:44:09.228534: train_loss -0.1982 
2025-07-09 21:44:09.228956: val_loss -0.2259 
2025-07-09 21:44:09.229036: Pseudo dice [np.float32(0.8349)] 
2025-07-09 21:44:09.229147: Epoch time: 45.95 s 
2025-07-09 21:44:09.229222: Yayy! New best EMA pseudo Dice: 0.8127999901771545 
2025-07-09 21:44:11.335500:  
2025-07-09 21:44:11.335979: Epoch 66 
2025-07-09 21:44:11.336136: Current learning rate: 0.0094 
2025-07-09 21:44:57.194093: train_loss -0.1941 
2025-07-09 21:44:57.194731: val_loss -0.1883 
2025-07-09 21:44:57.194827: Pseudo dice [np.float32(0.835)] 
2025-07-09 21:44:57.194960: Epoch time: 45.86 s 
2025-07-09 21:44:57.195051: Yayy! New best EMA pseudo Dice: 0.8149999976158142 
2025-07-09 21:44:59.456617:  
2025-07-09 21:44:59.456849: Epoch 67 
2025-07-09 21:44:59.456991: Current learning rate: 0.00939 
2025-07-09 21:45:46.252630: train_loss -0.2007 
2025-07-09 21:45:46.253824: val_loss -0.1947 
2025-07-09 21:45:46.253981: Pseudo dice [np.float32(0.8071)] 
2025-07-09 21:45:46.254192: Epoch time: 46.8 s 
2025-07-09 21:45:48.052084:  
2025-07-09 21:45:48.052413: Epoch 68 
2025-07-09 21:45:48.052656: Current learning rate: 0.00939 
2025-07-09 21:46:34.452800: train_loss -0.2033 
2025-07-09 21:46:34.453737: val_loss -0.2267 
2025-07-09 21:46:34.453839: Pseudo dice [np.float32(0.835)] 
2025-07-09 21:46:34.453977: Epoch time: 46.4 s 
2025-07-09 21:46:34.454063: Yayy! New best EMA pseudo Dice: 0.8162999749183655 
2025-07-09 21:46:36.648058:  
2025-07-09 21:46:36.648772: Epoch 69 
2025-07-09 21:46:36.649156: Current learning rate: 0.00938 
2025-07-09 21:47:23.424145: train_loss -0.2017 
2025-07-09 21:47:23.424511: val_loss -0.2199 
2025-07-09 21:47:23.424606: Pseudo dice [np.float32(0.8396)] 
2025-07-09 21:47:23.424713: Epoch time: 46.78 s 
2025-07-09 21:47:23.424784: Yayy! New best EMA pseudo Dice: 0.8185999989509583 
2025-07-09 21:47:25.388612:  
2025-07-09 21:47:25.388861: Epoch 70 
2025-07-09 21:47:25.388987: Current learning rate: 0.00937 
2025-07-09 21:48:11.761003: train_loss -0.2121 
2025-07-09 21:48:11.761319: val_loss -0.206 
2025-07-09 21:48:11.761530: Pseudo dice [np.float32(0.7953)] 
2025-07-09 21:48:11.761639: Epoch time: 46.37 s 
2025-07-09 21:48:12.920321:  
2025-07-09 21:48:12.920630: Epoch 71 
2025-07-09 21:48:12.920757: Current learning rate: 0.00936 
2025-07-09 21:48:59.232949: train_loss -0.2065 
2025-07-09 21:48:59.233662: val_loss -0.1978 
2025-07-09 21:48:59.233742: Pseudo dice [np.float32(0.7879)] 
2025-07-09 21:48:59.233852: Epoch time: 46.31 s 
2025-07-09 21:49:00.410691:  
2025-07-09 21:49:00.411031: Epoch 72 
2025-07-09 21:49:00.411301: Current learning rate: 0.00935 
2025-07-09 21:49:46.394156: train_loss -0.1936 
2025-07-09 21:49:46.394668: val_loss -0.2176 
2025-07-09 21:49:46.394754: Pseudo dice [np.float32(0.82)] 
2025-07-09 21:49:46.394880: Epoch time: 45.98 s 
2025-07-09 21:49:47.514262:  
2025-07-09 21:49:47.514466: Epoch 73 
2025-07-09 21:49:47.514630: Current learning rate: 0.00934 
2025-07-09 21:50:35.461689: train_loss -0.1957 
2025-07-09 21:50:35.462213: val_loss -0.1559 
2025-07-09 21:50:35.462302: Pseudo dice [np.float32(0.7969)] 
2025-07-09 21:50:35.462417: Epoch time: 47.95 s 
2025-07-09 21:50:36.616063:  
2025-07-09 21:50:36.616440: Epoch 74 
2025-07-09 21:50:36.616602: Current learning rate: 0.00933 
2025-07-09 21:51:23.177528: train_loss -0.2022 
2025-07-09 21:51:23.178119: val_loss -0.2276 
2025-07-09 21:51:23.178220: Pseudo dice [np.float32(0.7985)] 
2025-07-09 21:51:23.178329: Epoch time: 46.56 s 
2025-07-09 21:51:24.325881:  
2025-07-09 21:51:24.326221: Epoch 75 
2025-07-09 21:51:24.326407: Current learning rate: 0.00932 
2025-07-09 21:52:12.264292: train_loss -0.2069 
2025-07-09 21:52:12.264783: val_loss -0.217 
2025-07-09 21:52:12.264868: Pseudo dice [np.float32(0.8036)] 
2025-07-09 21:52:12.264970: Epoch time: 47.94 s 
2025-07-09 21:52:13.447177:  
2025-07-09 21:52:13.447496: Epoch 76 
2025-07-09 21:52:13.447648: Current learning rate: 0.00931 
2025-07-09 21:53:01.072385: train_loss -0.1993 
2025-07-09 21:53:01.072925: val_loss -0.1943 
2025-07-09 21:53:01.073002: Pseudo dice [np.float32(0.8094)] 
2025-07-09 21:53:01.073104: Epoch time: 47.63 s 
2025-07-09 21:53:02.238969:  
2025-07-09 21:53:02.239429: Epoch 77 
2025-07-09 21:53:02.239571: Current learning rate: 0.0093 
2025-07-09 21:53:49.827493: train_loss -0.1999 
2025-07-09 21:53:49.828692: val_loss -0.2267 
2025-07-09 21:53:49.828786: Pseudo dice [np.float32(0.8261)] 
2025-07-09 21:53:49.829042: Epoch time: 47.59 s 
2025-07-09 21:53:50.988398:  
2025-07-09 21:53:50.988654: Epoch 78 
2025-07-09 21:53:50.988914: Current learning rate: 0.0093 
2025-07-09 21:54:37.404172: train_loss -0.2061 
2025-07-09 21:54:37.404859: val_loss -0.2268 
2025-07-09 21:54:37.404985: Pseudo dice [np.float32(0.7792)] 
2025-07-09 21:54:37.405122: Epoch time: 46.42 s 
2025-07-09 21:54:39.237355:  
2025-07-09 21:54:39.237816: Epoch 79 
2025-07-09 21:54:39.238082: Current learning rate: 0.00929 
2025-07-09 21:55:25.517972: train_loss -0.2155 
2025-07-09 21:55:25.518957: val_loss -0.2276 
2025-07-09 21:55:25.519100: Pseudo dice [np.float32(0.8319)] 
2025-07-09 21:55:25.519262: Epoch time: 46.28 s 
2025-07-09 21:55:26.723648:  
2025-07-09 21:55:26.723940: Epoch 80 
2025-07-09 21:55:26.724144: Current learning rate: 0.00928 
2025-07-09 21:56:13.354110: train_loss -0.2069 
2025-07-09 21:56:13.354657: val_loss -0.2262 
2025-07-09 21:56:13.354753: Pseudo dice [np.float32(0.849)] 
2025-07-09 21:56:13.354882: Epoch time: 46.63 s 
2025-07-09 21:56:14.502472:  
2025-07-09 21:56:14.502953: Epoch 81 
2025-07-09 21:56:14.503086: Current learning rate: 0.00927 
2025-07-09 21:57:01.188871: train_loss -0.2124 
2025-07-09 21:57:01.189433: val_loss -0.2187 
2025-07-09 21:57:01.189533: Pseudo dice [np.float32(0.8443)] 
2025-07-09 21:57:01.189700: Epoch time: 46.69 s 
2025-07-09 21:57:02.328921:  
2025-07-09 21:57:02.329154: Epoch 82 
2025-07-09 21:57:02.329306: Current learning rate: 0.00926 
2025-07-09 21:57:48.233470: train_loss -0.2047 
2025-07-09 21:57:48.234221: val_loss -0.1848 
2025-07-09 21:57:48.234352: Pseudo dice [np.float32(0.8429)] 
2025-07-09 21:57:48.234507: Epoch time: 45.91 s 
2025-07-09 21:57:48.234615: Yayy! New best EMA pseudo Dice: 0.8202000260353088 
2025-07-09 21:57:50.257638:  
2025-07-09 21:57:50.258038: Epoch 83 
2025-07-09 21:57:50.258178: Current learning rate: 0.00925 
2025-07-09 21:58:36.517484: train_loss -0.2109 
2025-07-09 21:58:36.518495: val_loss -0.2481 
2025-07-09 21:58:36.518584: Pseudo dice [np.float32(0.8444)] 
2025-07-09 21:58:36.518722: Epoch time: 46.26 s 
2025-07-09 21:58:36.518798: Yayy! New best EMA pseudo Dice: 0.8226000070571899 
2025-07-09 21:58:38.543719:  
2025-07-09 21:58:38.543966: Epoch 84 
2025-07-09 21:58:38.544104: Current learning rate: 0.00924 
2025-07-09 21:59:24.886200: train_loss -0.2039 
2025-07-09 21:59:24.886668: val_loss -0.2332 
2025-07-09 21:59:24.886749: Pseudo dice [np.float32(0.8144)] 
2025-07-09 21:59:24.886858: Epoch time: 46.34 s 
2025-07-09 21:59:25.997615:  
2025-07-09 21:59:25.998150: Epoch 85 
2025-07-09 21:59:25.998336: Current learning rate: 0.00923 
2025-07-09 22:00:12.271064: train_loss -0.1984 
2025-07-09 22:00:12.271589: val_loss -0.2222 
2025-07-09 22:00:12.271679: Pseudo dice [np.float32(0.8488)] 
2025-07-09 22:00:12.271801: Epoch time: 46.27 s 
2025-07-09 22:00:12.271885: Yayy! New best EMA pseudo Dice: 0.8245000243186951 
2025-07-09 22:00:14.304228:  
2025-07-09 22:00:14.304492: Epoch 86 
2025-07-09 22:00:14.304646: Current learning rate: 0.00922 
2025-07-09 22:00:59.846629: train_loss -0.2058 
2025-07-09 22:00:59.847202: val_loss -0.214 
2025-07-09 22:00:59.847385: Pseudo dice [np.float32(0.8276)] 
2025-07-09 22:00:59.847520: Epoch time: 45.54 s 
2025-07-09 22:00:59.847672: Yayy! New best EMA pseudo Dice: 0.8248000144958496 
2025-07-09 22:01:01.938365:  
2025-07-09 22:01:01.938537: Epoch 87 
2025-07-09 22:01:01.938678: Current learning rate: 0.00921 
2025-07-09 22:01:48.954207: train_loss -0.2266 
2025-07-09 22:01:48.954731: val_loss -0.2331 
2025-07-09 22:01:48.954821: Pseudo dice [np.float32(0.8647)] 
2025-07-09 22:01:48.954927: Epoch time: 47.02 s 
2025-07-09 22:01:48.955009: Yayy! New best EMA pseudo Dice: 0.8288000226020813 
2025-07-09 22:01:51.234797:  
2025-07-09 22:01:51.235247: Epoch 88 
2025-07-09 22:01:51.235399: Current learning rate: 0.0092 
2025-07-09 22:02:37.142982: train_loss -0.211 
2025-07-09 22:02:37.143444: val_loss -0.209 
2025-07-09 22:02:37.143532: Pseudo dice [np.float32(0.834)] 
2025-07-09 22:02:37.143666: Epoch time: 45.91 s 
2025-07-09 22:02:37.143754: Yayy! New best EMA pseudo Dice: 0.8292999863624573 
2025-07-09 22:02:39.425593:  
2025-07-09 22:02:39.425955: Epoch 89 
2025-07-09 22:02:39.426173: Current learning rate: 0.0092 
2025-07-09 22:03:26.136694: train_loss -0.2031 
2025-07-09 22:03:26.137145: val_loss -0.1986 
2025-07-09 22:03:26.137232: Pseudo dice [np.float32(0.8347)] 
2025-07-09 22:03:26.137354: Epoch time: 46.71 s 
2025-07-09 22:03:26.137436: Yayy! New best EMA pseudo Dice: 0.829800009727478 
2025-07-09 22:03:28.903904:  
2025-07-09 22:03:28.904269: Epoch 90 
2025-07-09 22:03:28.904406: Current learning rate: 0.00919 
2025-07-09 22:04:16.249755: train_loss -0.1926 
2025-07-09 22:04:16.250766: val_loss -0.2086 
2025-07-09 22:04:16.250847: Pseudo dice [np.float32(0.8372)] 
2025-07-09 22:04:16.250990: Epoch time: 47.35 s 
2025-07-09 22:04:16.251074: Yayy! New best EMA pseudo Dice: 0.8306000232696533 
2025-07-09 22:04:18.312925:  
2025-07-09 22:04:18.313130: Epoch 91 
2025-07-09 22:04:18.313230: Current learning rate: 0.00918 
2025-07-09 22:05:04.517571: train_loss -0.2634 
2025-07-09 22:05:04.518304: val_loss -0.2529 
2025-07-09 22:05:04.518400: Pseudo dice [np.float32(0.0)] 
2025-07-09 22:05:04.518525: Epoch time: 46.21 s 
2025-07-09 22:05:05.616561:  
2025-07-09 22:05:05.616911: Epoch 92 
2025-07-09 22:05:05.617046: Current learning rate: 0.00917 
2025-07-09 22:05:52.192427: train_loss -0.3161 
2025-07-09 22:05:52.192804: val_loss -0.3231 
2025-07-09 22:05:52.192879: Pseudo dice [np.float32(0.0)] 
2025-07-09 22:05:52.192972: Epoch time: 46.58 s 
2025-07-09 22:05:53.275365:  
2025-07-09 22:05:53.275518: Epoch 93 
2025-07-09 22:05:53.275672: Current learning rate: 0.00916 
2025-07-09 22:06:40.805799: train_loss -0.3465 
2025-07-09 22:06:40.806292: val_loss -0.363 
2025-07-09 22:06:40.806380: Pseudo dice [np.float32(0.0)] 
2025-07-09 22:06:40.806480: Epoch time: 47.53 s 
2025-07-09 22:06:41.908628:  
2025-07-09 22:06:41.908855: Epoch 94 
2025-07-09 22:06:41.909029: Current learning rate: 0.00915 
2025-07-09 22:07:28.225751: train_loss -0.3649 
2025-07-09 22:07:28.226888: val_loss -0.2864 
2025-07-09 22:07:28.227033: Pseudo dice [np.float32(0.0034)] 
2025-07-09 22:07:28.227233: Epoch time: 46.32 s 
2025-07-09 22:07:29.455505:  
2025-07-09 22:07:29.455827: Epoch 95 
2025-07-09 22:07:29.455933: Current learning rate: 0.00914 
2025-07-09 22:08:17.028842: train_loss -0.3515 
2025-07-09 22:08:17.029176: val_loss -0.3163 
2025-07-09 22:08:17.029249: Pseudo dice [np.float32(0.0)] 
2025-07-09 22:08:17.029351: Epoch time: 47.57 s 
2025-07-09 22:08:18.210581:  
2025-07-09 22:08:18.210864: Epoch 96 
2025-07-09 22:08:18.211062: Current learning rate: 0.00913 
2025-07-09 22:09:05.835315: train_loss -0.3273 
2025-07-09 22:09:05.835847: val_loss -0.3434 
2025-07-09 22:09:05.835927: Pseudo dice [np.float32(0.0)] 
2025-07-09 22:09:05.836036: Epoch time: 47.63 s 
2025-07-09 22:09:06.909019:  
2025-07-09 22:09:06.909456: Epoch 97 
2025-07-09 22:09:06.909647: Current learning rate: 0.00912 
2025-07-09 22:09:54.016694: train_loss -0.3702 
2025-07-09 22:09:54.017074: val_loss -0.3838 
2025-07-09 22:09:54.017239: Pseudo dice [np.float32(0.4359)] 
2025-07-09 22:09:54.017343: Epoch time: 47.11 s 
2025-07-09 22:09:55.191913:  
2025-07-09 22:09:55.192485: Epoch 98 
2025-07-09 22:09:55.192642: Current learning rate: 0.00911 
2025-07-09 22:10:42.575057: train_loss -0.3716 
2025-07-09 22:10:42.575462: val_loss -0.3922 
2025-07-09 22:10:42.575579: Pseudo dice [np.float32(0.6788)] 
2025-07-09 22:10:42.575700: Epoch time: 47.38 s 
2025-07-09 22:10:43.694151:  
2025-07-09 22:10:43.694567: Epoch 99 
2025-07-09 22:10:43.694769: Current learning rate: 0.0091 
2025-07-09 22:11:29.714081: train_loss -0.3821 
2025-07-09 22:11:29.714549: val_loss -0.3693 
2025-07-09 22:11:29.714641: Pseudo dice [np.float32(0.6024)] 
2025-07-09 22:11:29.714761: Epoch time: 46.02 s 
2025-07-09 22:11:31.820138:  
2025-07-09 22:11:31.820604: Epoch 100 
2025-07-09 22:11:31.820802: Current learning rate: 0.0091 
2025-07-09 22:12:18.787298: train_loss -0.3903 
2025-07-09 22:12:18.787730: val_loss -0.3857 
2025-07-09 22:12:18.787806: Pseudo dice [np.float32(0.5393)] 
2025-07-09 22:12:18.787917: Epoch time: 46.97 s 
2025-07-09 22:12:20.549426:  
2025-07-09 22:12:20.550081: Epoch 101 
2025-07-09 22:12:20.550257: Current learning rate: 0.00909 
2025-07-09 22:13:07.946316: train_loss -0.3919 
2025-07-09 22:13:07.946812: val_loss -0.4056 
2025-07-09 22:13:07.946906: Pseudo dice [np.float32(0.6353)] 
2025-07-09 22:13:07.947013: Epoch time: 47.4 s 
2025-07-09 22:13:09.120304:  
2025-07-09 22:13:09.120767: Epoch 102 
2025-07-09 22:13:09.120903: Current learning rate: 0.00908 
2025-07-09 22:13:56.193098: train_loss -0.4005 
2025-07-09 22:13:56.193588: val_loss -0.4105 
2025-07-09 22:13:56.193671: Pseudo dice [np.float32(0.6846)] 
2025-07-09 22:13:56.193783: Epoch time: 47.07 s 
2025-07-09 22:13:57.311586:  
2025-07-09 22:13:57.311916: Epoch 103 
2025-07-09 22:13:57.312116: Current learning rate: 0.00907 
2025-07-09 22:14:44.266678: train_loss -0.3726 
2025-07-09 22:14:44.267778: val_loss -0.4043 
2025-07-09 22:14:44.267954: Pseudo dice [np.float32(0.4787)] 
2025-07-09 22:14:44.268126: Epoch time: 46.96 s 
2025-07-09 22:14:45.386314:  
2025-07-09 22:14:45.386710: Epoch 104 
2025-07-09 22:14:45.386931: Current learning rate: 0.00906 
2025-07-09 22:15:31.087949: train_loss -0.4003 
2025-07-09 22:15:31.089588: val_loss -0.4276 
2025-07-09 22:15:31.089760: Pseudo dice [np.float32(0.6573)] 
2025-07-09 22:15:31.089926: Epoch time: 45.7 s 
2025-07-09 22:15:32.203972:  
2025-07-09 22:15:32.204411: Epoch 105 
2025-07-09 22:15:32.204653: Current learning rate: 0.00905 
2025-07-09 22:16:18.316051: train_loss -0.3965 
2025-07-09 22:16:18.316619: val_loss -0.3611 
2025-07-09 22:16:18.316702: Pseudo dice [np.float32(0.5909)] 
2025-07-09 22:16:18.316805: Epoch time: 46.11 s 
2025-07-09 22:16:19.398078:  
2025-07-09 22:16:19.398321: Epoch 106 
2025-07-09 22:16:19.398454: Current learning rate: 0.00904 
2025-07-09 22:17:05.055270: train_loss -0.3834 
2025-07-09 22:17:05.055820: val_loss -0.3884 
2025-07-09 22:17:05.055912: Pseudo dice [np.float32(0.4807)] 
2025-07-09 22:17:05.056031: Epoch time: 45.66 s 
2025-07-09 22:17:06.153997:  
2025-07-09 22:17:06.154384: Epoch 107 
2025-07-09 22:17:06.154578: Current learning rate: 0.00903 
2025-07-09 22:17:52.535382: train_loss -0.4103 
2025-07-09 22:17:52.535764: val_loss -0.4109 
2025-07-09 22:17:52.535858: Pseudo dice [np.float32(0.6002)] 
2025-07-09 22:17:52.535969: Epoch time: 46.38 s 
2025-07-09 22:17:53.646175:  
2025-07-09 22:17:53.646518: Epoch 108 
2025-07-09 22:17:53.646674: Current learning rate: 0.00902 
2025-07-09 22:18:39.787394: train_loss -0.3974 
2025-07-09 22:18:39.787997: val_loss -0.4042 
2025-07-09 22:18:39.788086: Pseudo dice [np.float32(0.5498)] 
2025-07-09 22:18:39.788209: Epoch time: 46.14 s 
2025-07-09 22:18:40.889009:  
2025-07-09 22:18:40.889318: Epoch 109 
2025-07-09 22:18:40.889528: Current learning rate: 0.00901 
2025-07-09 22:19:26.778709: train_loss -0.407 
2025-07-09 22:19:26.779048: val_loss -0.3762 
2025-07-09 22:19:26.779125: Pseudo dice [np.float32(0.5807)] 
2025-07-09 22:19:26.779231: Epoch time: 45.89 s 
2025-07-09 22:19:27.853429:  
2025-07-09 22:19:27.853817: Epoch 110 
2025-07-09 22:19:27.854048: Current learning rate: 0.009 
2025-07-09 22:20:13.817402: train_loss -0.4101 
2025-07-09 22:20:13.817907: val_loss -0.3818 
2025-07-09 22:20:13.817984: Pseudo dice [np.float32(0.5479)] 
2025-07-09 22:20:13.818095: Epoch time: 45.96 s 
2025-07-09 22:20:15.187547:  
2025-07-09 22:20:15.187974: Epoch 111 
2025-07-09 22:20:15.188111: Current learning rate: 0.009 
2025-07-09 22:21:01.792327: train_loss -0.4054 
2025-07-09 22:21:01.792772: val_loss -0.4124 
2025-07-09 22:21:01.792848: Pseudo dice [np.float32(0.6082)] 
2025-07-09 22:21:01.792949: Epoch time: 46.61 s 
2025-07-09 22:21:02.848472:  
2025-07-09 22:21:02.848811: Epoch 112 
2025-07-09 22:21:02.848969: Current learning rate: 0.00899 
2025-07-09 22:21:48.710392: train_loss -0.3433 
2025-07-09 22:21:48.710802: val_loss -0.3886 
2025-07-09 22:21:48.710957: Pseudo dice [np.float32(0.6187)] 
2025-07-09 22:21:48.711067: Epoch time: 45.86 s 
2025-07-09 22:21:50.440180:  
2025-07-09 22:21:50.440388: Epoch 113 
2025-07-09 22:21:50.440575: Current learning rate: 0.00898 
2025-07-09 22:22:36.189041: train_loss -0.4068 
2025-07-09 22:22:36.189492: val_loss -0.3936 
2025-07-09 22:22:36.189620: Pseudo dice [np.float32(0.5331)] 
2025-07-09 22:22:36.189734: Epoch time: 45.75 s 
2025-07-09 22:22:37.293318:  
2025-07-09 22:22:37.293627: Epoch 114 
2025-07-09 22:22:37.293950: Current learning rate: 0.00897 
2025-07-09 22:23:23.666426: train_loss -0.4014 
2025-07-09 22:23:23.666831: val_loss -0.3883 
2025-07-09 22:23:23.666918: Pseudo dice [np.float32(0.5768)] 
2025-07-09 22:23:23.667036: Epoch time: 46.37 s 
2025-07-09 22:23:24.778703:  
2025-07-09 22:23:24.778995: Epoch 115 
2025-07-09 22:23:24.779242: Current learning rate: 0.00896 
2025-07-09 22:24:12.378292: train_loss -0.4131 
2025-07-09 22:24:12.378878: val_loss -0.344 
2025-07-09 22:24:12.378966: Pseudo dice [np.float32(0.3358)] 
2025-07-09 22:24:12.379094: Epoch time: 47.6 s 
2025-07-09 22:24:13.556519:  
2025-07-09 22:24:13.556815: Epoch 116 
2025-07-09 22:24:13.556943: Current learning rate: 0.00895 
2025-07-09 22:25:00.393204: train_loss -0.4124 
2025-07-09 22:25:00.393581: val_loss -0.4313 
2025-07-09 22:25:00.393714: Pseudo dice [np.float32(0.7319)] 
2025-07-09 22:25:00.393848: Epoch time: 46.84 s 
2025-07-09 22:25:01.481011:  
2025-07-09 22:25:01.481333: Epoch 117 
2025-07-09 22:25:01.481499: Current learning rate: 0.00894 
2025-07-09 22:25:47.582448: train_loss -0.4203 
2025-07-09 22:25:47.582994: val_loss -0.4365 
2025-07-09 22:25:47.583072: Pseudo dice [np.float32(0.6821)] 
2025-07-09 22:25:47.583188: Epoch time: 46.1 s 
2025-07-09 22:25:48.677495:  
2025-07-09 22:25:48.678005: Epoch 118 
2025-07-09 22:25:48.678133: Current learning rate: 0.00893 
2025-07-09 22:26:35.798846: train_loss -0.428 
2025-07-09 22:26:35.799287: val_loss -0.4307 
2025-07-09 22:26:35.799369: Pseudo dice [np.float32(0.7087)] 
2025-07-09 22:26:35.799481: Epoch time: 47.12 s 
2025-07-09 22:26:36.892596:  
2025-07-09 22:26:36.893204: Epoch 119 
2025-07-09 22:26:36.893340: Current learning rate: 0.00892 
2025-07-09 22:27:22.585814: train_loss -0.4224 
2025-07-09 22:27:22.586324: val_loss -0.4186 
2025-07-09 22:27:22.586429: Pseudo dice [np.float32(0.6301)] 
2025-07-09 22:27:22.586558: Epoch time: 45.69 s 
2025-07-09 22:27:23.737680:  
2025-07-09 22:27:23.738276: Epoch 120 
2025-07-09 22:27:23.738640: Current learning rate: 0.00891 
2025-07-09 22:28:10.132639: train_loss -0.4357 
2025-07-09 22:28:10.133422: val_loss -0.4108 
2025-07-09 22:28:10.133520: Pseudo dice [np.float32(0.6402)] 
2025-07-09 22:28:10.133752: Epoch time: 46.4 s 
2025-07-09 22:28:11.243599:  
2025-07-09 22:28:11.243860: Epoch 121 
2025-07-09 22:28:11.243955: Current learning rate: 0.0089 
2025-07-09 22:28:56.938381: train_loss -0.4268 
2025-07-09 22:28:56.938839: val_loss -0.4262 
2025-07-09 22:28:56.938921: Pseudo dice [np.float32(0.5806)] 
2025-07-09 22:28:56.939024: Epoch time: 45.7 s 
2025-07-09 22:28:58.037855:  
2025-07-09 22:28:58.038213: Epoch 122 
2025-07-09 22:28:58.038427: Current learning rate: 0.00889 
2025-07-09 22:29:43.232011: train_loss -0.4218 
2025-07-09 22:29:43.232455: val_loss -0.418 
2025-07-09 22:29:43.232605: Pseudo dice [np.float32(0.5819)] 
2025-07-09 22:29:43.232719: Epoch time: 45.2 s 
2025-07-09 22:29:44.383222:  
2025-07-09 22:29:44.383569: Epoch 123 
2025-07-09 22:29:44.383814: Current learning rate: 0.00889 
2025-07-09 22:30:29.381117: train_loss -0.3935 
2025-07-09 22:30:29.381748: val_loss -0.4016 
2025-07-09 22:30:29.381829: Pseudo dice [np.float32(0.5464)] 
2025-07-09 22:30:29.381955: Epoch time: 45.0 s 
2025-07-09 22:30:30.543058:  
2025-07-09 22:30:30.543278: Epoch 124 
2025-07-09 22:30:30.543425: Current learning rate: 0.00888 
2025-07-09 22:31:16.253292: train_loss -0.3992 
2025-07-09 22:31:16.253550: val_loss -0.4342 
2025-07-09 22:31:16.253624: Pseudo dice [np.float32(0.5178)] 
2025-07-09 22:31:16.253714: Epoch time: 45.71 s 
2025-07-09 22:31:17.825147:  
2025-07-09 22:31:17.825478: Epoch 125 
2025-07-09 22:31:17.825712: Current learning rate: 0.00887 
2025-07-09 22:32:04.171036: train_loss -0.4179 
2025-07-09 22:32:04.171602: val_loss -0.4269 
2025-07-09 22:32:04.171687: Pseudo dice [np.float32(0.6736)] 
2025-07-09 22:32:04.171789: Epoch time: 46.35 s 
2025-07-09 22:32:05.243700:  
2025-07-09 22:32:05.243982: Epoch 126 
2025-07-09 22:32:05.244104: Current learning rate: 0.00886 
2025-07-09 22:32:51.150208: train_loss -0.4327 
2025-07-09 22:32:51.150795: val_loss -0.4362 
2025-07-09 22:32:51.150882: Pseudo dice [np.float32(0.6648)] 
2025-07-09 22:32:51.151007: Epoch time: 45.91 s 
2025-07-09 22:32:52.292120:  
2025-07-09 22:32:52.292392: Epoch 127 
2025-07-09 22:32:52.292523: Current learning rate: 0.00885 
2025-07-09 22:33:38.504154: train_loss -0.4256 
2025-07-09 22:33:38.504622: val_loss -0.4045 
2025-07-09 22:33:38.504698: Pseudo dice [np.float32(0.6114)] 
2025-07-09 22:33:38.504794: Epoch time: 46.21 s 
2025-07-09 22:33:39.633476:  
2025-07-09 22:33:39.633826: Epoch 128 
2025-07-09 22:33:39.633928: Current learning rate: 0.00884 
2025-07-09 22:34:25.804840: train_loss -0.4295 
2025-07-09 22:34:25.805207: val_loss -0.4144 
2025-07-09 22:34:25.805284: Pseudo dice [np.float32(0.6249)] 
2025-07-09 22:34:25.805536: Epoch time: 46.17 s 
2025-07-09 22:34:26.901121:  
2025-07-09 22:34:26.901483: Epoch 129 
2025-07-09 22:34:26.901618: Current learning rate: 0.00883 
2025-07-09 22:35:13.092015: train_loss -0.4106 
2025-07-09 22:35:13.092504: val_loss -0.3975 
2025-07-09 22:35:13.092607: Pseudo dice [np.float32(0.6194)] 
2025-07-09 22:35:13.092722: Epoch time: 46.19 s 
2025-07-09 22:35:14.241658:  
2025-07-09 22:35:14.242064: Epoch 130 
2025-07-09 22:35:14.242188: Current learning rate: 0.00882 
2025-07-09 22:36:00.647464: train_loss -0.4082 
2025-07-09 22:36:00.648177: val_loss -0.435 
2025-07-09 22:36:00.648284: Pseudo dice [np.float32(0.6383)] 
2025-07-09 22:36:00.648410: Epoch time: 46.41 s 
2025-07-09 22:36:01.783347:  
2025-07-09 22:36:01.783813: Epoch 131 
2025-07-09 22:36:01.783939: Current learning rate: 0.00881 
2025-07-09 22:36:47.603947: train_loss -0.4259 
2025-07-09 22:36:47.605081: val_loss -0.4399 
2025-07-09 22:36:47.605229: Pseudo dice [np.float32(0.6813)] 
2025-07-09 22:36:47.605364: Epoch time: 45.82 s 
2025-07-09 22:36:48.698938:  
2025-07-09 22:36:48.699347: Epoch 132 
2025-07-09 22:36:48.699514: Current learning rate: 0.0088 
2025-07-09 22:37:34.799951: train_loss -0.3913 
2025-07-09 22:37:34.800598: val_loss -0.3881 
2025-07-09 22:37:34.800695: Pseudo dice [np.float32(0.5625)] 
2025-07-09 22:37:34.800819: Epoch time: 46.1 s 
2025-07-09 22:37:35.930208:  
2025-07-09 22:37:35.930574: Epoch 133 
2025-07-09 22:37:35.930715: Current learning rate: 0.00879 
2025-07-09 22:38:21.544672: train_loss -0.4165 
2025-07-09 22:38:21.545897: val_loss -0.4151 
2025-07-09 22:38:21.546051: Pseudo dice [np.float32(0.5584)] 
2025-07-09 22:38:21.546253: Epoch time: 45.62 s 
2025-07-09 22:38:22.753339:  
2025-07-09 22:38:22.753852: Epoch 134 
2025-07-09 22:38:22.753999: Current learning rate: 0.00879 
2025-07-09 22:39:08.400024: train_loss -0.4243 
2025-07-09 22:39:08.400434: val_loss -0.4282 
2025-07-09 22:39:08.400521: Pseudo dice [np.float32(0.6705)] 
2025-07-09 22:39:08.400652: Epoch time: 45.65 s 
2025-07-09 22:39:09.565763:  
2025-07-09 22:39:09.566453: Epoch 135 
2025-07-09 22:39:09.566667: Current learning rate: 0.00878 
2025-07-09 22:39:55.836234: train_loss -0.4213 
2025-07-09 22:39:55.837508: val_loss -0.4154 
2025-07-09 22:39:55.837670: Pseudo dice [np.float32(0.646)] 
2025-07-09 22:39:55.837884: Epoch time: 46.27 s 
2025-07-09 22:39:56.954240:  
2025-07-09 22:39:56.954705: Epoch 136 
2025-07-09 22:39:56.954955: Current learning rate: 0.00877 
2025-07-09 22:40:43.529458: train_loss -0.4127 
2025-07-09 22:40:43.529846: val_loss -0.4253 
2025-07-09 22:40:43.529926: Pseudo dice [np.float32(0.6636)] 
2025-07-09 22:40:43.530172: Epoch time: 46.58 s 
2025-07-09 22:40:45.319505:  
2025-07-09 22:40:45.319895: Epoch 137 
2025-07-09 22:40:45.320075: Current learning rate: 0.00876 
2025-07-09 22:41:31.966628: train_loss -0.4269 
2025-07-09 22:41:31.967269: val_loss -0.4319 
2025-07-09 22:41:31.970992: Pseudo dice [np.float32(0.5985)] 
2025-07-09 22:41:31.971220: Epoch time: 46.65 s 
2025-07-09 22:41:33.138608:  
2025-07-09 22:41:33.139126: Epoch 138 
2025-07-09 22:41:33.139256: Current learning rate: 0.00875 
2025-07-09 22:42:18.901754: train_loss -0.4312 
2025-07-09 22:42:18.902463: val_loss -0.4522 
2025-07-09 22:42:18.902569: Pseudo dice [np.float32(0.6883)] 
2025-07-09 22:42:18.902701: Epoch time: 45.76 s 
2025-07-09 22:42:20.098815:  
2025-07-09 22:42:20.099161: Epoch 139 
2025-07-09 22:42:20.099306: Current learning rate: 0.00874 
2025-07-09 22:43:05.608396: train_loss -0.4324 
2025-07-09 22:43:05.609121: val_loss -0.4455 
2025-07-09 22:43:05.609204: Pseudo dice [np.float32(0.7167)] 
2025-07-09 22:43:05.609334: Epoch time: 45.51 s 
2025-07-09 22:43:06.757791:  
2025-07-09 22:43:06.758192: Epoch 140 
2025-07-09 22:43:06.758445: Current learning rate: 0.00873 
2025-07-09 22:43:52.655031: train_loss -0.4243 
2025-07-09 22:43:52.655703: val_loss -0.4362 
2025-07-09 22:43:52.655812: Pseudo dice [np.float32(0.7247)] 
2025-07-09 22:43:52.655932: Epoch time: 45.9 s 
2025-07-09 22:43:53.807593:  
2025-07-09 22:43:53.807778: Epoch 141 
2025-07-09 22:43:53.807931: Current learning rate: 0.00872 
2025-07-09 22:44:39.154050: train_loss -0.4255 
2025-07-09 22:44:39.154721: val_loss -0.4158 
2025-07-09 22:44:39.154815: Pseudo dice [np.float32(0.6432)] 
2025-07-09 22:44:39.154933: Epoch time: 45.35 s 
2025-07-09 22:44:40.257635:  
2025-07-09 22:44:40.257814: Epoch 142 
2025-07-09 22:44:40.257975: Current learning rate: 0.00871 
2025-07-09 22:45:26.055406: train_loss -0.4236 
2025-07-09 22:45:26.056508: val_loss -0.4289 
2025-07-09 22:45:26.056729: Pseudo dice [np.float32(0.6614)] 
2025-07-09 22:45:26.056938: Epoch time: 45.8 s 
2025-07-09 22:45:27.278339:  
2025-07-09 22:45:27.278713: Epoch 143 
2025-07-09 22:45:27.279120: Current learning rate: 0.0087 
2025-07-09 22:46:12.969965: train_loss -0.413 
2025-07-09 22:46:12.970359: val_loss -0.4225 
2025-07-09 22:46:12.970433: Pseudo dice [np.float32(0.6752)] 
2025-07-09 22:46:12.970536: Epoch time: 45.69 s 
2025-07-09 22:46:14.066547:  
2025-07-09 22:46:14.066792: Epoch 144 
2025-07-09 22:46:14.066933: Current learning rate: 0.00869 
2025-07-09 22:46:59.582937: train_loss -0.4256 
2025-07-09 22:46:59.583437: val_loss -0.3782 
2025-07-09 22:46:59.583519: Pseudo dice [np.float32(0.3555)] 
2025-07-09 22:46:59.583641: Epoch time: 45.52 s 
2025-07-09 22:47:00.709064:  
2025-07-09 22:47:00.709806: Epoch 145 
2025-07-09 22:47:00.709986: Current learning rate: 0.00868 
2025-07-09 22:47:45.654315: train_loss -0.4013 
2025-07-09 22:47:45.655831: val_loss -0.4085 
2025-07-09 22:47:45.656006: Pseudo dice [np.float32(0.5604)] 
2025-07-09 22:47:45.656220: Epoch time: 44.95 s 
2025-07-09 22:47:46.768501:  
2025-07-09 22:47:46.768808: Epoch 146 
2025-07-09 22:47:46.769120: Current learning rate: 0.00868 
2025-07-09 22:48:32.912587: train_loss -0.4307 
2025-07-09 22:48:32.913017: val_loss -0.4281 
2025-07-09 22:48:32.913090: Pseudo dice [np.float32(0.6322)] 
2025-07-09 22:48:32.913186: Epoch time: 46.15 s 
2025-07-09 22:48:34.050801:  
2025-07-09 22:48:34.051116: Epoch 147 
2025-07-09 22:48:34.051296: Current learning rate: 0.00867 
2025-07-09 22:49:20.144365: train_loss -0.4458 
2025-07-09 22:49:20.145063: val_loss -0.4444 
2025-07-09 22:49:20.145146: Pseudo dice [np.float32(0.711)] 
2025-07-09 22:49:20.145276: Epoch time: 46.09 s 
2025-07-09 22:49:21.757593:  
2025-07-09 22:49:21.757890: Epoch 148 
2025-07-09 22:49:21.758044: Current learning rate: 0.00866 
2025-07-09 22:50:07.131422: train_loss -0.4285 
2025-07-09 22:50:07.131892: val_loss -0.4417 
2025-07-09 22:50:07.131972: Pseudo dice [np.float32(0.7431)] 
2025-07-09 22:50:07.132075: Epoch time: 45.37 s 
2025-07-09 22:50:08.234053:  
2025-07-09 22:50:08.234390: Epoch 149 
2025-07-09 22:50:08.234497: Current learning rate: 0.00865 
2025-07-09 22:50:54.695951: train_loss -0.4177 
2025-07-09 22:50:54.696340: val_loss -0.4224 
2025-07-09 22:50:54.696432: Pseudo dice [np.float32(0.7052)] 
2025-07-09 22:50:54.696584: Epoch time: 46.46 s 
2025-07-09 22:50:56.762817:  
2025-07-09 22:50:56.763158: Epoch 150 
2025-07-09 22:50:56.763294: Current learning rate: 0.00864 
2025-07-09 22:51:43.816065: train_loss -0.4444 
2025-07-09 22:51:43.816442: val_loss -0.4473 
2025-07-09 22:51:43.816530: Pseudo dice [np.float32(0.7256)] 
2025-07-09 22:51:43.816657: Epoch time: 47.05 s 
2025-07-09 22:51:45.027511:  
2025-07-09 22:51:45.028275: Epoch 151 
2025-07-09 22:51:45.028424: Current learning rate: 0.00863 
2025-07-09 22:52:31.706294: train_loss -0.4126 
2025-07-09 22:52:31.706798: val_loss -0.443 
2025-07-09 22:52:31.706886: Pseudo dice [np.float32(0.6764)] 
2025-07-09 22:52:31.707007: Epoch time: 46.68 s 
2025-07-09 22:52:32.847862:  
2025-07-09 22:52:32.848263: Epoch 152 
2025-07-09 22:52:32.848396: Current learning rate: 0.00862 
2025-07-09 22:53:19.339531: train_loss -0.4171 
2025-07-09 22:53:19.340012: val_loss -0.4254 
2025-07-09 22:53:19.340103: Pseudo dice [np.float32(0.6402)] 
2025-07-09 22:53:19.340244: Epoch time: 46.49 s 
2025-07-09 22:53:20.420903:  
2025-07-09 22:53:20.421283: Epoch 153 
2025-07-09 22:53:20.421442: Current learning rate: 0.00861 
2025-07-09 22:54:07.042842: train_loss -0.387 
2025-07-09 22:54:07.043392: val_loss -0.4108 
2025-07-09 22:54:07.043473: Pseudo dice [np.float32(0.6688)] 
2025-07-09 22:54:07.043597: Epoch time: 46.62 s 
2025-07-09 22:54:08.198830:  
2025-07-09 22:54:08.199448: Epoch 154 
2025-07-09 22:54:08.199587: Current learning rate: 0.0086 
2025-07-09 22:54:55.016726: train_loss -0.4032 
2025-07-09 22:54:55.017293: val_loss -0.3546 
2025-07-09 22:54:55.017387: Pseudo dice [np.float32(0.4182)] 
2025-07-09 22:54:55.017521: Epoch time: 46.82 s 
2025-07-09 22:54:56.301612:  
2025-07-09 22:54:56.301904: Epoch 155 
2025-07-09 22:54:56.302099: Current learning rate: 0.00859 
2025-07-09 22:55:41.776323: train_loss -0.3343 
2025-07-09 22:55:41.776761: val_loss -0.3567 
2025-07-09 22:55:41.776881: Pseudo dice [np.float32(0.2704)] 
2025-07-09 22:55:41.777027: Epoch time: 45.48 s 
2025-07-09 22:55:42.955280:  
2025-07-09 22:55:42.955575: Epoch 156 
2025-07-09 22:55:42.955781: Current learning rate: 0.00858 
2025-07-09 22:56:28.447881: train_loss -0.3382 
2025-07-09 22:56:28.448364: val_loss -0.3203 
2025-07-09 22:56:28.448439: Pseudo dice [np.float32(0.0)] 
2025-07-09 22:56:28.448535: Epoch time: 45.49 s 
2025-07-09 22:56:29.594043:  
2025-07-09 22:56:29.594229: Epoch 157 
2025-07-09 22:56:29.594349: Current learning rate: 0.00858 
2025-07-09 22:57:15.961158: train_loss -0.3101 
2025-07-09 22:57:15.961580: val_loss -0.294 
2025-07-09 22:57:15.961736: Pseudo dice [np.float32(0.0)] 
2025-07-09 22:57:15.961911: Epoch time: 46.37 s 
2025-07-09 22:57:17.107976:  
2025-07-09 22:57:17.108675: Epoch 158 
2025-07-09 22:57:17.108783: Current learning rate: 0.00857 
2025-07-09 22:58:03.636967: train_loss -0.3416 
2025-07-09 22:58:03.637710: val_loss -0.3299 
2025-07-09 22:58:03.637824: Pseudo dice [np.float32(0.0)] 
2025-07-09 22:58:03.637960: Epoch time: 46.53 s 
2025-07-09 22:58:05.475993:  
2025-07-09 22:58:05.476859: Epoch 159 
2025-07-09 22:58:05.477589: Current learning rate: 0.00856 
2025-07-09 22:58:52.557896: train_loss -0.3526 
2025-07-09 22:58:52.558384: val_loss -0.3903 
2025-07-09 22:58:52.558517: Pseudo dice [np.float32(0.0)] 
2025-07-09 22:58:52.558641: Epoch time: 47.08 s 
2025-07-09 22:58:53.702371:  
2025-07-09 22:58:53.702854: Epoch 160 
2025-07-09 22:58:53.702986: Current learning rate: 0.00855 
2025-07-09 22:59:40.330014: train_loss -0.3478 
2025-07-09 22:59:40.332318: val_loss -0.2946 
2025-07-09 22:59:40.332556: Pseudo dice [np.float32(0.0)] 
2025-07-09 22:59:40.332851: Epoch time: 46.63 s 
2025-07-09 22:59:41.649643:  
2025-07-09 22:59:41.650278: Epoch 161 
2025-07-09 22:59:41.650630: Current learning rate: 0.00854 
2025-07-09 23:00:28.295866: train_loss -0.3528 
2025-07-09 23:00:28.296430: val_loss -0.3511 
2025-07-09 23:00:28.296515: Pseudo dice [np.float32(0.0)] 
2025-07-09 23:00:28.296647: Epoch time: 46.65 s 
2025-07-09 23:00:29.445897:  
2025-07-09 23:00:29.446284: Epoch 162 
2025-07-09 23:00:29.446415: Current learning rate: 0.00853 
2025-07-09 23:01:16.214089: train_loss -0.3536 
2025-07-09 23:01:16.214680: val_loss -0.3499 
2025-07-09 23:01:16.214773: Pseudo dice [np.float32(0.0)] 
2025-07-09 23:01:16.214896: Epoch time: 46.77 s 
2025-07-09 23:01:17.360897:  
2025-07-09 23:01:17.361252: Epoch 163 
2025-07-09 23:01:17.361509: Current learning rate: 0.00852 
2025-07-09 23:02:02.723824: train_loss -0.3545 
2025-07-09 23:02:02.724509: val_loss -0.3633 
2025-07-09 23:02:02.724619: Pseudo dice [np.float32(0.0)] 
2025-07-09 23:02:02.724760: Epoch time: 45.36 s 
2025-07-09 23:02:03.917363:  
2025-07-09 23:02:03.917855: Epoch 164 
2025-07-09 23:02:03.918341: Current learning rate: 0.00851 
2025-07-09 23:02:49.668952: train_loss -0.4205 
2025-07-09 23:02:49.670268: val_loss -0.4371 
2025-07-09 23:02:49.670497: Pseudo dice [np.float32(0.69)] 
2025-07-09 23:02:49.670663: Epoch time: 45.75 s 
2025-07-09 23:02:50.868759:  
2025-07-09 23:02:50.869266: Epoch 165 
2025-07-09 23:02:50.869451: Current learning rate: 0.0085 
2025-07-09 23:03:36.005664: train_loss -0.431 
2025-07-09 23:03:36.006446: val_loss -0.4063 
2025-07-09 23:03:36.006559: Pseudo dice [np.float32(0.6353)] 
2025-07-09 23:03:36.006678: Epoch time: 45.14 s 
2025-07-09 23:03:37.154003:  
2025-07-09 23:03:37.154330: Epoch 166 
2025-07-09 23:03:37.154431: Current learning rate: 0.00849 
2025-07-09 23:04:22.596771: train_loss -0.4434 
2025-07-09 23:04:22.597741: val_loss -0.4468 
2025-07-09 23:04:22.597847: Pseudo dice [np.float32(0.6904)] 
2025-07-09 23:04:22.598096: Epoch time: 45.44 s 
2025-07-09 23:04:23.740964:  
2025-07-09 23:04:23.741312: Epoch 167 
2025-07-09 23:04:23.741514: Current learning rate: 0.00848 
2025-07-09 23:05:09.543138: train_loss -0.4383 
2025-07-09 23:05:09.543876: val_loss -0.443 
2025-07-09 23:05:09.543996: Pseudo dice [np.float32(0.6752)] 
2025-07-09 23:05:09.544163: Epoch time: 45.8 s 
2025-07-09 23:05:10.685686:  
2025-07-09 23:05:10.686503: Epoch 168 
2025-07-09 23:05:10.686901: Current learning rate: 0.00847 
2025-07-09 23:05:57.074003: train_loss -0.4244 
2025-07-09 23:05:57.074611: val_loss -0.413 
2025-07-09 23:05:57.074709: Pseudo dice [np.float32(0.6351)] 
2025-07-09 23:05:57.074869: Epoch time: 46.39 s 
2025-07-09 23:05:58.216051:  
2025-07-09 23:05:58.216373: Epoch 169 
2025-07-09 23:05:58.216551: Current learning rate: 0.00847 
2025-07-09 23:06:44.398067: train_loss -0.4234 
2025-07-09 23:06:44.398530: val_loss -0.4042 
2025-07-09 23:06:44.398622: Pseudo dice [np.float32(0.5666)] 
2025-07-09 23:06:44.398735: Epoch time: 46.18 s 
2025-07-09 23:06:46.221651:  
2025-07-09 23:06:46.222011: Epoch 170 
2025-07-09 23:06:46.222142: Current learning rate: 0.00846 
2025-07-09 23:07:32.572072: train_loss -0.4373 
2025-07-09 23:07:32.572567: val_loss -0.4612 
2025-07-09 23:07:32.572656: Pseudo dice [np.float32(0.7323)] 
2025-07-09 23:07:32.572777: Epoch time: 46.35 s 
2025-07-09 23:07:33.986489:  
2025-07-09 23:07:33.986794: Epoch 171 
2025-07-09 23:07:33.986918: Current learning rate: 0.00845 
2025-07-09 23:08:20.914009: train_loss -0.4393 
2025-07-09 23:08:20.914597: val_loss -0.4189 
2025-07-09 23:08:20.914686: Pseudo dice [np.float32(0.6636)] 
2025-07-09 23:08:20.914809: Epoch time: 46.93 s 
2025-07-09 23:08:22.039490:  
2025-07-09 23:08:22.039955: Epoch 172 
2025-07-09 23:08:22.040092: Current learning rate: 0.00844 
2025-07-09 23:09:09.118314: train_loss -0.4418 
2025-07-09 23:09:09.118821: val_loss -0.4594 
2025-07-09 23:09:09.118919: Pseudo dice [np.float32(0.7449)] 
2025-07-09 23:09:09.119040: Epoch time: 47.08 s 
2025-07-09 23:09:10.338346:  
2025-07-09 23:09:10.338704: Epoch 173 
2025-07-09 23:09:10.338863: Current learning rate: 0.00843 
2025-07-09 23:09:56.871459: train_loss -0.4487 
2025-07-09 23:09:56.871965: val_loss -0.4631 
2025-07-09 23:09:56.872055: Pseudo dice [np.float32(0.6366)] 
2025-07-09 23:09:56.872168: Epoch time: 46.53 s 
2025-07-09 23:09:57.988910:  
2025-07-09 23:09:57.989108: Epoch 174 
2025-07-09 23:09:57.989277: Current learning rate: 0.00842 
2025-07-09 23:10:45.135657: train_loss -0.4572 
2025-07-09 23:10:45.136340: val_loss -0.4544 
2025-07-09 23:10:45.136502: Pseudo dice [np.float32(0.6538)] 
2025-07-09 23:10:45.136678: Epoch time: 47.15 s 
2025-07-09 23:10:46.255141:  
2025-07-09 23:10:46.255527: Epoch 175 
2025-07-09 23:10:46.255666: Current learning rate: 0.00841 
2025-07-09 23:11:33.383163: train_loss -0.4483 
2025-07-09 23:11:33.383783: val_loss -0.4547 
2025-07-09 23:11:33.383891: Pseudo dice [np.float32(0.7173)] 
2025-07-09 23:11:33.384068: Epoch time: 47.13 s 
2025-07-09 23:11:34.521960:  
2025-07-09 23:11:34.522367: Epoch 176 
2025-07-09 23:11:34.522562: Current learning rate: 0.0084 
2025-07-09 23:12:21.295118: train_loss -0.4605 
2025-07-09 23:12:21.295567: val_loss -0.4541 
2025-07-09 23:12:21.298951: Pseudo dice [np.float32(0.7297)] 
2025-07-09 23:12:21.299083: Epoch time: 46.77 s 
2025-07-09 23:12:22.495002:  
2025-07-09 23:12:22.495314: Epoch 177 
2025-07-09 23:12:22.495531: Current learning rate: 0.00839 
2025-07-09 23:13:08.975440: train_loss -0.4505 
2025-07-09 23:13:08.975926: val_loss -0.431 
2025-07-09 23:13:08.976114: Pseudo dice [np.float32(0.748)] 
2025-07-09 23:13:08.976275: Epoch time: 46.48 s 
2025-07-09 23:13:10.155486:  
2025-07-09 23:13:10.155937: Epoch 178 
2025-07-09 23:13:10.156069: Current learning rate: 0.00838 
2025-07-09 23:13:56.547152: train_loss -0.4603 
2025-07-09 23:13:56.547653: val_loss -0.4425 
2025-07-09 23:13:56.547742: Pseudo dice [np.float32(0.6678)] 
2025-07-09 23:13:56.547849: Epoch time: 46.39 s 
2025-07-09 23:13:57.713228:  
2025-07-09 23:13:57.713527: Epoch 179 
2025-07-09 23:13:57.713883: Current learning rate: 0.00837 
2025-07-09 23:14:44.405907: train_loss -0.4695 
2025-07-09 23:14:44.406253: val_loss -0.4597 
2025-07-09 23:14:44.406345: Pseudo dice [np.float32(0.7479)] 
2025-07-09 23:14:44.406512: Epoch time: 46.69 s 
2025-07-09 23:14:45.534850:  
2025-07-09 23:14:45.535306: Epoch 180 
2025-07-09 23:14:45.535482: Current learning rate: 0.00836 
2025-07-09 23:15:33.481369: train_loss -0.4445 
2025-07-09 23:15:33.481738: val_loss -0.4267 
2025-07-09 23:15:33.481815: Pseudo dice [np.float32(0.7127)] 
2025-07-09 23:15:33.481909: Epoch time: 47.95 s 
2025-07-09 23:15:35.148398:  
2025-07-09 23:15:35.148844: Epoch 181 
2025-07-09 23:15:35.148985: Current learning rate: 0.00836 
2025-07-09 23:16:21.807234: train_loss -0.4468 
2025-07-09 23:16:21.807831: val_loss -0.4464 
2025-07-09 23:16:21.807929: Pseudo dice [np.float32(0.6707)] 
2025-07-09 23:16:21.808043: Epoch time: 46.66 s 
2025-07-09 23:16:22.989163:  
2025-07-09 23:16:22.989597: Epoch 182 
2025-07-09 23:16:22.989758: Current learning rate: 0.00835 
2025-07-09 23:17:09.235343: train_loss -0.4421 
2025-07-09 23:17:09.235904: val_loss -0.4486 
2025-07-09 23:17:09.235988: Pseudo dice [np.float32(0.7612)] 
2025-07-09 23:17:09.236104: Epoch time: 46.25 s 
2025-07-09 23:17:10.366455:  
2025-07-09 23:17:10.366620: Epoch 183 
2025-07-09 23:17:10.366737: Current learning rate: 0.00834 
2025-07-09 23:17:58.014457: train_loss -0.4194 
2025-07-09 23:17:58.014916: val_loss -0.453 
2025-07-09 23:17:58.015023: Pseudo dice [np.float32(0.688)] 
2025-07-09 23:17:58.015196: Epoch time: 47.65 s 
2025-07-09 23:17:59.246506:  
2025-07-09 23:17:59.246874: Epoch 184 
2025-07-09 23:17:59.247023: Current learning rate: 0.00833 
2025-07-09 23:18:46.537321: train_loss -0.4207 
2025-07-09 23:18:46.537643: val_loss -0.2986 
2025-07-09 23:18:46.537723: Pseudo dice [np.float32(0.0133)] 
2025-07-09 23:18:46.537829: Epoch time: 47.29 s 
2025-07-09 23:18:47.625040:  
2025-07-09 23:18:47.625311: Epoch 185 
2025-07-09 23:18:47.625486: Current learning rate: 0.00832 
2025-07-09 23:19:34.372652: train_loss -0.3213 
2025-07-09 23:19:34.373140: val_loss -0.3366 
2025-07-09 23:19:34.373234: Pseudo dice [np.float32(0.0)] 
2025-07-09 23:19:34.373455: Epoch time: 46.75 s 
2025-07-09 23:19:35.473452:  
2025-07-09 23:19:35.473830: Epoch 186 
2025-07-09 23:19:35.474004: Current learning rate: 0.00831 
2025-07-09 23:20:23.144765: train_loss -0.3773 
2025-07-09 23:20:23.145324: val_loss -0.3693 
2025-07-09 23:20:23.145484: Pseudo dice [np.float32(0.5923)] 
2025-07-09 23:20:23.145619: Epoch time: 47.67 s 
2025-07-09 23:20:24.358475:  
2025-07-09 23:20:24.358811: Epoch 187 
2025-07-09 23:20:24.358969: Current learning rate: 0.0083 
2025-07-09 23:21:12.718762: train_loss -0.4305 
2025-07-09 23:21:12.719107: val_loss -0.452 
2025-07-09 23:21:12.719180: Pseudo dice [np.float32(0.7077)] 
2025-07-09 23:21:12.719276: Epoch time: 48.36 s 
2025-07-09 23:21:13.857981:  
2025-07-09 23:21:13.858274: Epoch 188 
2025-07-09 23:21:13.858413: Current learning rate: 0.00829 
2025-07-09 23:22:00.848432: train_loss -0.4399 
2025-07-09 23:22:00.848935: val_loss -0.4427 
2025-07-09 23:22:00.849018: Pseudo dice [np.float32(0.7189)] 
2025-07-09 23:22:00.849138: Epoch time: 46.99 s 
2025-07-09 23:22:01.993764:  
2025-07-09 23:22:01.994152: Epoch 189 
2025-07-09 23:22:01.994334: Current learning rate: 0.00828 
2025-07-09 23:22:48.546578: train_loss -0.4178 
2025-07-09 23:22:48.547028: val_loss -0.4152 
2025-07-09 23:22:48.547105: Pseudo dice [np.float32(0.6299)] 
2025-07-09 23:22:48.547202: Epoch time: 46.55 s 
2025-07-09 23:22:49.728298:  
2025-07-09 23:22:49.728605: Epoch 190 
2025-07-09 23:22:49.728758: Current learning rate: 0.00827 
2025-07-09 23:23:35.723365: train_loss -0.4294 
2025-07-09 23:23:35.724028: val_loss -0.4323 
2025-07-09 23:23:35.724112: Pseudo dice [np.float32(0.6403)] 
2025-07-09 23:23:35.724237: Epoch time: 46.0 s 
2025-07-09 23:23:36.879133:  
2025-07-09 23:23:36.879394: Epoch 191 
2025-07-09 23:23:36.879574: Current learning rate: 0.00826 
2025-07-09 23:24:23.953520: train_loss -0.4379 
2025-07-09 23:24:23.953988: val_loss -0.4406 
2025-07-09 23:24:23.954146: Pseudo dice [np.float32(0.6989)] 
2025-07-09 23:24:23.954249: Epoch time: 47.08 s 
2025-07-09 23:24:25.551333:  
2025-07-09 23:24:25.551775: Epoch 192 
2025-07-09 23:24:25.551906: Current learning rate: 0.00825 
2025-07-09 23:25:12.398307: train_loss -0.4488 
2025-07-09 23:25:12.398667: val_loss -0.4316 
2025-07-09 23:25:12.398755: Pseudo dice [np.float32(0.6828)] 
2025-07-09 23:25:12.398866: Epoch time: 46.85 s 
2025-07-09 23:25:13.516603:  
2025-07-09 23:25:13.516880: Epoch 193 
2025-07-09 23:25:13.517006: Current learning rate: 0.00824 
2025-07-09 23:25:59.727454: train_loss -0.4285 
2025-07-09 23:25:59.728069: val_loss -0.4515 
2025-07-09 23:25:59.728188: Pseudo dice [np.float32(0.6782)] 
2025-07-09 23:25:59.728380: Epoch time: 46.21 s 
2025-07-09 23:26:00.869764:  
2025-07-09 23:26:00.870453: Epoch 194 
2025-07-09 23:26:00.870590: Current learning rate: 0.00824 
2025-07-09 23:26:47.375603: train_loss -0.4264 
2025-07-09 23:26:47.376000: val_loss -0.3845 
2025-07-09 23:26:47.376074: Pseudo dice [np.float32(0.594)] 
2025-07-09 23:26:47.376177: Epoch time: 46.51 s 
2025-07-09 23:26:48.484920:  
2025-07-09 23:26:48.485349: Epoch 195 
2025-07-09 23:26:48.485482: Current learning rate: 0.00823 
2025-07-09 23:27:35.029217: train_loss -0.3424 
2025-07-09 23:27:35.029676: val_loss -0.3401 
2025-07-09 23:27:35.029756: Pseudo dice [np.float32(0.0)] 
2025-07-09 23:27:35.029860: Epoch time: 46.55 s 
2025-07-09 23:27:36.146641:  
2025-07-09 23:27:36.147017: Epoch 196 
2025-07-09 23:27:36.147143: Current learning rate: 0.00822 
2025-07-09 23:28:22.062443: train_loss -0.3935 
2025-07-09 23:28:22.063403: val_loss -0.4492 
2025-07-09 23:28:22.063534: Pseudo dice [np.float32(0.6803)] 
2025-07-09 23:28:22.063714: Epoch time: 45.92 s 
2025-07-09 23:28:23.215470:  
2025-07-09 23:28:23.215719: Epoch 197 
2025-07-09 23:28:23.215841: Current learning rate: 0.00821 
2025-07-09 23:29:10.052785: train_loss -0.4184 
2025-07-09 23:29:10.054124: val_loss -0.3263 
2025-07-09 23:29:10.054256: Pseudo dice [np.float32(0.2841)] 
2025-07-09 23:29:10.054555: Epoch time: 46.84 s 
2025-07-09 23:29:11.316017:  
2025-07-09 23:29:11.316192: Epoch 198 
2025-07-09 23:29:11.316288: Current learning rate: 0.0082 
2025-07-09 23:29:58.311169: train_loss -0.4239 
2025-07-09 23:29:58.311771: val_loss -0.4468 
2025-07-09 23:29:58.311850: Pseudo dice [np.float32(0.736)] 
2025-07-09 23:29:58.311960: Epoch time: 47.0 s 
2025-07-09 23:29:59.486431:  
2025-07-09 23:29:59.486751: Epoch 199 
2025-07-09 23:29:59.486911: Current learning rate: 0.00819 
2025-07-09 23:30:45.925145: train_loss -0.4472 
2025-07-09 23:30:45.925723: val_loss -0.4285 
2025-07-09 23:30:45.925808: Pseudo dice [np.float32(0.7329)] 
2025-07-09 23:30:45.925931: Epoch time: 46.44 s 
2025-07-09 23:30:48.092841:  
2025-07-09 23:30:48.093413: Epoch 200 
2025-07-09 23:30:48.093851: Current learning rate: 0.00818 
2025-07-09 23:31:33.471425: train_loss -0.4371 
2025-07-09 23:31:33.472377: val_loss -0.4468 
2025-07-09 23:31:33.472480: Pseudo dice [np.float32(0.6582)] 
2025-07-09 23:31:33.472674: Epoch time: 45.38 s 
2025-07-09 23:31:34.638165:  
2025-07-09 23:31:34.638293: Epoch 201 
2025-07-09 23:31:34.638391: Current learning rate: 0.00817 
2025-07-09 23:32:20.857975: train_loss -0.4183 
2025-07-09 23:32:20.858672: val_loss -0.4485 
2025-07-09 23:32:20.858749: Pseudo dice [np.float32(0.7434)] 
2025-07-09 23:32:20.858892: Epoch time: 46.22 s 
2025-07-09 23:32:22.015703:  
2025-07-09 23:32:22.016059: Epoch 202 
2025-07-09 23:32:22.016180: Current learning rate: 0.00816 
2025-07-09 23:33:08.341885: train_loss -0.4298 
2025-07-09 23:33:08.342337: val_loss -0.4005 
2025-07-09 23:33:08.342419: Pseudo dice [np.float32(0.5469)] 
2025-07-09 23:33:08.342526: Epoch time: 46.33 s 
2025-07-09 23:33:09.984035:  
2025-07-09 23:33:09.984264: Epoch 203 
2025-07-09 23:33:09.984391: Current learning rate: 0.00815 
2025-07-09 23:33:56.184423: train_loss -0.4318 
2025-07-09 23:33:56.184892: val_loss -0.443 
2025-07-09 23:33:56.184969: Pseudo dice [np.float32(0.7087)] 
2025-07-09 23:33:56.185074: Epoch time: 46.2 s 
2025-07-09 23:33:57.344009:  
2025-07-09 23:33:57.344352: Epoch 204 
2025-07-09 23:33:57.344578: Current learning rate: 0.00814 
2025-07-09 23:34:42.982476: train_loss -0.4241 
2025-07-09 23:34:42.983180: val_loss -0.4514 
2025-07-09 23:34:42.983273: Pseudo dice [np.float32(0.667)] 
2025-07-09 23:34:42.983395: Epoch time: 45.64 s 
2025-07-09 23:34:44.190125:  
2025-07-09 23:34:44.190528: Epoch 205 
2025-07-09 23:34:44.190787: Current learning rate: 0.00813 
2025-07-09 23:35:29.704181: train_loss -0.4514 
2025-07-09 23:35:29.704737: val_loss -0.4086 
2025-07-09 23:35:29.704932: Pseudo dice [np.float32(0.6012)] 
2025-07-09 23:35:29.705098: Epoch time: 45.52 s 
2025-07-09 23:35:30.832797:  
2025-07-09 23:35:30.833376: Epoch 206 
2025-07-09 23:35:30.833569: Current learning rate: 0.00813 
2025-07-09 23:36:16.634718: train_loss -0.4439 
2025-07-09 23:36:16.635699: val_loss -0.4449 
2025-07-09 23:36:16.635812: Pseudo dice [np.float32(0.7256)] 
2025-07-09 23:36:16.636045: Epoch time: 45.8 s 
2025-07-09 23:36:17.746983:  
2025-07-09 23:36:17.747148: Epoch 207 
2025-07-09 23:36:17.747263: Current learning rate: 0.00812 
2025-07-09 23:37:04.380074: train_loss -0.4376 
2025-07-09 23:37:04.380562: val_loss -0.4194 
2025-07-09 23:37:04.380640: Pseudo dice [np.float32(0.5537)] 
2025-07-09 23:37:04.380758: Epoch time: 46.63 s 
2025-07-09 23:37:05.484801:  
2025-07-09 23:37:05.485191: Epoch 208 
2025-07-09 23:37:05.485369: Current learning rate: 0.00811 
2025-07-09 23:37:51.756911: train_loss -0.4426 
2025-07-09 23:37:51.757454: val_loss -0.4499 
2025-07-09 23:37:51.757559: Pseudo dice [np.float32(0.7158)] 
2025-07-09 23:37:51.757689: Epoch time: 46.27 s 
2025-07-09 23:37:52.949283:  
2025-07-09 23:37:52.949796: Epoch 209 
2025-07-09 23:37:52.950034: Current learning rate: 0.0081 
2025-07-09 23:38:39.669822: train_loss -0.4181 
2025-07-09 23:38:39.670360: val_loss -0.4355 
2025-07-09 23:38:39.670440: Pseudo dice [np.float32(0.7126)] 
2025-07-09 23:38:39.670564: Epoch time: 46.72 s 
2025-07-09 23:38:40.762331:  
2025-07-09 23:38:40.762626: Epoch 210 
2025-07-09 23:38:40.762766: Current learning rate: 0.00809 
2025-07-09 23:39:26.638379: train_loss -0.4278 
2025-07-09 23:39:26.638990: val_loss -0.4482 
2025-07-09 23:39:26.639064: Pseudo dice [np.float32(0.7111)] 
2025-07-09 23:39:26.639165: Epoch time: 45.88 s 
2025-07-09 23:39:27.837700:  
2025-07-09 23:39:27.837871: Epoch 211 
2025-07-09 23:39:27.838000: Current learning rate: 0.00808 
2025-07-09 23:40:15.209010: train_loss -0.4416 
2025-07-09 23:40:15.209403: val_loss -0.4334 
2025-07-09 23:40:15.209489: Pseudo dice [np.float32(0.7035)] 
2025-07-09 23:40:15.209687: Epoch time: 47.37 s 
2025-07-09 23:40:16.304506:  
2025-07-09 23:40:16.304990: Epoch 212 
2025-07-09 23:40:16.305125: Current learning rate: 0.00807 
2025-07-09 23:41:02.874828: train_loss -0.4556 
2025-07-09 23:41:02.875608: val_loss -0.4517 
2025-07-09 23:41:02.875749: Pseudo dice [np.float32(0.7134)] 
2025-07-09 23:41:02.875898: Epoch time: 46.57 s 
2025-07-09 23:41:03.995391:  
2025-07-09 23:41:03.995872: Epoch 213 
2025-07-09 23:41:03.996043: Current learning rate: 0.00806 
2025-07-09 23:41:49.171769: train_loss -0.4545 
2025-07-09 23:41:49.172173: val_loss -0.4647 
2025-07-09 23:41:49.172259: Pseudo dice [np.float32(0.7475)] 
2025-07-09 23:41:49.172374: Epoch time: 45.18 s 
2025-07-09 23:41:50.293326:  
2025-07-09 23:41:50.293774: Epoch 214 
2025-07-09 23:41:50.293973: Current learning rate: 0.00805 
2025-07-09 23:42:35.541937: train_loss -0.4596 
2025-07-09 23:42:35.542466: val_loss -0.435 
2025-07-09 23:42:35.542568: Pseudo dice [np.float32(0.6777)] 
2025-07-09 23:42:35.542686: Epoch time: 45.25 s 
2025-07-09 23:42:37.332995:  
2025-07-09 23:42:37.333800: Epoch 215 
2025-07-09 23:42:37.334145: Current learning rate: 0.00804 
2025-07-09 23:43:23.841511: train_loss -0.4581 
2025-07-09 23:43:23.842324: val_loss -0.4662 
2025-07-09 23:43:23.842420: Pseudo dice [np.float32(0.7396)] 
2025-07-09 23:43:23.842573: Epoch time: 46.51 s 
2025-07-09 23:43:25.044554:  
2025-07-09 23:43:25.044935: Epoch 216 
2025-07-09 23:43:25.045072: Current learning rate: 0.00803 
2025-07-09 23:44:11.230512: train_loss -0.4638 
2025-07-09 23:44:11.230922: val_loss -0.477 
2025-07-09 23:44:11.231011: Pseudo dice [np.float32(0.7879)] 
2025-07-09 23:44:11.231129: Epoch time: 46.19 s 
2025-07-09 23:44:12.349070:  
2025-07-09 23:44:12.349597: Epoch 217 
2025-07-09 23:44:12.349736: Current learning rate: 0.00802 
2025-07-09 23:44:57.547707: train_loss -0.4655 
2025-07-09 23:44:57.548066: val_loss -0.4526 
2025-07-09 23:44:57.548146: Pseudo dice [np.float32(0.7183)] 
2025-07-09 23:44:57.548241: Epoch time: 45.2 s 
2025-07-09 23:44:58.678533:  
2025-07-09 23:44:58.678860: Epoch 218 
2025-07-09 23:44:58.679054: Current learning rate: 0.00801 
2025-07-09 23:45:44.202213: train_loss -0.4569 
2025-07-09 23:45:44.202522: val_loss -0.4371 
2025-07-09 23:45:44.202606: Pseudo dice [np.float32(0.7297)] 
2025-07-09 23:45:44.202705: Epoch time: 45.52 s 
2025-07-09 23:45:45.311369:  
2025-07-09 23:45:45.311830: Epoch 219 
2025-07-09 23:45:45.311975: Current learning rate: 0.00801 
2025-07-09 23:46:31.188255: train_loss -0.4181 
2025-07-09 23:46:31.189612: val_loss -0.4345 
2025-07-09 23:46:31.189721: Pseudo dice [np.float32(0.5718)] 
2025-07-09 23:46:31.189846: Epoch time: 45.88 s 
2025-07-09 23:46:32.342567:  
2025-07-09 23:46:32.343020: Epoch 220 
2025-07-09 23:46:32.343155: Current learning rate: 0.008 
2025-07-09 23:47:19.075002: train_loss -0.4305 
2025-07-09 23:47:19.075697: val_loss -0.3779 
2025-07-09 23:47:19.075775: Pseudo dice [np.float32(0.5823)] 
2025-07-09 23:47:19.075935: Epoch time: 46.73 s 
2025-07-09 23:47:20.195620:  
2025-07-09 23:47:20.196306: Epoch 221 
2025-07-09 23:47:20.196496: Current learning rate: 0.00799 
2025-07-09 23:48:06.270039: train_loss -0.4198 
2025-07-09 23:48:06.270582: val_loss -0.4424 
2025-07-09 23:48:06.270682: Pseudo dice [np.float32(0.6858)] 
2025-07-09 23:48:06.270818: Epoch time: 46.08 s 
2025-07-09 23:48:07.404993:  
2025-07-09 23:48:07.405243: Epoch 222 
2025-07-09 23:48:07.405470: Current learning rate: 0.00798 
2025-07-09 23:48:53.991025: train_loss -0.44 
2025-07-09 23:48:53.991482: val_loss -0.4653 
2025-07-09 23:48:53.991668: Pseudo dice [np.float32(0.7523)] 
2025-07-09 23:48:53.991813: Epoch time: 46.59 s 
2025-07-09 23:48:55.074140:  
2025-07-09 23:48:55.074804: Epoch 223 
2025-07-09 23:48:55.075150: Current learning rate: 0.00797 
2025-07-09 23:49:41.032299: train_loss -0.4449 
2025-07-09 23:49:41.032873: val_loss -0.437 
2025-07-09 23:49:41.032962: Pseudo dice [np.float32(0.6274)] 
2025-07-09 23:49:41.033074: Epoch time: 45.96 s 
2025-07-09 23:49:42.233230:  
2025-07-09 23:49:42.233549: Epoch 224 
2025-07-09 23:49:42.233738: Current learning rate: 0.00796 
2025-07-09 23:50:28.206982: train_loss -0.447 
2025-07-09 23:50:28.207353: val_loss -0.432 
2025-07-09 23:50:28.207427: Pseudo dice [np.float32(0.6944)] 
2025-07-09 23:50:28.207535: Epoch time: 45.97 s 
2025-07-09 23:50:29.329494:  
2025-07-09 23:50:29.330071: Epoch 225 
2025-07-09 23:50:29.330211: Current learning rate: 0.00795 
2025-07-09 23:51:16.684588: train_loss -0.45 
2025-07-09 23:51:16.685330: val_loss -0.4551 
2025-07-09 23:51:16.685432: Pseudo dice [np.float32(0.7365)] 
2025-07-09 23:51:16.685578: Epoch time: 47.36 s 
2025-07-09 23:51:18.461679:  
2025-07-09 23:51:18.462180: Epoch 226 
2025-07-09 23:51:18.462352: Current learning rate: 0.00794 
2025-07-09 23:52:06.427660: train_loss -0.4399 
2025-07-09 23:52:06.428000: val_loss -0.4494 
2025-07-09 23:52:06.428086: Pseudo dice [np.float32(0.6415)] 
2025-07-09 23:52:06.428189: Epoch time: 47.97 s 
2025-07-09 23:52:07.560566:  
2025-07-09 23:52:07.560926: Epoch 227 
2025-07-09 23:52:07.561125: Current learning rate: 0.00793 
2025-07-09 23:52:54.528071: train_loss -0.4497 
2025-07-09 23:52:54.528736: val_loss -0.4446 
2025-07-09 23:52:54.528835: Pseudo dice [np.float32(0.619)] 
2025-07-09 23:52:54.528996: Epoch time: 46.97 s 
2025-07-09 23:52:55.623467:  
2025-07-09 23:52:55.623812: Epoch 228 
2025-07-09 23:52:55.623998: Current learning rate: 0.00792 
2025-07-09 23:53:42.627330: train_loss -0.4535 
2025-07-09 23:53:42.627869: val_loss -0.468 
2025-07-09 23:53:42.627948: Pseudo dice [np.float32(0.7117)] 
2025-07-09 23:53:42.628061: Epoch time: 47.01 s 
2025-07-09 23:53:43.745174:  
2025-07-09 23:53:43.745791: Epoch 229 
2025-07-09 23:53:43.746017: Current learning rate: 0.00791 
2025-07-09 23:54:30.924874: train_loss -0.4481 
2025-07-09 23:54:30.925409: val_loss -0.4745 
2025-07-09 23:54:30.925488: Pseudo dice [np.float32(0.7629)] 
2025-07-09 23:54:30.925617: Epoch time: 47.18 s 
2025-07-09 23:54:32.051288:  
2025-07-09 23:54:32.051738: Epoch 230 
2025-07-09 23:54:32.051915: Current learning rate: 0.0079 
2025-07-09 23:55:19.245996: train_loss -0.457 
2025-07-09 23:55:19.246453: val_loss -0.4483 
2025-07-09 23:55:19.246621: Pseudo dice [np.float32(0.6599)] 
2025-07-09 23:55:19.246746: Epoch time: 47.2 s 
2025-07-09 23:55:20.317699:  
2025-07-09 23:55:20.317939: Epoch 231 
2025-07-09 23:55:20.318128: Current learning rate: 0.00789 
2025-07-09 23:56:07.934134: train_loss -0.4434 
2025-07-09 23:56:07.934626: val_loss -0.418 
2025-07-09 23:56:07.934709: Pseudo dice [np.float32(0.672)] 
2025-07-09 23:56:07.934814: Epoch time: 47.62 s 
2025-07-09 23:56:09.035533:  
2025-07-09 23:56:09.036055: Epoch 232 
2025-07-09 23:56:09.036375: Current learning rate: 0.00789 
2025-07-09 23:56:55.792857: train_loss -0.4167 
2025-07-09 23:56:55.793396: val_loss -0.4186 
2025-07-09 23:56:55.793535: Pseudo dice [np.float32(0.5956)] 
2025-07-09 23:56:55.793665: Epoch time: 46.76 s 
2025-07-09 23:56:56.903758:  
2025-07-09 23:56:56.903946: Epoch 233 
2025-07-09 23:56:56.904083: Current learning rate: 0.00788 
2025-07-09 23:57:43.522536: train_loss -0.435 
2025-07-09 23:57:43.523130: val_loss -0.4356 
2025-07-09 23:57:43.523211: Pseudo dice [np.float32(0.6416)] 
2025-07-09 23:57:43.523322: Epoch time: 46.62 s 
2025-07-09 23:57:44.631250:  
2025-07-09 23:57:44.631631: Epoch 234 
2025-07-09 23:57:44.631738: Current learning rate: 0.00787 
2025-07-09 23:58:30.948447: train_loss -0.4488 
2025-07-09 23:58:30.949005: val_loss -0.4694 
2025-07-09 23:58:30.949089: Pseudo dice [np.float32(0.7518)] 
2025-07-09 23:58:30.949195: Epoch time: 46.32 s 
2025-07-09 23:58:32.035105:  
2025-07-09 23:58:32.035965: Epoch 235 
2025-07-09 23:58:32.036218: Current learning rate: 0.00786 
2025-07-09 23:59:19.884254: train_loss -0.4461 
2025-07-09 23:59:19.885005: val_loss -0.4447 
2025-07-09 23:59:19.885096: Pseudo dice [np.float32(0.7709)] 
2025-07-09 23:59:19.885257: Epoch time: 47.85 s 
2025-07-09 23:59:21.070395:  
2025-07-09 23:59:21.070765: Epoch 236 
2025-07-09 23:59:21.070959: Current learning rate: 0.00785 
2025-07-10 00:00:08.474285: train_loss -0.4365 
2025-07-10 00:00:08.474806: val_loss -0.4435 
2025-07-10 00:00:08.474887: Pseudo dice [np.float32(0.7662)] 
2025-07-10 00:00:08.474997: Epoch time: 47.41 s 
2025-07-10 00:00:09.607295:  
2025-07-10 00:00:09.607705: Epoch 237 
2025-07-10 00:00:09.607831: Current learning rate: 0.00784 
2025-07-10 00:00:56.766927: train_loss -0.4114 
2025-07-10 00:00:56.768045: val_loss -0.4372 
2025-07-10 00:00:56.768136: Pseudo dice [np.float32(0.6838)] 
2025-07-10 00:00:56.768327: Epoch time: 47.16 s 
2025-07-10 00:00:57.902599:  
2025-07-10 00:00:57.902859: Epoch 238 
2025-07-10 00:00:57.903060: Current learning rate: 0.00783 
2025-07-10 00:01:45.012224: train_loss -0.4514 
2025-07-10 00:01:45.012631: val_loss -0.4379 
2025-07-10 00:01:45.012708: Pseudo dice [np.float32(0.6676)] 
2025-07-10 00:01:45.012808: Epoch time: 47.11 s 
2025-07-10 00:01:46.147671:  
2025-07-10 00:01:46.147989: Epoch 239 
2025-07-10 00:01:46.148228: Current learning rate: 0.00782 
2025-07-10 00:02:32.822922: train_loss -0.446 
2025-07-10 00:02:32.823626: val_loss -0.453 
2025-07-10 00:02:32.823719: Pseudo dice [np.float32(0.7036)] 
2025-07-10 00:02:32.823831: Epoch time: 46.68 s 
2025-07-10 00:02:33.982525:  
2025-07-10 00:02:33.982857: Epoch 240 
2025-07-10 00:02:33.983060: Current learning rate: 0.00781 
2025-07-10 00:03:20.193080: train_loss -0.4649 
2025-07-10 00:03:20.193425: val_loss -0.4587 
2025-07-10 00:03:20.196799: Pseudo dice [np.float32(0.7252)] 
2025-07-10 00:03:20.196915: Epoch time: 46.21 s 
2025-07-10 00:03:21.307906:  
2025-07-10 00:03:21.308401: Epoch 241 
2025-07-10 00:03:21.308633: Current learning rate: 0.0078 
2025-07-10 00:04:07.650750: train_loss -0.4424 
2025-07-10 00:04:07.651222: val_loss -0.4602 
2025-07-10 00:04:07.651305: Pseudo dice [np.float32(0.7131)] 
2025-07-10 00:04:07.651406: Epoch time: 46.34 s 
2025-07-10 00:04:08.854739:  
2025-07-10 00:04:08.855002: Epoch 242 
2025-07-10 00:04:08.855162: Current learning rate: 0.00779 
2025-07-10 00:04:54.838993: train_loss -0.4556 
2025-07-10 00:04:54.839414: val_loss -0.4637 
2025-07-10 00:04:54.839505: Pseudo dice [np.float32(0.7467)] 
2025-07-10 00:04:54.839613: Epoch time: 45.99 s 
2025-07-10 00:04:55.984985:  
2025-07-10 00:04:55.985602: Epoch 243 
2025-07-10 00:04:55.985782: Current learning rate: 0.00778 
2025-07-10 00:05:42.686295: train_loss -0.4585 
2025-07-10 00:05:42.687176: val_loss -0.4514 
2025-07-10 00:05:42.687298: Pseudo dice [np.float32(0.7607)] 
2025-07-10 00:05:42.687485: Epoch time: 46.7 s 
2025-07-10 00:05:43.772956:  
2025-07-10 00:05:43.773334: Epoch 244 
2025-07-10 00:05:43.773535: Current learning rate: 0.00777 
2025-07-10 00:06:30.145015: train_loss -0.4482 
2025-07-10 00:06:30.145604: val_loss -0.4361 
2025-07-10 00:06:30.145693: Pseudo dice [np.float32(0.6923)] 
2025-07-10 00:06:30.145790: Epoch time: 46.37 s 
2025-07-10 00:06:31.352855:  
2025-07-10 00:06:31.353402: Epoch 245 
2025-07-10 00:06:31.353592: Current learning rate: 0.00777 
2025-07-10 00:07:19.077227: train_loss -0.4303 
2025-07-10 00:07:19.077735: val_loss -0.4011 
2025-07-10 00:07:19.077823: Pseudo dice [np.float32(0.6167)] 
2025-07-10 00:07:19.077920: Epoch time: 47.73 s 
2025-07-10 00:07:20.222224:  
2025-07-10 00:07:20.222713: Epoch 246 
2025-07-10 00:07:20.223046: Current learning rate: 0.00776 
2025-07-10 00:08:07.650591: train_loss -0.4225 
2025-07-10 00:08:07.651127: val_loss -0.4731 
2025-07-10 00:08:07.651214: Pseudo dice [np.float32(0.7274)] 
2025-07-10 00:08:07.651321: Epoch time: 47.43 s 
2025-07-10 00:08:08.754226:  
2025-07-10 00:08:08.754457: Epoch 247 
2025-07-10 00:08:08.754600: Current learning rate: 0.00775 
2025-07-10 00:08:56.547818: train_loss -0.4286 
2025-07-10 00:08:56.548203: val_loss -0.4466 
2025-07-10 00:08:56.548320: Pseudo dice [np.float32(0.7038)] 
2025-07-10 00:08:56.548455: Epoch time: 47.79 s 
2025-07-10 00:08:57.671020:  
2025-07-10 00:08:57.671278: Epoch 248 
2025-07-10 00:08:57.671385: Current learning rate: 0.00774 
2025-07-10 00:09:44.403274: train_loss -0.438 
2025-07-10 00:09:44.403671: val_loss -0.4595 
2025-07-10 00:09:44.403753: Pseudo dice [np.float32(0.7832)] 
2025-07-10 00:09:44.403852: Epoch time: 46.73 s 
2025-07-10 00:09:45.553488:  
2025-07-10 00:09:45.554060: Epoch 249 
2025-07-10 00:09:45.554194: Current learning rate: 0.00773 
2025-07-10 00:10:32.095357: train_loss -0.4477 
2025-07-10 00:10:32.095772: val_loss -0.4727 
2025-07-10 00:10:32.095852: Pseudo dice [np.float32(0.7433)] 
2025-07-10 00:10:32.095958: Epoch time: 46.54 s 
2025-07-10 00:10:34.578697:  
2025-07-10 00:10:34.579140: Epoch 250 
2025-07-10 00:10:34.579298: Current learning rate: 0.00772 
2025-07-10 00:11:22.549515: train_loss -0.4457 
2025-07-10 00:11:22.550009: val_loss -0.4662 
2025-07-10 00:11:22.550098: Pseudo dice [np.float32(0.7546)] 
2025-07-10 00:11:22.550210: Epoch time: 47.97 s 
2025-07-10 00:11:23.636188:  
2025-07-10 00:11:23.636458: Epoch 251 
2025-07-10 00:11:23.636615: Current learning rate: 0.00771 
2025-07-10 00:12:10.825443: train_loss -0.4226 
2025-07-10 00:12:10.825833: val_loss -0.4305 
2025-07-10 00:12:10.829344: Pseudo dice [np.float32(0.6714)] 
2025-07-10 00:12:10.829608: Epoch time: 47.19 s 
2025-07-10 00:12:11.913580:  
2025-07-10 00:12:11.913854: Epoch 252 
2025-07-10 00:12:11.914145: Current learning rate: 0.0077 
2025-07-10 00:12:58.947651: train_loss -0.4272 
2025-07-10 00:12:58.948206: val_loss -0.4407 
2025-07-10 00:12:58.948298: Pseudo dice [np.float32(0.6264)] 
2025-07-10 00:12:58.948417: Epoch time: 47.04 s 
2025-07-10 00:13:00.074854:  
2025-07-10 00:13:00.075401: Epoch 253 
2025-07-10 00:13:00.075618: Current learning rate: 0.00769 
2025-07-10 00:13:46.630736: train_loss -0.4275 
2025-07-10 00:13:46.631141: val_loss -0.373 
2025-07-10 00:13:46.631216: Pseudo dice [np.float32(0.6661)] 
2025-07-10 00:13:46.631317: Epoch time: 46.56 s 
2025-07-10 00:13:47.973609:  
2025-07-10 00:13:47.974153: Epoch 254 
2025-07-10 00:13:47.974420: Current learning rate: 0.00768 
2025-07-10 00:14:34.796623: train_loss -0.4303 
2025-07-10 00:14:34.797528: val_loss -0.4444 
2025-07-10 00:14:34.797696: Pseudo dice [np.float32(0.6703)] 
2025-07-10 00:14:34.797875: Epoch time: 46.82 s 
2025-07-10 00:14:35.965337:  
2025-07-10 00:14:35.965517: Epoch 255 
2025-07-10 00:14:35.965734: Current learning rate: 0.00767 
2025-07-10 00:15:23.193728: train_loss -0.4544 
2025-07-10 00:15:23.194133: val_loss -0.4552 
2025-07-10 00:15:23.194218: Pseudo dice [np.float32(0.72)] 
2025-07-10 00:15:23.194324: Epoch time: 47.23 s 
2025-07-10 00:15:24.342393:  
2025-07-10 00:15:24.342734: Epoch 256 
2025-07-10 00:15:24.342866: Current learning rate: 0.00766 
2025-07-10 00:16:11.561190: train_loss -0.4549 
2025-07-10 00:16:11.561975: val_loss -0.4692 
2025-07-10 00:16:11.562065: Pseudo dice [np.float32(0.7014)] 
2025-07-10 00:16:11.562191: Epoch time: 47.22 s 
2025-07-10 00:16:12.750320:  
2025-07-10 00:16:12.750689: Epoch 257 
2025-07-10 00:16:12.751066: Current learning rate: 0.00765 
2025-07-10 00:16:59.727958: train_loss -0.4451 
2025-07-10 00:16:59.728491: val_loss -0.4174 
2025-07-10 00:16:59.728586: Pseudo dice [np.float32(0.5524)] 
2025-07-10 00:16:59.728706: Epoch time: 46.98 s 
2025-07-10 00:17:00.831876:  
2025-07-10 00:17:00.832218: Epoch 258 
2025-07-10 00:17:00.832365: Current learning rate: 0.00764 
2025-07-10 00:17:47.233330: train_loss -0.4093 
2025-07-10 00:17:47.233778: val_loss -0.4509 
2025-07-10 00:17:47.233853: Pseudo dice [np.float32(0.7168)] 
2025-07-10 00:17:47.233966: Epoch time: 46.4 s 
2025-07-10 00:17:48.334370:  
2025-07-10 00:17:48.334505: Epoch 259 
2025-07-10 00:17:48.334642: Current learning rate: 0.00764 
2025-07-10 00:18:34.579276: train_loss -0.4382 
2025-07-10 00:18:34.580328: val_loss -0.4446 
2025-07-10 00:18:34.580505: Pseudo dice [np.float32(0.7711)] 
2025-07-10 00:18:34.580727: Epoch time: 46.25 s 
2025-07-10 00:18:35.760413:  
2025-07-10 00:18:35.760849: Epoch 260 
2025-07-10 00:18:35.760981: Current learning rate: 0.00763 
2025-07-10 00:19:22.297549: train_loss -0.4241 
2025-07-10 00:19:22.298088: val_loss -0.3803 
2025-07-10 00:19:22.298176: Pseudo dice [np.float32(0.6413)] 
2025-07-10 00:19:22.298283: Epoch time: 46.54 s 
2025-07-10 00:19:23.426030:  
2025-07-10 00:19:23.426384: Epoch 261 
2025-07-10 00:19:23.426507: Current learning rate: 0.00762 
2025-07-10 00:20:09.847462: train_loss -0.3283 
2025-07-10 00:20:09.848779: val_loss -0.3405 
2025-07-10 00:20:09.849203: Pseudo dice [np.float32(0.0)] 
2025-07-10 00:20:09.849573: Epoch time: 46.42 s 
2025-07-10 00:20:11.735185:  
2025-07-10 00:20:11.735647: Epoch 262 
2025-07-10 00:20:11.735790: Current learning rate: 0.00761 
2025-07-10 00:20:58.751720: train_loss -0.35 
2025-07-10 00:20:58.752236: val_loss -0.3324 
2025-07-10 00:20:58.752328: Pseudo dice [np.float32(0.0)] 
2025-07-10 00:20:58.752432: Epoch time: 47.02 s 
2025-07-10 00:20:59.928730:  
2025-07-10 00:20:59.929101: Epoch 263 
2025-07-10 00:20:59.929368: Current learning rate: 0.0076 
2025-07-10 00:21:46.590803: train_loss -0.3581 
2025-07-10 00:21:46.591708: val_loss -0.3359 
2025-07-10 00:21:46.591820: Pseudo dice [np.float32(0.0)] 
2025-07-10 00:21:46.591946: Epoch time: 46.66 s 
2025-07-10 00:21:47.740933:  
2025-07-10 00:21:47.741410: Epoch 264 
2025-07-10 00:21:47.741606: Current learning rate: 0.00759 
2025-07-10 00:22:35.099075: train_loss -0.362 
2025-07-10 00:22:35.099846: val_loss -0.3713 
2025-07-10 00:22:35.099934: Pseudo dice [np.float32(0.0)] 
2025-07-10 00:22:35.100068: Epoch time: 47.36 s 
2025-07-10 00:22:36.198731:  
2025-07-10 00:22:36.198898: Epoch 265 
2025-07-10 00:22:36.199028: Current learning rate: 0.00758 
2025-07-10 00:23:23.434034: train_loss -0.3794 
2025-07-10 00:23:23.434887: val_loss -0.4357 
2025-07-10 00:23:23.435005: Pseudo dice [np.float32(0.7201)] 
2025-07-10 00:23:23.435210: Epoch time: 47.24 s 
2025-07-10 00:23:24.628859:  
2025-07-10 00:23:24.629097: Epoch 266 
2025-07-10 00:23:24.629199: Current learning rate: 0.00757 
2025-07-10 00:24:11.571043: train_loss -0.3892 
2025-07-10 00:24:11.571731: val_loss -0.3463 
2025-07-10 00:24:11.571914: Pseudo dice [np.float32(0.4336)] 
2025-07-10 00:24:11.572067: Epoch time: 46.94 s 
2025-07-10 00:24:12.722415:  
2025-07-10 00:24:12.722848: Epoch 267 
2025-07-10 00:24:12.722996: Current learning rate: 0.00756 
2025-07-10 00:24:58.902394: train_loss -0.3629 
2025-07-10 00:24:58.903219: val_loss -0.373 
2025-07-10 00:24:58.903373: Pseudo dice [np.float32(0.6525)] 
2025-07-10 00:24:58.903571: Epoch time: 46.18 s 
2025-07-10 00:25:00.054379:  
2025-07-10 00:25:00.054713: Epoch 268 
2025-07-10 00:25:00.054882: Current learning rate: 0.00755 
2025-07-10 00:25:47.444275: train_loss -0.4115 
2025-07-10 00:25:47.444709: val_loss -0.4277 
2025-07-10 00:25:47.444799: Pseudo dice [np.float32(0.7098)] 
2025-07-10 00:25:47.445018: Epoch time: 47.39 s 
2025-07-10 00:25:48.631824:  
2025-07-10 00:25:48.632207: Epoch 269 
2025-07-10 00:25:48.632388: Current learning rate: 0.00754 
2025-07-10 00:26:35.388155: train_loss -0.3846 
2025-07-10 00:26:35.388670: val_loss -0.421 
2025-07-10 00:26:35.388751: Pseudo dice [np.float32(0.6748)] 
2025-07-10 00:26:35.388856: Epoch time: 46.76 s 
2025-07-10 00:26:36.568498:  
2025-07-10 00:26:36.568924: Epoch 270 
2025-07-10 00:26:36.569051: Current learning rate: 0.00753 
2025-07-10 00:27:23.244493: train_loss -0.4055 
2025-07-10 00:27:23.245178: val_loss -0.4216 
2025-07-10 00:27:23.245279: Pseudo dice [np.float32(0.6366)] 
2025-07-10 00:27:23.245412: Epoch time: 46.68 s 
2025-07-10 00:27:24.496171:  
2025-07-10 00:27:24.496624: Epoch 271 
2025-07-10 00:27:24.496747: Current learning rate: 0.00752 
2025-07-10 00:28:11.615040: train_loss -0.4473 
2025-07-10 00:28:11.615410: val_loss -0.4511 
2025-07-10 00:28:11.615484: Pseudo dice [np.float32(0.6888)] 
2025-07-10 00:28:11.615597: Epoch time: 47.12 s 
2025-07-10 00:28:12.772727:  
2025-07-10 00:28:12.773179: Epoch 272 
2025-07-10 00:28:12.773393: Current learning rate: 0.00751 
2025-07-10 00:28:58.884279: train_loss -0.4325 
2025-07-10 00:28:58.884647: val_loss -0.4228 
2025-07-10 00:28:58.884724: Pseudo dice [np.float32(0.5357)] 
2025-07-10 00:28:58.884829: Epoch time: 46.11 s 
2025-07-10 00:29:00.018261:  
2025-07-10 00:29:00.018882: Epoch 273 
2025-07-10 00:29:00.019019: Current learning rate: 0.00751 
2025-07-10 00:29:45.888074: train_loss -0.4586 
2025-07-10 00:29:45.888789: val_loss -0.4593 
2025-07-10 00:29:45.889035: Pseudo dice [np.float32(0.7272)] 
2025-07-10 00:29:45.889240: Epoch time: 45.87 s 
2025-07-10 00:29:47.670688:  
2025-07-10 00:29:47.670903: Epoch 274 
2025-07-10 00:29:47.671095: Current learning rate: 0.0075 
2025-07-10 00:30:34.499964: train_loss -0.4605 
2025-07-10 00:30:34.500525: val_loss -0.4595 
2025-07-10 00:30:34.500667: Pseudo dice [np.float32(0.7448)] 
2025-07-10 00:30:34.500779: Epoch time: 46.83 s 
2025-07-10 00:30:35.605250:  
2025-07-10 00:30:35.605531: Epoch 275 
2025-07-10 00:30:35.605910: Current learning rate: 0.00749 
2025-07-10 00:31:22.468794: train_loss -0.439 
2025-07-10 00:31:22.469181: val_loss -0.4392 
2025-07-10 00:31:22.469494: Pseudo dice [np.float32(0.6442)] 
2025-07-10 00:31:22.469666: Epoch time: 46.86 s 
2025-07-10 00:31:23.612596:  
2025-07-10 00:31:23.613051: Epoch 276 
2025-07-10 00:31:23.613228: Current learning rate: 0.00748 
2025-07-10 00:32:10.478190: train_loss -0.4392 
2025-07-10 00:32:10.478694: val_loss -0.4354 
2025-07-10 00:32:10.478804: Pseudo dice [np.float32(0.7154)] 
2025-07-10 00:32:10.478949: Epoch time: 46.87 s 
2025-07-10 00:32:11.638282:  
2025-07-10 00:32:11.638471: Epoch 277 
2025-07-10 00:32:11.638824: Current learning rate: 0.00747 
2025-07-10 00:32:58.371240: train_loss -0.436 
2025-07-10 00:32:58.371725: val_loss -0.4425 
2025-07-10 00:32:58.371869: Pseudo dice [np.float32(0.7193)] 
2025-07-10 00:32:58.371979: Epoch time: 46.73 s 
2025-07-10 00:32:59.544067:  
2025-07-10 00:32:59.544347: Epoch 278 
2025-07-10 00:32:59.544479: Current learning rate: 0.00746 
2025-07-10 00:33:45.998367: train_loss -0.4674 
2025-07-10 00:33:45.999321: val_loss -0.4366 
2025-07-10 00:33:45.999430: Pseudo dice [np.float32(0.7086)] 
2025-07-10 00:33:45.999586: Epoch time: 46.46 s 
2025-07-10 00:33:47.167355:  
2025-07-10 00:33:47.167906: Epoch 279 
2025-07-10 00:33:47.168180: Current learning rate: 0.00745 
2025-07-10 00:34:33.355647: train_loss -0.4611 
2025-07-10 00:34:33.356250: val_loss -0.477 
2025-07-10 00:34:33.356368: Pseudo dice [np.float32(0.7681)] 
2025-07-10 00:34:33.356488: Epoch time: 46.19 s 
2025-07-10 00:34:34.525425:  
2025-07-10 00:34:34.525659: Epoch 280 
2025-07-10 00:34:34.525787: Current learning rate: 0.00744 
2025-07-10 00:35:20.765733: train_loss -0.4603 
2025-07-10 00:35:20.766188: val_loss -0.461 
2025-07-10 00:35:20.766266: Pseudo dice [np.float32(0.7307)] 
2025-07-10 00:35:20.766447: Epoch time: 46.24 s 
2025-07-10 00:35:21.863301:  
2025-07-10 00:35:21.863810: Epoch 281 
2025-07-10 00:35:21.864054: Current learning rate: 0.00743 
2025-07-10 00:36:07.773287: train_loss -0.4621 
2025-07-10 00:36:07.773772: val_loss -0.4607 
2025-07-10 00:36:07.773858: Pseudo dice [np.float32(0.7629)] 
2025-07-10 00:36:07.773985: Epoch time: 45.91 s 
2025-07-10 00:36:08.983903:  
2025-07-10 00:36:08.984181: Epoch 282 
2025-07-10 00:36:08.984314: Current learning rate: 0.00742 
2025-07-10 00:36:55.496319: train_loss -0.4602 
2025-07-10 00:36:55.496865: val_loss -0.4708 
2025-07-10 00:36:55.496952: Pseudo dice [np.float32(0.7251)] 
2025-07-10 00:36:55.497063: Epoch time: 46.51 s 
2025-07-10 00:36:56.618862:  
2025-07-10 00:36:56.619255: Epoch 283 
2025-07-10 00:36:56.619383: Current learning rate: 0.00741 
2025-07-10 00:37:43.444226: train_loss -0.4463 
2025-07-10 00:37:43.445427: val_loss -0.457 
2025-07-10 00:37:43.445671: Pseudo dice [np.float32(0.7248)] 
2025-07-10 00:37:43.445886: Epoch time: 46.83 s 
2025-07-10 00:37:44.588331:  
2025-07-10 00:37:44.588719: Epoch 284 
2025-07-10 00:37:44.588823: Current learning rate: 0.0074 
2025-07-10 00:38:32.048713: train_loss -0.4246 
2025-07-10 00:38:32.049234: val_loss -0.4149 
2025-07-10 00:38:32.049321: Pseudo dice [np.float32(0.6841)] 
2025-07-10 00:38:32.049433: Epoch time: 47.46 s 
2025-07-10 00:38:33.203480:  
2025-07-10 00:38:33.203915: Epoch 285 
2025-07-10 00:38:33.204083: Current learning rate: 0.00739 
2025-07-10 00:39:19.999100: train_loss -0.4368 
2025-07-10 00:39:19.999852: val_loss -0.4618 
2025-07-10 00:39:19.999934: Pseudo dice [np.float32(0.7286)] 
2025-07-10 00:39:20.000109: Epoch time: 46.8 s 
2025-07-10 00:39:21.873136:  
2025-07-10 00:39:21.873523: Epoch 286 
2025-07-10 00:39:21.873812: Current learning rate: 0.00738 
2025-07-10 00:40:08.247370: train_loss -0.4529 
2025-07-10 00:40:08.247909: val_loss -0.4585 
2025-07-10 00:40:08.248002: Pseudo dice [np.float32(0.6957)] 
2025-07-10 00:40:08.248129: Epoch time: 46.38 s 
2025-07-10 00:40:09.422218:  
2025-07-10 00:40:09.422479: Epoch 287 
2025-07-10 00:40:09.422719: Current learning rate: 0.00738 
2025-07-10 00:40:55.733044: train_loss -0.4523 
2025-07-10 00:40:55.733774: val_loss -0.4307 
2025-07-10 00:40:55.733865: Pseudo dice [np.float32(0.71)] 
2025-07-10 00:40:55.734013: Epoch time: 46.31 s 
2025-07-10 00:40:56.894158:  
2025-07-10 00:40:56.894343: Epoch 288 
2025-07-10 00:40:56.894470: Current learning rate: 0.00737 
2025-07-10 00:41:42.986499: train_loss -0.4525 
2025-07-10 00:41:42.986888: val_loss -0.4475 
2025-07-10 00:41:42.986995: Pseudo dice [np.float32(0.668)] 
2025-07-10 00:41:42.987104: Epoch time: 46.09 s 
2025-07-10 00:41:44.139003:  
2025-07-10 00:41:44.139531: Epoch 289 
2025-07-10 00:41:44.139666: Current learning rate: 0.00736 
2025-07-10 00:42:29.352973: train_loss -0.4226 
2025-07-10 00:42:29.353486: val_loss -0.3442 
2025-07-10 00:42:29.353576: Pseudo dice [np.float32(0.5127)] 
2025-07-10 00:42:29.353693: Epoch time: 45.22 s 
2025-07-10 00:42:30.536713:  
2025-07-10 00:42:30.537005: Epoch 290 
2025-07-10 00:42:30.537172: Current learning rate: 0.00735 
2025-07-10 00:43:16.602272: train_loss -0.4076 
2025-07-10 00:43:16.602778: val_loss -0.4464 
2025-07-10 00:43:16.602873: Pseudo dice [np.float32(0.7042)] 
2025-07-10 00:43:16.602990: Epoch time: 46.07 s 
2025-07-10 00:43:17.774881:  
2025-07-10 00:43:17.775509: Epoch 291 
2025-07-10 00:43:17.775660: Current learning rate: 0.00734 
2025-07-10 00:44:03.408609: train_loss -0.4409 
2025-07-10 00:44:03.408996: val_loss -0.4237 
2025-07-10 00:44:03.409071: Pseudo dice [np.float32(0.6284)] 
2025-07-10 00:44:03.409192: Epoch time: 45.63 s 
2025-07-10 00:44:04.512956:  
2025-07-10 00:44:04.513132: Epoch 292 
2025-07-10 00:44:04.513261: Current learning rate: 0.00733 
2025-07-10 00:44:50.465692: train_loss -0.4336 
2025-07-10 00:44:50.466149: val_loss -0.4526 
2025-07-10 00:44:50.466227: Pseudo dice [np.float32(0.6905)] 
2025-07-10 00:44:50.466325: Epoch time: 45.95 s 
2025-07-10 00:44:51.581076:  
2025-07-10 00:44:51.581389: Epoch 293 
2025-07-10 00:44:51.581653: Current learning rate: 0.00732 
2025-07-10 00:45:38.321303: train_loss -0.4431 
2025-07-10 00:45:38.323039: val_loss -0.4676 
2025-07-10 00:45:38.323186: Pseudo dice [np.float32(0.7411)] 
2025-07-10 00:45:38.323451: Epoch time: 46.74 s 
2025-07-10 00:45:39.498986:  
2025-07-10 00:45:39.499327: Epoch 294 
2025-07-10 00:45:39.499457: Current learning rate: 0.00731 
2025-07-10 00:46:25.572460: train_loss -0.4518 
2025-07-10 00:46:25.572946: val_loss -0.4621 
2025-07-10 00:46:25.573034: Pseudo dice [np.float32(0.7644)] 
2025-07-10 00:46:25.573144: Epoch time: 46.07 s 
2025-07-10 00:46:26.697851:  
2025-07-10 00:46:26.698119: Epoch 295 
2025-07-10 00:46:26.698259: Current learning rate: 0.0073 
2025-07-10 00:47:13.052346: train_loss -0.4599 
2025-07-10 00:47:13.052924: val_loss -0.4857 
2025-07-10 00:47:13.053033: Pseudo dice [np.float32(0.8021)] 
2025-07-10 00:47:13.053254: Epoch time: 46.36 s 
2025-07-10 00:47:14.245104:  
2025-07-10 00:47:14.245518: Epoch 296 
2025-07-10 00:47:14.245742: Current learning rate: 0.00729 
2025-07-10 00:48:00.313756: train_loss -0.43 
2025-07-10 00:48:00.314567: val_loss -0.4484 
2025-07-10 00:48:00.314663: Pseudo dice [np.float32(0.6417)] 
2025-07-10 00:48:00.314812: Epoch time: 46.07 s 
2025-07-10 00:48:01.947886:  
2025-07-10 00:48:01.948096: Epoch 297 
2025-07-10 00:48:01.948207: Current learning rate: 0.00728 
2025-07-10 00:48:47.824148: train_loss -0.4261 
2025-07-10 00:48:47.824589: val_loss -0.3614 
2025-07-10 00:48:47.824668: Pseudo dice [np.float32(0.2601)] 
2025-07-10 00:48:47.824787: Epoch time: 45.88 s 
2025-07-10 00:48:48.984566:  
2025-07-10 00:48:48.984877: Epoch 298 
2025-07-10 00:48:48.985162: Current learning rate: 0.00727 
2025-07-10 00:49:34.868161: train_loss -0.3877 
2025-07-10 00:49:34.868843: val_loss -0.4388 
2025-07-10 00:49:34.869164: Pseudo dice [np.float32(0.6754)] 
2025-07-10 00:49:34.869389: Epoch time: 45.88 s 
2025-07-10 00:49:36.061944:  
2025-07-10 00:49:36.062187: Epoch 299 
2025-07-10 00:49:36.062373: Current learning rate: 0.00726 
2025-07-10 00:50:22.214823: train_loss -0.4173 
2025-07-10 00:50:22.215233: val_loss -0.4118 
2025-07-10 00:50:22.215321: Pseudo dice [np.float32(0.5716)] 
2025-07-10 00:50:22.215537: Epoch time: 46.15 s 
2025-07-10 00:50:24.375431:  
2025-07-10 00:50:24.376224: Epoch 300 
2025-07-10 00:50:24.376625: Current learning rate: 0.00725 
2025-07-10 00:51:10.841784: train_loss -0.4246 
2025-07-10 00:51:10.842367: val_loss -0.408 
2025-07-10 00:51:10.842467: Pseudo dice [np.float32(0.7316)] 
2025-07-10 00:51:10.842620: Epoch time: 46.47 s 
2025-07-10 00:51:12.040242:  
2025-07-10 00:51:12.040752: Epoch 301 
2025-07-10 00:51:12.040956: Current learning rate: 0.00724 
2025-07-10 00:51:58.826785: train_loss -0.4384 
2025-07-10 00:51:58.827163: val_loss -0.4461 
2025-07-10 00:51:58.827253: Pseudo dice [np.float32(0.6657)] 
2025-07-10 00:51:58.827370: Epoch time: 46.79 s 
2025-07-10 00:52:00.013444:  
2025-07-10 00:52:00.013772: Epoch 302 
2025-07-10 00:52:00.014000: Current learning rate: 0.00724 
2025-07-10 00:52:45.899219: train_loss -0.4259 
2025-07-10 00:52:45.899714: val_loss -0.4242 
2025-07-10 00:52:45.903275: Pseudo dice [np.float32(0.6154)] 
2025-07-10 00:52:45.903531: Epoch time: 45.89 s 
2025-07-10 00:52:47.077363:  
2025-07-10 00:52:47.077663: Epoch 303 
2025-07-10 00:52:47.077793: Current learning rate: 0.00723 
2025-07-10 00:53:33.497458: train_loss -0.4377 
2025-07-10 00:53:33.498031: val_loss -0.4443 
2025-07-10 00:53:33.498116: Pseudo dice [np.float32(0.6985)] 
2025-07-10 00:53:33.498230: Epoch time: 46.42 s 
2025-07-10 00:53:34.679727:  
2025-07-10 00:53:34.680223: Epoch 304 
2025-07-10 00:53:34.680385: Current learning rate: 0.00722 
2025-07-10 00:54:20.387582: train_loss -0.4312 
2025-07-10 00:54:20.388306: val_loss -0.4397 
2025-07-10 00:54:20.388389: Pseudo dice [np.float32(0.6627)] 
2025-07-10 00:54:20.388522: Epoch time: 45.71 s 
2025-07-10 00:54:21.537623:  
2025-07-10 00:54:21.537882: Epoch 305 
2025-07-10 00:54:21.538048: Current learning rate: 0.00721 
2025-07-10 00:55:08.026748: train_loss -0.4465 
2025-07-10 00:55:08.027217: val_loss -0.4603 
2025-07-10 00:55:08.027306: Pseudo dice [np.float32(0.7252)] 
2025-07-10 00:55:08.027524: Epoch time: 46.49 s 
2025-07-10 00:55:09.175935:  
2025-07-10 00:55:09.176296: Epoch 306 
2025-07-10 00:55:09.176497: Current learning rate: 0.0072 
2025-07-10 00:55:55.208321: train_loss -0.4457 
2025-07-10 00:55:55.208914: val_loss -0.4373 
2025-07-10 00:55:55.209008: Pseudo dice [np.float32(0.6842)] 
2025-07-10 00:55:55.209159: Epoch time: 46.03 s 
2025-07-10 00:55:56.342884:  
2025-07-10 00:55:56.343051: Epoch 307 
2025-07-10 00:55:56.343174: Current learning rate: 0.00719 
2025-07-10 00:56:42.561522: train_loss -0.4541 
2025-07-10 00:56:42.561930: val_loss -0.4582 
2025-07-10 00:56:42.562005: Pseudo dice [np.float32(0.7066)] 
2025-07-10 00:56:42.562107: Epoch time: 46.22 s 
2025-07-10 00:56:43.671549:  
2025-07-10 00:56:43.671918: Epoch 308 
2025-07-10 00:56:43.672094: Current learning rate: 0.00718 
2025-07-10 00:57:30.404055: train_loss -0.4006 
2025-07-10 00:57:30.404605: val_loss -0.4515 
2025-07-10 00:57:30.404690: Pseudo dice [np.float32(0.7105)] 
2025-07-10 00:57:30.404800: Epoch time: 46.73 s 
2025-07-10 00:57:32.238776:  
2025-07-10 00:57:32.239098: Epoch 309 
2025-07-10 00:57:32.239477: Current learning rate: 0.00717 
2025-07-10 00:58:18.442332: train_loss -0.4292 
2025-07-10 00:58:18.442819: val_loss -0.3695 
2025-07-10 00:58:18.442977: Pseudo dice [np.float32(0.5459)] 
2025-07-10 00:58:18.443099: Epoch time: 46.2 s 
2025-07-10 00:58:19.657400:  
2025-07-10 00:58:19.657941: Epoch 310 
2025-07-10 00:58:19.658139: Current learning rate: 0.00716 
2025-07-10 00:59:05.980173: train_loss -0.4231 
2025-07-10 00:59:05.980686: val_loss -0.4244 
2025-07-10 00:59:05.980769: Pseudo dice [np.float32(0.7)] 
2025-07-10 00:59:05.980888: Epoch time: 46.32 s 
2025-07-10 00:59:07.139272:  
2025-07-10 00:59:07.139509: Epoch 311 
2025-07-10 00:59:07.139866: Current learning rate: 0.00715 
2025-07-10 00:59:53.847625: train_loss -0.4536 
2025-07-10 00:59:53.848368: val_loss -0.4646 
2025-07-10 00:59:53.848458: Pseudo dice [np.float32(0.7292)] 
2025-07-10 00:59:53.848657: Epoch time: 46.71 s 
2025-07-10 00:59:55.005173:  
2025-07-10 00:59:55.005374: Epoch 312 
2025-07-10 00:59:55.005672: Current learning rate: 0.00714 
2025-07-10 01:00:41.595767: train_loss -0.4372 
2025-07-10 01:00:41.596517: val_loss -0.434 
2025-07-10 01:00:41.596609: Pseudo dice [np.float32(0.674)] 
2025-07-10 01:00:41.596740: Epoch time: 46.59 s 
2025-07-10 01:00:42.757153:  
2025-07-10 01:00:42.757597: Epoch 313 
2025-07-10 01:00:42.757719: Current learning rate: 0.00713 
2025-07-10 01:01:29.056712: train_loss -0.4381 
2025-07-10 01:01:29.057194: val_loss -0.4421 
2025-07-10 01:01:29.057274: Pseudo dice [np.float32(0.6809)] 
2025-07-10 01:01:29.057406: Epoch time: 46.3 s 
2025-07-10 01:01:30.235746:  
2025-07-10 01:01:30.236130: Epoch 314 
2025-07-10 01:01:30.236302: Current learning rate: 0.00712 
2025-07-10 01:02:16.400782: train_loss -0.4527 
2025-07-10 01:02:16.401357: val_loss -0.4631 
2025-07-10 01:02:16.401532: Pseudo dice [np.float32(0.7565)] 
2025-07-10 01:02:16.401674: Epoch time: 46.17 s 
2025-07-10 01:02:17.550805:  
2025-07-10 01:02:17.551043: Epoch 315 
2025-07-10 01:02:17.551178: Current learning rate: 0.00711 
2025-07-10 01:03:03.815872: train_loss -0.4622 
2025-07-10 01:03:03.816401: val_loss -0.4837 
2025-07-10 01:03:03.816487: Pseudo dice [np.float32(0.7856)] 
2025-07-10 01:03:03.816603: Epoch time: 46.27 s 
2025-07-10 01:03:05.076688:  
2025-07-10 01:03:05.077098: Epoch 316 
2025-07-10 01:03:05.077229: Current learning rate: 0.0071 
2025-07-10 01:03:51.840813: train_loss -0.4571 
2025-07-10 01:03:51.841254: val_loss -0.4833 
2025-07-10 01:03:51.841329: Pseudo dice [np.float32(0.7876)] 
2025-07-10 01:03:51.841436: Epoch time: 46.77 s 
2025-07-10 01:03:53.019835:  
2025-07-10 01:03:53.020208: Epoch 317 
2025-07-10 01:03:53.020502: Current learning rate: 0.0071 
2025-07-10 01:04:39.570852: train_loss -0.4573 
2025-07-10 01:04:39.571215: val_loss -0.4493 
2025-07-10 01:04:39.571286: Pseudo dice [np.float32(0.7397)] 
2025-07-10 01:04:39.571388: Epoch time: 46.55 s 
2025-07-10 01:04:40.730123:  
2025-07-10 01:04:40.730685: Epoch 318 
2025-07-10 01:04:40.730870: Current learning rate: 0.00709 
2025-07-10 01:05:27.067243: train_loss -0.4695 
2025-07-10 01:05:27.067609: val_loss -0.4763 
2025-07-10 01:05:27.067686: Pseudo dice [np.float32(0.7428)] 
2025-07-10 01:05:27.067798: Epoch time: 46.34 s 
2025-07-10 01:05:28.225450:  
2025-07-10 01:05:28.225809: Epoch 319 
2025-07-10 01:05:28.225946: Current learning rate: 0.00708 
2025-07-10 01:06:14.707053: train_loss -0.4453 
2025-07-10 01:06:14.707975: val_loss -0.4649 
2025-07-10 01:06:14.708062: Pseudo dice [np.float32(0.7454)] 
2025-07-10 01:06:14.708189: Epoch time: 46.48 s 
2025-07-10 01:06:16.531622:  
2025-07-10 01:06:16.531929: Epoch 320 
2025-07-10 01:06:16.532052: Current learning rate: 0.00707 
2025-07-10 01:07:02.502297: train_loss -0.4349 
2025-07-10 01:07:02.502709: val_loss -0.4617 
2025-07-10 01:07:02.502779: Pseudo dice [np.float32(0.7258)] 
2025-07-10 01:07:02.502872: Epoch time: 45.97 s 
2025-07-10 01:07:03.601483:  
2025-07-10 01:07:03.601639: Epoch 321 
2025-07-10 01:07:03.601737: Current learning rate: 0.00706 
2025-07-10 01:07:49.510557: train_loss -0.4347 
2025-07-10 01:07:49.511036: val_loss -0.4422 
2025-07-10 01:07:49.511113: Pseudo dice [np.float32(0.7337)] 
2025-07-10 01:07:49.511213: Epoch time: 45.91 s 
2025-07-10 01:07:50.677560:  
2025-07-10 01:07:50.677906: Epoch 322 
2025-07-10 01:07:50.678038: Current learning rate: 0.00705 
2025-07-10 01:08:36.476816: train_loss -0.3685 
2025-07-10 01:08:36.477205: val_loss -0.3215 
2025-07-10 01:08:36.477343: Pseudo dice [np.float32(0.3576)] 
2025-07-10 01:08:36.477454: Epoch time: 45.8 s 
2025-07-10 01:08:37.628054:  
2025-07-10 01:08:37.628654: Epoch 323 
2025-07-10 01:08:37.628805: Current learning rate: 0.00704 
2025-07-10 01:09:22.922854: train_loss -0.3734 
2025-07-10 01:09:22.923822: val_loss -0.4153 
2025-07-10 01:09:22.923954: Pseudo dice [np.float32(0.6864)] 
2025-07-10 01:09:22.924159: Epoch time: 45.3 s 
2025-07-10 01:09:24.089763:  
2025-07-10 01:09:24.090187: Epoch 324 
2025-07-10 01:09:24.090379: Current learning rate: 0.00703 
2025-07-10 01:10:10.163617: train_loss -0.404 
2025-07-10 01:10:10.164238: val_loss -0.4075 
2025-07-10 01:10:10.164317: Pseudo dice [np.float32(0.5769)] 
2025-07-10 01:10:10.164478: Epoch time: 46.07 s 
2025-07-10 01:10:11.292031:  
2025-07-10 01:10:11.292441: Epoch 325 
2025-07-10 01:10:11.292567: Current learning rate: 0.00702 
2025-07-10 01:10:56.576684: train_loss -0.405 
2025-07-10 01:10:56.577296: val_loss -0.4162 
2025-07-10 01:10:56.577382: Pseudo dice [np.float32(0.6106)] 
2025-07-10 01:10:56.577499: Epoch time: 45.29 s 
2025-07-10 01:10:57.763915:  
2025-07-10 01:10:57.764352: Epoch 326 
2025-07-10 01:10:57.764482: Current learning rate: 0.00701 
2025-07-10 01:11:43.386208: train_loss -0.4295 
2025-07-10 01:11:43.386566: val_loss -0.4629 
2025-07-10 01:11:43.386642: Pseudo dice [np.float32(0.7359)] 
2025-07-10 01:11:43.386750: Epoch time: 45.62 s 
2025-07-10 01:11:44.546976:  
2025-07-10 01:11:44.547142: Epoch 327 
2025-07-10 01:11:44.547267: Current learning rate: 0.007 
2025-07-10 01:12:30.806739: train_loss -0.4451 
2025-07-10 01:12:30.807223: val_loss -0.4325 
2025-07-10 01:12:30.807301: Pseudo dice [np.float32(0.6363)] 
2025-07-10 01:12:30.807408: Epoch time: 46.26 s 
2025-07-10 01:12:31.951509:  
2025-07-10 01:12:31.951862: Epoch 328 
2025-07-10 01:12:31.952092: Current learning rate: 0.00699 
2025-07-10 01:13:17.918347: train_loss -0.4202 
2025-07-10 01:13:17.918790: val_loss -0.3569 
2025-07-10 01:13:17.918884: Pseudo dice [np.float32(0.1796)] 
2025-07-10 01:13:17.918989: Epoch time: 45.97 s 
2025-07-10 01:13:19.073633:  
2025-07-10 01:13:19.073928: Epoch 329 
2025-07-10 01:13:19.074106: Current learning rate: 0.00698 
2025-07-10 01:14:05.770907: train_loss -0.3418 
2025-07-10 01:14:05.771389: val_loss -0.3196 
2025-07-10 01:14:05.771478: Pseudo dice [np.float32(0.0)] 
2025-07-10 01:14:05.771616: Epoch time: 46.7 s 
2025-07-10 01:14:06.909359:  
2025-07-10 01:14:06.909673: Epoch 330 
2025-07-10 01:14:06.909837: Current learning rate: 0.00697 
2025-07-10 01:14:53.119447: train_loss -0.3835 
2025-07-10 01:14:53.119965: val_loss -0.4004 
2025-07-10 01:14:53.120046: Pseudo dice [np.float32(0.5043)] 
2025-07-10 01:14:53.120166: Epoch time: 46.21 s 
2025-07-10 01:14:54.762360:  
2025-07-10 01:14:54.762695: Epoch 331 
2025-07-10 01:14:54.763170: Current learning rate: 0.00696 
2025-07-10 01:15:41.493144: train_loss -0.4082 
2025-07-10 01:15:41.493995: val_loss -0.3717 
2025-07-10 01:15:41.494112: Pseudo dice [np.float32(0.4125)] 
2025-07-10 01:15:41.494261: Epoch time: 46.73 s 
2025-07-10 01:15:42.654851:  
2025-07-10 01:15:42.655470: Epoch 332 
2025-07-10 01:15:42.655606: Current learning rate: 0.00696 
2025-07-10 01:16:28.932592: train_loss -0.3667 
2025-07-10 01:16:28.932932: val_loss -0.406 
2025-07-10 01:16:28.936273: Pseudo dice [np.float32(0.7287)] 
2025-07-10 01:16:28.936389: Epoch time: 46.28 s 
2025-07-10 01:16:30.077883:  
2025-07-10 01:16:30.078305: Epoch 333 
2025-07-10 01:16:30.078433: Current learning rate: 0.00695 
2025-07-10 01:17:15.876760: train_loss -0.416 
2025-07-10 01:17:15.877240: val_loss -0.4264 
2025-07-10 01:17:15.877320: Pseudo dice [np.float32(0.686)] 
2025-07-10 01:17:15.877427: Epoch time: 45.8 s 
2025-07-10 01:17:17.049838:  
2025-07-10 01:17:17.050025: Epoch 334 
2025-07-10 01:17:17.050299: Current learning rate: 0.00694 
2025-07-10 01:18:03.473310: train_loss -0.4407 
2025-07-10 01:18:03.474309: val_loss -0.436 
2025-07-10 01:18:03.474502: Pseudo dice [np.float32(0.7296)] 
2025-07-10 01:18:03.474689: Epoch time: 46.42 s 
2025-07-10 01:18:04.672755:  
2025-07-10 01:18:04.672909: Epoch 335 
2025-07-10 01:18:04.673012: Current learning rate: 0.00693 
2025-07-10 01:18:51.044090: train_loss -0.4445 
2025-07-10 01:18:51.044625: val_loss -0.4571 
2025-07-10 01:18:51.044717: Pseudo dice [np.float32(0.7308)] 
2025-07-10 01:18:51.044825: Epoch time: 46.37 s 
2025-07-10 01:18:52.237045:  
2025-07-10 01:18:52.237444: Epoch 336 
2025-07-10 01:18:52.237648: Current learning rate: 0.00692 
2025-07-10 01:19:38.750124: train_loss -0.4475 
2025-07-10 01:19:38.751311: val_loss -0.4212 
2025-07-10 01:19:38.751446: Pseudo dice [np.float32(0.6693)] 
2025-07-10 01:19:38.751633: Epoch time: 46.51 s 
2025-07-10 01:19:39.917999:  
2025-07-10 01:19:39.918535: Epoch 337 
2025-07-10 01:19:39.918763: Current learning rate: 0.00691 
2025-07-10 01:20:26.010690: train_loss -0.4492 
2025-07-10 01:20:26.011173: val_loss -0.4438 
2025-07-10 01:20:26.011260: Pseudo dice [np.float32(0.6724)] 
2025-07-10 01:20:26.011379: Epoch time: 46.09 s 
2025-07-10 01:20:27.219202:  
2025-07-10 01:20:27.219698: Epoch 338 
2025-07-10 01:20:27.219901: Current learning rate: 0.0069 
2025-07-10 01:21:14.513230: train_loss -0.4637 
2025-07-10 01:21:14.513693: val_loss -0.4377 
2025-07-10 01:21:14.513772: Pseudo dice [np.float32(0.6693)] 
2025-07-10 01:21:14.513878: Epoch time: 47.3 s 
2025-07-10 01:21:15.660149:  
2025-07-10 01:21:15.660509: Epoch 339 
2025-07-10 01:21:15.660880: Current learning rate: 0.00689 
2025-07-10 01:22:03.428884: train_loss -0.4222 
2025-07-10 01:22:03.429258: val_loss -0.3433 
2025-07-10 01:22:03.429332: Pseudo dice [np.float32(0.4111)] 
2025-07-10 01:22:03.429433: Epoch time: 47.77 s 
2025-07-10 01:22:04.612770:  
2025-07-10 01:22:04.612958: Epoch 340 
2025-07-10 01:22:04.613124: Current learning rate: 0.00688 
2025-07-10 01:22:52.585342: train_loss -0.4112 
2025-07-10 01:22:52.585931: val_loss -0.4386 
2025-07-10 01:22:52.586017: Pseudo dice [np.float32(0.6385)] 
2025-07-10 01:22:52.586174: Epoch time: 47.97 s 
2025-07-10 01:22:53.730101:  
2025-07-10 01:22:53.730454: Epoch 341 
2025-07-10 01:22:53.730587: Current learning rate: 0.00687 
2025-07-10 01:23:41.120258: train_loss -0.4356 
2025-07-10 01:23:41.121254: val_loss -0.391 
2025-07-10 01:23:41.121362: Pseudo dice [np.float32(0.5096)] 
2025-07-10 01:23:41.121563: Epoch time: 47.39 s 
2025-07-10 01:23:42.776212:  
2025-07-10 01:23:42.776464: Epoch 342 
2025-07-10 01:23:42.776614: Current learning rate: 0.00686 
2025-07-10 01:24:29.417379: train_loss -0.3761 
2025-07-10 01:24:29.417854: val_loss -0.4003 
2025-07-10 01:24:29.417938: Pseudo dice [np.float32(0.5997)] 
2025-07-10 01:24:29.418051: Epoch time: 46.64 s 
2025-07-10 01:24:30.579281:  
2025-07-10 01:24:30.579613: Epoch 343 
2025-07-10 01:24:30.579765: Current learning rate: 0.00685 
2025-07-10 01:25:18.466453: train_loss -0.4384 
2025-07-10 01:25:18.467154: val_loss -0.4595 
2025-07-10 01:25:18.467244: Pseudo dice [np.float32(0.7338)] 
2025-07-10 01:25:18.467360: Epoch time: 47.89 s 
2025-07-10 01:25:19.575960:  
2025-07-10 01:25:19.576131: Epoch 344 
2025-07-10 01:25:19.576250: Current learning rate: 0.00684 
2025-07-10 01:26:06.231865: train_loss -0.4447 
2025-07-10 01:26:06.232257: val_loss -0.4603 
2025-07-10 01:26:06.232337: Pseudo dice [np.float32(0.745)] 
2025-07-10 01:26:06.232447: Epoch time: 46.66 s 
2025-07-10 01:26:07.413803:  
2025-07-10 01:26:07.414196: Epoch 345 
2025-07-10 01:26:07.414350: Current learning rate: 0.00683 
2025-07-10 01:26:54.774094: train_loss -0.4489 
2025-07-10 01:26:54.774688: val_loss -0.4679 
2025-07-10 01:26:54.774765: Pseudo dice [np.float32(0.7543)] 
2025-07-10 01:26:54.774862: Epoch time: 47.36 s 
2025-07-10 01:26:56.000876:  
2025-07-10 01:26:56.001107: Epoch 346 
2025-07-10 01:26:56.001226: Current learning rate: 0.00682 
2025-07-10 01:27:43.277334: train_loss -0.4544 
2025-07-10 01:27:43.278047: val_loss -0.4832 
2025-07-10 01:27:43.278140: Pseudo dice [np.float32(0.755)] 
2025-07-10 01:27:43.278262: Epoch time: 47.28 s 
2025-07-10 01:27:44.503491:  
2025-07-10 01:27:44.503759: Epoch 347 
2025-07-10 01:27:44.503919: Current learning rate: 0.00681 
2025-07-10 01:28:31.431535: train_loss -0.4429 
2025-07-10 01:28:31.432376: val_loss -0.4484 
2025-07-10 01:28:31.432474: Pseudo dice [np.float32(0.7571)] 
2025-07-10 01:28:31.432619: Epoch time: 46.93 s 
2025-07-10 01:28:32.579013:  
2025-07-10 01:28:32.579388: Epoch 348 
2025-07-10 01:28:32.579629: Current learning rate: 0.0068 
2025-07-10 01:29:19.040386: train_loss -0.4307 
2025-07-10 01:29:19.041000: val_loss -0.4166 
2025-07-10 01:29:19.041095: Pseudo dice [np.float32(0.5283)] 
2025-07-10 01:29:19.041234: Epoch time: 46.46 s 
2025-07-10 01:29:20.209801:  
2025-07-10 01:29:20.210260: Epoch 349 
2025-07-10 01:29:20.210433: Current learning rate: 0.0068 
2025-07-10 01:30:07.054554: train_loss -0.445 
2025-07-10 01:30:07.054986: val_loss -0.451 
2025-07-10 01:30:07.055077: Pseudo dice [np.float32(0.766)] 
2025-07-10 01:30:07.055196: Epoch time: 46.85 s 
2025-07-10 01:30:09.122007:  
2025-07-10 01:30:09.122424: Epoch 350 
2025-07-10 01:30:09.122577: Current learning rate: 0.00679 
2025-07-10 01:30:56.499408: train_loss -0.4277 
2025-07-10 01:30:56.499777: val_loss -0.4576 
2025-07-10 01:30:56.499853: Pseudo dice [np.float32(0.6759)] 
2025-07-10 01:30:56.499959: Epoch time: 47.38 s 
2025-07-10 01:30:57.687825:  
2025-07-10 01:30:57.688396: Epoch 351 
2025-07-10 01:30:57.688594: Current learning rate: 0.00678 
2025-07-10 01:31:45.747370: train_loss -0.4546 
2025-07-10 01:31:45.748304: val_loss -0.4713 
2025-07-10 01:31:45.748440: Pseudo dice [np.float32(0.7001)] 
2025-07-10 01:31:45.748583: Epoch time: 48.06 s 
2025-07-10 01:31:46.956528:  
2025-07-10 01:31:46.956991: Epoch 352 
2025-07-10 01:31:46.957120: Current learning rate: 0.00677 
2025-07-10 01:32:34.170569: train_loss -0.4697 
2025-07-10 01:32:34.171419: val_loss -0.4717 
2025-07-10 01:32:34.171523: Pseudo dice [np.float32(0.7277)] 
2025-07-10 01:32:34.171656: Epoch time: 47.22 s 
2025-07-10 01:32:35.428502:  
2025-07-10 01:32:35.428807: Epoch 353 
2025-07-10 01:32:35.428948: Current learning rate: 0.00676 
2025-07-10 01:33:23.394574: train_loss -0.4677 
2025-07-10 01:33:23.395263: val_loss -0.4661 
2025-07-10 01:33:23.395360: Pseudo dice [np.float32(0.7616)] 
2025-07-10 01:33:23.395495: Epoch time: 47.97 s 
2025-07-10 01:33:25.185207:  
2025-07-10 01:33:25.185442: Epoch 354 
2025-07-10 01:33:25.185626: Current learning rate: 0.00675 
2025-07-10 01:34:12.479969: train_loss -0.4519 
2025-07-10 01:34:12.480399: val_loss -0.4612 
2025-07-10 01:34:12.480559: Pseudo dice [np.float32(0.7042)] 
2025-07-10 01:34:12.480659: Epoch time: 47.3 s 
2025-07-10 01:34:13.833782:  
2025-07-10 01:34:13.834360: Epoch 355 
2025-07-10 01:34:13.834515: Current learning rate: 0.00674 
2025-07-10 01:35:01.221949: train_loss -0.462 
2025-07-10 01:35:01.222333: val_loss -0.4613 
2025-07-10 01:35:01.222491: Pseudo dice [np.float32(0.7135)] 
2025-07-10 01:35:01.222625: Epoch time: 47.39 s 
2025-07-10 01:35:02.388792:  
2025-07-10 01:35:02.389043: Epoch 356 
2025-07-10 01:35:02.389168: Current learning rate: 0.00673 
2025-07-10 01:35:48.984181: train_loss -0.4462 
2025-07-10 01:35:48.984670: val_loss -0.4434 
2025-07-10 01:35:48.984747: Pseudo dice [np.float32(0.6674)] 
2025-07-10 01:35:48.984857: Epoch time: 46.6 s 
2025-07-10 01:35:50.139335:  
2025-07-10 01:35:50.139583: Epoch 357 
2025-07-10 01:35:50.139779: Current learning rate: 0.00672 
2025-07-10 01:36:37.144042: train_loss -0.4393 
2025-07-10 01:36:37.144629: val_loss -0.4415 
2025-07-10 01:36:37.144728: Pseudo dice [np.float32(0.7113)] 
2025-07-10 01:36:37.144854: Epoch time: 47.01 s 
2025-07-10 01:36:38.290043:  
2025-07-10 01:36:38.290346: Epoch 358 
2025-07-10 01:36:38.290564: Current learning rate: 0.00671 
2025-07-10 01:37:23.917652: train_loss -0.4602 
2025-07-10 01:37:23.918036: val_loss -0.4421 
2025-07-10 01:37:23.918117: Pseudo dice [np.float32(0.7039)] 
2025-07-10 01:37:23.918235: Epoch time: 45.63 s 
2025-07-10 01:37:25.117718:  
2025-07-10 01:37:25.118202: Epoch 359 
2025-07-10 01:37:25.118456: Current learning rate: 0.0067 
2025-07-10 01:38:11.414731: train_loss -0.4532 
2025-07-10 01:38:11.415299: val_loss -0.4136 
2025-07-10 01:38:11.415385: Pseudo dice [np.float32(0.6356)] 
2025-07-10 01:38:11.415505: Epoch time: 46.3 s 
2025-07-10 01:38:12.540444:  
2025-07-10 01:38:12.540818: Epoch 360 
2025-07-10 01:38:12.540985: Current learning rate: 0.00669 
2025-07-10 01:38:59.189359: train_loss -0.4389 
2025-07-10 01:38:59.190131: val_loss -0.4257 
2025-07-10 01:38:59.190214: Pseudo dice [np.float32(0.6732)] 
2025-07-10 01:38:59.190333: Epoch time: 46.65 s 
2025-07-10 01:39:00.348686:  
2025-07-10 01:39:00.349113: Epoch 361 
2025-07-10 01:39:00.349241: Current learning rate: 0.00668 
2025-07-10 01:39:46.115451: train_loss -0.4087 
2025-07-10 01:39:46.116041: val_loss -0.4276 
2025-07-10 01:39:46.116117: Pseudo dice [np.float32(0.5721)] 
2025-07-10 01:39:46.116227: Epoch time: 45.77 s 
2025-07-10 01:39:47.283831:  
2025-07-10 01:39:47.284143: Epoch 362 
2025-07-10 01:39:47.284405: Current learning rate: 0.00667 
2025-07-10 01:40:34.076414: train_loss -0.4383 
2025-07-10 01:40:34.077004: val_loss -0.416 
2025-07-10 01:40:34.077089: Pseudo dice [np.float32(0.6683)] 
2025-07-10 01:40:34.077209: Epoch time: 46.79 s 
2025-07-10 01:40:35.334981:  
2025-07-10 01:40:35.335301: Epoch 363 
2025-07-10 01:40:35.335447: Current learning rate: 0.00666 
2025-07-10 01:41:21.134982: train_loss -0.4236 
2025-07-10 01:41:21.135628: val_loss -0.4255 
2025-07-10 01:41:21.135716: Pseudo dice [np.float32(0.7112)] 
2025-07-10 01:41:21.135829: Epoch time: 45.8 s 
2025-07-10 01:41:22.319641:  
2025-07-10 01:41:22.319794: Epoch 364 
2025-07-10 01:41:22.319914: Current learning rate: 0.00665 
2025-07-10 01:42:08.918626: train_loss -0.41 
2025-07-10 01:42:08.919066: val_loss -0.395 
2025-07-10 01:42:08.919147: Pseudo dice [np.float32(0.4977)] 
2025-07-10 01:42:08.919251: Epoch time: 46.6 s 
2025-07-10 01:42:10.737719:  
2025-07-10 01:42:10.738037: Epoch 365 
2025-07-10 01:42:10.738370: Current learning rate: 0.00665 
2025-07-10 01:42:57.177262: train_loss -0.4348 
2025-07-10 01:42:57.177800: val_loss -0.4227 
2025-07-10 01:42:57.177884: Pseudo dice [np.float32(0.6312)] 
2025-07-10 01:42:57.178002: Epoch time: 46.44 s 
2025-07-10 01:42:58.310763:  
2025-07-10 01:42:58.311142: Epoch 366 
2025-07-10 01:42:58.311267: Current learning rate: 0.00664 
2025-07-10 01:43:45.071937: train_loss -0.3561 
2025-07-10 01:43:45.072411: val_loss -0.4463 
2025-07-10 01:43:45.072490: Pseudo dice [np.float32(0.6427)] 
2025-07-10 01:43:45.072607: Epoch time: 46.76 s 
2025-07-10 01:43:46.211911:  
2025-07-10 01:43:46.212435: Epoch 367 
2025-07-10 01:43:46.212577: Current learning rate: 0.00663 
2025-07-10 01:44:33.666894: train_loss -0.4057 
2025-07-10 01:44:33.667604: val_loss -0.4264 
2025-07-10 01:44:33.667691: Pseudo dice [np.float32(0.6473)] 
2025-07-10 01:44:33.667793: Epoch time: 47.46 s 
2025-07-10 01:44:34.799134:  
2025-07-10 01:44:34.799483: Epoch 368 
2025-07-10 01:44:34.799628: Current learning rate: 0.00662 
2025-07-10 01:45:22.701935: train_loss -0.4323 
2025-07-10 01:45:22.702399: val_loss -0.4588 
2025-07-10 01:45:22.702477: Pseudo dice [np.float32(0.6616)] 
2025-07-10 01:45:22.702590: Epoch time: 47.9 s 
2025-07-10 01:45:23.889343:  
2025-07-10 01:45:23.889716: Epoch 369 
2025-07-10 01:45:23.889853: Current learning rate: 0.00661 
2025-07-10 01:46:11.244433: train_loss -0.4345 
2025-07-10 01:46:11.244841: val_loss -0.4346 
2025-07-10 01:46:11.244953: Pseudo dice [np.float32(0.6607)] 
2025-07-10 01:46:11.245091: Epoch time: 47.36 s 
2025-07-10 01:46:12.378577:  
2025-07-10 01:46:12.378988: Epoch 370 
2025-07-10 01:46:12.379113: Current learning rate: 0.0066 
2025-07-10 01:47:00.330093: train_loss -0.4377 
2025-07-10 01:47:00.330535: val_loss -0.3871 
2025-07-10 01:47:00.330635: Pseudo dice [np.float32(0.2564)] 
2025-07-10 01:47:00.330743: Epoch time: 47.95 s 
2025-07-10 01:47:01.489176:  
2025-07-10 01:47:01.489616: Epoch 371 
2025-07-10 01:47:01.489745: Current learning rate: 0.00659 
2025-07-10 01:47:50.237880: train_loss -0.4349 
2025-07-10 01:47:50.238636: val_loss -0.44 
2025-07-10 01:47:50.238783: Pseudo dice [np.float32(0.6669)] 
2025-07-10 01:47:50.238952: Epoch time: 48.75 s 
2025-07-10 01:47:51.376445:  
2025-07-10 01:47:51.376759: Epoch 372 
2025-07-10 01:47:51.376899: Current learning rate: 0.00658 
2025-07-10 01:48:39.372399: train_loss -0.4212 
2025-07-10 01:48:39.373041: val_loss -0.4032 
2025-07-10 01:48:39.373117: Pseudo dice [np.float32(0.6948)] 
2025-07-10 01:48:39.373226: Epoch time: 48.0 s 
2025-07-10 01:48:40.495640:  
2025-07-10 01:48:40.496196: Epoch 373 
2025-07-10 01:48:40.496319: Current learning rate: 0.00657 
2025-07-10 01:49:27.533298: train_loss -0.4395 
2025-07-10 01:49:27.533915: val_loss -0.4074 
2025-07-10 01:49:27.533993: Pseudo dice [np.float32(0.7369)] 
2025-07-10 01:49:27.534123: Epoch time: 47.04 s 
2025-07-10 01:49:28.686375:  
2025-07-10 01:49:28.686753: Epoch 374 
2025-07-10 01:49:28.686938: Current learning rate: 0.00656 
2025-07-10 01:50:15.432138: train_loss -0.4409 
2025-07-10 01:50:15.433071: val_loss -0.4378 
2025-07-10 01:50:15.433382: Pseudo dice [np.float32(0.6847)] 
2025-07-10 01:50:15.433735: Epoch time: 46.75 s 
2025-07-10 01:50:16.645397:  
2025-07-10 01:50:16.645594: Epoch 375 
2025-07-10 01:50:16.645786: Current learning rate: 0.00655 
2025-07-10 01:51:03.527215: train_loss -0.4466 
2025-07-10 01:51:03.527721: val_loss -0.4584 
2025-07-10 01:51:03.527798: Pseudo dice [np.float32(0.6886)] 
2025-07-10 01:51:03.527912: Epoch time: 46.88 s 
2025-07-10 01:51:05.288414:  
2025-07-10 01:51:05.288903: Epoch 376 
2025-07-10 01:51:05.289273: Current learning rate: 0.00654 
2025-07-10 01:51:52.542794: train_loss -0.4489 
2025-07-10 01:51:52.543251: val_loss -0.4566 
2025-07-10 01:51:52.543345: Pseudo dice [np.float32(0.7434)] 
2025-07-10 01:51:52.543441: Epoch time: 47.26 s 
2025-07-10 01:51:53.659672:  
2025-07-10 01:51:53.660363: Epoch 377 
2025-07-10 01:51:53.660484: Current learning rate: 0.00653 
2025-07-10 01:52:40.539961: train_loss -0.4615 
2025-07-10 01:52:40.540369: val_loss -0.4773 
2025-07-10 01:52:40.540448: Pseudo dice [np.float32(0.7493)] 
2025-07-10 01:52:40.540588: Epoch time: 46.88 s 
2025-07-10 01:52:41.757566:  
2025-07-10 01:52:41.757872: Epoch 378 
2025-07-10 01:52:41.758052: Current learning rate: 0.00652 
2025-07-10 01:53:28.784413: train_loss -0.4498 
2025-07-10 01:53:28.784919: val_loss -0.4464 
2025-07-10 01:53:28.784999: Pseudo dice [np.float32(0.8136)] 
2025-07-10 01:53:28.785111: Epoch time: 47.03 s 
2025-07-10 01:53:29.954857:  
2025-07-10 01:53:29.955239: Epoch 379 
2025-07-10 01:53:29.955370: Current learning rate: 0.00651 
2025-07-10 01:54:16.648676: train_loss -0.4293 
2025-07-10 01:54:16.649283: val_loss -0.4516 
2025-07-10 01:54:16.649590: Pseudo dice [np.float32(0.714)] 
2025-07-10 01:54:16.649791: Epoch time: 46.69 s 
2025-07-10 01:54:17.813941:  
2025-07-10 01:54:17.814579: Epoch 380 
2025-07-10 01:54:17.814723: Current learning rate: 0.0065 
2025-07-10 01:55:04.747351: train_loss -0.4585 
2025-07-10 01:55:04.747710: val_loss -0.4823 
2025-07-10 01:55:04.747783: Pseudo dice [np.float32(0.8006)] 
2025-07-10 01:55:04.747879: Epoch time: 46.93 s 
2025-07-10 01:55:06.023468:  
2025-07-10 01:55:06.023864: Epoch 381 
2025-07-10 01:55:06.024045: Current learning rate: 0.00649 
2025-07-10 01:55:53.406479: train_loss -0.4613 
2025-07-10 01:55:53.406902: val_loss -0.4745 
2025-07-10 01:55:53.406974: Pseudo dice [np.float32(0.7677)] 
2025-07-10 01:55:53.407071: Epoch time: 47.38 s 
2025-07-10 01:55:54.614837:  
2025-07-10 01:55:54.615445: Epoch 382 
2025-07-10 01:55:54.615736: Current learning rate: 0.00648 
2025-07-10 01:56:42.063954: train_loss -0.4463 
2025-07-10 01:56:42.064307: val_loss -0.4428 
2025-07-10 01:56:42.064390: Pseudo dice [np.float32(0.6835)] 
2025-07-10 01:56:42.064508: Epoch time: 47.45 s 
2025-07-10 01:56:43.250186:  
2025-07-10 01:56:43.250731: Epoch 383 
2025-07-10 01:56:43.250918: Current learning rate: 0.00648 
2025-07-10 01:57:29.531253: train_loss -0.4333 
2025-07-10 01:57:29.532245: val_loss -0.4515 
2025-07-10 01:57:29.532325: Pseudo dice [np.float32(0.6895)] 
2025-07-10 01:57:29.532492: Epoch time: 46.28 s 
2025-07-10 01:57:30.732072:  
2025-07-10 01:57:30.732192: Epoch 384 
2025-07-10 01:57:30.732295: Current learning rate: 0.00647 
2025-07-10 01:58:17.153126: train_loss -0.4382 
2025-07-10 01:58:17.153891: val_loss -0.4446 
2025-07-10 01:58:17.154026: Pseudo dice [np.float32(0.7153)] 
2025-07-10 01:58:17.154181: Epoch time: 46.42 s 
2025-07-10 01:58:18.366690:  
2025-07-10 01:58:18.367099: Epoch 385 
2025-07-10 01:58:18.367246: Current learning rate: 0.00646 
2025-07-10 01:59:04.899500: train_loss -0.446 
2025-07-10 01:59:04.900019: val_loss -0.4716 
2025-07-10 01:59:04.900093: Pseudo dice [np.float32(0.7764)] 
2025-07-10 01:59:04.900189: Epoch time: 46.53 s 
2025-07-10 01:59:06.158490:  
2025-07-10 01:59:06.158864: Epoch 386 
2025-07-10 01:59:06.158994: Current learning rate: 0.00645 
2025-07-10 01:59:52.259082: train_loss -0.44 
2025-07-10 01:59:52.259684: val_loss -0.4606 
2025-07-10 01:59:52.259774: Pseudo dice [np.float32(0.6806)] 
2025-07-10 01:59:52.259885: Epoch time: 46.1 s 
2025-07-10 01:59:54.105916:  
2025-07-10 01:59:54.106566: Epoch 387 
2025-07-10 01:59:54.106753: Current learning rate: 0.00644 
2025-07-10 02:00:41.673589: train_loss -0.454 
2025-07-10 02:00:41.674351: val_loss -0.4317 
2025-07-10 02:00:41.674482: Pseudo dice [np.float32(0.7235)] 
2025-07-10 02:00:41.674652: Epoch time: 47.57 s 
2025-07-10 02:00:42.872530:  
2025-07-10 02:00:42.873237: Epoch 388 
2025-07-10 02:00:42.873397: Current learning rate: 0.00643 
2025-07-10 02:01:29.590866: train_loss -0.4382 
2025-07-10 02:01:29.591172: val_loss -0.4225 
2025-07-10 02:01:29.591254: Pseudo dice [np.float32(0.6572)] 
2025-07-10 02:01:29.591351: Epoch time: 46.72 s 
2025-07-10 02:01:30.743241:  
2025-07-10 02:01:30.743656: Epoch 389 
2025-07-10 02:01:30.743985: Current learning rate: 0.00642 
2025-07-10 02:02:18.127157: train_loss -0.4173 
2025-07-10 02:02:18.127516: val_loss -0.3919 
2025-07-10 02:02:18.127610: Pseudo dice [np.float32(0.5561)] 
2025-07-10 02:02:18.127721: Epoch time: 47.38 s 
2025-07-10 02:02:19.298727:  
2025-07-10 02:02:19.299168: Epoch 390 
2025-07-10 02:02:19.299417: Current learning rate: 0.00641 
2025-07-10 02:03:06.374509: train_loss -0.3977 
2025-07-10 02:03:06.375049: val_loss -0.3878 
2025-07-10 02:03:06.375133: Pseudo dice [np.float32(0.539)] 
2025-07-10 02:03:06.375239: Epoch time: 47.08 s 
2025-07-10 02:03:07.545851:  
2025-07-10 02:03:07.546083: Epoch 391 
2025-07-10 02:03:07.546204: Current learning rate: 0.0064 
2025-07-10 02:03:53.836090: train_loss -0.4275 
2025-07-10 02:03:53.836585: val_loss -0.4533 
2025-07-10 02:03:53.836712: Pseudo dice [np.float32(0.6989)] 
2025-07-10 02:03:53.836851: Epoch time: 46.29 s 
2025-07-10 02:03:54.976636:  
2025-07-10 02:03:54.976957: Epoch 392 
2025-07-10 02:03:54.977129: Current learning rate: 0.00639 
2025-07-10 02:04:41.622989: train_loss -0.4621 
2025-07-10 02:04:41.623413: val_loss -0.4502 
2025-07-10 02:04:41.623487: Pseudo dice [np.float32(0.7378)] 
2025-07-10 02:04:41.623600: Epoch time: 46.65 s 
2025-07-10 02:04:42.803687:  
2025-07-10 02:04:42.804063: Epoch 393 
2025-07-10 02:04:42.804191: Current learning rate: 0.00638 
2025-07-10 02:05:28.690816: train_loss -0.4554 
2025-07-10 02:05:28.691463: val_loss -0.475 
2025-07-10 02:05:28.691564: Pseudo dice [np.float32(0.7829)] 
2025-07-10 02:05:28.691698: Epoch time: 45.89 s 
2025-07-10 02:05:29.925399:  
2025-07-10 02:05:29.925860: Epoch 394 
2025-07-10 02:05:29.926001: Current learning rate: 0.00637 
2025-07-10 02:06:16.110598: train_loss -0.4675 
2025-07-10 02:06:16.111351: val_loss -0.4652 
2025-07-10 02:06:16.111497: Pseudo dice [np.float32(0.7527)] 
2025-07-10 02:06:16.111687: Epoch time: 46.19 s 
2025-07-10 02:06:17.247385:  
2025-07-10 02:06:17.247798: Epoch 395 
2025-07-10 02:06:17.247929: Current learning rate: 0.00636 
2025-07-10 02:07:04.597829: train_loss -0.4685 
2025-07-10 02:07:04.598439: val_loss -0.4934 
2025-07-10 02:07:04.598554: Pseudo dice [np.float32(0.7726)] 
2025-07-10 02:07:04.598681: Epoch time: 47.35 s 
2025-07-10 02:07:05.837153:  
2025-07-10 02:07:05.837554: Epoch 396 
2025-07-10 02:07:05.837767: Current learning rate: 0.00635 
2025-07-10 02:07:52.737552: train_loss -0.4494 
2025-07-10 02:07:52.737983: val_loss -0.4142 
2025-07-10 02:07:52.738069: Pseudo dice [np.float32(0.7081)] 
2025-07-10 02:07:52.738182: Epoch time: 46.9 s 
2025-07-10 02:07:53.929862:  
2025-07-10 02:07:53.930138: Epoch 397 
2025-07-10 02:07:53.930440: Current learning rate: 0.00634 
2025-07-10 02:08:41.054293: train_loss -0.4262 
2025-07-10 02:08:41.054745: val_loss -0.4449 
2025-07-10 02:08:41.054822: Pseudo dice [np.float32(0.6678)] 
2025-07-10 02:08:41.054926: Epoch time: 47.13 s 
2025-07-10 02:08:42.838681:  
2025-07-10 02:08:42.838874: Epoch 398 
2025-07-10 02:08:42.839038: Current learning rate: 0.00633 
2025-07-10 02:09:28.749413: train_loss -0.4483 
2025-07-10 02:09:28.749933: val_loss -0.4538 
2025-07-10 02:09:28.750017: Pseudo dice [np.float32(0.7678)] 
2025-07-10 02:09:28.750130: Epoch time: 45.91 s 
2025-07-10 02:09:29.948058:  
2025-07-10 02:09:29.948420: Epoch 399 
2025-07-10 02:09:29.948562: Current learning rate: 0.00632 
2025-07-10 02:10:15.802839: train_loss -0.4185 
2025-07-10 02:10:15.803572: val_loss -0.4397 
2025-07-10 02:10:15.803655: Pseudo dice [np.float32(0.6748)] 
2025-07-10 02:10:15.803817: Epoch time: 45.86 s 
2025-07-10 02:10:18.024551:  
2025-07-10 02:10:18.024848: Epoch 400 
2025-07-10 02:10:18.025015: Current learning rate: 0.00631 
2025-07-10 02:11:04.092705: train_loss -0.4416 
2025-07-10 02:11:04.093876: val_loss -0.4242 
2025-07-10 02:11:04.093968: Pseudo dice [np.float32(0.6686)] 
2025-07-10 02:11:04.094128: Epoch time: 46.07 s 
2025-07-10 02:11:05.299853:  
2025-07-10 02:11:05.300273: Epoch 401 
2025-07-10 02:11:05.300394: Current learning rate: 0.0063 
2025-07-10 02:11:52.172839: train_loss -0.4307 
2025-07-10 02:11:52.173581: val_loss -0.4389 
2025-07-10 02:11:52.173676: Pseudo dice [np.float32(0.5905)] 
2025-07-10 02:11:52.173812: Epoch time: 46.87 s 
2025-07-10 02:11:53.367199:  
2025-07-10 02:11:53.367330: Epoch 402 
2025-07-10 02:11:53.367432: Current learning rate: 0.0063 
2025-07-10 02:12:39.424443: train_loss -0.4287 
2025-07-10 02:12:39.424999: val_loss -0.4298 
2025-07-10 02:12:39.425129: Pseudo dice [np.float32(0.7232)] 
2025-07-10 02:12:39.425255: Epoch time: 46.06 s 
2025-07-10 02:12:40.609025:  
2025-07-10 02:12:40.609264: Epoch 403 
2025-07-10 02:12:40.609452: Current learning rate: 0.00629 
2025-07-10 02:13:27.022196: train_loss -0.4525 
2025-07-10 02:13:27.022624: val_loss -0.4558 
2025-07-10 02:13:27.022707: Pseudo dice [np.float32(0.7125)] 
2025-07-10 02:13:27.022824: Epoch time: 46.41 s 
2025-07-10 02:13:28.180790:  
2025-07-10 02:13:28.181090: Epoch 404 
2025-07-10 02:13:28.181278: Current learning rate: 0.00628 
2025-07-10 02:14:14.982410: train_loss -0.4347 
2025-07-10 02:14:14.982896: val_loss -0.3937 
2025-07-10 02:14:14.982969: Pseudo dice [np.float32(0.6444)] 
2025-07-10 02:14:14.983082: Epoch time: 46.8 s 
2025-07-10 02:14:16.166430:  
2025-07-10 02:14:16.166768: Epoch 405 
2025-07-10 02:14:16.166864: Current learning rate: 0.00627 
2025-07-10 02:15:02.533510: train_loss -0.4057 
2025-07-10 02:15:02.534815: val_loss -0.4541 
2025-07-10 02:15:02.534932: Pseudo dice [np.float32(0.6977)] 
2025-07-10 02:15:02.535174: Epoch time: 46.37 s 
2025-07-10 02:15:03.779344:  
2025-07-10 02:15:03.779828: Epoch 406 
2025-07-10 02:15:03.780053: Current learning rate: 0.00626 
2025-07-10 02:15:49.016919: train_loss -0.4296 
2025-07-10 02:15:49.017768: val_loss -0.4154 
2025-07-10 02:15:49.017891: Pseudo dice [np.float32(0.7003)] 
2025-07-10 02:15:49.018075: Epoch time: 45.24 s 
2025-07-10 02:15:50.238091:  
2025-07-10 02:15:50.238444: Epoch 407 
2025-07-10 02:15:50.238580: Current learning rate: 0.00625 
2025-07-10 02:16:35.862261: train_loss -0.4468 
2025-07-10 02:16:35.862640: val_loss -0.4535 
2025-07-10 02:16:35.862731: Pseudo dice [np.float32(0.7344)] 
2025-07-10 02:16:35.862927: Epoch time: 45.63 s 
2025-07-10 02:16:37.658344:  
2025-07-10 02:16:37.658712: Epoch 408 
2025-07-10 02:16:37.658900: Current learning rate: 0.00624 
2025-07-10 02:17:22.762705: train_loss -0.455 
2025-07-10 02:17:22.763554: val_loss -0.4348 
2025-07-10 02:17:22.763786: Pseudo dice [np.float32(0.7852)] 
2025-07-10 02:17:22.763976: Epoch time: 45.11 s 
2025-07-10 02:17:23.946077:  
2025-07-10 02:17:23.946300: Epoch 409 
2025-07-10 02:17:23.946606: Current learning rate: 0.00623 
2025-07-10 02:18:10.436102: train_loss -0.4434 
2025-07-10 02:18:10.436688: val_loss -0.4584 
2025-07-10 02:18:10.436765: Pseudo dice [np.float32(0.7169)] 
2025-07-10 02:18:10.436876: Epoch time: 46.49 s 
2025-07-10 02:18:11.584414:  
2025-07-10 02:18:11.584984: Epoch 410 
2025-07-10 02:18:11.585138: Current learning rate: 0.00622 
2025-07-10 02:18:57.717936: train_loss -0.4542 
2025-07-10 02:18:57.718477: val_loss -0.4558 
2025-07-10 02:18:57.718611: Pseudo dice [np.float32(0.7139)] 
2025-07-10 02:18:57.718719: Epoch time: 46.13 s 
2025-07-10 02:18:58.846242:  
2025-07-10 02:18:58.846470: Epoch 411 
2025-07-10 02:18:58.846717: Current learning rate: 0.00621 
2025-07-10 02:19:45.196687: train_loss -0.4218 
2025-07-10 02:19:45.197083: val_loss -0.4328 
2025-07-10 02:19:45.197209: Pseudo dice [np.float32(0.7121)] 
2025-07-10 02:19:45.197313: Epoch time: 46.35 s 
2025-07-10 02:19:46.319249:  
2025-07-10 02:19:46.319654: Epoch 412 
2025-07-10 02:19:46.319790: Current learning rate: 0.0062 
2025-07-10 02:20:32.170625: train_loss -0.4397 
2025-07-10 02:20:32.171102: val_loss -0.4655 
2025-07-10 02:20:32.171183: Pseudo dice [np.float32(0.6849)] 
2025-07-10 02:20:32.171286: Epoch time: 45.85 s 
2025-07-10 02:20:33.315084:  
2025-07-10 02:20:33.315561: Epoch 413 
2025-07-10 02:20:33.315777: Current learning rate: 0.00619 
2025-07-10 02:21:19.428358: train_loss -0.4466 
2025-07-10 02:21:19.428921: val_loss -0.453 
2025-07-10 02:21:19.429017: Pseudo dice [np.float32(0.7015)] 
2025-07-10 02:21:19.429151: Epoch time: 46.11 s 
2025-07-10 02:21:20.567719:  
2025-07-10 02:21:20.567976: Epoch 414 
2025-07-10 02:21:20.568093: Current learning rate: 0.00618 
2025-07-10 02:22:06.735487: train_loss -0.4497 
2025-07-10 02:22:06.736068: val_loss -0.4283 
2025-07-10 02:22:06.736173: Pseudo dice [np.float32(0.702)] 
2025-07-10 02:22:06.736318: Epoch time: 46.17 s 
2025-07-10 02:22:07.954659:  
2025-07-10 02:22:07.955018: Epoch 415 
2025-07-10 02:22:07.955138: Current learning rate: 0.00617 
2025-07-10 02:22:54.292547: train_loss -0.4362 
2025-07-10 02:22:54.293081: val_loss -0.4498 
2025-07-10 02:22:54.293177: Pseudo dice [np.float32(0.7068)] 
2025-07-10 02:22:54.293300: Epoch time: 46.34 s 
2025-07-10 02:22:55.463059:  
2025-07-10 02:22:55.463361: Epoch 416 
2025-07-10 02:22:55.463500: Current learning rate: 0.00616 
2025-07-10 02:23:41.108080: train_loss -0.3818 
2025-07-10 02:23:41.108509: val_loss -0.3402 
2025-07-10 02:23:41.108661: Pseudo dice [np.float32(0.0)] 
2025-07-10 02:23:41.108835: Epoch time: 45.65 s 
2025-07-10 02:23:42.322262:  
2025-07-10 02:23:42.322716: Epoch 417 
2025-07-10 02:23:42.322897: Current learning rate: 0.00615 
2025-07-10 02:24:28.114584: train_loss -0.3396 
2025-07-10 02:24:28.115207: val_loss -0.3673 
2025-07-10 02:24:28.115295: Pseudo dice [np.float32(0.0)] 
2025-07-10 02:24:28.115427: Epoch time: 45.79 s 
2025-07-10 02:24:29.335781:  
2025-07-10 02:24:29.336099: Epoch 418 
2025-07-10 02:24:29.336260: Current learning rate: 0.00614 
2025-07-10 02:25:14.915183: train_loss -0.4049 
2025-07-10 02:25:14.916006: val_loss -0.4313 
2025-07-10 02:25:14.919667: Pseudo dice [np.float32(0.7591)] 
2025-07-10 02:25:14.920172: Epoch time: 45.58 s 
2025-07-10 02:25:16.075515:  
2025-07-10 02:25:16.075841: Epoch 419 
2025-07-10 02:25:16.075982: Current learning rate: 0.00613 
2025-07-10 02:26:02.678796: train_loss -0.4369 
2025-07-10 02:26:02.679744: val_loss -0.4571 
2025-07-10 02:26:02.679831: Pseudo dice [np.float32(0.7589)] 
2025-07-10 02:26:02.679983: Epoch time: 46.6 s 
2025-07-10 02:26:04.348481:  
2025-07-10 02:26:04.348723: Epoch 420 
2025-07-10 02:26:04.348885: Current learning rate: 0.00612 
2025-07-10 02:26:50.634594: train_loss -0.4069 
2025-07-10 02:26:50.635268: val_loss -0.3762 
2025-07-10 02:26:50.635461: Pseudo dice [np.float32(0.5826)] 
2025-07-10 02:26:50.635656: Epoch time: 46.29 s 
2025-07-10 02:26:51.780233:  
2025-07-10 02:26:51.780571: Epoch 421 
2025-07-10 02:26:51.780698: Current learning rate: 0.00612 
2025-07-10 02:27:38.862277: train_loss -0.4296 
2025-07-10 02:27:38.862817: val_loss -0.4293 
2025-07-10 02:27:38.862913: Pseudo dice [np.float32(0.6634)] 
2025-07-10 02:27:38.863047: Epoch time: 47.08 s 
2025-07-10 02:27:40.050184:  
2025-07-10 02:27:40.050461: Epoch 422 
2025-07-10 02:27:40.050731: Current learning rate: 0.00611 
2025-07-10 02:28:26.615421: train_loss -0.4273 
2025-07-10 02:28:26.615828: val_loss -0.4553 
2025-07-10 02:28:26.615911: Pseudo dice [np.float32(0.7416)] 
2025-07-10 02:28:26.616013: Epoch time: 46.57 s 
2025-07-10 02:28:27.814102:  
2025-07-10 02:28:27.814482: Epoch 423 
2025-07-10 02:28:27.814635: Current learning rate: 0.0061 
2025-07-10 02:29:13.627699: train_loss -0.4134 
2025-07-10 02:29:13.628200: val_loss -0.2853 
2025-07-10 02:29:13.628277: Pseudo dice [np.float32(0.0)] 
2025-07-10 02:29:13.628380: Epoch time: 45.81 s 
2025-07-10 02:29:14.785176:  
2025-07-10 02:29:14.785422: Epoch 424 
2025-07-10 02:29:14.785615: Current learning rate: 0.00609 
2025-07-10 02:30:01.200982: train_loss -0.3205 
2025-07-10 02:30:01.201928: val_loss -0.349 
2025-07-10 02:30:01.202008: Pseudo dice [np.float32(0.0)] 
2025-07-10 02:30:01.202198: Epoch time: 46.42 s 
2025-07-10 02:30:02.327939:  
2025-07-10 02:30:02.328112: Epoch 425 
2025-07-10 02:30:02.328206: Current learning rate: 0.00608 
2025-07-10 02:30:48.055822: train_loss -0.3407 
2025-07-10 02:30:48.056401: val_loss -0.3436 
2025-07-10 02:30:48.056485: Pseudo dice [np.float32(0.0)] 
2025-07-10 02:30:48.056669: Epoch time: 45.73 s 
2025-07-10 02:30:49.195668:  
2025-07-10 02:30:49.195835: Epoch 426 
2025-07-10 02:30:49.196088: Current learning rate: 0.00607 
2025-07-10 02:31:34.748128: train_loss -0.3613 
2025-07-10 02:31:34.748845: val_loss -0.3735 
2025-07-10 02:31:34.748950: Pseudo dice [np.float32(0.0)] 
2025-07-10 02:31:34.749088: Epoch time: 45.55 s 
2025-07-10 02:31:35.964000:  
2025-07-10 02:31:35.964311: Epoch 427 
2025-07-10 02:31:35.964521: Current learning rate: 0.00606 
2025-07-10 02:32:21.040301: train_loss -0.389 
2025-07-10 02:32:21.040934: val_loss -0.4346 
2025-07-10 02:32:21.041013: Pseudo dice [np.float32(0.7342)] 
2025-07-10 02:32:21.041127: Epoch time: 45.08 s 
2025-07-10 02:32:22.210393:  
2025-07-10 02:32:22.210739: Epoch 428 
2025-07-10 02:32:22.210883: Current learning rate: 0.00605 
2025-07-10 02:33:07.417973: train_loss -0.4353 
2025-07-10 02:33:07.418605: val_loss -0.4304 
2025-07-10 02:33:07.418765: Pseudo dice [np.float32(0.6849)] 
2025-07-10 02:33:07.418890: Epoch time: 45.21 s 
2025-07-10 02:33:08.626442:  
2025-07-10 02:33:08.626689: Epoch 429 
2025-07-10 02:33:08.626813: Current learning rate: 0.00604 
2025-07-10 02:33:54.005605: train_loss -0.429 
2025-07-10 02:33:54.006085: val_loss -0.4528 
2025-07-10 02:33:54.006160: Pseudo dice [np.float32(0.729)] 
2025-07-10 02:33:54.006261: Epoch time: 45.38 s 
2025-07-10 02:33:55.200598:  
2025-07-10 02:33:55.200944: Epoch 430 
2025-07-10 02:33:55.201229: Current learning rate: 0.00603 
2025-07-10 02:34:40.136505: train_loss -0.4464 
2025-07-10 02:34:40.137081: val_loss -0.4371 
2025-07-10 02:34:40.137176: Pseudo dice [np.float32(0.7487)] 
2025-07-10 02:34:40.137309: Epoch time: 44.94 s 
2025-07-10 02:34:41.315968:  
2025-07-10 02:34:41.316121: Epoch 431 
2025-07-10 02:34:41.316228: Current learning rate: 0.00602 
2025-07-10 02:35:26.227315: train_loss -0.4246 
2025-07-10 02:35:26.228026: val_loss -0.4543 
2025-07-10 02:35:26.228110: Pseudo dice [np.float32(0.6109)] 
2025-07-10 02:35:26.228244: Epoch time: 44.91 s 
2025-07-10 02:35:27.942812:  
2025-07-10 02:35:27.943497: Epoch 432 
2025-07-10 02:35:27.943916: Current learning rate: 0.00601 
2025-07-10 02:36:13.587558: train_loss -0.4395 
2025-07-10 02:36:13.588082: val_loss -0.4397 
2025-07-10 02:36:13.588182: Pseudo dice [np.float32(0.7121)] 
2025-07-10 02:36:13.588309: Epoch time: 45.65 s 
2025-07-10 02:36:14.759497:  
2025-07-10 02:36:14.759874: Epoch 433 
2025-07-10 02:36:14.760046: Current learning rate: 0.006 
2025-07-10 02:37:00.155079: train_loss -0.4432 
2025-07-10 02:37:00.155449: val_loss -0.4416 
2025-07-10 02:37:00.155524: Pseudo dice [np.float32(0.7175)] 
2025-07-10 02:37:00.155642: Epoch time: 45.4 s 
2025-07-10 02:37:01.323585:  
2025-07-10 02:37:01.324110: Epoch 434 
2025-07-10 02:37:01.324310: Current learning rate: 0.00599 
2025-07-10 02:37:46.913925: train_loss -0.4564 
2025-07-10 02:37:46.914568: val_loss -0.4552 
2025-07-10 02:37:46.914677: Pseudo dice [np.float32(0.6729)] 
2025-07-10 02:37:46.914855: Epoch time: 45.59 s 
2025-07-10 02:37:48.113673:  
2025-07-10 02:37:48.113839: Epoch 435 
2025-07-10 02:37:48.113939: Current learning rate: 0.00598 
2025-07-10 02:38:33.858418: train_loss -0.4632 
2025-07-10 02:38:33.859172: val_loss -0.4363 
2025-07-10 02:38:33.859326: Pseudo dice [np.float32(0.6804)] 
2025-07-10 02:38:33.859471: Epoch time: 45.75 s 
2025-07-10 02:38:34.997066:  
2025-07-10 02:38:34.997272: Epoch 436 
2025-07-10 02:38:34.997401: Current learning rate: 0.00597 
2025-07-10 02:39:21.139174: train_loss -0.46 
2025-07-10 02:39:21.139510: val_loss -0.464 
2025-07-10 02:39:21.139686: Pseudo dice [np.float32(0.7355)] 
2025-07-10 02:39:21.139806: Epoch time: 46.14 s 
2025-07-10 02:39:22.340793:  
2025-07-10 02:39:22.341213: Epoch 437 
2025-07-10 02:39:22.341557: Current learning rate: 0.00596 
2025-07-10 02:40:07.810725: train_loss -0.434 
2025-07-10 02:40:07.811228: val_loss -0.4595 
2025-07-10 02:40:07.811304: Pseudo dice [np.float32(0.6647)] 
2025-07-10 02:40:07.811425: Epoch time: 45.47 s 
2025-07-10 02:40:08.946272:  
2025-07-10 02:40:08.946579: Epoch 438 
2025-07-10 02:40:08.946859: Current learning rate: 0.00595 
2025-07-10 02:40:54.223233: train_loss -0.4231 
2025-07-10 02:40:54.223719: val_loss -0.4582 
2025-07-10 02:40:54.223800: Pseudo dice [np.float32(0.6978)] 
2025-07-10 02:40:54.223914: Epoch time: 45.28 s 
2025-07-10 02:40:55.359891:  
2025-07-10 02:40:55.360275: Epoch 439 
2025-07-10 02:40:55.360416: Current learning rate: 0.00594 
2025-07-10 02:41:40.618605: train_loss -0.4604 
2025-07-10 02:41:40.619054: val_loss -0.463 
2025-07-10 02:41:40.619225: Pseudo dice [np.float32(0.7878)] 
2025-07-10 02:41:40.619340: Epoch time: 45.26 s 
2025-07-10 02:41:41.898412:  
2025-07-10 02:41:41.898649: Epoch 440 
2025-07-10 02:41:41.898820: Current learning rate: 0.00593 
2025-07-10 02:42:27.494055: train_loss -0.437 
2025-07-10 02:42:27.495116: val_loss -0.4399 
2025-07-10 02:42:27.495302: Pseudo dice [np.float32(0.6614)] 
2025-07-10 02:42:27.495448: Epoch time: 45.6 s 
2025-07-10 02:42:28.655404:  
2025-07-10 02:42:28.655858: Epoch 441 
2025-07-10 02:42:28.655988: Current learning rate: 0.00592 
2025-07-10 02:43:14.203492: train_loss -0.4381 
2025-07-10 02:43:14.203990: val_loss -0.453 
2025-07-10 02:43:14.204077: Pseudo dice [np.float32(0.7278)] 
2025-07-10 02:43:14.204198: Epoch time: 45.55 s 
2025-07-10 02:43:15.376410:  
2025-07-10 02:43:15.377007: Epoch 442 
2025-07-10 02:43:15.377187: Current learning rate: 0.00592 
2025-07-10 02:44:01.025185: train_loss -0.45 
2025-07-10 02:44:01.025644: val_loss -0.4465 
2025-07-10 02:44:01.025725: Pseudo dice [np.float32(0.6977)] 
2025-07-10 02:44:01.025840: Epoch time: 45.65 s 
2025-07-10 02:44:02.827793:  
2025-07-10 02:44:02.828347: Epoch 443 
2025-07-10 02:44:02.828613: Current learning rate: 0.00591 
2025-07-10 02:44:48.362971: train_loss -0.4505 
2025-07-10 02:44:48.363499: val_loss -0.4305 
2025-07-10 02:44:48.363641: Pseudo dice [np.float32(0.5792)] 
2025-07-10 02:44:48.363768: Epoch time: 45.54 s 
2025-07-10 02:44:49.610411:  
2025-07-10 02:44:49.610631: Epoch 444 
2025-07-10 02:44:49.610755: Current learning rate: 0.0059 
2025-07-10 02:45:35.481813: train_loss -0.4289 
2025-07-10 02:45:35.482215: val_loss -0.4713 
2025-07-10 02:45:35.482291: Pseudo dice [np.float32(0.6888)] 
2025-07-10 02:45:35.482424: Epoch time: 45.87 s 
2025-07-10 02:45:36.618173:  
2025-07-10 02:45:36.618400: Epoch 445 
2025-07-10 02:45:36.618610: Current learning rate: 0.00589 
2025-07-10 02:46:22.206295: train_loss -0.4611 
2025-07-10 02:46:22.206919: val_loss -0.4927 
2025-07-10 02:46:22.207005: Pseudo dice [np.float32(0.7654)] 
2025-07-10 02:46:22.207128: Epoch time: 45.59 s 
2025-07-10 02:46:23.367925:  
2025-07-10 02:46:23.368250: Epoch 446 
2025-07-10 02:46:23.368405: Current learning rate: 0.00588 
2025-07-10 02:47:09.393147: train_loss -0.4631 
2025-07-10 02:47:09.393749: val_loss -0.4715 
2025-07-10 02:47:09.393833: Pseudo dice [np.float32(0.7511)] 
2025-07-10 02:47:09.393958: Epoch time: 46.03 s 
2025-07-10 02:47:10.561674:  
2025-07-10 02:47:10.562020: Epoch 447 
2025-07-10 02:47:10.562211: Current learning rate: 0.00587 
2025-07-10 02:47:56.120877: train_loss -0.4525 
2025-07-10 02:47:56.121177: val_loss -0.4763 
2025-07-10 02:47:56.121254: Pseudo dice [np.float32(0.7671)] 
2025-07-10 02:47:56.121350: Epoch time: 45.56 s 
2025-07-10 02:47:57.274736:  
2025-07-10 02:47:57.275143: Epoch 448 
2025-07-10 02:47:57.275274: Current learning rate: 0.00586 
2025-07-10 02:48:44.162246: train_loss -0.4469 
2025-07-10 02:48:44.162604: val_loss -0.4576 
2025-07-10 02:48:44.162679: Pseudo dice [np.float32(0.7506)] 
2025-07-10 02:48:44.162770: Epoch time: 46.89 s 
2025-07-10 02:48:45.318180:  
2025-07-10 02:48:45.318636: Epoch 449 
2025-07-10 02:48:45.318847: Current learning rate: 0.00585 
2025-07-10 02:49:30.751617: train_loss -0.4526 
2025-07-10 02:49:30.752150: val_loss -0.4426 
2025-07-10 02:49:30.752246: Pseudo dice [np.float32(0.6559)] 
2025-07-10 02:49:30.752368: Epoch time: 45.43 s 
2025-07-10 02:49:32.930474:  
2025-07-10 02:49:32.930728: Epoch 450 
2025-07-10 02:49:32.930833: Current learning rate: 0.00584 
2025-07-10 02:50:18.029772: train_loss -0.4166 
2025-07-10 02:50:18.030457: val_loss -0.4253 
2025-07-10 02:50:18.030592: Pseudo dice [np.float32(0.5524)] 
2025-07-10 02:50:18.030730: Epoch time: 45.1 s 
2025-07-10 02:50:19.174699:  
2025-07-10 02:50:19.175024: Epoch 451 
2025-07-10 02:50:19.175222: Current learning rate: 0.00583 
2025-07-10 02:51:04.659176: train_loss -0.4551 
2025-07-10 02:51:04.659734: val_loss -0.46 
2025-07-10 02:51:04.659833: Pseudo dice [np.float32(0.7693)] 
2025-07-10 02:51:04.659943: Epoch time: 45.49 s 
2025-07-10 02:51:05.818722:  
2025-07-10 02:51:05.819168: Epoch 452 
2025-07-10 02:51:05.819293: Current learning rate: 0.00582 
2025-07-10 02:51:52.483903: train_loss -0.46 
2025-07-10 02:51:52.484368: val_loss -0.4576 
2025-07-10 02:51:52.484443: Pseudo dice [np.float32(0.7409)] 
2025-07-10 02:51:52.484559: Epoch time: 46.67 s 
2025-07-10 02:51:53.585469:  
2025-07-10 02:51:53.585870: Epoch 453 
2025-07-10 02:51:53.586029: Current learning rate: 0.00581 
2025-07-10 02:52:39.276412: train_loss -0.4145 
2025-07-10 02:52:39.277174: val_loss -0.4276 
2025-07-10 02:52:39.277341: Pseudo dice [np.float32(0.6535)] 
2025-07-10 02:52:39.277452: Epoch time: 45.69 s 
2025-07-10 02:52:40.499952:  
2025-07-10 02:52:40.500235: Epoch 454 
2025-07-10 02:52:40.500363: Current learning rate: 0.0058 
2025-07-10 02:53:25.791877: train_loss -0.4297 
2025-07-10 02:53:25.792591: val_loss -0.4505 
2025-07-10 02:53:25.792726: Pseudo dice [np.float32(0.7007)] 
2025-07-10 02:53:25.792864: Epoch time: 45.29 s 
2025-07-10 02:53:27.662135:  
2025-07-10 02:53:27.662824: Epoch 455 
2025-07-10 02:53:27.663010: Current learning rate: 0.00579 
2025-07-10 02:54:13.982741: train_loss -0.4349 
2025-07-10 02:54:13.983094: val_loss -0.4414 
2025-07-10 02:54:13.983171: Pseudo dice [np.float32(0.6319)] 
2025-07-10 02:54:13.983276: Epoch time: 46.32 s 
2025-07-10 02:54:15.114738:  
2025-07-10 02:54:15.115001: Epoch 456 
2025-07-10 02:54:15.115180: Current learning rate: 0.00578 
2025-07-10 02:55:01.009285: train_loss -0.4502 
2025-07-10 02:55:01.009746: val_loss -0.4676 
2025-07-10 02:55:01.009832: Pseudo dice [np.float32(0.7796)] 
2025-07-10 02:55:01.009937: Epoch time: 45.9 s 
2025-07-10 02:55:02.135865:  
2025-07-10 02:55:02.136262: Epoch 457 
2025-07-10 02:55:02.136392: Current learning rate: 0.00577 
2025-07-10 02:55:47.964117: train_loss -0.4511 
2025-07-10 02:55:47.964494: val_loss -0.4729 
2025-07-10 02:55:47.964577: Pseudo dice [np.float32(0.7393)] 
2025-07-10 02:55:47.964679: Epoch time: 45.83 s 
2025-07-10 02:55:49.091032:  
2025-07-10 02:55:49.091342: Epoch 458 
2025-07-10 02:55:49.091483: Current learning rate: 0.00576 
2025-07-10 02:56:34.645994: train_loss -0.4447 
2025-07-10 02:56:34.646489: val_loss -0.4233 
2025-07-10 02:56:34.646582: Pseudo dice [np.float32(0.6988)] 
2025-07-10 02:56:34.646697: Epoch time: 45.56 s 
2025-07-10 02:56:35.820561:  
2025-07-10 02:56:35.821149: Epoch 459 
2025-07-10 02:56:35.821338: Current learning rate: 0.00575 
2025-07-10 02:57:21.653248: train_loss -0.4428 
2025-07-10 02:57:21.653851: val_loss -0.4486 
2025-07-10 02:57:21.653937: Pseudo dice [np.float32(0.654)] 
2025-07-10 02:57:21.654042: Epoch time: 45.83 s 
2025-07-10 02:57:22.783810:  
2025-07-10 02:57:22.784163: Epoch 460 
2025-07-10 02:57:22.784322: Current learning rate: 0.00574 
2025-07-10 02:58:08.782499: train_loss -0.4414 
2025-07-10 02:58:08.782788: val_loss -0.4218 
2025-07-10 02:58:08.782854: Pseudo dice [np.float32(0.6437)] 
2025-07-10 02:58:08.782947: Epoch time: 46.0 s 
2025-07-10 02:58:09.906144:  
2025-07-10 02:58:09.906512: Epoch 461 
2025-07-10 02:58:09.906699: Current learning rate: 0.00573 
2025-07-10 02:58:55.425303: train_loss -0.3538 
2025-07-10 02:58:55.426254: val_loss -0.3786 
2025-07-10 02:58:55.426331: Pseudo dice [np.float32(0.6167)] 
2025-07-10 02:58:55.426556: Epoch time: 45.52 s 
2025-07-10 02:58:56.536144:  
2025-07-10 02:58:56.536610: Epoch 462 
2025-07-10 02:58:56.536809: Current learning rate: 0.00572 
2025-07-10 02:59:42.338067: train_loss -0.3871 
2025-07-10 02:59:42.338498: val_loss -0.445 
2025-07-10 02:59:42.338662: Pseudo dice [np.float32(0.6992)] 
2025-07-10 02:59:42.338778: Epoch time: 45.8 s 
2025-07-10 02:59:43.425794:  
2025-07-10 02:59:43.426264: Epoch 463 
2025-07-10 02:59:43.426397: Current learning rate: 0.00571 
2025-07-10 03:00:29.267366: train_loss -0.4419 
2025-07-10 03:00:29.267870: val_loss -0.4247 
2025-07-10 03:00:29.267947: Pseudo dice [np.float32(0.6809)] 
2025-07-10 03:00:29.268067: Epoch time: 45.84 s 
2025-07-10 03:00:30.405584:  
2025-07-10 03:00:30.405900: Epoch 464 
2025-07-10 03:00:30.406105: Current learning rate: 0.0057 
2025-07-10 03:01:16.435357: train_loss -0.4309 
2025-07-10 03:01:16.436488: val_loss -0.4549 
2025-07-10 03:01:16.436676: Pseudo dice [np.float32(0.7419)] 
2025-07-10 03:01:16.436848: Epoch time: 46.03 s 
2025-07-10 03:01:17.667877:  
2025-07-10 03:01:17.668212: Epoch 465 
2025-07-10 03:01:17.668339: Current learning rate: 0.0057 
2025-07-10 03:02:03.817448: train_loss -0.454 
2025-07-10 03:02:03.818071: val_loss -0.4505 
2025-07-10 03:02:03.818524: Pseudo dice [np.float32(0.7445)] 
2025-07-10 03:02:03.818727: Epoch time: 46.15 s 
2025-07-10 03:02:05.098221:  
2025-07-10 03:02:05.098654: Epoch 466 
2025-07-10 03:02:05.098801: Current learning rate: 0.00569 
2025-07-10 03:02:51.130423: train_loss -0.4547 
2025-07-10 03:02:51.131410: val_loss -0.4567 
2025-07-10 03:02:51.131495: Pseudo dice [np.float32(0.7114)] 
2025-07-10 03:02:51.131660: Epoch time: 46.03 s 
2025-07-10 03:02:53.088013:  
2025-07-10 03:02:53.088691: Epoch 467 
2025-07-10 03:02:53.088869: Current learning rate: 0.00568 
2025-07-10 03:03:39.498124: train_loss -0.4558 
2025-07-10 03:03:39.498687: val_loss -0.4621 
2025-07-10 03:03:39.498815: Pseudo dice [np.float32(0.6989)] 
2025-07-10 03:03:39.498949: Epoch time: 46.41 s 
2025-07-10 03:03:40.718173:  
2025-07-10 03:03:40.718649: Epoch 468 
2025-07-10 03:03:40.718848: Current learning rate: 0.00567 
2025-07-10 03:04:28.271583: train_loss -0.4398 
2025-07-10 03:04:28.272250: val_loss -0.4422 
2025-07-10 03:04:28.272345: Pseudo dice [np.float32(0.7007)] 
2025-07-10 03:04:28.272476: Epoch time: 47.55 s 
2025-07-10 03:04:29.416882:  
2025-07-10 03:04:29.417311: Epoch 469 
2025-07-10 03:04:29.417502: Current learning rate: 0.00566 
2025-07-10 03:05:16.931024: train_loss -0.4489 
2025-07-10 03:05:16.931843: val_loss -0.4656 
2025-07-10 03:05:16.931925: Pseudo dice [np.float32(0.7019)] 
2025-07-10 03:05:16.932046: Epoch time: 47.52 s 
2025-07-10 03:05:18.075740:  
2025-07-10 03:05:18.075972: Epoch 470 
2025-07-10 03:05:18.076229: Current learning rate: 0.00565 
2025-07-10 03:06:05.128345: train_loss -0.4648 
2025-07-10 03:06:05.128869: val_loss -0.4642 
2025-07-10 03:06:05.128949: Pseudo dice [np.float32(0.7697)] 
2025-07-10 03:06:05.129050: Epoch time: 47.05 s 
2025-07-10 03:06:06.268527:  
2025-07-10 03:06:06.268937: Epoch 471 
2025-07-10 03:06:06.269066: Current learning rate: 0.00564 
2025-07-10 03:06:52.501225: train_loss -0.4708 
2025-07-10 03:06:52.501737: val_loss -0.4797 
2025-07-10 03:06:52.501857: Pseudo dice [np.float32(0.7767)] 
2025-07-10 03:06:52.501974: Epoch time: 46.23 s 
2025-07-10 03:06:53.714823:  
2025-07-10 03:06:53.715350: Epoch 472 
2025-07-10 03:06:53.715499: Current learning rate: 0.00563 
2025-07-10 03:07:39.619876: train_loss -0.4633 
2025-07-10 03:07:39.620536: val_loss -0.4484 
2025-07-10 03:07:39.620648: Pseudo dice [np.float32(0.7617)] 
2025-07-10 03:07:39.620815: Epoch time: 45.91 s 
2025-07-10 03:07:40.730505:  
2025-07-10 03:07:40.730865: Epoch 473 
2025-07-10 03:07:40.731057: Current learning rate: 0.00562 
2025-07-10 03:08:26.043325: train_loss -0.4177 
2025-07-10 03:08:26.043786: val_loss -0.4307 
2025-07-10 03:08:26.043862: Pseudo dice [np.float32(0.6423)] 
2025-07-10 03:08:26.043964: Epoch time: 45.31 s 
2025-07-10 03:08:27.198236:  
2025-07-10 03:08:27.198672: Epoch 474 
2025-07-10 03:08:27.198844: Current learning rate: 0.00561 
2025-07-10 03:09:12.949705: train_loss -0.4446 
2025-07-10 03:09:12.950499: val_loss -0.417 
2025-07-10 03:09:12.950637: Pseudo dice [np.float32(0.5895)] 
2025-07-10 03:09:12.950800: Epoch time: 45.75 s 
2025-07-10 03:09:14.173609:  
2025-07-10 03:09:14.173882: Epoch 475 
2025-07-10 03:09:14.174064: Current learning rate: 0.0056 
2025-07-10 03:10:00.678250: train_loss -0.4397 
2025-07-10 03:10:00.678815: val_loss -0.4625 
2025-07-10 03:10:00.678895: Pseudo dice [np.float32(0.6602)] 
2025-07-10 03:10:00.679004: Epoch time: 46.51 s 
2025-07-10 03:10:01.815798:  
2025-07-10 03:10:01.816207: Epoch 476 
2025-07-10 03:10:01.816372: Current learning rate: 0.00559 
2025-07-10 03:10:47.772117: train_loss -0.4622 
2025-07-10 03:10:47.772566: val_loss -0.466 
2025-07-10 03:10:47.772652: Pseudo dice [np.float32(0.7898)] 
2025-07-10 03:10:47.772758: Epoch time: 45.96 s 
2025-07-10 03:10:48.888341:  
2025-07-10 03:10:48.888672: Epoch 477 
2025-07-10 03:10:48.888807: Current learning rate: 0.00558 
2025-07-10 03:11:35.327775: train_loss -0.4653 
2025-07-10 03:11:35.328204: val_loss -0.4668 
2025-07-10 03:11:35.328282: Pseudo dice [np.float32(0.739)] 
2025-07-10 03:11:35.328372: Epoch time: 46.44 s 
2025-07-10 03:11:36.493869:  
2025-07-10 03:11:36.494397: Epoch 478 
2025-07-10 03:11:36.494557: Current learning rate: 0.00557 
2025-07-10 03:12:22.355554: train_loss -0.4575 
2025-07-10 03:12:22.356141: val_loss -0.4647 
2025-07-10 03:12:22.356223: Pseudo dice [np.float32(0.7405)] 
2025-07-10 03:12:22.356344: Epoch time: 45.86 s 
2025-07-10 03:12:23.500463:  
2025-07-10 03:12:23.500776: Epoch 479 
2025-07-10 03:12:23.500929: Current learning rate: 0.00556 
2025-07-10 03:13:09.456342: train_loss -0.4453 
2025-07-10 03:13:09.457031: val_loss -0.451 
2025-07-10 03:13:09.457110: Pseudo dice [np.float32(0.7766)] 
2025-07-10 03:13:09.457259: Epoch time: 45.96 s 
2025-07-10 03:13:11.232048:  
2025-07-10 03:13:11.232444: Epoch 480 
2025-07-10 03:13:11.232662: Current learning rate: 0.00555 
2025-07-10 03:13:56.899839: train_loss -0.4599 
2025-07-10 03:13:56.900450: val_loss -0.4459 
2025-07-10 03:13:56.900623: Pseudo dice [np.float32(0.6812)] 
2025-07-10 03:13:56.900814: Epoch time: 45.67 s 
2025-07-10 03:13:58.085445:  
2025-07-10 03:13:58.085685: Epoch 481 
2025-07-10 03:13:58.085830: Current learning rate: 0.00554 
2025-07-10 03:14:43.224861: train_loss -0.4177 
2025-07-10 03:14:43.225415: val_loss -0.3968 
2025-07-10 03:14:43.225498: Pseudo dice [np.float32(0.6577)] 
2025-07-10 03:14:43.225628: Epoch time: 45.14 s 
2025-07-10 03:14:44.429480:  
2025-07-10 03:14:44.429725: Epoch 482 
2025-07-10 03:14:44.430056: Current learning rate: 0.00553 
2025-07-10 03:15:32.394246: train_loss -0.4181 
2025-07-10 03:15:32.394925: val_loss -0.4118 
2025-07-10 03:15:32.395006: Pseudo dice [np.float32(0.6879)] 
2025-07-10 03:15:32.395173: Epoch time: 47.97 s 
2025-07-10 03:15:33.541377:  
2025-07-10 03:15:33.541885: Epoch 483 
2025-07-10 03:15:33.542101: Current learning rate: 0.00552 
2025-07-10 03:16:19.584094: train_loss -0.4293 
2025-07-10 03:16:19.584617: val_loss -0.36 
2025-07-10 03:16:19.584698: Pseudo dice [np.float32(0.3948)] 
2025-07-10 03:16:19.584810: Epoch time: 46.04 s 
2025-07-10 03:16:20.794096:  
2025-07-10 03:16:20.794830: Epoch 484 
2025-07-10 03:16:20.795001: Current learning rate: 0.00551 
2025-07-10 03:17:07.778044: train_loss -0.4306 
2025-07-10 03:17:07.778656: val_loss -0.4369 
2025-07-10 03:17:07.778757: Pseudo dice [np.float32(0.6273)] 
2025-07-10 03:17:07.778879: Epoch time: 46.99 s 
2025-07-10 03:17:08.945608:  
2025-07-10 03:17:08.945946: Epoch 485 
2025-07-10 03:17:08.946076: Current learning rate: 0.0055 
2025-07-10 03:17:54.977131: train_loss -0.437 
2025-07-10 03:17:54.977565: val_loss -0.454 
2025-07-10 03:17:54.977649: Pseudo dice [np.float32(0.6681)] 
2025-07-10 03:17:54.977753: Epoch time: 46.03 s 
2025-07-10 03:17:56.111803:  
2025-07-10 03:17:56.112214: Epoch 486 
2025-07-10 03:17:56.112387: Current learning rate: 0.00549 
2025-07-10 03:18:42.541939: train_loss -0.4421 
2025-07-10 03:18:42.542339: val_loss -0.4777 
2025-07-10 03:18:42.542427: Pseudo dice [np.float32(0.7363)] 
2025-07-10 03:18:42.542819: Epoch time: 46.43 s 
2025-07-10 03:18:43.713581:  
2025-07-10 03:18:43.713947: Epoch 487 
2025-07-10 03:18:43.714054: Current learning rate: 0.00548 
2025-07-10 03:19:30.055148: train_loss -0.4294 
2025-07-10 03:19:30.055867: val_loss -0.3987 
2025-07-10 03:19:30.055958: Pseudo dice [np.float32(0.6016)] 
2025-07-10 03:19:30.056079: Epoch time: 46.34 s 
2025-07-10 03:19:31.229053:  
2025-07-10 03:19:31.229382: Epoch 488 
2025-07-10 03:19:31.229517: Current learning rate: 0.00547 
2025-07-10 03:20:18.157511: train_loss -0.4271 
2025-07-10 03:20:18.158080: val_loss -0.4585 
2025-07-10 03:20:18.158175: Pseudo dice [np.float32(0.7182)] 
2025-07-10 03:20:18.158289: Epoch time: 46.93 s 
2025-07-10 03:20:19.331307:  
2025-07-10 03:20:19.331744: Epoch 489 
2025-07-10 03:20:19.331904: Current learning rate: 0.00546 
2025-07-10 03:21:05.360737: train_loss -0.4279 
2025-07-10 03:21:05.361203: val_loss -0.423 
2025-07-10 03:21:05.361426: Pseudo dice [np.float32(0.6984)] 
2025-07-10 03:21:05.361615: Epoch time: 46.03 s 
2025-07-10 03:21:06.611525:  
2025-07-10 03:21:06.611737: Epoch 490 
2025-07-10 03:21:06.611896: Current learning rate: 0.00546 
2025-07-10 03:21:52.542419: train_loss -0.4072 
2025-07-10 03:21:52.542893: val_loss -0.4359 
2025-07-10 03:21:52.542975: Pseudo dice [np.float32(0.6964)] 
2025-07-10 03:21:52.543078: Epoch time: 45.93 s 
2025-07-10 03:21:54.076664:  
2025-07-10 03:21:54.077030: Epoch 491 
2025-07-10 03:21:54.077134: Current learning rate: 0.00545 
2025-07-10 03:22:40.191643: train_loss -0.4053 
2025-07-10 03:22:40.192024: val_loss -0.4108 
2025-07-10 03:22:40.192114: Pseudo dice [np.float32(0.6023)] 
2025-07-10 03:22:40.192211: Epoch time: 46.12 s 
2025-07-10 03:22:41.294623:  
2025-07-10 03:22:41.294803: Epoch 492 
2025-07-10 03:22:41.294943: Current learning rate: 0.00544 
2025-07-10 03:23:26.471243: train_loss -0.4327 
2025-07-10 03:23:26.472217: val_loss -0.4381 
2025-07-10 03:23:26.472304: Pseudo dice [np.float32(0.6178)] 
2025-07-10 03:23:26.472457: Epoch time: 45.18 s 
2025-07-10 03:23:27.658688:  
2025-07-10 03:23:27.659115: Epoch 493 
2025-07-10 03:23:27.659366: Current learning rate: 0.00543 
2025-07-10 03:24:13.425724: train_loss -0.4355 
2025-07-10 03:24:13.426185: val_loss -0.457 
2025-07-10 03:24:13.426268: Pseudo dice [np.float32(0.7146)] 
2025-07-10 03:24:13.426370: Epoch time: 45.77 s 
2025-07-10 03:24:14.651818:  
2025-07-10 03:24:14.652300: Epoch 494 
2025-07-10 03:24:14.652434: Current learning rate: 0.00542 
2025-07-10 03:25:01.062817: train_loss -0.4617 
2025-07-10 03:25:01.063250: val_loss -0.4664 
2025-07-10 03:25:01.063403: Pseudo dice [np.float32(0.7127)] 
2025-07-10 03:25:01.063571: Epoch time: 46.41 s 
2025-07-10 03:25:02.247800:  
2025-07-10 03:25:02.248145: Epoch 495 
2025-07-10 03:25:02.248279: Current learning rate: 0.00541 
2025-07-10 03:25:48.335626: train_loss -0.4624 
2025-07-10 03:25:48.336117: val_loss -0.4309 
2025-07-10 03:25:48.336190: Pseudo dice [np.float32(0.6323)] 
2025-07-10 03:25:48.336299: Epoch time: 46.09 s 
2025-07-10 03:25:49.521480:  
2025-07-10 03:25:49.521802: Epoch 496 
2025-07-10 03:25:49.521980: Current learning rate: 0.0054 
2025-07-10 03:26:34.540296: train_loss -0.4617 
2025-07-10 03:26:34.540709: val_loss -0.4382 
2025-07-10 03:26:34.540787: Pseudo dice [np.float32(0.6646)] 
2025-07-10 03:26:34.540892: Epoch time: 45.02 s 
2025-07-10 03:26:35.678811:  
2025-07-10 03:26:35.679270: Epoch 497 
2025-07-10 03:26:35.679525: Current learning rate: 0.00539 
2025-07-10 03:27:21.750300: train_loss -0.4678 
2025-07-10 03:27:21.750851: val_loss -0.4257 
2025-07-10 03:27:21.750946: Pseudo dice [np.float32(0.5936)] 
2025-07-10 03:27:21.751057: Epoch time: 46.07 s 
2025-07-10 03:27:22.889762:  
2025-07-10 03:27:22.889956: Epoch 498 
2025-07-10 03:27:22.890080: Current learning rate: 0.00538 
2025-07-10 03:28:09.511553: train_loss -0.4181 
2025-07-10 03:28:09.512047: val_loss -0.3734 
2025-07-10 03:28:09.512130: Pseudo dice [np.float32(0.4894)] 
2025-07-10 03:28:09.512251: Epoch time: 46.62 s 
2025-07-10 03:28:10.644211:  
2025-07-10 03:28:10.644465: Epoch 499 
2025-07-10 03:28:10.644744: Current learning rate: 0.00537 
2025-07-10 03:28:56.023236: train_loss -0.4205 
2025-07-10 03:28:56.023670: val_loss -0.4295 
2025-07-10 03:28:56.023835: Pseudo dice [np.float32(0.5383)] 
2025-07-10 03:28:56.023947: Epoch time: 45.38 s 
2025-07-10 03:28:58.120212:  
2025-07-10 03:28:58.120712: Epoch 500 
2025-07-10 03:28:58.120953: Current learning rate: 0.00536 
2025-07-10 03:29:44.451251: train_loss -0.4573 
2025-07-10 03:29:44.451689: val_loss -0.4604 
2025-07-10 03:29:44.451788: Pseudo dice [np.float32(0.752)] 
2025-07-10 03:29:44.451892: Epoch time: 46.33 s 
2025-07-10 03:29:45.572240:  
2025-07-10 03:29:45.572559: Epoch 501 
2025-07-10 03:29:45.572694: Current learning rate: 0.00535 
2025-07-10 03:30:31.314106: train_loss -0.442 
2025-07-10 03:30:31.314905: val_loss -0.4489 
2025-07-10 03:30:31.314981: Pseudo dice [np.float32(0.7586)] 
2025-07-10 03:30:31.315108: Epoch time: 45.74 s 
2025-07-10 03:30:32.453554:  
2025-07-10 03:30:32.453786: Epoch 502 
2025-07-10 03:30:32.453879: Current learning rate: 0.00534 
2025-07-10 03:31:18.733524: train_loss -0.4498 
2025-07-10 03:31:18.733946: val_loss -0.4277 
2025-07-10 03:31:18.737479: Pseudo dice [np.float32(0.6724)] 
2025-07-10 03:31:18.737622: Epoch time: 46.28 s 
2025-07-10 03:31:20.503786:  
2025-07-10 03:31:20.504175: Epoch 503 
2025-07-10 03:31:20.504354: Current learning rate: 0.00533 
2025-07-10 03:32:06.481333: train_loss -0.4501 
2025-07-10 03:32:06.482022: val_loss -0.4468 
2025-07-10 03:32:06.482105: Pseudo dice [np.float32(0.7312)] 
2025-07-10 03:32:06.482210: Epoch time: 45.98 s 
2025-07-10 03:32:07.675572:  
2025-07-10 03:32:07.676024: Epoch 504 
2025-07-10 03:32:07.676221: Current learning rate: 0.00532 
2025-07-10 03:32:53.578572: train_loss -0.4472 
2025-07-10 03:32:53.579033: val_loss -0.4613 
2025-07-10 03:32:53.579211: Pseudo dice [np.float32(0.6755)] 
2025-07-10 03:32:53.579407: Epoch time: 45.9 s 
2025-07-10 03:32:54.808344:  
2025-07-10 03:32:54.808783: Epoch 505 
2025-07-10 03:32:54.808916: Current learning rate: 0.00531 
2025-07-10 03:33:41.352811: train_loss -0.4421 
2025-07-10 03:33:41.353243: val_loss -0.4156 
2025-07-10 03:33:41.353328: Pseudo dice [np.float32(0.617)] 
2025-07-10 03:33:41.353440: Epoch time: 46.55 s 
2025-07-10 03:33:42.501807:  
2025-07-10 03:33:42.502450: Epoch 506 
2025-07-10 03:33:42.502609: Current learning rate: 0.0053 
2025-07-10 03:34:28.838360: train_loss -0.4318 
2025-07-10 03:34:28.838858: val_loss -0.4478 
2025-07-10 03:34:28.838979: Pseudo dice [np.float32(0.6898)] 
2025-07-10 03:34:28.839160: Epoch time: 46.34 s 
2025-07-10 03:34:29.994026:  
2025-07-10 03:34:29.994237: Epoch 507 
2025-07-10 03:34:29.994384: Current learning rate: 0.00529 
2025-07-10 03:35:16.358746: train_loss -0.4638 
2025-07-10 03:35:16.359315: val_loss -0.4067 
2025-07-10 03:35:16.359407: Pseudo dice [np.float32(0.6097)] 
2025-07-10 03:35:16.359531: Epoch time: 46.37 s 
2025-07-10 03:35:17.550924:  
2025-07-10 03:35:17.551199: Epoch 508 
2025-07-10 03:35:17.551371: Current learning rate: 0.00528 
2025-07-10 03:36:03.474206: train_loss -0.3938 
2025-07-10 03:36:03.474742: val_loss -0.3749 
2025-07-10 03:36:03.474844: Pseudo dice [np.float32(0.5747)] 
2025-07-10 03:36:03.474970: Epoch time: 45.92 s 
2025-07-10 03:36:04.625924:  
2025-07-10 03:36:04.626302: Epoch 509 
2025-07-10 03:36:04.626523: Current learning rate: 0.00527 
2025-07-10 03:36:50.848437: train_loss -0.3876 
2025-07-10 03:36:50.848849: val_loss -0.4314 
2025-07-10 03:36:50.848925: Pseudo dice [np.float32(0.6547)] 
2025-07-10 03:36:50.849020: Epoch time: 46.22 s 
2025-07-10 03:36:52.002526:  
2025-07-10 03:36:52.003008: Epoch 510 
2025-07-10 03:36:52.003191: Current learning rate: 0.00526 
2025-07-10 03:37:38.753354: train_loss -0.4358 
2025-07-10 03:37:38.753758: val_loss -0.4716 
2025-07-10 03:37:38.753844: Pseudo dice [np.float32(0.6613)] 
2025-07-10 03:37:38.753965: Epoch time: 46.75 s 
2025-07-10 03:37:39.921686:  
2025-07-10 03:37:39.921990: Epoch 511 
2025-07-10 03:37:39.922191: Current learning rate: 0.00525 
2025-07-10 03:38:25.863159: train_loss -0.4356 
2025-07-10 03:38:25.863777: val_loss -0.434 
2025-07-10 03:38:25.863862: Pseudo dice [np.float32(0.679)] 
2025-07-10 03:38:25.863968: Epoch time: 45.94 s 
2025-07-10 03:38:27.010710:  
2025-07-10 03:38:27.011057: Epoch 512 
2025-07-10 03:38:27.011185: Current learning rate: 0.00524 
2025-07-10 03:39:14.913286: train_loss -0.4406 
2025-07-10 03:39:14.913813: val_loss -0.4555 
2025-07-10 03:39:14.913894: Pseudo dice [np.float32(0.6857)] 
2025-07-10 03:39:14.914003: Epoch time: 47.9 s 
2025-07-10 03:39:16.064785:  
2025-07-10 03:39:16.065558: Epoch 513 
2025-07-10 03:39:16.065754: Current learning rate: 0.00523 
2025-07-10 03:40:02.000021: train_loss -0.4495 
2025-07-10 03:40:02.000705: val_loss -0.4586 
2025-07-10 03:40:02.000878: Pseudo dice [np.float32(0.8047)] 
2025-07-10 03:40:02.000987: Epoch time: 45.94 s 
2025-07-10 03:40:03.205965:  
2025-07-10 03:40:03.206287: Epoch 514 
2025-07-10 03:40:03.206557: Current learning rate: 0.00522 
2025-07-10 03:40:49.300323: train_loss -0.4421 
2025-07-10 03:40:49.301145: val_loss -0.4284 
2025-07-10 03:40:49.301367: Pseudo dice [np.float32(0.674)] 
2025-07-10 03:40:49.301652: Epoch time: 46.1 s 
2025-07-10 03:40:50.949288:  
2025-07-10 03:40:50.949599: Epoch 515 
2025-07-10 03:40:50.949707: Current learning rate: 0.00521 
2025-07-10 03:41:37.217446: train_loss -0.4206 
2025-07-10 03:41:37.218226: val_loss -0.4296 
2025-07-10 03:41:37.218330: Pseudo dice [np.float32(0.6713)] 
2025-07-10 03:41:37.218451: Epoch time: 46.27 s 
2025-07-10 03:41:38.383495:  
2025-07-10 03:41:38.383953: Epoch 516 
2025-07-10 03:41:38.384088: Current learning rate: 0.0052 
2025-07-10 03:42:24.441914: train_loss -0.4139 
2025-07-10 03:42:24.442494: val_loss -0.4614 
2025-07-10 03:42:24.442622: Pseudo dice [np.float32(0.7504)] 
2025-07-10 03:42:24.442763: Epoch time: 46.06 s 
2025-07-10 03:42:25.658391:  
2025-07-10 03:42:25.658586: Epoch 517 
2025-07-10 03:42:25.658952: Current learning rate: 0.00519 
2025-07-10 03:43:11.324960: train_loss -0.4327 
2025-07-10 03:43:11.325598: val_loss -0.4256 
2025-07-10 03:43:11.325701: Pseudo dice [np.float32(0.6197)] 
2025-07-10 03:43:11.325835: Epoch time: 45.67 s 
2025-07-10 03:43:12.584348:  
2025-07-10 03:43:12.584662: Epoch 518 
2025-07-10 03:43:12.584955: Current learning rate: 0.00518 
2025-07-10 03:43:58.664498: train_loss -0.3509 
2025-07-10 03:43:58.664953: val_loss -0.3645 
2025-07-10 03:43:58.665029: Pseudo dice [np.float32(0.298)] 
2025-07-10 03:43:58.665133: Epoch time: 46.08 s 
2025-07-10 03:43:59.903228:  
2025-07-10 03:43:59.903672: Epoch 519 
2025-07-10 03:43:59.903819: Current learning rate: 0.00518 
2025-07-10 03:44:45.307978: train_loss -0.3605 
2025-07-10 03:44:45.308591: val_loss -0.3616 
2025-07-10 03:44:45.308704: Pseudo dice [np.float32(0.4984)] 
2025-07-10 03:44:45.308844: Epoch time: 45.41 s 
2025-07-10 03:44:46.526792:  
2025-07-10 03:44:46.527235: Epoch 520 
2025-07-10 03:44:46.527357: Current learning rate: 0.00517 
2025-07-10 03:45:33.630588: train_loss -0.3941 
2025-07-10 03:45:33.631878: val_loss -0.4346 
2025-07-10 03:45:33.631977: Pseudo dice [np.float32(0.6324)] 
2025-07-10 03:45:33.632117: Epoch time: 47.1 s 
2025-07-10 03:45:34.833005:  
2025-07-10 03:45:34.833408: Epoch 521 
2025-07-10 03:45:34.833556: Current learning rate: 0.00516 
2025-07-10 03:46:21.109236: train_loss -0.4279 
2025-07-10 03:46:21.110205: val_loss -0.432 
2025-07-10 03:46:21.110315: Pseudo dice [np.float32(0.574)] 
2025-07-10 03:46:21.110459: Epoch time: 46.28 s 
2025-07-10 03:46:22.382508:  
2025-07-10 03:46:22.382825: Epoch 522 
2025-07-10 03:46:22.382955: Current learning rate: 0.00515 
2025-07-10 03:47:09.274872: train_loss -0.4486 
2025-07-10 03:47:09.275596: val_loss -0.4463 
2025-07-10 03:47:09.275719: Pseudo dice [np.float32(0.713)] 
2025-07-10 03:47:09.275873: Epoch time: 46.89 s 
2025-07-10 03:47:10.501256:  
2025-07-10 03:47:10.501627: Epoch 523 
2025-07-10 03:47:10.501852: Current learning rate: 0.00514 
2025-07-10 03:47:58.264270: train_loss -0.3878 
2025-07-10 03:47:58.264701: val_loss -0.3646 
2025-07-10 03:47:58.264783: Pseudo dice [np.float32(0.5142)] 
2025-07-10 03:47:58.264895: Epoch time: 47.76 s 
2025-07-10 03:47:59.436733:  
2025-07-10 03:47:59.437236: Epoch 524 
2025-07-10 03:47:59.437665: Current learning rate: 0.00513 
2025-07-10 03:48:46.738490: train_loss -0.3258 
2025-07-10 03:48:46.738921: val_loss -0.3009 
2025-07-10 03:48:46.739002: Pseudo dice [np.float32(0.0)] 
2025-07-10 03:48:46.739102: Epoch time: 47.3 s 
2025-07-10 03:48:47.893694:  
2025-07-10 03:48:47.894382: Epoch 525 
2025-07-10 03:48:47.894551: Current learning rate: 0.00512 
2025-07-10 03:49:34.838758: train_loss -0.3341 
2025-07-10 03:49:34.839122: val_loss -0.3286 
2025-07-10 03:49:34.839197: Pseudo dice [np.float32(0.0)] 
2025-07-10 03:49:34.839301: Epoch time: 46.95 s 
2025-07-10 03:49:36.009728:  
2025-07-10 03:49:36.010085: Epoch 526 
2025-07-10 03:49:36.010266: Current learning rate: 0.00511 
2025-07-10 03:50:22.956507: train_loss -0.3566 
2025-07-10 03:50:22.956887: val_loss -0.333 
2025-07-10 03:50:22.956966: Pseudo dice [np.float32(0.0)] 
2025-07-10 03:50:22.957066: Epoch time: 46.95 s 
2025-07-10 03:50:24.572158:  
2025-07-10 03:50:24.572536: Epoch 527 
2025-07-10 03:50:24.572820: Current learning rate: 0.0051 
2025-07-10 03:51:11.486313: train_loss -0.3597 
2025-07-10 03:51:11.487033: val_loss -0.3581 
2025-07-10 03:51:11.487120: Pseudo dice [np.float32(0.0)] 
2025-07-10 03:51:11.487260: Epoch time: 46.92 s 
2025-07-10 03:51:12.699789:  
2025-07-10 03:51:12.700121: Epoch 528 
2025-07-10 03:51:12.700292: Current learning rate: 0.00509 
2025-07-10 03:52:00.828135: train_loss -0.353 
2025-07-10 03:52:00.828614: val_loss -0.3302 
2025-07-10 03:52:00.828703: Pseudo dice [np.float32(0.0)] 
2025-07-10 03:52:00.828812: Epoch time: 48.13 s 
2025-07-10 03:52:02.000037:  
2025-07-10 03:52:02.001022: Epoch 529 
2025-07-10 03:52:02.001272: Current learning rate: 0.00508 
2025-07-10 03:52:48.979087: train_loss -0.3854 
2025-07-10 03:52:48.979526: val_loss -0.4266 
2025-07-10 03:52:48.983263: Pseudo dice [np.float32(0.7375)] 
2025-07-10 03:52:48.983483: Epoch time: 46.98 s 
2025-07-10 03:52:50.148207:  
2025-07-10 03:52:50.148520: Epoch 530 
2025-07-10 03:52:50.148662: Current learning rate: 0.00507 
2025-07-10 03:53:37.067919: train_loss -0.435 
2025-07-10 03:53:37.068484: val_loss -0.4427 
2025-07-10 03:53:37.068597: Pseudo dice [np.float32(0.7049)] 
2025-07-10 03:53:37.068817: Epoch time: 46.92 s 
2025-07-10 03:53:38.208271:  
2025-07-10 03:53:38.208663: Epoch 531 
2025-07-10 03:53:38.208929: Current learning rate: 0.00506 
2025-07-10 03:54:25.669310: train_loss -0.4369 
2025-07-10 03:54:25.669832: val_loss -0.4453 
2025-07-10 03:54:25.669913: Pseudo dice [np.float32(0.734)] 
2025-07-10 03:54:25.670066: Epoch time: 47.46 s 
2025-07-10 03:54:26.867589:  
2025-07-10 03:54:26.868111: Epoch 532 
2025-07-10 03:54:26.868425: Current learning rate: 0.00505 
2025-07-10 03:55:14.124440: train_loss -0.4507 
2025-07-10 03:55:14.124943: val_loss -0.4444 
2025-07-10 03:55:14.125021: Pseudo dice [np.float32(0.6995)] 
2025-07-10 03:55:14.125136: Epoch time: 47.26 s 
2025-07-10 03:55:15.269593:  
2025-07-10 03:55:15.269933: Epoch 533 
2025-07-10 03:55:15.270292: Current learning rate: 0.00504 
2025-07-10 03:56:02.123464: train_loss -0.4489 
2025-07-10 03:56:02.123899: val_loss -0.4545 
2025-07-10 03:56:02.123978: Pseudo dice [np.float32(0.7678)] 
2025-07-10 03:56:02.124087: Epoch time: 46.86 s 
2025-07-10 03:56:03.289215:  
2025-07-10 03:56:03.289549: Epoch 534 
2025-07-10 03:56:03.289775: Current learning rate: 0.00503 
2025-07-10 03:56:49.128399: train_loss -0.4522 
2025-07-10 03:56:49.128953: val_loss -0.4564 
2025-07-10 03:56:49.129036: Pseudo dice [np.float32(0.7387)] 
2025-07-10 03:56:49.129150: Epoch time: 45.84 s 
2025-07-10 03:56:50.346880:  
2025-07-10 03:56:50.347146: Epoch 535 
2025-07-10 03:56:50.347360: Current learning rate: 0.00502 
2025-07-10 03:57:36.427723: train_loss -0.4508 
2025-07-10 03:57:36.428275: val_loss -0.4562 
2025-07-10 03:57:36.428370: Pseudo dice [np.float32(0.7086)] 
2025-07-10 03:57:36.428514: Epoch time: 46.08 s 
2025-07-10 03:57:37.598505:  
2025-07-10 03:57:37.598846: Epoch 536 
2025-07-10 03:57:37.599127: Current learning rate: 0.00501 
2025-07-10 03:58:23.500937: train_loss -0.4453 
2025-07-10 03:58:23.501569: val_loss -0.452 
2025-07-10 03:58:23.501656: Pseudo dice [np.float32(0.7412)] 
2025-07-10 03:58:23.501767: Epoch time: 45.9 s 
2025-07-10 03:58:24.629883:  
2025-07-10 03:58:24.630211: Epoch 537 
2025-07-10 03:58:24.630393: Current learning rate: 0.005 
2025-07-10 03:59:10.874159: train_loss -0.4177 
2025-07-10 03:59:10.874768: val_loss -0.4185 
2025-07-10 03:59:10.874885: Pseudo dice [np.float32(0.6432)] 
2025-07-10 03:59:10.874999: Epoch time: 46.25 s 
2025-07-10 03:59:12.159058:  
2025-07-10 03:59:12.159449: Epoch 538 
2025-07-10 03:59:12.159660: Current learning rate: 0.00499 
2025-07-10 03:59:57.969035: train_loss -0.4305 
2025-07-10 03:59:57.969566: val_loss -0.4271 
2025-07-10 03:59:57.969651: Pseudo dice [np.float32(0.7212)] 
2025-07-10 03:59:57.969765: Epoch time: 45.81 s 
2025-07-10 03:59:59.779392:  
2025-07-10 03:59:59.779768: Epoch 539 
2025-07-10 03:59:59.779875: Current learning rate: 0.00498 
2025-07-10 04:00:46.336641: train_loss -0.4378 
2025-07-10 04:00:46.337036: val_loss -0.4431 
2025-07-10 04:00:46.337151: Pseudo dice [np.float32(0.5831)] 
2025-07-10 04:00:46.337266: Epoch time: 46.56 s 
2025-07-10 04:00:47.565697:  
2025-07-10 04:00:47.566004: Epoch 540 
2025-07-10 04:00:47.566141: Current learning rate: 0.00497 
2025-07-10 04:01:33.881788: train_loss -0.4376 
2025-07-10 04:01:33.882248: val_loss -0.4307 
2025-07-10 04:01:33.882324: Pseudo dice [np.float32(0.6542)] 
2025-07-10 04:01:33.882427: Epoch time: 46.32 s 
2025-07-10 04:01:35.053329:  
2025-07-10 04:01:35.053866: Epoch 541 
2025-07-10 04:01:35.054343: Current learning rate: 0.00496 
2025-07-10 04:02:21.214954: train_loss -0.4498 
2025-07-10 04:02:21.215991: val_loss -0.4321 
2025-07-10 04:02:21.216104: Pseudo dice [np.float32(0.6266)] 
2025-07-10 04:02:21.216310: Epoch time: 46.16 s 
2025-07-10 04:02:22.417770:  
2025-07-10 04:02:22.418231: Epoch 542 
2025-07-10 04:02:22.418362: Current learning rate: 0.00495 
2025-07-10 04:03:08.464463: train_loss -0.4201 
2025-07-10 04:03:08.465112: val_loss -0.4324 
2025-07-10 04:03:08.465261: Pseudo dice [np.float32(0.6562)] 
2025-07-10 04:03:08.465487: Epoch time: 46.05 s 
2025-07-10 04:03:09.743789:  
2025-07-10 04:03:09.743972: Epoch 543 
2025-07-10 04:03:09.744246: Current learning rate: 0.00494 
2025-07-10 04:03:55.542395: train_loss -0.4232 
2025-07-10 04:03:55.543168: val_loss -0.4231 
2025-07-10 04:03:55.543242: Pseudo dice [np.float32(0.6474)] 
2025-07-10 04:03:55.543407: Epoch time: 45.8 s 
2025-07-10 04:03:56.715751:  
2025-07-10 04:03:56.716257: Epoch 544 
2025-07-10 04:03:56.716392: Current learning rate: 0.00493 
2025-07-10 04:04:43.080258: train_loss -0.423 
2025-07-10 04:04:43.080668: val_loss -0.433 
2025-07-10 04:04:43.080751: Pseudo dice [np.float32(0.6402)] 
2025-07-10 04:04:43.080861: Epoch time: 46.37 s 
2025-07-10 04:04:44.256440:  
2025-07-10 04:04:44.256798: Epoch 545 
2025-07-10 04:04:44.256927: Current learning rate: 0.00492 
2025-07-10 04:05:30.648816: train_loss -0.4422 
2025-07-10 04:05:30.649194: val_loss -0.4751 
2025-07-10 04:05:30.649289: Pseudo dice [np.float32(0.7581)] 
2025-07-10 04:05:30.649431: Epoch time: 46.39 s 
2025-07-10 04:05:31.797204:  
2025-07-10 04:05:31.797975: Epoch 546 
2025-07-10 04:05:31.798183: Current learning rate: 0.00491 
2025-07-10 04:06:17.405727: train_loss -0.4448 
2025-07-10 04:06:17.406181: val_loss -0.4468 
2025-07-10 04:06:17.409693: Pseudo dice [np.float32(0.7477)] 
2025-07-10 04:06:17.409828: Epoch time: 45.61 s 
2025-07-10 04:06:18.574194:  
2025-07-10 04:06:18.574501: Epoch 547 
2025-07-10 04:06:18.574653: Current learning rate: 0.0049 
2025-07-10 04:07:04.400925: train_loss -0.4518 
2025-07-10 04:07:04.401168: val_loss -0.4605 
2025-07-10 04:07:04.401237: Pseudo dice [np.float32(0.7273)] 
2025-07-10 04:07:04.401333: Epoch time: 45.83 s 
2025-07-10 04:07:05.523361:  
2025-07-10 04:07:05.524001: Epoch 548 
2025-07-10 04:07:05.524242: Current learning rate: 0.00489 
2025-07-10 04:07:51.443501: train_loss -0.4605 
2025-07-10 04:07:51.444023: val_loss -0.4366 
2025-07-10 04:07:51.444167: Pseudo dice [np.float32(0.686)] 
2025-07-10 04:07:51.444320: Epoch time: 45.92 s 
2025-07-10 04:07:52.688348:  
2025-07-10 04:07:52.688821: Epoch 549 
2025-07-10 04:07:52.689045: Current learning rate: 0.00488 
2025-07-10 04:08:39.290033: train_loss -0.449 
2025-07-10 04:08:39.290501: val_loss -0.4268 
2025-07-10 04:08:39.290660: Pseudo dice [np.float32(0.7194)] 
2025-07-10 04:08:39.290776: Epoch time: 46.6 s 
2025-07-10 04:08:41.432462:  
2025-07-10 04:08:41.432766: Epoch 550 
2025-07-10 04:08:41.432972: Current learning rate: 0.00487 
2025-07-10 04:09:26.520555: train_loss -0.4507 
2025-07-10 04:09:26.520928: val_loss -0.457 
2025-07-10 04:09:26.521125: Pseudo dice [np.float32(0.6777)] 
2025-07-10 04:09:26.521233: Epoch time: 45.09 s 
2025-07-10 04:09:28.324766:  
2025-07-10 04:09:28.324945: Epoch 551 
2025-07-10 04:09:28.325079: Current learning rate: 0.00486 
2025-07-10 04:10:14.620435: train_loss -0.462 
2025-07-10 04:10:14.621485: val_loss -0.4715 
2025-07-10 04:10:14.621629: Pseudo dice [np.float32(0.7398)] 
2025-07-10 04:10:14.621824: Epoch time: 46.3 s 
2025-07-10 04:10:15.842191:  
2025-07-10 04:10:15.842650: Epoch 552 
2025-07-10 04:10:15.842880: Current learning rate: 0.00485 
2025-07-10 04:11:02.242938: train_loss -0.469 
2025-07-10 04:11:02.243413: val_loss -0.4629 
2025-07-10 04:11:02.243506: Pseudo dice [np.float32(0.6971)] 
2025-07-10 04:11:02.243640: Epoch time: 46.4 s 
2025-07-10 04:11:03.449359:  
2025-07-10 04:11:03.449821: Epoch 553 
2025-07-10 04:11:03.450083: Current learning rate: 0.00484 
2025-07-10 04:11:50.299554: train_loss -0.4492 
2025-07-10 04:11:50.299987: val_loss -0.4141 
2025-07-10 04:11:50.300087: Pseudo dice [np.float32(0.6973)] 
2025-07-10 04:11:50.300214: Epoch time: 46.85 s 
2025-07-10 04:11:51.436068:  
2025-07-10 04:11:51.436396: Epoch 554 
2025-07-10 04:11:51.436527: Current learning rate: 0.00484 
2025-07-10 04:12:38.806431: train_loss -0.4359 
2025-07-10 04:12:38.807108: val_loss -0.441 
2025-07-10 04:12:38.807201: Pseudo dice [np.float32(0.709)] 
2025-07-10 04:12:38.807329: Epoch time: 47.37 s 
2025-07-10 04:12:40.007960:  
2025-07-10 04:12:40.008476: Epoch 555 
2025-07-10 04:12:40.008623: Current learning rate: 0.00483 
2025-07-10 04:13:25.640877: train_loss -0.4432 
2025-07-10 04:13:25.641335: val_loss -0.4438 
2025-07-10 04:13:25.641414: Pseudo dice [np.float32(0.6448)] 
2025-07-10 04:13:25.641520: Epoch time: 45.63 s 
2025-07-10 04:13:26.838586:  
2025-07-10 04:13:26.839009: Epoch 556 
2025-07-10 04:13:26.839225: Current learning rate: 0.00482 
2025-07-10 04:14:13.539045: train_loss -0.4208 
2025-07-10 04:14:13.539485: val_loss -0.4223 
2025-07-10 04:14:13.539570: Pseudo dice [np.float32(0.6373)] 
2025-07-10 04:14:13.539679: Epoch time: 46.7 s 
2025-07-10 04:14:14.706255:  
2025-07-10 04:14:14.706648: Epoch 557 
2025-07-10 04:14:14.706776: Current learning rate: 0.00481 
2025-07-10 04:15:00.749516: train_loss -0.4195 
2025-07-10 04:15:00.750872: val_loss -0.4198 
2025-07-10 04:15:00.750969: Pseudo dice [np.float32(0.6462)] 
2025-07-10 04:15:00.751106: Epoch time: 46.04 s 
2025-07-10 04:15:01.951391:  
2025-07-10 04:15:01.951722: Epoch 558 
2025-07-10 04:15:01.952037: Current learning rate: 0.0048 
2025-07-10 04:15:47.729601: train_loss -0.4364 
2025-07-10 04:15:47.730157: val_loss -0.4249 
2025-07-10 04:15:47.730234: Pseudo dice [np.float32(0.6358)] 
2025-07-10 04:15:47.730375: Epoch time: 45.78 s 
2025-07-10 04:15:48.915338:  
2025-07-10 04:15:48.915496: Epoch 559 
2025-07-10 04:15:48.915627: Current learning rate: 0.00479 
2025-07-10 04:16:34.854863: train_loss -0.4135 
2025-07-10 04:16:34.855990: val_loss -0.4455 
2025-07-10 04:16:34.856076: Pseudo dice [np.float32(0.7459)] 
2025-07-10 04:16:34.856225: Epoch time: 45.94 s 
2025-07-10 04:16:36.012305:  
2025-07-10 04:16:36.012513: Epoch 560 
2025-07-10 04:16:36.012624: Current learning rate: 0.00478 
2025-07-10 04:17:22.266578: train_loss -0.4238 
2025-07-10 04:17:22.267247: val_loss -0.4524 
2025-07-10 04:17:22.267325: Pseudo dice [np.float32(0.7095)] 
2025-07-10 04:17:22.267429: Epoch time: 46.26 s 
2025-07-10 04:17:23.403911:  
2025-07-10 04:17:23.404117: Epoch 561 
2025-07-10 04:17:23.404380: Current learning rate: 0.00477 
2025-07-10 04:18:09.412261: train_loss -0.447 
2025-07-10 04:18:09.413049: val_loss -0.4386 
2025-07-10 04:18:09.413148: Pseudo dice [np.float32(0.7033)] 
2025-07-10 04:18:09.413348: Epoch time: 46.01 s 
2025-07-10 04:18:11.042075:  
2025-07-10 04:18:11.042342: Epoch 562 
2025-07-10 04:18:11.042487: Current learning rate: 0.00476 
2025-07-10 04:18:56.652632: train_loss -0.4568 
2025-07-10 04:18:56.653162: val_loss -0.4421 
2025-07-10 04:18:56.653325: Pseudo dice [np.float32(0.6686)] 
2025-07-10 04:18:56.653473: Epoch time: 45.61 s 
2025-07-10 04:18:57.836833:  
2025-07-10 04:18:57.837338: Epoch 563 
2025-07-10 04:18:57.837469: Current learning rate: 0.00475 
2025-07-10 04:19:43.651098: train_loss -0.4426 
2025-07-10 04:19:43.651576: val_loss -0.4756 
2025-07-10 04:19:43.651657: Pseudo dice [np.float32(0.751)] 
2025-07-10 04:19:43.651771: Epoch time: 45.82 s 
2025-07-10 04:19:44.803811:  
2025-07-10 04:19:44.804005: Epoch 564 
2025-07-10 04:19:44.804126: Current learning rate: 0.00474 
2025-07-10 04:20:30.648934: train_loss -0.4505 
2025-07-10 04:20:30.649962: val_loss -0.4439 
2025-07-10 04:20:30.650067: Pseudo dice [np.float32(0.7342)] 
2025-07-10 04:20:30.650237: Epoch time: 45.85 s 
2025-07-10 04:20:31.882342:  
2025-07-10 04:20:31.882638: Epoch 565 
2025-07-10 04:20:31.882775: Current learning rate: 0.00473 
2025-07-10 04:21:17.504058: train_loss -0.4504 
2025-07-10 04:21:17.504755: val_loss -0.4552 
2025-07-10 04:21:17.504879: Pseudo dice [np.float32(0.6846)] 
2025-07-10 04:21:17.505019: Epoch time: 45.62 s 
2025-07-10 04:21:18.766040:  
2025-07-10 04:21:18.766592: Epoch 566 
2025-07-10 04:21:18.766797: Current learning rate: 0.00472 
2025-07-10 04:22:04.536088: train_loss -0.4683 
2025-07-10 04:22:04.536532: val_loss -0.4689 
2025-07-10 04:22:04.536665: Pseudo dice [np.float32(0.794)] 
2025-07-10 04:22:04.536774: Epoch time: 45.77 s 
2025-07-10 04:22:05.770223:  
2025-07-10 04:22:05.770610: Epoch 567 
2025-07-10 04:22:05.770730: Current learning rate: 0.00471 
2025-07-10 04:22:51.194588: train_loss -0.461 
2025-07-10 04:22:51.195110: val_loss -0.4499 
2025-07-10 04:22:51.195193: Pseudo dice [np.float32(0.6904)] 
2025-07-10 04:22:51.195283: Epoch time: 45.43 s 
2025-07-10 04:22:52.353997:  
2025-07-10 04:22:52.354242: Epoch 568 
2025-07-10 04:22:52.354373: Current learning rate: 0.0047 
2025-07-10 04:23:38.142946: train_loss -0.456 
2025-07-10 04:23:38.143227: val_loss -0.4297 
2025-07-10 04:23:38.143296: Pseudo dice [np.float32(0.7324)] 
2025-07-10 04:23:38.143393: Epoch time: 45.79 s 
2025-07-10 04:23:39.262634:  
2025-07-10 04:23:39.263155: Epoch 569 
2025-07-10 04:23:39.263288: Current learning rate: 0.00469 
2025-07-10 04:24:24.885911: train_loss -0.4422 
2025-07-10 04:24:24.886353: val_loss -0.4663 
2025-07-10 04:24:24.886429: Pseudo dice [np.float32(0.7432)] 
2025-07-10 04:24:24.886552: Epoch time: 45.62 s 
2025-07-10 04:24:26.076771:  
2025-07-10 04:24:26.077194: Epoch 570 
2025-07-10 04:24:26.077324: Current learning rate: 0.00468 
2025-07-10 04:25:12.221634: train_loss -0.4499 
2025-07-10 04:25:12.222064: val_loss -0.4546 
2025-07-10 04:25:12.222144: Pseudo dice [np.float32(0.6629)] 
2025-07-10 04:25:12.222259: Epoch time: 46.15 s 
2025-07-10 04:25:13.380388:  
2025-07-10 04:25:13.380730: Epoch 571 
2025-07-10 04:25:13.380962: Current learning rate: 0.00467 
2025-07-10 04:25:59.972236: train_loss -0.4579 
2025-07-10 04:25:59.972651: val_loss -0.4177 
2025-07-10 04:25:59.972793: Pseudo dice [np.float32(0.7507)] 
2025-07-10 04:25:59.972901: Epoch time: 46.59 s 
2025-07-10 04:26:01.121481:  
2025-07-10 04:26:01.122043: Epoch 572 
2025-07-10 04:26:01.122456: Current learning rate: 0.00466 
2025-07-10 04:26:47.657786: train_loss -0.4428 
2025-07-10 04:26:47.658355: val_loss -0.4659 
2025-07-10 04:26:47.658461: Pseudo dice [np.float32(0.7393)] 
2025-07-10 04:26:47.658613: Epoch time: 46.54 s 
2025-07-10 04:26:48.947855:  
2025-07-10 04:26:48.948231: Epoch 573 
2025-07-10 04:26:48.948419: Current learning rate: 0.00465 
2025-07-10 04:27:34.874720: train_loss -0.456 
2025-07-10 04:27:34.875070: val_loss -0.4638 
2025-07-10 04:27:34.875184: Pseudo dice [np.float32(0.7636)] 
2025-07-10 04:27:34.875326: Epoch time: 45.93 s 
2025-07-10 04:27:36.688291:  
2025-07-10 04:27:36.688586: Epoch 574 
2025-07-10 04:27:36.688713: Current learning rate: 0.00464 
2025-07-10 04:28:22.609382: train_loss -0.4107 
2025-07-10 04:28:22.609934: val_loss -0.3889 
2025-07-10 04:28:22.610015: Pseudo dice [np.float32(0.6095)] 
2025-07-10 04:28:22.610126: Epoch time: 45.92 s 
2025-07-10 04:28:23.759801:  
2025-07-10 04:28:23.760107: Epoch 575 
2025-07-10 04:28:23.760390: Current learning rate: 0.00463 
2025-07-10 04:29:10.025843: train_loss -0.4201 
2025-07-10 04:29:10.026197: val_loss -0.4585 
2025-07-10 04:29:10.026281: Pseudo dice [np.float32(0.6699)] 
2025-07-10 04:29:10.026411: Epoch time: 46.27 s 
2025-07-10 04:29:11.161187:  
2025-07-10 04:29:11.161376: Epoch 576 
2025-07-10 04:29:11.161570: Current learning rate: 0.00462 
2025-07-10 04:29:57.919039: train_loss -0.4592 
2025-07-10 04:29:57.919746: val_loss -0.4652 
2025-07-10 04:29:57.919855: Pseudo dice [np.float32(0.7704)] 
2025-07-10 04:29:57.920006: Epoch time: 46.76 s 
2025-07-10 04:29:59.092353:  
2025-07-10 04:29:59.092860: Epoch 577 
2025-07-10 04:29:59.093105: Current learning rate: 0.00461 
2025-07-10 04:30:45.431991: train_loss -0.4621 
2025-07-10 04:30:45.432359: val_loss -0.4546 
2025-07-10 04:30:45.432430: Pseudo dice [np.float32(0.7875)] 
2025-07-10 04:30:45.432533: Epoch time: 46.34 s 
2025-07-10 04:30:46.569458:  
2025-07-10 04:30:46.569849: Epoch 578 
2025-07-10 04:30:46.570090: Current learning rate: 0.0046 
2025-07-10 04:31:33.045216: train_loss -0.4485 
2025-07-10 04:31:33.045591: val_loss -0.4654 
2025-07-10 04:31:33.045667: Pseudo dice [np.float32(0.7182)] 
2025-07-10 04:31:33.045764: Epoch time: 46.48 s 
2025-07-10 04:31:34.258420:  
2025-07-10 04:31:34.258740: Epoch 579 
2025-07-10 04:31:34.258847: Current learning rate: 0.00459 
2025-07-10 04:32:21.069769: train_loss -0.4642 
2025-07-10 04:32:21.070369: val_loss -0.4809 
2025-07-10 04:32:21.070493: Pseudo dice [np.float32(0.794)] 
2025-07-10 04:32:21.070639: Epoch time: 46.81 s 
2025-07-10 04:32:22.266892:  
2025-07-10 04:32:22.267217: Epoch 580 
2025-07-10 04:32:22.267368: Current learning rate: 0.00458 
2025-07-10 04:33:09.134554: train_loss -0.4561 
2025-07-10 04:33:09.134964: val_loss -0.4514 
2025-07-10 04:33:09.135036: Pseudo dice [np.float32(0.6733)] 
2025-07-10 04:33:09.135131: Epoch time: 46.87 s 
2025-07-10 04:33:10.275659:  
2025-07-10 04:33:10.276124: Epoch 581 
2025-07-10 04:33:10.276260: Current learning rate: 0.00457 
2025-07-10 04:33:56.872640: train_loss -0.4341 
2025-07-10 04:33:56.873010: val_loss -0.4256 
2025-07-10 04:33:56.873089: Pseudo dice [np.float32(0.6912)] 
2025-07-10 04:33:56.873183: Epoch time: 46.6 s 
2025-07-10 04:33:58.008577:  
2025-07-10 04:33:58.008724: Epoch 582 
2025-07-10 04:33:58.008849: Current learning rate: 0.00456 
2025-07-10 04:34:45.199706: train_loss -0.4455 
2025-07-10 04:34:45.200253: val_loss -0.4545 
2025-07-10 04:34:45.200335: Pseudo dice [np.float32(0.6598)] 
2025-07-10 04:34:45.200443: Epoch time: 47.19 s 
2025-07-10 04:34:46.385960:  
2025-07-10 04:34:46.386156: Epoch 583 
2025-07-10 04:34:46.386282: Current learning rate: 0.00455 
2025-07-10 04:35:32.533782: train_loss -0.4474 
2025-07-10 04:35:32.534234: val_loss -0.4384 
2025-07-10 04:35:32.534317: Pseudo dice [np.float32(0.7358)] 
2025-07-10 04:35:32.534452: Epoch time: 46.15 s 
2025-07-10 04:35:33.705575:  
2025-07-10 04:35:33.705843: Epoch 584 
2025-07-10 04:35:33.705976: Current learning rate: 0.00454 
2025-07-10 04:36:22.070876: train_loss -0.4178 
2025-07-10 04:36:22.071371: val_loss -0.4422 
2025-07-10 04:36:22.071455: Pseudo dice [np.float32(0.6599)] 
2025-07-10 04:36:22.071589: Epoch time: 48.37 s 
2025-07-10 04:36:23.378067:  
2025-07-10 04:36:23.378335: Epoch 585 
2025-07-10 04:36:23.378495: Current learning rate: 0.00453 
2025-07-10 04:37:11.036563: train_loss -0.4344 
2025-07-10 04:37:11.036981: val_loss -0.4516 
2025-07-10 04:37:11.037056: Pseudo dice [np.float32(0.7383)] 
2025-07-10 04:37:11.037185: Epoch time: 47.66 s 
2025-07-10 04:37:12.713349:  
2025-07-10 04:37:12.713893: Epoch 586 
2025-07-10 04:37:12.714091: Current learning rate: 0.00452 
2025-07-10 04:38:00.278077: train_loss -0.4479 
2025-07-10 04:38:00.278688: val_loss -0.4558 
2025-07-10 04:38:00.278786: Pseudo dice [np.float32(0.6643)] 
2025-07-10 04:38:00.278892: Epoch time: 47.57 s 
2025-07-10 04:38:01.471139:  
2025-07-10 04:38:01.471570: Epoch 587 
2025-07-10 04:38:01.471796: Current learning rate: 0.00451 
2025-07-10 04:38:49.661329: train_loss -0.4269 
2025-07-10 04:38:49.662051: val_loss -0.4371 
2025-07-10 04:38:49.662149: Pseudo dice [np.float32(0.7188)] 
2025-07-10 04:38:49.662277: Epoch time: 48.19 s 
2025-07-10 04:38:50.835859:  
2025-07-10 04:38:50.836390: Epoch 588 
2025-07-10 04:38:50.836580: Current learning rate: 0.0045 
2025-07-10 04:39:39.922720: train_loss -0.3579 
2025-07-10 04:39:39.923163: val_loss -0.4273 
2025-07-10 04:39:39.923286: Pseudo dice [np.float32(0.739)] 
2025-07-10 04:39:39.923383: Epoch time: 49.09 s 
2025-07-10 04:39:41.067956:  
2025-07-10 04:39:41.068388: Epoch 589 
2025-07-10 04:39:41.068510: Current learning rate: 0.00449 
2025-07-10 04:40:30.039238: train_loss -0.434 
2025-07-10 04:40:30.039867: val_loss -0.4493 
2025-07-10 04:40:30.039959: Pseudo dice [np.float32(0.7215)] 
2025-07-10 04:40:30.040086: Epoch time: 48.97 s 
2025-07-10 04:40:31.287050:  
2025-07-10 04:40:31.287689: Epoch 590 
2025-07-10 04:40:31.287936: Current learning rate: 0.00448 
2025-07-10 04:41:18.533858: train_loss -0.4195 
2025-07-10 04:41:18.534508: val_loss -0.4289 
2025-07-10 04:41:18.534628: Pseudo dice [np.float32(0.6294)] 
2025-07-10 04:41:18.534777: Epoch time: 47.25 s 
2025-07-10 04:41:19.708583:  
2025-07-10 04:41:19.708867: Epoch 591 
2025-07-10 04:41:19.709003: Current learning rate: 0.00447 
2025-07-10 04:42:08.041575: train_loss -0.4361 
2025-07-10 04:42:08.041909: val_loss -0.4571 
2025-07-10 04:42:08.041993: Pseudo dice [np.float32(0.6879)] 
2025-07-10 04:42:08.042106: Epoch time: 48.33 s 
2025-07-10 04:42:09.225057:  
2025-07-10 04:42:09.225405: Epoch 592 
2025-07-10 04:42:09.225559: Current learning rate: 0.00446 
2025-07-10 04:42:56.944335: train_loss -0.4498 
2025-07-10 04:42:56.944910: val_loss -0.4319 
2025-07-10 04:42:56.944991: Pseudo dice [np.float32(0.6552)] 
2025-07-10 04:42:56.945108: Epoch time: 47.72 s 
2025-07-10 04:42:58.165179:  
2025-07-10 04:42:58.165795: Epoch 593 
2025-07-10 04:42:58.165926: Current learning rate: 0.00445 
2025-07-10 04:43:44.954084: train_loss -0.4274 
2025-07-10 04:43:44.955042: val_loss -0.4169 
2025-07-10 04:43:44.955180: Pseudo dice [np.float32(0.5028)] 
2025-07-10 04:43:44.955332: Epoch time: 46.79 s 
2025-07-10 04:43:46.135293:  
2025-07-10 04:43:46.135768: Epoch 594 
2025-07-10 04:43:46.135900: Current learning rate: 0.00444 
2025-07-10 04:44:32.505764: train_loss -0.4384 
2025-07-10 04:44:32.506596: val_loss -0.419 
2025-07-10 04:44:32.506703: Pseudo dice [np.float32(0.6585)] 
2025-07-10 04:44:32.506839: Epoch time: 46.37 s 
2025-07-10 04:44:33.689381:  
2025-07-10 04:44:33.689558: Epoch 595 
2025-07-10 04:44:33.689764: Current learning rate: 0.00443 
2025-07-10 04:45:19.745518: train_loss -0.4584 
2025-07-10 04:45:19.745986: val_loss -0.4927 
2025-07-10 04:45:19.746063: Pseudo dice [np.float32(0.7985)] 
2025-07-10 04:45:19.746169: Epoch time: 46.06 s 
2025-07-10 04:45:20.938636:  
2025-07-10 04:45:20.939301: Epoch 596 
2025-07-10 04:45:20.939429: Current learning rate: 0.00442 
2025-07-10 04:46:07.017585: train_loss -0.4575 
2025-07-10 04:46:07.018069: val_loss -0.4718 
2025-07-10 04:46:07.018149: Pseudo dice [np.float32(0.7448)] 
2025-07-10 04:46:07.018244: Epoch time: 46.08 s 
2025-07-10 04:46:08.826721:  
2025-07-10 04:46:08.827078: Epoch 597 
2025-07-10 04:46:08.827274: Current learning rate: 0.00441 
2025-07-10 04:46:55.182523: train_loss -0.4369 
2025-07-10 04:46:55.183065: val_loss -0.4651 
2025-07-10 04:46:55.183177: Pseudo dice [np.float32(0.7504)] 
2025-07-10 04:46:55.183300: Epoch time: 46.36 s 
2025-07-10 04:46:56.330630:  
2025-07-10 04:46:56.330952: Epoch 598 
2025-07-10 04:46:56.331141: Current learning rate: 0.0044 
2025-07-10 04:47:42.604396: train_loss -0.4424 
2025-07-10 04:47:42.604765: val_loss -0.4222 
2025-07-10 04:47:42.604842: Pseudo dice [np.float32(0.6765)] 
2025-07-10 04:47:42.605028: Epoch time: 46.27 s 
2025-07-10 04:47:43.742167:  
2025-07-10 04:47:43.742486: Epoch 599 
2025-07-10 04:47:43.742739: Current learning rate: 0.00439 
2025-07-10 04:48:31.105930: train_loss -0.4455 
2025-07-10 04:48:31.106816: val_loss -0.4548 
2025-07-10 04:48:31.106951: Pseudo dice [np.float32(0.7419)] 
2025-07-10 04:48:31.107051: Epoch time: 47.36 s 
2025-07-10 04:48:33.308977:  
2025-07-10 04:48:33.309411: Epoch 600 
2025-07-10 04:48:33.309547: Current learning rate: 0.00438 
2025-07-10 04:49:20.067467: train_loss -0.4546 
2025-07-10 04:49:20.068125: val_loss -0.4657 
2025-07-10 04:49:20.068200: Pseudo dice [np.float32(0.7693)] 
2025-07-10 04:49:20.068316: Epoch time: 46.76 s 
2025-07-10 04:49:21.216414:  
2025-07-10 04:49:21.216643: Epoch 601 
2025-07-10 04:49:21.216798: Current learning rate: 0.00437 
2025-07-10 04:50:08.317233: train_loss -0.4244 
2025-07-10 04:50:08.317775: val_loss -0.3428 
2025-07-10 04:50:08.317861: Pseudo dice [np.float32(0.5218)] 
2025-07-10 04:50:08.317971: Epoch time: 47.1 s 
2025-07-10 04:50:09.461776:  
2025-07-10 04:50:09.462210: Epoch 602 
2025-07-10 04:50:09.462344: Current learning rate: 0.00436 
2025-07-10 04:50:56.028498: train_loss -0.3823 
2025-07-10 04:50:56.029277: val_loss -0.3877 
2025-07-10 04:50:56.029389: Pseudo dice [np.float32(0.6536)] 
2025-07-10 04:50:56.029520: Epoch time: 46.57 s 
2025-07-10 04:50:57.228316:  
2025-07-10 04:50:57.228742: Epoch 603 
2025-07-10 04:50:57.228935: Current learning rate: 0.00435 
2025-07-10 04:51:43.891510: train_loss -0.416 
2025-07-10 04:51:43.892518: val_loss -0.4576 
2025-07-10 04:51:43.892652: Pseudo dice [np.float32(0.755)] 
2025-07-10 04:51:43.892900: Epoch time: 46.66 s 
2025-07-10 04:51:45.092649:  
2025-07-10 04:51:45.092916: Epoch 604 
2025-07-10 04:51:45.093086: Current learning rate: 0.00434 
2025-07-10 04:52:32.136575: train_loss -0.4242 
2025-07-10 04:52:32.136948: val_loss -0.4319 
2025-07-10 04:52:32.137023: Pseudo dice [np.float32(0.7011)] 
2025-07-10 04:52:32.137134: Epoch time: 47.04 s 
2025-07-10 04:52:33.294652:  
2025-07-10 04:52:33.295012: Epoch 605 
2025-07-10 04:52:33.295149: Current learning rate: 0.00433 
2025-07-10 04:53:19.980321: train_loss -0.4476 
2025-07-10 04:53:19.980780: val_loss -0.4777 
2025-07-10 04:53:19.980865: Pseudo dice [np.float32(0.7043)] 
2025-07-10 04:53:19.981088: Epoch time: 46.69 s 
2025-07-10 04:53:21.318579:  
2025-07-10 04:53:21.318978: Epoch 606 
2025-07-10 04:53:21.319102: Current learning rate: 0.00432 
2025-07-10 04:54:07.547304: train_loss -0.454 
2025-07-10 04:54:07.548086: val_loss -0.4322 
2025-07-10 04:54:07.548237: Pseudo dice [np.float32(0.6564)] 
2025-07-10 04:54:07.548390: Epoch time: 46.23 s 
2025-07-10 04:54:08.818338:  
2025-07-10 04:54:08.819073: Epoch 607 
2025-07-10 04:54:08.819373: Current learning rate: 0.00431 
2025-07-10 04:54:55.810819: train_loss -0.4295 
2025-07-10 04:54:55.811243: val_loss -0.4267 
2025-07-10 04:54:55.811323: Pseudo dice [np.float32(0.6553)] 
2025-07-10 04:54:55.811431: Epoch time: 46.99 s 
2025-07-10 04:54:56.967269:  
2025-07-10 04:54:56.967447: Epoch 608 
2025-07-10 04:54:56.967609: Current learning rate: 0.0043 
2025-07-10 04:55:43.285975: train_loss -0.4543 
2025-07-10 04:55:43.286438: val_loss -0.455 
2025-07-10 04:55:43.286606: Pseudo dice [np.float32(0.7517)] 
2025-07-10 04:55:43.286731: Epoch time: 46.32 s 
2025-07-10 04:55:44.972693:  
2025-07-10 04:55:44.972880: Epoch 609 
2025-07-10 04:55:44.973112: Current learning rate: 0.00429 
2025-07-10 04:56:31.434936: train_loss -0.4604 
2025-07-10 04:56:31.435860: val_loss -0.4757 
2025-07-10 04:56:31.436005: Pseudo dice [np.float32(0.774)] 
2025-07-10 04:56:31.436205: Epoch time: 46.46 s 
2025-07-10 04:56:32.691962:  
2025-07-10 04:56:32.692481: Epoch 610 
2025-07-10 04:56:32.692600: Current learning rate: 0.00429 
2025-07-10 04:57:19.327385: train_loss -0.4663 
2025-07-10 04:57:19.327946: val_loss -0.4558 
2025-07-10 04:57:19.328036: Pseudo dice [np.float32(0.7873)] 
2025-07-10 04:57:19.328150: Epoch time: 46.64 s 
2025-07-10 04:57:20.518579:  
2025-07-10 04:57:20.518772: Epoch 611 
2025-07-10 04:57:20.518903: Current learning rate: 0.00428 
2025-07-10 04:58:06.864964: train_loss -0.465 
2025-07-10 04:58:06.865386: val_loss -0.4861 
2025-07-10 04:58:06.865459: Pseudo dice [np.float32(0.7754)] 
2025-07-10 04:58:06.865574: Epoch time: 46.35 s 
2025-07-10 04:58:08.036580:  
2025-07-10 04:58:08.036876: Epoch 612 
2025-07-10 04:58:08.036999: Current learning rate: 0.00427 
2025-07-10 04:58:53.828082: train_loss -0.4479 
2025-07-10 04:58:53.828430: val_loss -0.444 
2025-07-10 04:58:53.828507: Pseudo dice [np.float32(0.7354)] 
2025-07-10 04:58:53.828620: Epoch time: 45.79 s 
2025-07-10 04:58:54.982813:  
2025-07-10 04:58:54.983158: Epoch 613 
2025-07-10 04:58:54.983403: Current learning rate: 0.00426 
2025-07-10 04:59:40.192138: train_loss -0.4526 
2025-07-10 04:59:40.192439: val_loss -0.4408 
2025-07-10 04:59:40.192512: Pseudo dice [np.float32(0.7225)] 
2025-07-10 04:59:40.192614: Epoch time: 45.21 s 
2025-07-10 04:59:41.377797:  
2025-07-10 04:59:41.378193: Epoch 614 
2025-07-10 04:59:41.378446: Current learning rate: 0.00425 
2025-07-10 05:00:28.142783: train_loss -0.4101 
2025-07-10 05:00:28.143330: val_loss -0.4167 
2025-07-10 05:00:28.143406: Pseudo dice [np.float32(0.6192)] 
2025-07-10 05:00:28.143525: Epoch time: 46.77 s 
2025-07-10 05:00:29.345812:  
2025-07-10 05:00:29.345997: Epoch 615 
2025-07-10 05:00:29.346120: Current learning rate: 0.00424 
2025-07-10 05:01:16.273066: train_loss -0.4446 
2025-07-10 05:01:16.273556: val_loss -0.4621 
2025-07-10 05:01:16.273636: Pseudo dice [np.float32(0.7419)] 
2025-07-10 05:01:16.273741: Epoch time: 46.93 s 
2025-07-10 05:01:17.430520:  
2025-07-10 05:01:17.430939: Epoch 616 
2025-07-10 05:01:17.431149: Current learning rate: 0.00423 
2025-07-10 05:02:03.426468: train_loss -0.4575 
2025-07-10 05:02:03.426973: val_loss -0.4593 
2025-07-10 05:02:03.427057: Pseudo dice [np.float32(0.7523)] 
2025-07-10 05:02:03.427175: Epoch time: 46.0 s 
2025-07-10 05:02:04.713091:  
2025-07-10 05:02:04.713215: Epoch 617 
2025-07-10 05:02:04.713311: Current learning rate: 0.00422 
2025-07-10 05:02:51.112285: train_loss -0.4453 
2025-07-10 05:02:51.112617: val_loss -0.4492 
2025-07-10 05:02:51.112704: Pseudo dice [np.float32(0.6959)] 
2025-07-10 05:02:51.112815: Epoch time: 46.4 s 
2025-07-10 05:02:52.329189:  
2025-07-10 05:02:52.329695: Epoch 618 
2025-07-10 05:02:52.329879: Current learning rate: 0.00421 
2025-07-10 05:03:38.175302: train_loss -0.4484 
2025-07-10 05:03:38.176010: val_loss -0.455 
2025-07-10 05:03:38.176094: Pseudo dice [np.float32(0.6872)] 
2025-07-10 05:03:38.176222: Epoch time: 45.85 s 
2025-07-10 05:03:39.412659:  
2025-07-10 05:03:39.412937: Epoch 619 
2025-07-10 05:03:39.413062: Current learning rate: 0.0042 
2025-07-10 05:04:25.627059: train_loss -0.46 
2025-07-10 05:04:25.627433: val_loss -0.4688 
2025-07-10 05:04:25.627511: Pseudo dice [np.float32(0.7331)] 
2025-07-10 05:04:25.627635: Epoch time: 46.22 s 
2025-07-10 05:04:27.424177:  
2025-07-10 05:04:27.424717: Epoch 620 
2025-07-10 05:04:27.424887: Current learning rate: 0.00419 
2025-07-10 05:05:13.824615: train_loss -0.4572 
2025-07-10 05:05:13.825096: val_loss -0.4434 
2025-07-10 05:05:13.825246: Pseudo dice [np.float32(0.7675)] 
2025-07-10 05:05:13.825428: Epoch time: 46.4 s 
2025-07-10 05:05:15.018683:  
2025-07-10 05:05:15.018860: Epoch 621 
2025-07-10 05:05:15.018956: Current learning rate: 0.00418 
2025-07-10 05:06:01.785766: train_loss -0.4623 
2025-07-10 05:06:01.786299: val_loss -0.4623 
2025-07-10 05:06:01.786380: Pseudo dice [np.float32(0.7092)] 
2025-07-10 05:06:01.786484: Epoch time: 46.77 s 
2025-07-10 05:06:02.973832:  
2025-07-10 05:06:02.974018: Epoch 622 
2025-07-10 05:06:02.974300: Current learning rate: 0.00417 
2025-07-10 05:06:49.080851: train_loss -0.4584 
2025-07-10 05:06:49.081316: val_loss -0.4605 
2025-07-10 05:06:49.081391: Pseudo dice [np.float32(0.7432)] 
2025-07-10 05:06:49.081504: Epoch time: 46.11 s 
2025-07-10 05:06:50.206533:  
2025-07-10 05:06:50.207135: Epoch 623 
2025-07-10 05:06:50.207256: Current learning rate: 0.00416 
2025-07-10 05:07:37.101853: train_loss -0.4559 
2025-07-10 05:07:37.102297: val_loss -0.4237 
2025-07-10 05:07:37.102380: Pseudo dice [np.float32(0.6959)] 
2025-07-10 05:07:37.102487: Epoch time: 46.9 s 
2025-07-10 05:07:38.343701:  
2025-07-10 05:07:38.343863: Epoch 624 
2025-07-10 05:07:38.344038: Current learning rate: 0.00415 
2025-07-10 05:08:25.131286: train_loss -0.4416 
2025-07-10 05:08:25.132012: val_loss -0.4164 
2025-07-10 05:08:25.132125: Pseudo dice [np.float32(0.6581)] 
2025-07-10 05:08:25.132276: Epoch time: 46.79 s 
2025-07-10 05:08:26.355552:  
2025-07-10 05:08:26.355850: Epoch 625 
2025-07-10 05:08:26.356243: Current learning rate: 0.00414 
2025-07-10 05:09:13.317769: train_loss -0.4428 
2025-07-10 05:09:13.318243: val_loss -0.4408 
2025-07-10 05:09:13.318322: Pseudo dice [np.float32(0.7112)] 
2025-07-10 05:09:13.318441: Epoch time: 46.96 s 
2025-07-10 05:09:14.561137:  
2025-07-10 05:09:14.561459: Epoch 626 
2025-07-10 05:09:14.561661: Current learning rate: 0.00413 
2025-07-10 05:10:00.379560: train_loss -0.4584 
2025-07-10 05:10:00.380068: val_loss -0.3804 
2025-07-10 05:10:00.380152: Pseudo dice [np.float32(0.3832)] 
2025-07-10 05:10:00.380266: Epoch time: 45.82 s 
2025-07-10 05:10:01.636781:  
2025-07-10 05:10:01.637814: Epoch 627 
2025-07-10 05:10:01.638400: Current learning rate: 0.00412 
2025-07-10 05:10:47.675782: train_loss -0.3986 
2025-07-10 05:10:47.676504: val_loss -0.4057 
2025-07-10 05:10:47.676625: Pseudo dice [np.float32(0.682)] 
2025-07-10 05:10:47.676767: Epoch time: 46.04 s 
2025-07-10 05:10:48.898155:  
2025-07-10 05:10:48.898603: Epoch 628 
2025-07-10 05:10:48.898746: Current learning rate: 0.00411 
2025-07-10 05:11:34.959176: train_loss -0.4345 
2025-07-10 05:11:34.960232: val_loss -0.4427 
2025-07-10 05:11:34.960442: Pseudo dice [np.float32(0.6809)] 
2025-07-10 05:11:34.960921: Epoch time: 46.06 s 
2025-07-10 05:11:36.193942:  
2025-07-10 05:11:36.194267: Epoch 629 
2025-07-10 05:11:36.194395: Current learning rate: 0.0041 
2025-07-10 05:12:22.212237: train_loss -0.4249 
2025-07-10 05:12:22.212678: val_loss -0.3994 
2025-07-10 05:12:22.212771: Pseudo dice [np.float32(0.5828)] 
2025-07-10 05:12:22.212873: Epoch time: 46.02 s 
2025-07-10 05:12:23.351152:  
2025-07-10 05:12:23.351342: Epoch 630 
2025-07-10 05:12:23.351478: Current learning rate: 0.00409 
2025-07-10 05:13:08.974823: train_loss -0.4283 
2025-07-10 05:13:08.975846: val_loss -0.3958 
2025-07-10 05:13:08.976110: Pseudo dice [np.float32(0.5943)] 
2025-07-10 05:13:08.976393: Epoch time: 45.62 s 
2025-07-10 05:13:10.626815:  
2025-07-10 05:13:10.627062: Epoch 631 
2025-07-10 05:13:10.627164: Current learning rate: 0.00408 
2025-07-10 05:13:56.326591: train_loss -0.4469 
2025-07-10 05:13:56.327122: val_loss -0.4443 
2025-07-10 05:13:56.327214: Pseudo dice [np.float32(0.7283)] 
2025-07-10 05:13:56.327346: Epoch time: 45.7 s 
2025-07-10 05:13:57.548144:  
2025-07-10 05:13:57.548470: Epoch 632 
2025-07-10 05:13:57.548732: Current learning rate: 0.00407 
2025-07-10 05:14:43.796930: train_loss -0.4344 
2025-07-10 05:14:43.797918: val_loss -0.3932 
2025-07-10 05:14:43.798000: Pseudo dice [np.float32(0.6219)] 
2025-07-10 05:14:43.798192: Epoch time: 46.25 s 
2025-07-10 05:14:44.985753:  
2025-07-10 05:14:44.986107: Epoch 633 
2025-07-10 05:14:44.986228: Current learning rate: 0.00406 
2025-07-10 05:15:30.989272: train_loss -0.4279 
2025-07-10 05:15:30.989944: val_loss -0.4513 
2025-07-10 05:15:30.990051: Pseudo dice [np.float32(0.6944)] 
2025-07-10 05:15:30.990190: Epoch time: 46.0 s 
2025-07-10 05:15:32.244026:  
2025-07-10 05:15:32.244581: Epoch 634 
2025-07-10 05:15:32.244763: Current learning rate: 0.00405 
2025-07-10 05:16:18.037290: train_loss -0.4558 
2025-07-10 05:16:18.037841: val_loss -0.473 
2025-07-10 05:16:18.037918: Pseudo dice [np.float32(0.7462)] 
2025-07-10 05:16:18.038016: Epoch time: 45.79 s 
2025-07-10 05:16:19.198524:  
2025-07-10 05:16:19.199180: Epoch 635 
2025-07-10 05:16:19.199341: Current learning rate: 0.00404 
2025-07-10 05:17:05.006288: train_loss -0.4656 
2025-07-10 05:17:05.006624: val_loss -0.4547 
2025-07-10 05:17:05.006707: Pseudo dice [np.float32(0.7606)] 
2025-07-10 05:17:05.006827: Epoch time: 45.81 s 
2025-07-10 05:17:06.146700:  
2025-07-10 05:17:06.147081: Epoch 636 
2025-07-10 05:17:06.147207: Current learning rate: 0.00403 
2025-07-10 05:17:52.536844: train_loss -0.4558 
2025-07-10 05:17:52.537714: val_loss -0.4679 
2025-07-10 05:17:52.537832: Pseudo dice [np.float32(0.7113)] 
2025-07-10 05:17:52.538001: Epoch time: 46.39 s 
2025-07-10 05:17:53.737265:  
2025-07-10 05:17:53.737681: Epoch 637 
2025-07-10 05:17:53.737813: Current learning rate: 0.00402 
2025-07-10 05:18:39.939682: train_loss -0.4668 
2025-07-10 05:18:39.940091: val_loss -0.4681 
2025-07-10 05:18:39.940169: Pseudo dice [np.float32(0.7849)] 
2025-07-10 05:18:39.940283: Epoch time: 46.2 s 
2025-07-10 05:18:41.086959:  
2025-07-10 05:18:41.087289: Epoch 638 
2025-07-10 05:18:41.087577: Current learning rate: 0.00401 
2025-07-10 05:19:27.191981: train_loss -0.4473 
2025-07-10 05:19:27.193204: val_loss -0.3951 
2025-07-10 05:19:27.193467: Pseudo dice [np.float32(0.6631)] 
2025-07-10 05:19:27.193741: Epoch time: 46.11 s 
2025-07-10 05:19:28.552516:  
2025-07-10 05:19:28.552910: Epoch 639 
2025-07-10 05:19:28.553201: Current learning rate: 0.004 
2025-07-10 05:20:14.244607: train_loss -0.4284 
2025-07-10 05:20:14.245050: val_loss -0.4058 
2025-07-10 05:20:14.245142: Pseudo dice [np.float32(0.6642)] 
2025-07-10 05:20:14.245271: Epoch time: 45.69 s 
2025-07-10 05:20:15.487889:  
2025-07-10 05:20:15.488394: Epoch 640 
2025-07-10 05:20:15.488670: Current learning rate: 0.00399 
2025-07-10 05:21:01.331789: train_loss -0.4349 
2025-07-10 05:21:01.332369: val_loss -0.4185 
2025-07-10 05:21:01.332469: Pseudo dice [np.float32(0.6065)] 
2025-07-10 05:21:01.332625: Epoch time: 45.84 s 
2025-07-10 05:21:02.587902:  
2025-07-10 05:21:02.588160: Epoch 641 
2025-07-10 05:21:02.588285: Current learning rate: 0.00398 
2025-07-10 05:21:49.714911: train_loss -0.4532 
2025-07-10 05:21:49.715470: val_loss -0.466 
2025-07-10 05:21:49.715577: Pseudo dice [np.float32(0.7235)] 
2025-07-10 05:21:49.715725: Epoch time: 47.13 s 
2025-07-10 05:21:50.924982:  
2025-07-10 05:21:50.925355: Epoch 642 
2025-07-10 05:21:50.925524: Current learning rate: 0.00397 
2025-07-10 05:22:37.158719: train_loss -0.4618 
2025-07-10 05:22:37.159101: val_loss -0.4645 
2025-07-10 05:22:37.159181: Pseudo dice [np.float32(0.8054)] 
2025-07-10 05:22:37.159306: Epoch time: 46.23 s 
2025-07-10 05:22:39.009424:  
2025-07-10 05:22:39.009846: Epoch 643 
2025-07-10 05:22:39.010081: Current learning rate: 0.00396 
2025-07-10 05:23:24.424110: train_loss -0.4522 
2025-07-10 05:23:24.424627: val_loss -0.4307 
2025-07-10 05:23:24.424725: Pseudo dice [np.float32(0.6157)] 
2025-07-10 05:23:24.424907: Epoch time: 45.42 s 
2025-07-10 05:23:25.663122:  
2025-07-10 05:23:25.663805: Epoch 644 
2025-07-10 05:23:25.663980: Current learning rate: 0.00395 
2025-07-10 05:24:12.384304: train_loss -0.4601 
2025-07-10 05:24:12.384863: val_loss -0.4733 
2025-07-10 05:24:12.384969: Pseudo dice [np.float32(0.7314)] 
2025-07-10 05:24:12.385229: Epoch time: 46.72 s 
2025-07-10 05:24:13.585442:  
2025-07-10 05:24:13.586251: Epoch 645 
2025-07-10 05:24:13.586616: Current learning rate: 0.00394 
2025-07-10 05:25:00.351346: train_loss -0.4478 
2025-07-10 05:25:00.351977: val_loss -0.4595 
2025-07-10 05:25:00.352060: Pseudo dice [np.float32(0.7561)] 
2025-07-10 05:25:00.352181: Epoch time: 46.77 s 
2025-07-10 05:25:01.532148:  
2025-07-10 05:25:01.532615: Epoch 646 
2025-07-10 05:25:01.532860: Current learning rate: 0.00393 
2025-07-10 05:25:47.576268: train_loss -0.4607 
2025-07-10 05:25:47.576788: val_loss -0.4387 
2025-07-10 05:25:47.576866: Pseudo dice [np.float32(0.7175)] 
2025-07-10 05:25:47.576971: Epoch time: 46.05 s 
2025-07-10 05:25:48.763441:  
2025-07-10 05:25:48.763705: Epoch 647 
2025-07-10 05:25:48.763881: Current learning rate: 0.00392 
2025-07-10 05:26:34.886518: train_loss -0.4605 
2025-07-10 05:26:34.886998: val_loss -0.4651 
2025-07-10 05:26:34.887087: Pseudo dice [np.float32(0.7504)] 
2025-07-10 05:26:34.887203: Epoch time: 46.12 s 
2025-07-10 05:26:36.081749:  
2025-07-10 05:26:36.082214: Epoch 648 
2025-07-10 05:26:36.082352: Current learning rate: 0.00391 
2025-07-10 05:27:22.011257: train_loss -0.4617 
2025-07-10 05:27:22.012032: val_loss -0.4713 
2025-07-10 05:27:22.012120: Pseudo dice [np.float32(0.7799)] 
2025-07-10 05:27:22.012286: Epoch time: 45.93 s 
2025-07-10 05:27:23.141339:  
2025-07-10 05:27:23.141834: Epoch 649 
2025-07-10 05:27:23.142089: Current learning rate: 0.0039 
2025-07-10 05:28:09.318631: train_loss -0.4576 
2025-07-10 05:28:09.319127: val_loss -0.4644 
2025-07-10 05:28:09.319201: Pseudo dice [np.float32(0.7241)] 
2025-07-10 05:28:09.319305: Epoch time: 46.18 s 
2025-07-10 05:28:11.507656:  
2025-07-10 05:28:11.508012: Epoch 650 
2025-07-10 05:28:11.508213: Current learning rate: 0.00389 
2025-07-10 05:28:57.650360: train_loss -0.466 
2025-07-10 05:28:57.650856: val_loss -0.4712 
2025-07-10 05:28:57.650940: Pseudo dice [np.float32(0.7658)] 
2025-07-10 05:28:57.651044: Epoch time: 46.14 s 
2025-07-10 05:28:58.813988:  
2025-07-10 05:28:58.814160: Epoch 651 
2025-07-10 05:28:58.814411: Current learning rate: 0.00388 
2025-07-10 05:29:45.586320: train_loss -0.4548 
2025-07-10 05:29:45.587157: val_loss -0.4287 
2025-07-10 05:29:45.587247: Pseudo dice [np.float32(0.6704)] 
2025-07-10 05:29:45.587389: Epoch time: 46.77 s 
2025-07-10 05:29:46.841443:  
2025-07-10 05:29:46.841911: Epoch 652 
2025-07-10 05:29:46.842076: Current learning rate: 0.00387 
2025-07-10 05:30:34.090385: train_loss -0.4584 
2025-07-10 05:30:34.090728: val_loss -0.4741 
2025-07-10 05:30:34.090815: Pseudo dice [np.float32(0.7539)] 
2025-07-10 05:30:34.090926: Epoch time: 47.25 s 
2025-07-10 05:30:35.330573:  
2025-07-10 05:30:35.331150: Epoch 653 
2025-07-10 05:30:35.331421: Current learning rate: 0.00386 
2025-07-10 05:31:22.353875: train_loss -0.4387 
2025-07-10 05:31:22.354363: val_loss -0.4578 
2025-07-10 05:31:22.354465: Pseudo dice [np.float32(0.755)] 
2025-07-10 05:31:22.354609: Epoch time: 47.02 s 
2025-07-10 05:31:24.216000:  
2025-07-10 05:31:24.216350: Epoch 654 
2025-07-10 05:31:24.216646: Current learning rate: 0.00385 
2025-07-10 05:32:11.411763: train_loss -0.441 
2025-07-10 05:32:11.412606: val_loss -0.4292 
2025-07-10 05:32:11.412700: Pseudo dice [np.float32(0.762)] 
2025-07-10 05:32:11.412865: Epoch time: 47.2 s 
2025-07-10 05:32:12.644729:  
2025-07-10 05:32:12.645149: Epoch 655 
2025-07-10 05:32:12.645442: Current learning rate: 0.00384 
2025-07-10 05:32:58.417984: train_loss -0.4079 
2025-07-10 05:32:58.419152: val_loss -0.4235 
2025-07-10 05:32:58.419274: Pseudo dice [np.float32(0.6034)] 
2025-07-10 05:32:58.419525: Epoch time: 45.77 s 
2025-07-10 05:32:59.705559:  
2025-07-10 05:32:59.705878: Epoch 656 
2025-07-10 05:32:59.706057: Current learning rate: 0.00383 
2025-07-10 05:33:46.011909: train_loss -0.4252 
2025-07-10 05:33:46.012578: val_loss -0.4378 
2025-07-10 05:33:46.012661: Pseudo dice [np.float32(0.5616)] 
2025-07-10 05:33:46.012795: Epoch time: 46.31 s 
2025-07-10 05:33:47.168557:  
2025-07-10 05:33:47.168840: Epoch 657 
2025-07-10 05:33:47.168944: Current learning rate: 0.00382 
2025-07-10 05:34:33.123456: train_loss -0.4549 
2025-07-10 05:34:33.124316: val_loss -0.443 
2025-07-10 05:34:33.124489: Pseudo dice [np.float32(0.6661)] 
2025-07-10 05:34:33.124732: Epoch time: 45.96 s 
2025-07-10 05:34:34.314063:  
2025-07-10 05:34:34.314484: Epoch 658 
2025-07-10 05:34:34.314630: Current learning rate: 0.00381 
2025-07-10 05:35:19.883244: train_loss -0.4645 
2025-07-10 05:35:19.883916: val_loss -0.4665 
2025-07-10 05:35:19.884018: Pseudo dice [np.float32(0.7626)] 
2025-07-10 05:35:19.884161: Epoch time: 45.57 s 
2025-07-10 05:35:21.091677:  
2025-07-10 05:35:21.092229: Epoch 659 
2025-07-10 05:35:21.092368: Current learning rate: 0.0038 
2025-07-10 05:36:07.232577: train_loss -0.4394 
2025-07-10 05:36:07.232944: val_loss -0.4327 
2025-07-10 05:36:07.236226: Pseudo dice [np.float32(0.6505)] 
2025-07-10 05:36:07.236347: Epoch time: 46.14 s 
2025-07-10 05:36:08.415379:  
2025-07-10 05:36:08.415760: Epoch 660 
2025-07-10 05:36:08.416077: Current learning rate: 0.00379 
2025-07-10 05:36:54.733009: train_loss -0.4436 
2025-07-10 05:36:54.733609: val_loss -0.4407 
2025-07-10 05:36:54.733706: Pseudo dice [np.float32(0.6727)] 
2025-07-10 05:36:54.733834: Epoch time: 46.32 s 
2025-07-10 05:36:55.908509:  
2025-07-10 05:36:55.909152: Epoch 661 
2025-07-10 05:36:55.909291: Current learning rate: 0.00378 
2025-07-10 05:37:41.984956: train_loss -0.4375 
2025-07-10 05:37:41.985708: val_loss -0.3907 
2025-07-10 05:37:41.985800: Pseudo dice [np.float32(0.5661)] 
2025-07-10 05:37:41.985924: Epoch time: 46.08 s 
2025-07-10 05:37:43.158058:  
2025-07-10 05:37:43.158334: Epoch 662 
2025-07-10 05:37:43.158459: Current learning rate: 0.00377 
2025-07-10 05:38:29.639961: train_loss -0.441 
2025-07-10 05:38:29.640494: val_loss -0.3123 
2025-07-10 05:38:29.640604: Pseudo dice [np.float32(0.2726)] 
2025-07-10 05:38:29.640758: Epoch time: 46.48 s 
2025-07-10 05:38:30.968157:  
2025-07-10 05:38:30.968537: Epoch 663 
2025-07-10 05:38:30.968795: Current learning rate: 0.00376 
2025-07-10 05:39:16.776471: train_loss -0.3847 
2025-07-10 05:39:16.777114: val_loss -0.4339 
2025-07-10 05:39:16.777222: Pseudo dice [np.float32(0.6046)] 
2025-07-10 05:39:16.777375: Epoch time: 45.81 s 
2025-07-10 05:39:17.997673:  
2025-07-10 05:39:17.997896: Epoch 664 
2025-07-10 05:39:17.998046: Current learning rate: 0.00375 
2025-07-10 05:40:04.015286: train_loss -0.4357 
2025-07-10 05:40:04.015727: val_loss -0.3785 
2025-07-10 05:40:04.015810: Pseudo dice [np.float32(0.4709)] 
2025-07-10 05:40:04.015985: Epoch time: 46.02 s 
2025-07-10 05:40:05.195668:  
2025-07-10 05:40:05.196039: Epoch 665 
2025-07-10 05:40:05.196136: Current learning rate: 0.00374 
2025-07-10 05:40:50.742767: train_loss -0.3756 
2025-07-10 05:40:50.743191: val_loss -0.379 
2025-07-10 05:40:50.743266: Pseudo dice [np.float32(0.5992)] 
2025-07-10 05:40:50.743366: Epoch time: 45.55 s 
2025-07-10 05:40:52.578664:  
2025-07-10 05:40:52.579068: Epoch 666 
2025-07-10 05:40:52.579200: Current learning rate: 0.00373 
2025-07-10 05:41:38.734297: train_loss -0.4035 
2025-07-10 05:41:38.735132: val_loss -0.3679 
2025-07-10 05:41:38.735249: Pseudo dice [np.float32(0.3643)] 
2025-07-10 05:41:38.735380: Epoch time: 46.16 s 
2025-07-10 05:41:39.952352:  
2025-07-10 05:41:39.952706: Epoch 667 
2025-07-10 05:41:39.952921: Current learning rate: 0.00372 
2025-07-10 05:42:26.699925: train_loss -0.3822 
2025-07-10 05:42:26.700514: val_loss -0.4366 
2025-07-10 05:42:26.700614: Pseudo dice [np.float32(0.7052)] 
2025-07-10 05:42:26.700758: Epoch time: 46.75 s 
2025-07-10 05:42:27.860918:  
2025-07-10 05:42:27.861109: Epoch 668 
2025-07-10 05:42:27.861230: Current learning rate: 0.00371 
2025-07-10 05:43:14.455850: train_loss -0.444 
2025-07-10 05:43:14.457065: val_loss -0.4424 
2025-07-10 05:43:14.457234: Pseudo dice [np.float32(0.7381)] 
2025-07-10 05:43:14.457428: Epoch time: 46.6 s 
2025-07-10 05:43:15.739015:  
2025-07-10 05:43:15.739418: Epoch 669 
2025-07-10 05:43:15.739604: Current learning rate: 0.0037 
2025-07-10 05:44:01.472774: train_loss -0.4471 
2025-07-10 05:44:01.473293: val_loss -0.4415 
2025-07-10 05:44:01.473386: Pseudo dice [np.float32(0.705)] 
2025-07-10 05:44:01.473511: Epoch time: 45.73 s 
2025-07-10 05:44:02.678924:  
2025-07-10 05:44:02.679350: Epoch 670 
2025-07-10 05:44:02.679482: Current learning rate: 0.00369 
2025-07-10 05:44:48.744871: train_loss -0.4575 
2025-07-10 05:44:48.745527: val_loss -0.4812 
2025-07-10 05:44:48.745626: Pseudo dice [np.float32(0.7249)] 
2025-07-10 05:44:48.745752: Epoch time: 46.07 s 
2025-07-10 05:44:49.941020:  
2025-07-10 05:44:49.941379: Epoch 671 
2025-07-10 05:44:49.941578: Current learning rate: 0.00368 
2025-07-10 05:45:35.991213: train_loss -0.4574 
2025-07-10 05:45:35.991875: val_loss -0.4757 
2025-07-10 05:45:35.991975: Pseudo dice [np.float32(0.7831)] 
2025-07-10 05:45:35.992106: Epoch time: 46.05 s 
2025-07-10 05:45:37.148619:  
2025-07-10 05:45:37.149090: Epoch 672 
2025-07-10 05:45:37.149280: Current learning rate: 0.00367 
2025-07-10 05:46:22.644414: train_loss -0.4695 
2025-07-10 05:46:22.644888: val_loss -0.4703 
2025-07-10 05:46:22.644991: Pseudo dice [np.float32(0.7799)] 
2025-07-10 05:46:22.645102: Epoch time: 45.5 s 
2025-07-10 05:46:23.795415:  
2025-07-10 05:46:23.795835: Epoch 673 
2025-07-10 05:46:23.796142: Current learning rate: 0.00366 
2025-07-10 05:47:08.984441: train_loss -0.3515 
2025-07-10 05:47:08.984943: val_loss -0.3443 
2025-07-10 05:47:08.985032: Pseudo dice [np.float32(0.0)] 
2025-07-10 05:47:08.985141: Epoch time: 45.19 s 
2025-07-10 05:47:10.225719:  
2025-07-10 05:47:10.226040: Epoch 674 
2025-07-10 05:47:10.226181: Current learning rate: 0.00365 
2025-07-10 05:47:56.282709: train_loss -0.3477 
2025-07-10 05:47:56.283116: val_loss -0.3383 
2025-07-10 05:47:56.283198: Pseudo dice [np.float32(0.0)] 
2025-07-10 05:47:56.283306: Epoch time: 46.06 s 
2025-07-10 05:47:57.542245:  
2025-07-10 05:47:57.543015: Epoch 675 
2025-07-10 05:47:57.543275: Current learning rate: 0.00364 
2025-07-10 05:48:43.423255: train_loss -0.356 
2025-07-10 05:48:43.423906: val_loss -0.3847 
2025-07-10 05:48:43.423990: Pseudo dice [np.float32(0.0)] 
2025-07-10 05:48:43.424102: Epoch time: 45.88 s 
2025-07-10 05:48:44.642429:  
2025-07-10 05:48:44.642970: Epoch 676 
2025-07-10 05:48:44.643095: Current learning rate: 0.00363 
2025-07-10 05:49:30.144678: train_loss -0.3894 
2025-07-10 05:49:30.145066: val_loss -0.4127 
2025-07-10 05:49:30.145144: Pseudo dice [np.float32(0.6211)] 
2025-07-10 05:49:30.145249: Epoch time: 45.5 s 
2025-07-10 05:49:31.999002:  
2025-07-10 05:49:31.999297: Epoch 677 
2025-07-10 05:49:31.999437: Current learning rate: 0.00362 
2025-07-10 05:50:17.452019: train_loss -0.4348 
2025-07-10 05:50:17.452614: val_loss -0.4176 
2025-07-10 05:50:17.452703: Pseudo dice [np.float32(0.7252)] 
2025-07-10 05:50:17.452820: Epoch time: 45.45 s 
2025-07-10 05:50:18.680106:  
2025-07-10 05:50:18.680404: Epoch 678 
2025-07-10 05:50:18.680620: Current learning rate: 0.00361 
2025-07-10 05:51:04.205807: train_loss -0.4502 
2025-07-10 05:51:04.206519: val_loss -0.4583 
2025-07-10 05:51:04.206645: Pseudo dice [np.float32(0.7309)] 
2025-07-10 05:51:04.206818: Epoch time: 45.53 s 
2025-07-10 05:51:05.367808:  
2025-07-10 05:51:05.368068: Epoch 679 
2025-07-10 05:51:05.368317: Current learning rate: 0.0036 
2025-07-10 05:51:51.192742: train_loss -0.461 
2025-07-10 05:51:51.193185: val_loss -0.4761 
2025-07-10 05:51:51.193280: Pseudo dice [np.float32(0.8049)] 
2025-07-10 05:51:51.193415: Epoch time: 45.83 s 
2025-07-10 05:51:52.408428:  
2025-07-10 05:51:52.408796: Epoch 680 
2025-07-10 05:51:52.408992: Current learning rate: 0.00359 
2025-07-10 05:52:38.376003: train_loss -0.4674 
2025-07-10 05:52:38.376742: val_loss -0.4486 
2025-07-10 05:52:38.376833: Pseudo dice [np.float32(0.7407)] 
2025-07-10 05:52:38.376940: Epoch time: 45.97 s 
2025-07-10 05:52:39.546962:  
2025-07-10 05:52:39.547219: Epoch 681 
2025-07-10 05:52:39.547459: Current learning rate: 0.00358 
2025-07-10 05:53:25.401793: train_loss -0.4542 
2025-07-10 05:53:25.402268: val_loss -0.4261 
2025-07-10 05:53:25.402346: Pseudo dice [np.float32(0.7288)] 
2025-07-10 05:53:25.402462: Epoch time: 45.86 s 
2025-07-10 05:53:26.607466:  
2025-07-10 05:53:26.608125: Epoch 682 
2025-07-10 05:53:26.608299: Current learning rate: 0.00357 
2025-07-10 05:54:12.310113: train_loss -0.4515 
2025-07-10 05:54:12.310670: val_loss -0.4425 
2025-07-10 05:54:12.310765: Pseudo dice [np.float32(0.6442)] 
2025-07-10 05:54:12.310886: Epoch time: 45.7 s 
2025-07-10 05:54:13.532015:  
2025-07-10 05:54:13.532357: Epoch 683 
2025-07-10 05:54:13.532547: Current learning rate: 0.00356 
2025-07-10 05:54:59.750156: train_loss -0.4508 
2025-07-10 05:54:59.750808: val_loss -0.4619 
2025-07-10 05:54:59.750884: Pseudo dice [np.float32(0.7671)] 
2025-07-10 05:54:59.751020: Epoch time: 46.22 s 
2025-07-10 05:55:00.947805:  
2025-07-10 05:55:00.948066: Epoch 684 
2025-07-10 05:55:00.948168: Current learning rate: 0.00355 
2025-07-10 05:55:47.071036: train_loss -0.4576 
2025-07-10 05:55:47.072135: val_loss -0.4528 
2025-07-10 05:55:47.072248: Pseudo dice [np.float32(0.711)] 
2025-07-10 05:55:47.072389: Epoch time: 46.12 s 
2025-07-10 05:55:48.286898:  
2025-07-10 05:55:48.287224: Epoch 685 
2025-07-10 05:55:48.287563: Current learning rate: 0.00354 
2025-07-10 05:56:33.595758: train_loss -0.4665 
2025-07-10 05:56:33.596021: val_loss -0.4596 
2025-07-10 05:56:33.596094: Pseudo dice [np.float32(0.7119)] 
2025-07-10 05:56:33.596245: Epoch time: 45.31 s 
2025-07-10 05:56:34.800648:  
2025-07-10 05:56:34.800826: Epoch 686 
2025-07-10 05:56:34.801039: Current learning rate: 0.00353 
2025-07-10 05:57:19.936376: train_loss -0.4637 
2025-07-10 05:57:19.937192: val_loss -0.4885 
2025-07-10 05:57:19.937295: Pseudo dice [np.float32(0.7533)] 
2025-07-10 05:57:19.937450: Epoch time: 45.14 s 
2025-07-10 05:57:21.168628:  
2025-07-10 05:57:21.169231: Epoch 687 
2025-07-10 05:57:21.169380: Current learning rate: 0.00352 
2025-07-10 05:58:06.865345: train_loss -0.4713 
2025-07-10 05:58:06.865946: val_loss -0.4617 
2025-07-10 05:58:06.866028: Pseudo dice [np.float32(0.6983)] 
2025-07-10 05:58:06.866145: Epoch time: 45.7 s 
2025-07-10 05:58:08.824584:  
2025-07-10 05:58:08.824991: Epoch 688 
2025-07-10 05:58:08.825496: Current learning rate: 0.00351 
2025-07-10 05:58:53.883275: train_loss -0.4656 
2025-07-10 05:58:53.883873: val_loss -0.4638 
2025-07-10 05:58:53.883978: Pseudo dice [np.float32(0.7645)] 
2025-07-10 05:58:53.884114: Epoch time: 45.06 s 
2025-07-10 05:58:55.085218:  
2025-07-10 05:58:55.085479: Epoch 689 
2025-07-10 05:58:55.085688: Current learning rate: 0.0035 
2025-07-10 05:59:40.753366: train_loss -0.4817 
2025-07-10 05:59:40.753893: val_loss -0.4874 
2025-07-10 05:59:40.753974: Pseudo dice [np.float32(0.7685)] 
2025-07-10 05:59:40.754097: Epoch time: 45.67 s 
2025-07-10 05:59:41.932223:  
2025-07-10 05:59:41.932428: Epoch 690 
2025-07-10 05:59:41.932798: Current learning rate: 0.00349 
2025-07-10 06:00:28.461871: train_loss -0.4544 
2025-07-10 06:00:28.462335: val_loss -0.438 
2025-07-10 06:00:28.462418: Pseudo dice [np.float32(0.6947)] 
2025-07-10 06:00:28.462531: Epoch time: 46.53 s 
2025-07-10 06:00:29.661647:  
2025-07-10 06:00:29.662045: Epoch 691 
2025-07-10 06:00:29.662181: Current learning rate: 0.00348 
2025-07-10 06:01:15.548940: train_loss -0.4574 
2025-07-10 06:01:15.549355: val_loss -0.4863 
2025-07-10 06:01:15.549434: Pseudo dice [np.float32(0.7752)] 
2025-07-10 06:01:15.549551: Epoch time: 45.89 s 
2025-07-10 06:01:16.727633:  
2025-07-10 06:01:16.728035: Epoch 692 
2025-07-10 06:01:16.728166: Current learning rate: 0.00346 
2025-07-10 06:02:02.305471: train_loss -0.4744 
2025-07-10 06:02:02.305902: val_loss -0.4676 
2025-07-10 06:02:02.305978: Pseudo dice [np.float32(0.7192)] 
2025-07-10 06:02:02.306077: Epoch time: 45.58 s 
2025-07-10 06:02:03.577295:  
2025-07-10 06:02:03.577461: Epoch 693 
2025-07-10 06:02:03.577586: Current learning rate: 0.00345 
2025-07-10 06:02:48.993190: train_loss -0.4651 
2025-07-10 06:02:48.993603: val_loss -0.4823 
2025-07-10 06:02:48.993683: Pseudo dice [np.float32(0.7909)] 
2025-07-10 06:02:48.993788: Epoch time: 45.42 s 
2025-07-10 06:02:50.190812:  
2025-07-10 06:02:50.191103: Epoch 694 
2025-07-10 06:02:50.191420: Current learning rate: 0.00344 
2025-07-10 06:03:35.521336: train_loss -0.4704 
2025-07-10 06:03:35.522007: val_loss -0.4941 
2025-07-10 06:03:35.522099: Pseudo dice [np.float32(0.7851)] 
2025-07-10 06:03:35.522229: Epoch time: 45.33 s 
2025-07-10 06:03:36.815866:  
2025-07-10 06:03:36.816181: Epoch 695 
2025-07-10 06:03:36.816306: Current learning rate: 0.00343 
2025-07-10 06:04:22.970509: train_loss -0.4791 
2025-07-10 06:04:22.970899: val_loss -0.4772 
2025-07-10 06:04:22.970983: Pseudo dice [np.float32(0.7425)] 
2025-07-10 06:04:22.971081: Epoch time: 46.16 s 
2025-07-10 06:04:24.167024:  
2025-07-10 06:04:24.167229: Epoch 696 
2025-07-10 06:04:24.167326: Current learning rate: 0.00342 
2025-07-10 06:05:10.211501: train_loss -0.4461 
2025-07-10 06:05:10.211967: val_loss -0.4175 
2025-07-10 06:05:10.212048: Pseudo dice [np.float32(0.6768)] 
2025-07-10 06:05:10.212157: Epoch time: 46.05 s 
2025-07-10 06:05:11.389467:  
2025-07-10 06:05:11.390007: Epoch 697 
2025-07-10 06:05:11.390184: Current learning rate: 0.00341 
2025-07-10 06:05:57.016188: train_loss -0.4436 
2025-07-10 06:05:57.016515: val_loss -0.4628 
2025-07-10 06:05:57.016667: Pseudo dice [np.float32(0.7627)] 
2025-07-10 06:05:57.016829: Epoch time: 45.63 s 
2025-07-10 06:05:58.278492:  
2025-07-10 06:05:58.279010: Epoch 698 
2025-07-10 06:05:58.279143: Current learning rate: 0.0034 
2025-07-10 06:06:43.506002: train_loss -0.4723 
2025-07-10 06:06:43.506505: val_loss -0.4715 
2025-07-10 06:06:43.506608: Pseudo dice [np.float32(0.732)] 
2025-07-10 06:06:43.506715: Epoch time: 45.23 s 
2025-07-10 06:06:45.335229:  
2025-07-10 06:06:45.335668: Epoch 699 
2025-07-10 06:06:45.335836: Current learning rate: 0.00339 
2025-07-10 06:07:30.572752: train_loss -0.4748 
2025-07-10 06:07:30.573169: val_loss -0.5032 
2025-07-10 06:07:30.573249: Pseudo dice [np.float32(0.8081)] 
2025-07-10 06:07:30.573360: Epoch time: 45.24 s 
2025-07-10 06:07:32.746697:  
2025-07-10 06:07:32.747103: Epoch 700 
2025-07-10 06:07:32.747288: Current learning rate: 0.00338 
2025-07-10 06:08:17.610573: train_loss -0.4753 
2025-07-10 06:08:17.611100: val_loss -0.4983 
2025-07-10 06:08:17.611184: Pseudo dice [np.float32(0.7721)] 
2025-07-10 06:08:17.611298: Epoch time: 44.86 s 
2025-07-10 06:08:18.837594:  
2025-07-10 06:08:18.837962: Epoch 701 
2025-07-10 06:08:18.838088: Current learning rate: 0.00337 
2025-07-10 06:09:05.195893: train_loss -0.4738 
2025-07-10 06:09:05.196338: val_loss -0.4705 
2025-07-10 06:09:05.196421: Pseudo dice [np.float32(0.7791)] 
2025-07-10 06:09:05.196536: Epoch time: 46.36 s 
2025-07-10 06:09:06.395506:  
2025-07-10 06:09:06.395909: Epoch 702 
2025-07-10 06:09:06.396012: Current learning rate: 0.00336 
2025-07-10 06:09:51.654906: train_loss -0.4799 
2025-07-10 06:09:51.657041: val_loss -0.4784 
2025-07-10 06:09:51.657249: Pseudo dice [np.float32(0.7946)] 
2025-07-10 06:09:51.657479: Epoch time: 45.26 s 
2025-07-10 06:09:52.839392:  
2025-07-10 06:09:52.839573: Epoch 703 
2025-07-10 06:09:52.839761: Current learning rate: 0.00335 
2025-07-10 06:10:38.142911: train_loss -0.4786 
2025-07-10 06:10:38.143357: val_loss -0.4692 
2025-07-10 06:10:38.143557: Pseudo dice [np.float32(0.7291)] 
2025-07-10 06:10:38.143676: Epoch time: 45.3 s 
2025-07-10 06:10:39.310755:  
2025-07-10 06:10:39.311057: Epoch 704 
2025-07-10 06:10:39.311230: Current learning rate: 0.00334 
2025-07-10 06:11:24.895819: train_loss -0.461 
2025-07-10 06:11:24.896186: val_loss -0.4648 
2025-07-10 06:11:24.896260: Pseudo dice [np.float32(0.7858)] 
2025-07-10 06:11:24.896355: Epoch time: 45.59 s 
2025-07-10 06:11:26.059935:  
2025-07-10 06:11:26.060062: Epoch 705 
2025-07-10 06:11:26.060155: Current learning rate: 0.00333 
2025-07-10 06:12:11.855342: train_loss -0.4788 
2025-07-10 06:12:11.855943: val_loss -0.4657 
2025-07-10 06:12:11.856051: Pseudo dice [np.float32(0.7809)] 
2025-07-10 06:12:11.856196: Epoch time: 45.8 s 
2025-07-10 06:12:13.209265:  
2025-07-10 06:12:13.209454: Epoch 706 
2025-07-10 06:12:13.209742: Current learning rate: 0.00332 
2025-07-10 06:12:59.198390: train_loss -0.4762 
2025-07-10 06:12:59.199945: val_loss -0.4708 
2025-07-10 06:12:59.200133: Pseudo dice [np.float32(0.7854)] 
2025-07-10 06:12:59.200351: Epoch time: 45.99 s 
2025-07-10 06:13:00.492707:  
2025-07-10 06:13:00.492877: Epoch 707 
2025-07-10 06:13:00.493006: Current learning rate: 0.00331 
2025-07-10 06:13:45.409927: train_loss -0.461 
2025-07-10 06:13:45.410381: val_loss -0.455 
2025-07-10 06:13:45.410468: Pseudo dice [np.float32(0.7147)] 
2025-07-10 06:13:45.410588: Epoch time: 44.92 s 
2025-07-10 06:13:46.626548:  
2025-07-10 06:13:46.626776: Epoch 708 
2025-07-10 06:13:46.626965: Current learning rate: 0.0033 
2025-07-10 06:14:32.488874: train_loss -0.4657 
2025-07-10 06:14:32.489788: val_loss -0.463 
2025-07-10 06:14:32.489866: Pseudo dice [np.float32(0.7497)] 
2025-07-10 06:14:32.490014: Epoch time: 45.86 s 
2025-07-10 06:14:33.675720:  
2025-07-10 06:14:33.675985: Epoch 709 
2025-07-10 06:14:33.676213: Current learning rate: 0.00329 
2025-07-10 06:15:19.741102: train_loss -0.4763 
2025-07-10 06:15:19.742177: val_loss -0.4601 
2025-07-10 06:15:19.742297: Pseudo dice [np.float32(0.7524)] 
2025-07-10 06:15:19.742489: Epoch time: 46.07 s 
2025-07-10 06:15:21.560867:  
2025-07-10 06:15:21.561592: Epoch 710 
2025-07-10 06:15:21.562011: Current learning rate: 0.00328 
2025-07-10 06:16:07.468062: train_loss -0.4555 
2025-07-10 06:16:07.468934: val_loss -0.476 
2025-07-10 06:16:07.469099: Pseudo dice [np.float32(0.7946)] 
2025-07-10 06:16:07.469273: Epoch time: 45.91 s 
2025-07-10 06:16:08.684488:  
2025-07-10 06:16:08.684868: Epoch 711 
2025-07-10 06:16:08.685037: Current learning rate: 0.00327 
2025-07-10 06:16:53.796962: train_loss -0.4433 
2025-07-10 06:16:53.797306: val_loss -0.4448 
2025-07-10 06:16:53.797388: Pseudo dice [np.float32(0.6631)] 
2025-07-10 06:16:53.797490: Epoch time: 45.11 s 
2025-07-10 06:16:55.015576:  
2025-07-10 06:16:55.016091: Epoch 712 
2025-07-10 06:16:55.016225: Current learning rate: 0.00326 
2025-07-10 06:17:40.628648: train_loss -0.4629 
2025-07-10 06:17:40.629046: val_loss -0.4578 
2025-07-10 06:17:40.629122: Pseudo dice [np.float32(0.6985)] 
2025-07-10 06:17:40.629221: Epoch time: 45.61 s 
2025-07-10 06:17:41.804709:  
2025-07-10 06:17:41.805066: Epoch 713 
2025-07-10 06:17:41.805194: Current learning rate: 0.00325 
2025-07-10 06:18:27.512012: train_loss -0.4478 
2025-07-10 06:18:27.512472: val_loss -0.4245 
2025-07-10 06:18:27.512561: Pseudo dice [np.float32(0.6615)] 
2025-07-10 06:18:27.512681: Epoch time: 45.71 s 
2025-07-10 06:18:28.697019:  
2025-07-10 06:18:28.697208: Epoch 714 
2025-07-10 06:18:28.697512: Current learning rate: 0.00324 
2025-07-10 06:19:14.403900: train_loss -0.4526 
2025-07-10 06:19:14.404597: val_loss -0.4719 
2025-07-10 06:19:14.404734: Pseudo dice [np.float32(0.7661)] 
2025-07-10 06:19:14.405057: Epoch time: 45.71 s 
2025-07-10 06:19:15.580085:  
2025-07-10 06:19:15.580367: Epoch 715 
2025-07-10 06:19:15.580468: Current learning rate: 0.00323 
2025-07-10 06:20:01.285908: train_loss -0.4717 
2025-07-10 06:20:01.286313: val_loss -0.4789 
2025-07-10 06:20:01.286395: Pseudo dice [np.float32(0.8069)] 
2025-07-10 06:20:01.286500: Epoch time: 45.71 s 
2025-07-10 06:20:02.480597:  
2025-07-10 06:20:02.480904: Epoch 716 
2025-07-10 06:20:02.481041: Current learning rate: 0.00322 
2025-07-10 06:20:48.083613: train_loss -0.4598 
2025-07-10 06:20:48.084223: val_loss -0.4632 
2025-07-10 06:20:48.084308: Pseudo dice [np.float32(0.734)] 
2025-07-10 06:20:48.084473: Epoch time: 45.6 s 
2025-07-10 06:20:49.299762:  
2025-07-10 06:20:49.300118: Epoch 717 
2025-07-10 06:20:49.300243: Current learning rate: 0.00321 
2025-07-10 06:21:35.478222: train_loss -0.4741 
2025-07-10 06:21:35.478733: val_loss -0.4733 
2025-07-10 06:21:35.478824: Pseudo dice [np.float32(0.765)] 
2025-07-10 06:21:35.478961: Epoch time: 46.18 s 
2025-07-10 06:21:36.675091:  
2025-07-10 06:21:36.675318: Epoch 718 
2025-07-10 06:21:36.675494: Current learning rate: 0.0032 
2025-07-10 06:22:22.626276: train_loss -0.4866 
2025-07-10 06:22:22.626796: val_loss -0.4912 
2025-07-10 06:22:22.626880: Pseudo dice [np.float32(0.7996)] 
2025-07-10 06:22:22.626977: Epoch time: 45.95 s 
2025-07-10 06:22:23.889247:  
2025-07-10 06:22:23.889459: Epoch 719 
2025-07-10 06:22:23.889598: Current learning rate: 0.00319 
2025-07-10 06:23:09.257405: train_loss -0.4623 
2025-07-10 06:23:09.258665: val_loss -0.4925 
2025-07-10 06:23:09.258791: Pseudo dice [np.float32(0.7963)] 
2025-07-10 06:23:09.259105: Epoch time: 45.37 s 
2025-07-10 06:23:10.482913:  
2025-07-10 06:23:10.483262: Epoch 720 
2025-07-10 06:23:10.483499: Current learning rate: 0.00318 
2025-07-10 06:23:56.635842: train_loss -0.4866 
2025-07-10 06:23:56.636317: val_loss -0.4743 
2025-07-10 06:23:56.636400: Pseudo dice [np.float32(0.7943)] 
2025-07-10 06:23:56.636514: Epoch time: 46.15 s 
2025-07-10 06:23:58.518003:  
2025-07-10 06:23:58.518343: Epoch 721 
2025-07-10 06:23:58.518478: Current learning rate: 0.00317 
2025-07-10 06:24:44.584847: train_loss -0.4793 
2025-07-10 06:24:44.585311: val_loss -0.4754 
2025-07-10 06:24:44.585389: Pseudo dice [np.float32(0.7559)] 
2025-07-10 06:24:44.585617: Epoch time: 46.07 s 
2025-07-10 06:24:45.788774:  
2025-07-10 06:24:45.789072: Epoch 722 
2025-07-10 06:24:45.789230: Current learning rate: 0.00316 
2025-07-10 06:25:31.370076: train_loss -0.4684 
2025-07-10 06:25:31.370708: val_loss -0.4726 
2025-07-10 06:25:31.370804: Pseudo dice [np.float32(0.7258)] 
2025-07-10 06:25:31.370925: Epoch time: 45.58 s 
2025-07-10 06:25:32.639282:  
2025-07-10 06:25:32.639796: Epoch 723 
2025-07-10 06:25:32.639984: Current learning rate: 0.00315 
2025-07-10 06:26:18.105585: train_loss -0.4761 
2025-07-10 06:26:18.105968: val_loss -0.4552 
2025-07-10 06:26:18.106056: Pseudo dice [np.float32(0.7478)] 
2025-07-10 06:26:18.106184: Epoch time: 45.47 s 
2025-07-10 06:26:19.285123:  
2025-07-10 06:26:19.285593: Epoch 724 
2025-07-10 06:26:19.285733: Current learning rate: 0.00314 
2025-07-10 06:27:04.997809: train_loss -0.4671 
2025-07-10 06:27:04.998386: val_loss -0.4592 
2025-07-10 06:27:04.998510: Pseudo dice [np.float32(0.7711)] 
2025-07-10 06:27:04.998720: Epoch time: 45.71 s 
2025-07-10 06:27:06.227252:  
2025-07-10 06:27:06.227706: Epoch 725 
2025-07-10 06:27:06.227963: Current learning rate: 0.00313 
2025-07-10 06:27:52.233371: train_loss -0.4612 
2025-07-10 06:27:52.233764: val_loss -0.4733 
2025-07-10 06:27:52.233839: Pseudo dice [np.float32(0.7308)] 
2025-07-10 06:27:52.233944: Epoch time: 46.01 s 
2025-07-10 06:27:53.557529:  
2025-07-10 06:27:53.557930: Epoch 726 
2025-07-10 06:27:53.558058: Current learning rate: 0.00312 
2025-07-10 06:28:38.232867: train_loss -0.4263 
2025-07-10 06:28:38.234130: val_loss -0.4379 
2025-07-10 06:28:38.234419: Pseudo dice [np.float32(0.703)] 
2025-07-10 06:28:38.234716: Epoch time: 44.68 s 
2025-07-10 06:28:39.589233:  
2025-07-10 06:28:39.589691: Epoch 727 
2025-07-10 06:28:39.589826: Current learning rate: 0.00311 
2025-07-10 06:29:24.835010: train_loss -0.4386 
2025-07-10 06:29:24.835423: val_loss -0.45 
2025-07-10 06:29:24.835509: Pseudo dice [np.float32(0.7495)] 
2025-07-10 06:29:24.835644: Epoch time: 45.25 s 
2025-07-10 06:29:26.069459:  
2025-07-10 06:29:26.069903: Epoch 728 
2025-07-10 06:29:26.070029: Current learning rate: 0.0031 
2025-07-10 06:30:11.233604: train_loss -0.4575 
2025-07-10 06:30:11.234523: val_loss -0.484 
2025-07-10 06:30:11.234632: Pseudo dice [np.float32(0.7814)] 
2025-07-10 06:30:11.234761: Epoch time: 45.16 s 
2025-07-10 06:30:12.512470:  
2025-07-10 06:30:12.512870: Epoch 729 
2025-07-10 06:30:12.513134: Current learning rate: 0.00309 
2025-07-10 06:30:57.871360: train_loss -0.4805 
2025-07-10 06:30:57.872096: val_loss -0.502 
2025-07-10 06:30:57.872200: Pseudo dice [np.float32(0.7765)] 
2025-07-10 06:30:57.872359: Epoch time: 45.36 s 
2025-07-10 06:30:59.053497:  
2025-07-10 06:30:59.053622: Epoch 730 
2025-07-10 06:30:59.053717: Current learning rate: 0.00308 
2025-07-10 06:31:44.638066: train_loss -0.4827 
2025-07-10 06:31:44.639987: val_loss -0.4826 
2025-07-10 06:31:44.640273: Pseudo dice [np.float32(0.7954)] 
2025-07-10 06:31:44.640652: Epoch time: 45.59 s 
2025-07-10 06:31:45.865568:  
2025-07-10 06:31:45.865952: Epoch 731 
2025-07-10 06:31:45.866153: Current learning rate: 0.00307 
2025-07-10 06:32:32.197615: train_loss -0.4755 
2025-07-10 06:32:32.198141: val_loss -0.4923 
2025-07-10 06:32:32.198221: Pseudo dice [np.float32(0.7653)] 
2025-07-10 06:32:32.198338: Epoch time: 46.33 s 
2025-07-10 06:32:34.015916:  
2025-07-10 06:32:34.016184: Epoch 732 
2025-07-10 06:32:34.016310: Current learning rate: 0.00306 
2025-07-10 06:33:19.601898: train_loss -0.4742 
2025-07-10 06:33:19.602599: val_loss -0.4535 
2025-07-10 06:33:19.602788: Pseudo dice [np.float32(0.751)] 
2025-07-10 06:33:19.602917: Epoch time: 45.59 s 
2025-07-10 06:33:20.836548:  
2025-07-10 06:33:20.836944: Epoch 733 
2025-07-10 06:33:20.837153: Current learning rate: 0.00305 
2025-07-10 06:34:06.509891: train_loss -0.459 
2025-07-10 06:34:06.510348: val_loss -0.4425 
2025-07-10 06:34:06.510445: Pseudo dice [np.float32(0.7352)] 
2025-07-10 06:34:06.510583: Epoch time: 45.67 s 
2025-07-10 06:34:07.766338:  
2025-07-10 06:34:07.766663: Epoch 734 
2025-07-10 06:34:07.766846: Current learning rate: 0.00304 
2025-07-10 06:34:53.256721: train_loss -0.4651 
2025-07-10 06:34:53.257195: val_loss -0.462 
2025-07-10 06:34:53.257333: Pseudo dice [np.float32(0.7468)] 
2025-07-10 06:34:53.257472: Epoch time: 45.49 s 
2025-07-10 06:34:54.493575:  
2025-07-10 06:34:54.493799: Epoch 735 
2025-07-10 06:34:54.493928: Current learning rate: 0.00303 
2025-07-10 06:35:40.882318: train_loss -0.4883 
2025-07-10 06:35:40.882992: val_loss -0.4919 
2025-07-10 06:35:40.883070: Pseudo dice [np.float32(0.771)] 
2025-07-10 06:35:40.883195: Epoch time: 46.39 s 
2025-07-10 06:35:42.076455:  
2025-07-10 06:35:42.076901: Epoch 736 
2025-07-10 06:35:42.077031: Current learning rate: 0.00302 
2025-07-10 06:36:28.266683: train_loss -0.477 
2025-07-10 06:36:28.267731: val_loss -0.4378 
2025-07-10 06:36:28.267946: Pseudo dice [np.float32(0.7489)] 
2025-07-10 06:36:28.268457: Epoch time: 46.19 s 
2025-07-10 06:36:29.467679:  
2025-07-10 06:36:29.467972: Epoch 737 
2025-07-10 06:36:29.468207: Current learning rate: 0.00301 
2025-07-10 06:37:15.711203: train_loss -0.4441 
2025-07-10 06:37:15.711734: val_loss -0.4166 
2025-07-10 06:37:15.711812: Pseudo dice [np.float32(0.6505)] 
2025-07-10 06:37:15.711919: Epoch time: 46.24 s 
2025-07-10 06:37:16.927744:  
2025-07-10 06:37:16.928102: Epoch 738 
2025-07-10 06:37:16.928315: Current learning rate: 0.003 
2025-07-10 06:38:03.026944: train_loss -0.411 
2025-07-10 06:38:03.027570: val_loss -0.4036 
2025-07-10 06:38:03.027710: Pseudo dice [np.float32(0.5835)] 
2025-07-10 06:38:03.027914: Epoch time: 46.1 s 
2025-07-10 06:38:04.267636:  
2025-07-10 06:38:04.267992: Epoch 739 
2025-07-10 06:38:04.268302: Current learning rate: 0.00299 
2025-07-10 06:38:50.411968: train_loss -0.4429 
2025-07-10 06:38:50.412567: val_loss -0.4652 
2025-07-10 06:38:50.412663: Pseudo dice [np.float32(0.7655)] 
2025-07-10 06:38:50.412783: Epoch time: 46.15 s 
2025-07-10 06:38:51.634091:  
2025-07-10 06:38:51.634746: Epoch 740 
2025-07-10 06:38:51.634875: Current learning rate: 0.00297 
2025-07-10 06:39:36.993722: train_loss -0.4555 
2025-07-10 06:39:36.994936: val_loss -0.4739 
2025-07-10 06:39:36.995115: Pseudo dice [np.float32(0.76)] 
2025-07-10 06:39:36.995288: Epoch time: 45.36 s 
2025-07-10 06:39:38.365401:  
2025-07-10 06:39:38.365597: Epoch 741 
2025-07-10 06:39:38.365728: Current learning rate: 0.00296 
2025-07-10 06:40:24.132494: train_loss -0.4501 
2025-07-10 06:40:24.133031: val_loss -0.3722 
2025-07-10 06:40:24.133116: Pseudo dice [np.float32(0.5419)] 
2025-07-10 06:40:24.133248: Epoch time: 45.77 s 
2025-07-10 06:40:25.396202:  
2025-07-10 06:40:25.396399: Epoch 742 
2025-07-10 06:40:25.396523: Current learning rate: 0.00295 
2025-07-10 06:41:10.648103: train_loss -0.4214 
2025-07-10 06:41:10.648725: val_loss -0.4673 
2025-07-10 06:41:10.648807: Pseudo dice [np.float32(0.6453)] 
2025-07-10 06:41:10.648924: Epoch time: 45.25 s 
2025-07-10 06:41:12.491951:  
2025-07-10 06:41:12.492431: Epoch 743 
2025-07-10 06:41:12.492580: Current learning rate: 0.00294 
2025-07-10 06:41:57.493236: train_loss -0.4656 
2025-07-10 06:41:57.493716: val_loss -0.4727 
2025-07-10 06:41:57.493812: Pseudo dice [np.float32(0.7628)] 
2025-07-10 06:41:57.493968: Epoch time: 45.0 s 
2025-07-10 06:41:58.678348:  
2025-07-10 06:41:58.678680: Epoch 744 
2025-07-10 06:41:58.678828: Current learning rate: 0.00293 
2025-07-10 06:42:44.908041: train_loss -0.4757 
2025-07-10 06:42:44.908587: val_loss -0.4809 
2025-07-10 06:42:44.908689: Pseudo dice [np.float32(0.767)] 
2025-07-10 06:42:44.908820: Epoch time: 46.23 s 
2025-07-10 06:42:46.181992:  
2025-07-10 06:42:46.182269: Epoch 745 
2025-07-10 06:42:46.182552: Current learning rate: 0.00292 
2025-07-10 06:43:31.482067: train_loss -0.4756 
2025-07-10 06:43:31.482565: val_loss -0.4881 
2025-07-10 06:43:31.482649: Pseudo dice [np.float32(0.7718)] 
2025-07-10 06:43:31.482766: Epoch time: 45.3 s 
2025-07-10 06:43:32.681599:  
2025-07-10 06:43:32.682205: Epoch 746 
2025-07-10 06:43:32.682381: Current learning rate: 0.00291 
2025-07-10 06:44:17.408477: train_loss -0.4894 
2025-07-10 06:44:17.409089: val_loss -0.4895 
2025-07-10 06:44:17.409176: Pseudo dice [np.float32(0.8095)] 
2025-07-10 06:44:17.409302: Epoch time: 44.73 s 
2025-07-10 06:44:18.631407:  
2025-07-10 06:44:18.631778: Epoch 747 
2025-07-10 06:44:18.631933: Current learning rate: 0.0029 
2025-07-10 06:45:04.744787: train_loss -0.4852 
2025-07-10 06:45:04.745208: val_loss -0.4884 
2025-07-10 06:45:04.745283: Pseudo dice [np.float32(0.7996)] 
2025-07-10 06:45:04.745389: Epoch time: 46.11 s 
2025-07-10 06:45:05.936922:  
2025-07-10 06:45:05.937274: Epoch 748 
2025-07-10 06:45:05.937483: Current learning rate: 0.00289 
2025-07-10 06:45:52.275872: train_loss -0.4702 
2025-07-10 06:45:52.276648: val_loss -0.482 
2025-07-10 06:45:52.276746: Pseudo dice [np.float32(0.8134)] 
2025-07-10 06:45:52.276882: Epoch time: 46.34 s 
2025-07-10 06:45:53.482807:  
2025-07-10 06:45:53.483412: Epoch 749 
2025-07-10 06:45:53.483565: Current learning rate: 0.00288 
2025-07-10 06:46:40.488479: train_loss -0.4849 
2025-07-10 06:46:40.489263: val_loss -0.4644 
2025-07-10 06:46:40.489350: Pseudo dice [np.float32(0.7097)] 
2025-07-10 06:46:40.489489: Epoch time: 47.01 s 
2025-07-10 06:46:42.727904:  
2025-07-10 06:46:42.728071: Epoch 750 
2025-07-10 06:46:42.728275: Current learning rate: 0.00287 
2025-07-10 06:47:30.302076: train_loss -0.4774 
2025-07-10 06:47:30.302559: val_loss -0.465 
2025-07-10 06:47:30.302631: Pseudo dice [np.float32(0.7673)] 
2025-07-10 06:47:30.302732: Epoch time: 47.58 s 
2025-07-10 06:47:31.574047:  
2025-07-10 06:47:31.574795: Epoch 751 
2025-07-10 06:47:31.575083: Current learning rate: 0.00286 
2025-07-10 06:48:17.468615: train_loss -0.4866 
2025-07-10 06:48:17.469179: val_loss -0.4628 
2025-07-10 06:48:17.469292: Pseudo dice [np.float32(0.7345)] 
2025-07-10 06:48:17.469450: Epoch time: 45.9 s 
2025-07-10 06:48:18.684104:  
2025-07-10 06:48:18.684433: Epoch 752 
2025-07-10 06:48:18.684600: Current learning rate: 0.00285 
2025-07-10 06:49:04.407661: train_loss -0.4767 
2025-07-10 06:49:04.408400: val_loss -0.5002 
2025-07-10 06:49:04.408495: Pseudo dice [np.float32(0.8063)] 
2025-07-10 06:49:04.408719: Epoch time: 45.72 s 
2025-07-10 06:49:05.626202:  
2025-07-10 06:49:05.626451: Epoch 753 
2025-07-10 06:49:05.626642: Current learning rate: 0.00284 
2025-07-10 06:49:51.775501: train_loss -0.4827 
2025-07-10 06:49:51.775990: val_loss -0.4825 
2025-07-10 06:49:51.776068: Pseudo dice [np.float32(0.7928)] 
2025-07-10 06:49:51.776180: Epoch time: 46.15 s 
2025-07-10 06:49:53.680302:  
2025-07-10 06:49:53.680698: Epoch 754 
2025-07-10 06:49:53.680880: Current learning rate: 0.00283 
2025-07-10 06:50:40.180118: train_loss -0.4783 
2025-07-10 06:50:40.180810: val_loss -0.4625 
2025-07-10 06:50:40.180893: Pseudo dice [np.float32(0.7409)] 
2025-07-10 06:50:40.181014: Epoch time: 46.5 s 
2025-07-10 06:50:41.353109:  
2025-07-10 06:50:41.353375: Epoch 755 
2025-07-10 06:50:41.353585: Current learning rate: 0.00282 
2025-07-10 06:51:26.898129: train_loss -0.4526 
2025-07-10 06:51:26.898453: val_loss -0.4656 
2025-07-10 06:51:26.898525: Pseudo dice [np.float32(0.7138)] 
2025-07-10 06:51:26.898632: Epoch time: 45.55 s 
2025-07-10 06:51:28.089281:  
2025-07-10 06:51:28.089976: Epoch 756 
2025-07-10 06:51:28.090115: Current learning rate: 0.00281 
2025-07-10 06:52:14.424806: train_loss -0.4667 
2025-07-10 06:52:14.425632: val_loss -0.4694 
2025-07-10 06:52:14.425735: Pseudo dice [np.float32(0.8211)] 
2025-07-10 06:52:14.425858: Epoch time: 46.34 s 
2025-07-10 06:52:15.616622:  
2025-07-10 06:52:15.617094: Epoch 757 
2025-07-10 06:52:15.617248: Current learning rate: 0.0028 
2025-07-10 06:53:00.921894: train_loss -0.4765 
2025-07-10 06:53:00.922348: val_loss -0.4622 
2025-07-10 06:53:00.922432: Pseudo dice [np.float32(0.7509)] 
2025-07-10 06:53:00.922558: Epoch time: 45.31 s 
2025-07-10 06:53:02.137247:  
2025-07-10 06:53:02.137599: Epoch 758 
2025-07-10 06:53:02.137818: Current learning rate: 0.00279 
2025-07-10 06:53:46.911984: train_loss -0.4652 
2025-07-10 06:53:46.912581: val_loss -0.4789 
2025-07-10 06:53:46.912676: Pseudo dice [np.float32(0.7776)] 
2025-07-10 06:53:46.912780: Epoch time: 44.78 s 
2025-07-10 06:53:48.099351:  
2025-07-10 06:53:48.099719: Epoch 759 
2025-07-10 06:53:48.099827: Current learning rate: 0.00278 
2025-07-10 06:54:33.582668: train_loss -0.4746 
2025-07-10 06:54:33.583062: val_loss -0.4964 
2025-07-10 06:54:33.586757: Pseudo dice [np.float32(0.8227)] 
2025-07-10 06:54:33.587017: Epoch time: 45.48 s 
2025-07-10 06:54:34.826510:  
2025-07-10 06:54:34.826895: Epoch 760 
2025-07-10 06:54:34.827075: Current learning rate: 0.00277 
2025-07-10 06:55:20.169681: train_loss -0.4789 
2025-07-10 06:55:20.170286: val_loss -0.476 
2025-07-10 06:55:20.170382: Pseudo dice [np.float32(0.7666)] 
2025-07-10 06:55:20.170501: Epoch time: 45.34 s 
2025-07-10 06:55:21.462108:  
2025-07-10 06:55:21.462423: Epoch 761 
2025-07-10 06:55:21.462572: Current learning rate: 0.00276 
2025-07-10 06:56:05.990873: train_loss -0.4797 
2025-07-10 06:56:05.992692: val_loss -0.49 
2025-07-10 06:56:05.993055: Pseudo dice [np.float32(0.801)] 
2025-07-10 06:56:05.993332: Epoch time: 44.53 s 
2025-07-10 06:56:07.270017:  
2025-07-10 06:56:07.270401: Epoch 762 
2025-07-10 06:56:07.270578: Current learning rate: 0.00275 
2025-07-10 06:56:52.637290: train_loss -0.4665 
2025-07-10 06:56:52.637898: val_loss -0.4569 
2025-07-10 06:56:52.637984: Pseudo dice [np.float32(0.7845)] 
2025-07-10 06:56:52.638101: Epoch time: 45.37 s 
2025-07-10 06:56:53.850457:  
2025-07-10 06:56:53.850780: Epoch 763 
2025-07-10 06:56:53.850945: Current learning rate: 0.00274 
2025-07-10 06:57:38.820003: train_loss -0.458 
2025-07-10 06:57:38.820378: val_loss -0.4528 
2025-07-10 06:57:38.820456: Pseudo dice [np.float32(0.6615)] 
2025-07-10 06:57:38.820573: Epoch time: 44.97 s 
2025-07-10 06:57:40.041346:  
2025-07-10 06:57:40.041602: Epoch 764 
2025-07-10 06:57:40.041821: Current learning rate: 0.00273 
2025-07-10 06:58:25.679491: train_loss -0.4495 
2025-07-10 06:58:25.679995: val_loss -0.4561 
2025-07-10 06:58:25.680073: Pseudo dice [np.float32(0.7757)] 
2025-07-10 06:58:25.680178: Epoch time: 45.64 s 
2025-07-10 06:58:27.530006:  
2025-07-10 06:58:27.530471: Epoch 765 
2025-07-10 06:58:27.530703: Current learning rate: 0.00272 
2025-07-10 06:59:13.252010: train_loss -0.4684 
2025-07-10 06:59:13.252690: val_loss -0.4692 
2025-07-10 06:59:13.252857: Pseudo dice [np.float32(0.7036)] 
2025-07-10 06:59:13.252981: Epoch time: 45.72 s 
2025-07-10 06:59:14.428729:  
2025-07-10 06:59:14.429007: Epoch 766 
2025-07-10 06:59:14.429163: Current learning rate: 0.00271 
2025-07-10 07:00:00.545675: train_loss -0.4786 
2025-07-10 07:00:00.546132: val_loss -0.4791 
2025-07-10 07:00:00.546214: Pseudo dice [np.float32(0.7869)] 
2025-07-10 07:00:00.546327: Epoch time: 46.12 s 
2025-07-10 07:00:01.777772:  
2025-07-10 07:00:01.778099: Epoch 767 
2025-07-10 07:00:01.778231: Current learning rate: 0.0027 
2025-07-10 07:00:47.578092: train_loss -0.4605 
2025-07-10 07:00:47.578696: val_loss -0.4218 
2025-07-10 07:00:47.578783: Pseudo dice [np.float32(0.7152)] 
2025-07-10 07:00:47.578895: Epoch time: 45.8 s 
2025-07-10 07:00:48.802818:  
2025-07-10 07:00:48.803204: Epoch 768 
2025-07-10 07:00:48.803341: Current learning rate: 0.00268 
2025-07-10 07:01:35.114966: train_loss -0.452 
2025-07-10 07:01:35.115711: val_loss -0.4727 
2025-07-10 07:01:35.115822: Pseudo dice [np.float32(0.7637)] 
2025-07-10 07:01:35.116037: Epoch time: 46.31 s 
2025-07-10 07:01:36.408433:  
2025-07-10 07:01:36.409263: Epoch 769 
2025-07-10 07:01:36.409614: Current learning rate: 0.00267 
2025-07-10 07:02:22.617897: train_loss -0.4559 
2025-07-10 07:02:22.618235: val_loss -0.4565 
2025-07-10 07:02:22.618308: Pseudo dice [np.float32(0.7367)] 
2025-07-10 07:02:22.618406: Epoch time: 46.21 s 
2025-07-10 07:02:23.805650:  
2025-07-10 07:02:23.806008: Epoch 770 
2025-07-10 07:02:23.806136: Current learning rate: 0.00266 
2025-07-10 07:03:10.280550: train_loss -0.4596 
2025-07-10 07:03:10.281319: val_loss -0.4575 
2025-07-10 07:03:10.281406: Pseudo dice [np.float32(0.7102)] 
2025-07-10 07:03:10.281533: Epoch time: 46.48 s 
2025-07-10 07:03:11.494678:  
2025-07-10 07:03:11.495137: Epoch 771 
2025-07-10 07:03:11.495267: Current learning rate: 0.00265 
2025-07-10 07:03:57.010392: train_loss -0.4546 
2025-07-10 07:03:57.010893: val_loss -0.4849 
2025-07-10 07:03:57.010985: Pseudo dice [np.float32(0.806)] 
2025-07-10 07:03:57.011104: Epoch time: 45.52 s 
2025-07-10 07:03:58.208423:  
2025-07-10 07:03:58.209043: Epoch 772 
2025-07-10 07:03:58.209176: Current learning rate: 0.00264 
2025-07-10 07:04:45.128992: train_loss -0.4726 
2025-07-10 07:04:45.129429: val_loss -0.4679 
2025-07-10 07:04:45.129510: Pseudo dice [np.float32(0.79)] 
2025-07-10 07:04:45.129622: Epoch time: 46.92 s 
2025-07-10 07:04:46.321247:  
2025-07-10 07:04:46.321535: Epoch 773 
2025-07-10 07:04:46.321862: Current learning rate: 0.00263 
2025-07-10 07:05:32.245425: train_loss -0.4792 
2025-07-10 07:05:32.245860: val_loss -0.4718 
2025-07-10 07:05:32.245949: Pseudo dice [np.float32(0.778)] 
2025-07-10 07:05:32.246059: Epoch time: 45.93 s 
2025-07-10 07:05:33.592040:  
2025-07-10 07:05:33.592326: Epoch 774 
2025-07-10 07:05:33.592458: Current learning rate: 0.00262 
2025-07-10 07:06:19.514237: train_loss -0.4783 
2025-07-10 07:06:19.514522: val_loss -0.4855 
2025-07-10 07:06:19.514610: Pseudo dice [np.float32(0.7695)] 
2025-07-10 07:06:19.514705: Epoch time: 45.92 s 
2025-07-10 07:06:20.941737:  
2025-07-10 07:06:20.942292: Epoch 775 
2025-07-10 07:06:20.942434: Current learning rate: 0.00261 
2025-07-10 07:07:07.244566: train_loss -0.4823 
2025-07-10 07:07:07.245213: val_loss -0.4942 
2025-07-10 07:07:07.245322: Pseudo dice [np.float32(0.7872)] 
2025-07-10 07:07:07.245517: Epoch time: 46.3 s 
2025-07-10 07:07:09.118897:  
2025-07-10 07:07:09.119193: Epoch 776 
2025-07-10 07:07:09.119322: Current learning rate: 0.0026 
2025-07-10 07:07:54.418114: train_loss -0.4956 
2025-07-10 07:07:54.418654: val_loss -0.4772 
2025-07-10 07:07:54.418736: Pseudo dice [np.float32(0.8228)] 
2025-07-10 07:07:54.418835: Epoch time: 45.3 s 
2025-07-10 07:07:55.690733:  
2025-07-10 07:07:55.691183: Epoch 777 
2025-07-10 07:07:55.691319: Current learning rate: 0.00259 
2025-07-10 07:08:41.649330: train_loss -0.4932 
2025-07-10 07:08:41.649796: val_loss -0.4956 
2025-07-10 07:08:41.653157: Pseudo dice [np.float32(0.8314)] 
2025-07-10 07:08:41.653269: Epoch time: 45.96 s 
2025-07-10 07:08:42.867958:  
2025-07-10 07:08:42.868503: Epoch 778 
2025-07-10 07:08:42.868663: Current learning rate: 0.00258 
2025-07-10 07:09:28.781492: train_loss -0.4831 
2025-07-10 07:09:28.782041: val_loss -0.4864 
2025-07-10 07:09:28.782120: Pseudo dice [np.float32(0.7986)] 
2025-07-10 07:09:28.782232: Epoch time: 45.91 s 
2025-07-10 07:09:30.019111:  
2025-07-10 07:09:30.019298: Epoch 779 
2025-07-10 07:09:30.019468: Current learning rate: 0.00257 
2025-07-10 07:10:16.139704: train_loss -0.4587 
2025-07-10 07:10:16.140526: val_loss -0.4824 
2025-07-10 07:10:16.140667: Pseudo dice [np.float32(0.7976)] 
2025-07-10 07:10:16.140829: Epoch time: 46.12 s 
2025-07-10 07:10:17.356195:  
2025-07-10 07:10:17.356373: Epoch 780 
2025-07-10 07:10:17.356528: Current learning rate: 0.00256 
2025-07-10 07:11:03.300853: train_loss -0.4733 
2025-07-10 07:11:03.301573: val_loss -0.4863 
2025-07-10 07:11:03.301694: Pseudo dice [np.float32(0.7896)] 
2025-07-10 07:11:03.301802: Epoch time: 45.95 s 
2025-07-10 07:11:04.504014:  
2025-07-10 07:11:04.504340: Epoch 781 
2025-07-10 07:11:04.504683: Current learning rate: 0.00255 
2025-07-10 07:11:49.919144: train_loss -0.4923 
2025-07-10 07:11:49.919832: val_loss -0.504 
2025-07-10 07:11:49.919971: Pseudo dice [np.float32(0.7926)] 
2025-07-10 07:11:49.920123: Epoch time: 45.42 s 
2025-07-10 07:11:51.175788:  
2025-07-10 07:11:51.176118: Epoch 782 
2025-07-10 07:11:51.176427: Current learning rate: 0.00254 
2025-07-10 07:12:37.399913: train_loss -0.4832 
2025-07-10 07:12:37.400577: val_loss -0.494 
2025-07-10 07:12:37.400678: Pseudo dice [np.float32(0.821)] 
2025-07-10 07:12:37.400799: Epoch time: 46.23 s 
2025-07-10 07:12:38.600374:  
2025-07-10 07:12:38.600559: Epoch 783 
2025-07-10 07:12:38.600769: Current learning rate: 0.00253 
2025-07-10 07:13:24.085341: train_loss -0.4902 
2025-07-10 07:13:24.085662: val_loss -0.4843 
2025-07-10 07:13:24.085736: Pseudo dice [np.float32(0.7781)] 
2025-07-10 07:13:24.085828: Epoch time: 45.49 s 
2025-07-10 07:13:25.255987:  
2025-07-10 07:13:25.256384: Epoch 784 
2025-07-10 07:13:25.256534: Current learning rate: 0.00252 
2025-07-10 07:14:10.968313: train_loss -0.4925 
2025-07-10 07:14:10.968856: val_loss -0.5258 
2025-07-10 07:14:10.972496: Pseudo dice [np.float32(0.8378)] 
2025-07-10 07:14:10.972655: Epoch time: 45.71 s 
2025-07-10 07:14:12.166444:  
2025-07-10 07:14:12.166652: Epoch 785 
2025-07-10 07:14:12.166873: Current learning rate: 0.00251 
2025-07-10 07:14:57.285449: train_loss -0.5071 
2025-07-10 07:14:57.285875: val_loss -0.495 
2025-07-10 07:14:57.285952: Pseudo dice [np.float32(0.807)] 
2025-07-10 07:14:57.286068: Epoch time: 45.12 s 
2025-07-10 07:14:58.510854:  
2025-07-10 07:14:58.511239: Epoch 786 
2025-07-10 07:14:58.511371: Current learning rate: 0.0025 
2025-07-10 07:15:43.849211: train_loss -0.4979 
2025-07-10 07:15:43.849660: val_loss -0.4856 
2025-07-10 07:15:43.849754: Pseudo dice [np.float32(0.8259)] 
2025-07-10 07:15:43.849858: Epoch time: 45.34 s 
2025-07-10 07:15:45.764644:  
2025-07-10 07:15:45.765133: Epoch 787 
2025-07-10 07:15:45.765320: Current learning rate: 0.00249 
2025-07-10 07:16:30.975651: train_loss -0.4716 
2025-07-10 07:16:30.976103: val_loss -0.4815 
2025-07-10 07:16:30.976184: Pseudo dice [np.float32(0.7827)] 
2025-07-10 07:16:30.976290: Epoch time: 45.21 s 
2025-07-10 07:16:32.188321:  
2025-07-10 07:16:32.188805: Epoch 788 
2025-07-10 07:16:32.188911: Current learning rate: 0.00248 
2025-07-10 07:17:17.983904: train_loss -0.4811 
2025-07-10 07:17:17.984885: val_loss -0.497 
2025-07-10 07:17:17.985034: Pseudo dice [np.float32(0.8328)] 
2025-07-10 07:17:17.985298: Epoch time: 45.8 s 
2025-07-10 07:17:19.295314:  
2025-07-10 07:17:19.295667: Epoch 789 
2025-07-10 07:17:19.295989: Current learning rate: 0.00247 
2025-07-10 07:18:05.650961: train_loss -0.4838 
2025-07-10 07:18:05.651365: val_loss -0.4874 
2025-07-10 07:18:05.651443: Pseudo dice [np.float32(0.7624)] 
2025-07-10 07:18:05.651552: Epoch time: 46.36 s 
2025-07-10 07:18:06.834277:  
2025-07-10 07:18:06.834467: Epoch 790 
2025-07-10 07:18:06.834572: Current learning rate: 0.00245 
2025-07-10 07:18:52.885404: train_loss -0.486 
2025-07-10 07:18:52.885723: val_loss -0.5102 
2025-07-10 07:18:52.885795: Pseudo dice [np.float32(0.8034)] 
2025-07-10 07:18:52.885887: Epoch time: 46.05 s 
2025-07-10 07:18:54.100919:  
2025-07-10 07:18:54.101095: Epoch 791 
2025-07-10 07:18:54.101244: Current learning rate: 0.00244 
2025-07-10 07:19:39.688774: train_loss -0.4835 
2025-07-10 07:19:39.689168: val_loss -0.3767 
2025-07-10 07:19:39.689254: Pseudo dice [np.float32(0.7505)] 
2025-07-10 07:19:39.689404: Epoch time: 45.59 s 
2025-07-10 07:19:40.932586:  
2025-07-10 07:19:40.932867: Epoch 792 
2025-07-10 07:19:40.932996: Current learning rate: 0.00243 
2025-07-10 07:20:26.323026: train_loss -0.4308 
2025-07-10 07:20:26.323512: val_loss -0.4659 
2025-07-10 07:20:26.323607: Pseudo dice [np.float32(0.7117)] 
2025-07-10 07:20:26.323728: Epoch time: 45.39 s 
2025-07-10 07:20:27.584213:  
2025-07-10 07:20:27.584384: Epoch 793 
2025-07-10 07:20:27.584734: Current learning rate: 0.00242 
2025-07-10 07:21:13.250331: train_loss -0.4379 
2025-07-10 07:21:13.250840: val_loss -0.4472 
2025-07-10 07:21:13.250931: Pseudo dice [np.float32(0.6735)] 
2025-07-10 07:21:13.251042: Epoch time: 45.67 s 
2025-07-10 07:21:14.495700:  
2025-07-10 07:21:14.495987: Epoch 794 
2025-07-10 07:21:14.496087: Current learning rate: 0.00241 
2025-07-10 07:21:59.608623: train_loss -0.4218 
2025-07-10 07:21:59.609716: val_loss -0.4341 
2025-07-10 07:21:59.610181: Pseudo dice [np.float32(0.7201)] 
2025-07-10 07:21:59.610510: Epoch time: 45.11 s 
2025-07-10 07:22:00.847361:  
2025-07-10 07:22:00.847641: Epoch 795 
2025-07-10 07:22:00.847800: Current learning rate: 0.0024 
2025-07-10 07:22:46.317089: train_loss -0.4603 
2025-07-10 07:22:46.317813: val_loss -0.4975 
2025-07-10 07:22:46.317896: Pseudo dice [np.float32(0.8149)] 
2025-07-10 07:22:46.318004: Epoch time: 45.47 s 
2025-07-10 07:22:47.527738:  
2025-07-10 07:22:47.528065: Epoch 796 
2025-07-10 07:22:47.528262: Current learning rate: 0.00239 
2025-07-10 07:23:32.677390: train_loss -0.4834 
2025-07-10 07:23:32.678066: val_loss -0.4772 
2025-07-10 07:23:32.678161: Pseudo dice [np.float32(0.7398)] 
2025-07-10 07:23:32.678288: Epoch time: 45.15 s 
2025-07-10 07:23:33.915906:  
2025-07-10 07:23:33.916111: Epoch 797 
2025-07-10 07:23:33.916239: Current learning rate: 0.00238 
2025-07-10 07:24:19.896229: train_loss -0.4686 
2025-07-10 07:24:19.896719: val_loss -0.473 
2025-07-10 07:24:19.896802: Pseudo dice [np.float32(0.7792)] 
2025-07-10 07:24:19.896910: Epoch time: 45.98 s 
2025-07-10 07:24:21.154107:  
2025-07-10 07:24:21.154572: Epoch 798 
2025-07-10 07:24:21.154752: Current learning rate: 0.00237 
2025-07-10 07:25:06.120522: train_loss -0.4677 
2025-07-10 07:25:06.120935: val_loss -0.4564 
2025-07-10 07:25:06.121046: Pseudo dice [np.float32(0.7691)] 
2025-07-10 07:25:06.121144: Epoch time: 44.97 s 
2025-07-10 07:25:07.341669:  
2025-07-10 07:25:07.341969: Epoch 799 
2025-07-10 07:25:07.342224: Current learning rate: 0.00236 
2025-07-10 07:25:53.416110: train_loss -0.4743 
2025-07-10 07:25:53.416555: val_loss -0.4805 
2025-07-10 07:25:53.416635: Pseudo dice [np.float32(0.7561)] 
2025-07-10 07:25:53.416733: Epoch time: 46.08 s 
2025-07-10 07:25:55.551345:  
2025-07-10 07:25:55.552037: Epoch 800 
2025-07-10 07:25:55.552226: Current learning rate: 0.00235 
2025-07-10 07:26:41.375951: train_loss -0.4661 
2025-07-10 07:26:41.376286: val_loss -0.4722 
2025-07-10 07:26:41.376359: Pseudo dice [np.float32(0.7549)] 
2025-07-10 07:26:41.376462: Epoch time: 45.83 s 
2025-07-10 07:26:42.608742:  
2025-07-10 07:26:42.609255: Epoch 801 
2025-07-10 07:26:42.609604: Current learning rate: 0.00234 
2025-07-10 07:27:28.444333: train_loss -0.4863 
2025-07-10 07:27:28.444809: val_loss -0.4748 
2025-07-10 07:27:28.444889: Pseudo dice [np.float32(0.809)] 
2025-07-10 07:27:28.444989: Epoch time: 45.84 s 
2025-07-10 07:27:29.666715:  
2025-07-10 07:27:29.667138: Epoch 802 
2025-07-10 07:27:29.667263: Current learning rate: 0.00233 
2025-07-10 07:28:15.130964: train_loss -0.46 
2025-07-10 07:28:15.131504: val_loss -0.4496 
2025-07-10 07:28:15.131599: Pseudo dice [np.float32(0.7602)] 
2025-07-10 07:28:15.131720: Epoch time: 45.47 s 
2025-07-10 07:28:16.355760:  
2025-07-10 07:28:16.356304: Epoch 803 
2025-07-10 07:28:16.356626: Current learning rate: 0.00232 
2025-07-10 07:29:02.938344: train_loss -0.4704 
2025-07-10 07:29:02.939071: val_loss -0.4582 
2025-07-10 07:29:02.939167: Pseudo dice [np.float32(0.7377)] 
2025-07-10 07:29:02.939355: Epoch time: 46.58 s 
2025-07-10 07:29:04.124166:  
2025-07-10 07:29:04.124565: Epoch 804 
2025-07-10 07:29:04.124771: Current learning rate: 0.00231 
2025-07-10 07:29:49.412365: train_loss -0.4581 
2025-07-10 07:29:49.413211: val_loss -0.463 
2025-07-10 07:29:49.413394: Pseudo dice [np.float32(0.7564)] 
2025-07-10 07:29:49.413641: Epoch time: 45.29 s 
2025-07-10 07:29:50.627938:  
2025-07-10 07:29:50.628313: Epoch 805 
2025-07-10 07:29:50.628470: Current learning rate: 0.0023 
2025-07-10 07:30:36.168190: train_loss -0.4791 
2025-07-10 07:30:36.168840: val_loss -0.4892 
2025-07-10 07:30:36.168946: Pseudo dice [np.float32(0.8001)] 
2025-07-10 07:30:36.169094: Epoch time: 45.54 s 
2025-07-10 07:30:37.437989:  
2025-07-10 07:30:37.438651: Epoch 806 
2025-07-10 07:30:37.438788: Current learning rate: 0.00229 
2025-07-10 07:31:23.090661: train_loss -0.4771 
2025-07-10 07:31:23.091056: val_loss -0.4868 
2025-07-10 07:31:23.091133: Pseudo dice [np.float32(0.8097)] 
2025-07-10 07:31:23.091231: Epoch time: 45.65 s 
2025-07-10 07:31:24.291488:  
2025-07-10 07:31:24.291882: Epoch 807 
2025-07-10 07:31:24.292012: Current learning rate: 0.00228 
2025-07-10 07:32:10.006031: train_loss -0.4793 
2025-07-10 07:32:10.006383: val_loss -0.4833 
2025-07-10 07:32:10.006457: Pseudo dice [np.float32(0.7895)] 
2025-07-10 07:32:10.006586: Epoch time: 45.72 s 
2025-07-10 07:32:11.823518:  
2025-07-10 07:32:11.823874: Epoch 808 
2025-07-10 07:32:11.824091: Current learning rate: 0.00226 
2025-07-10 07:32:56.823468: train_loss -0.4569 
2025-07-10 07:32:56.824013: val_loss -0.4863 
2025-07-10 07:32:56.824095: Pseudo dice [np.float32(0.7706)] 
2025-07-10 07:32:56.824210: Epoch time: 45.0 s 
2025-07-10 07:32:58.078579:  
2025-07-10 07:32:58.079117: Epoch 809 
2025-07-10 07:32:58.079265: Current learning rate: 0.00225 
2025-07-10 07:33:43.038247: train_loss -0.4763 
2025-07-10 07:33:43.038792: val_loss -0.4756 
2025-07-10 07:33:43.038875: Pseudo dice [np.float32(0.7333)] 
2025-07-10 07:33:43.038982: Epoch time: 44.96 s 
2025-07-10 07:33:44.310079:  
2025-07-10 07:33:44.310404: Epoch 810 
2025-07-10 07:33:44.310689: Current learning rate: 0.00224 
2025-07-10 07:34:29.281690: train_loss -0.4838 
2025-07-10 07:34:29.282168: val_loss -0.5066 
2025-07-10 07:34:29.282245: Pseudo dice [np.float32(0.8198)] 
2025-07-10 07:34:29.282347: Epoch time: 44.97 s 
2025-07-10 07:34:30.512393:  
2025-07-10 07:34:30.512951: Epoch 811 
2025-07-10 07:34:30.513484: Current learning rate: 0.00223 
2025-07-10 07:35:16.091033: train_loss -0.4885 
2025-07-10 07:35:16.091892: val_loss -0.4808 
2025-07-10 07:35:16.092010: Pseudo dice [np.float32(0.8294)] 
2025-07-10 07:35:16.092193: Epoch time: 45.58 s 
2025-07-10 07:35:17.305162:  
2025-07-10 07:35:17.305753: Epoch 812 
2025-07-10 07:35:17.305884: Current learning rate: 0.00222 
2025-07-10 07:36:03.528702: train_loss -0.4887 
2025-07-10 07:36:03.529385: val_loss -0.4999 
2025-07-10 07:36:03.529473: Pseudo dice [np.float32(0.8089)] 
2025-07-10 07:36:03.529606: Epoch time: 46.23 s 
2025-07-10 07:36:04.858791:  
2025-07-10 07:36:04.859195: Epoch 813 
2025-07-10 07:36:04.859363: Current learning rate: 0.00221 
2025-07-10 07:36:50.712521: train_loss -0.4852 
2025-07-10 07:36:50.712970: val_loss -0.4746 
2025-07-10 07:36:50.713046: Pseudo dice [np.float32(0.7225)] 
2025-07-10 07:36:50.713149: Epoch time: 45.85 s 
2025-07-10 07:36:51.966195:  
2025-07-10 07:36:51.966554: Epoch 814 
2025-07-10 07:36:51.966932: Current learning rate: 0.0022 
2025-07-10 07:37:37.440449: train_loss -0.4636 
2025-07-10 07:37:37.440945: val_loss -0.4859 
2025-07-10 07:37:37.441031: Pseudo dice [np.float32(0.7667)] 
2025-07-10 07:37:37.441131: Epoch time: 45.48 s 
2025-07-10 07:37:38.636658:  
2025-07-10 07:37:38.637071: Epoch 815 
2025-07-10 07:37:38.637197: Current learning rate: 0.00219 
2025-07-10 07:38:25.053455: train_loss -0.4487 
2025-07-10 07:38:25.053922: val_loss -0.4638 
2025-07-10 07:38:25.053999: Pseudo dice [np.float32(0.7878)] 
2025-07-10 07:38:25.054106: Epoch time: 46.42 s 
2025-07-10 07:38:26.257017:  
2025-07-10 07:38:26.257310: Epoch 816 
2025-07-10 07:38:26.257621: Current learning rate: 0.00218 
2025-07-10 07:39:12.131112: train_loss -0.4812 
2025-07-10 07:39:12.131732: val_loss -0.4672 
2025-07-10 07:39:12.131836: Pseudo dice [np.float32(0.7233)] 
2025-07-10 07:39:12.131957: Epoch time: 45.88 s 
2025-07-10 07:39:13.414328:  
2025-07-10 07:39:13.414766: Epoch 817 
2025-07-10 07:39:13.414897: Current learning rate: 0.00217 
2025-07-10 07:39:59.372466: train_loss -0.4721 
2025-07-10 07:39:59.372966: val_loss -0.4946 
2025-07-10 07:39:59.373161: Pseudo dice [np.float32(0.821)] 
2025-07-10 07:39:59.373309: Epoch time: 45.96 s 
2025-07-10 07:40:01.274770:  
2025-07-10 07:40:01.275215: Epoch 818 
2025-07-10 07:40:01.275346: Current learning rate: 0.00216 
2025-07-10 07:40:47.990151: train_loss -0.4829 
2025-07-10 07:40:47.990563: val_loss -0.493 
2025-07-10 07:40:47.990639: Pseudo dice [np.float32(0.7899)] 
2025-07-10 07:40:47.990745: Epoch time: 46.72 s 
2025-07-10 07:40:49.247818:  
2025-07-10 07:40:49.248192: Epoch 819 
2025-07-10 07:40:49.248325: Current learning rate: 0.00215 
2025-07-10 07:41:34.978132: train_loss -0.481 
2025-07-10 07:41:34.978866: val_loss -0.4924 
2025-07-10 07:41:34.978962: Pseudo dice [np.float32(0.7867)] 
2025-07-10 07:41:34.979101: Epoch time: 45.73 s 
2025-07-10 07:41:36.165928:  
2025-07-10 07:41:36.166345: Epoch 820 
2025-07-10 07:41:36.166528: Current learning rate: 0.00214 
2025-07-10 07:42:21.690865: train_loss -0.4815 
2025-07-10 07:42:21.691451: val_loss -0.4918 
2025-07-10 07:42:21.691552: Pseudo dice [np.float32(0.8049)] 
2025-07-10 07:42:21.691682: Epoch time: 45.53 s 
2025-07-10 07:42:22.872042:  
2025-07-10 07:42:22.872316: Epoch 821 
2025-07-10 07:42:22.872491: Current learning rate: 0.00213 
2025-07-10 07:43:08.855576: train_loss -0.4808 
2025-07-10 07:43:08.856090: val_loss -0.506 
2025-07-10 07:43:08.856181: Pseudo dice [np.float32(0.8544)] 
2025-07-10 07:43:08.856293: Epoch time: 45.98 s 
2025-07-10 07:43:10.039437:  
2025-07-10 07:43:10.039917: Epoch 822 
2025-07-10 07:43:10.040121: Current learning rate: 0.00212 
2025-07-10 07:43:56.216238: train_loss -0.4889 
2025-07-10 07:43:56.216694: val_loss -0.4934 
2025-07-10 07:43:56.216774: Pseudo dice [np.float32(0.8186)] 
2025-07-10 07:43:56.216893: Epoch time: 46.18 s 
2025-07-10 07:43:57.461377:  
2025-07-10 07:43:57.461860: Epoch 823 
2025-07-10 07:43:57.462033: Current learning rate: 0.0021 
2025-07-10 07:44:43.568800: train_loss -0.4809 
2025-07-10 07:44:43.569558: val_loss -0.4741 
2025-07-10 07:44:43.569648: Pseudo dice [np.float32(0.7838)] 
2025-07-10 07:44:43.569762: Epoch time: 46.11 s 
2025-07-10 07:44:44.768219:  
2025-07-10 07:44:44.768804: Epoch 824 
2025-07-10 07:44:44.769025: Current learning rate: 0.00209 
2025-07-10 07:45:30.107478: train_loss -0.4494 
2025-07-10 07:45:30.107958: val_loss -0.4791 
2025-07-10 07:45:30.108033: Pseudo dice [np.float32(0.8341)] 
2025-07-10 07:45:30.108133: Epoch time: 45.34 s 
2025-07-10 07:45:31.307692:  
2025-07-10 07:45:31.308180: Epoch 825 
2025-07-10 07:45:31.308361: Current learning rate: 0.00208 
2025-07-10 07:46:17.483255: train_loss -0.477 
2025-07-10 07:46:17.483671: val_loss -0.499 
2025-07-10 07:46:17.483745: Pseudo dice [np.float32(0.8053)] 
2025-07-10 07:46:17.483845: Epoch time: 46.18 s 
2025-07-10 07:46:18.656599:  
2025-07-10 07:46:18.656949: Epoch 826 
2025-07-10 07:46:18.657108: Current learning rate: 0.00207 
2025-07-10 07:47:04.142279: train_loss -0.4849 
2025-07-10 07:47:04.142712: val_loss -0.4961 
2025-07-10 07:47:04.142802: Pseudo dice [np.float32(0.8125)] 
2025-07-10 07:47:04.142914: Epoch time: 45.49 s 
2025-07-10 07:47:05.337177:  
2025-07-10 07:47:05.337450: Epoch 827 
2025-07-10 07:47:05.337601: Current learning rate: 0.00206 
2025-07-10 07:47:50.678765: train_loss -0.4842 
2025-07-10 07:47:50.679132: val_loss -0.4912 
2025-07-10 07:47:50.679214: Pseudo dice [np.float32(0.806)] 
2025-07-10 07:47:50.679321: Epoch time: 45.34 s 
2025-07-10 07:47:51.852689:  
2025-07-10 07:47:51.853163: Epoch 828 
2025-07-10 07:47:51.853304: Current learning rate: 0.00205 
2025-07-10 07:48:37.542075: train_loss -0.4896 
2025-07-10 07:48:37.543057: val_loss -0.4937 
2025-07-10 07:48:37.543215: Pseudo dice [np.float32(0.7801)] 
2025-07-10 07:48:37.543403: Epoch time: 45.69 s 
2025-07-10 07:48:38.753882:  
2025-07-10 07:48:38.754459: Epoch 829 
2025-07-10 07:48:38.754622: Current learning rate: 0.00204 
2025-07-10 07:49:24.420482: train_loss -0.4812 
2025-07-10 07:49:24.421044: val_loss -0.4924 
2025-07-10 07:49:24.421202: Pseudo dice [np.float32(0.7926)] 
2025-07-10 07:49:24.421438: Epoch time: 45.67 s 
2025-07-10 07:49:26.292965:  
2025-07-10 07:49:26.293565: Epoch 830 
2025-07-10 07:49:26.293695: Current learning rate: 0.00203 
2025-07-10 07:50:11.187646: train_loss -0.4969 
2025-07-10 07:50:11.188044: val_loss -0.4848 
2025-07-10 07:50:11.188146: Pseudo dice [np.float32(0.7763)] 
2025-07-10 07:50:11.188246: Epoch time: 44.9 s 
2025-07-10 07:50:12.355305:  
2025-07-10 07:50:12.355608: Epoch 831 
2025-07-10 07:50:12.355940: Current learning rate: 0.00202 
2025-07-10 07:50:58.649807: train_loss -0.4884 
2025-07-10 07:50:58.650264: val_loss -0.4879 
2025-07-10 07:50:58.650353: Pseudo dice [np.float32(0.8322)] 
2025-07-10 07:50:58.650478: Epoch time: 46.3 s 
2025-07-10 07:50:59.942930:  
2025-07-10 07:50:59.943586: Epoch 832 
2025-07-10 07:50:59.943721: Current learning rate: 0.00201 
2025-07-10 07:51:46.152764: train_loss -0.4736 
2025-07-10 07:51:46.153155: val_loss -0.4766 
2025-07-10 07:51:46.153232: Pseudo dice [np.float32(0.7661)] 
2025-07-10 07:51:46.153328: Epoch time: 46.21 s 
2025-07-10 07:51:47.294369:  
2025-07-10 07:51:47.294892: Epoch 833 
2025-07-10 07:51:47.295233: Current learning rate: 0.002 
2025-07-10 07:52:32.737408: train_loss -0.4891 
2025-07-10 07:52:32.737730: val_loss -0.5018 
2025-07-10 07:52:32.737811: Pseudo dice [np.float32(0.8013)] 
2025-07-10 07:52:32.737908: Epoch time: 45.44 s 
2025-07-10 07:52:33.896981:  
2025-07-10 07:52:33.897235: Epoch 834 
2025-07-10 07:52:33.897365: Current learning rate: 0.00199 
2025-07-10 07:53:20.337470: train_loss -0.4846 
2025-07-10 07:53:20.337761: val_loss -0.5003 
2025-07-10 07:53:20.337833: Pseudo dice [np.float32(0.7715)] 
2025-07-10 07:53:20.337930: Epoch time: 46.44 s 
2025-07-10 07:53:21.509166:  
2025-07-10 07:53:21.509492: Epoch 835 
2025-07-10 07:53:21.509739: Current learning rate: 0.00198 
2025-07-10 07:54:09.047471: train_loss -0.4762 
2025-07-10 07:54:09.048443: val_loss -0.4892 
2025-07-10 07:54:09.048531: Pseudo dice [np.float32(0.7637)] 
2025-07-10 07:54:09.048732: Epoch time: 47.54 s 
2025-07-10 07:54:10.309778:  
2025-07-10 07:54:10.310293: Epoch 836 
2025-07-10 07:54:10.310494: Current learning rate: 0.00196 
2025-07-10 07:54:56.565099: train_loss -0.5013 
2025-07-10 07:54:56.565808: val_loss -0.4975 
2025-07-10 07:54:56.565999: Pseudo dice [np.float32(0.8217)] 
2025-07-10 07:54:56.566142: Epoch time: 46.26 s 
2025-07-10 07:54:57.756618:  
2025-07-10 07:54:57.756955: Epoch 837 
2025-07-10 07:54:57.757079: Current learning rate: 0.00195 
2025-07-10 07:55:44.623755: train_loss -0.4898 
2025-07-10 07:55:44.624653: val_loss -0.4752 
2025-07-10 07:55:44.624752: Pseudo dice [np.float32(0.8204)] 
2025-07-10 07:55:44.624874: Epoch time: 46.87 s 
2025-07-10 07:55:45.843712:  
2025-07-10 07:55:45.843879: Epoch 838 
2025-07-10 07:55:45.844059: Current learning rate: 0.00194 
2025-07-10 07:56:32.431662: train_loss -0.4989 
2025-07-10 07:56:32.432168: val_loss -0.4951 
2025-07-10 07:56:32.432251: Pseudo dice [np.float32(0.8198)] 
2025-07-10 07:56:32.432360: Epoch time: 46.59 s 
2025-07-10 07:56:33.606553:  
2025-07-10 07:56:33.606916: Epoch 839 
2025-07-10 07:56:33.607047: Current learning rate: 0.00193 
2025-07-10 07:57:19.790932: train_loss -0.4797 
2025-07-10 07:57:19.791531: val_loss -0.4913 
2025-07-10 07:57:19.791663: Pseudo dice [np.float32(0.8083)] 
2025-07-10 07:57:19.791816: Epoch time: 46.19 s 
2025-07-10 07:57:21.012399:  
2025-07-10 07:57:21.012609: Epoch 840 
2025-07-10 07:57:21.012750: Current learning rate: 0.00192 
2025-07-10 07:58:06.924923: train_loss -0.5006 
2025-07-10 07:58:06.925788: val_loss -0.493 
2025-07-10 07:58:06.925917: Pseudo dice [np.float32(0.7148)] 
2025-07-10 07:58:06.926095: Epoch time: 45.91 s 
2025-07-10 07:58:08.122389:  
2025-07-10 07:58:08.122768: Epoch 841 
2025-07-10 07:58:08.122910: Current learning rate: 0.00191 
2025-07-10 07:58:54.689400: train_loss -0.4473 
2025-07-10 07:58:54.689828: val_loss -0.5119 
2025-07-10 07:58:54.689903: Pseudo dice [np.float32(0.8164)] 
2025-07-10 07:58:54.690010: Epoch time: 46.57 s 
2025-07-10 07:58:56.479351:  
2025-07-10 07:58:56.479734: Epoch 842 
2025-07-10 07:58:56.479918: Current learning rate: 0.0019 
2025-07-10 07:59:42.638390: train_loss -0.4844 
2025-07-10 07:59:42.638869: val_loss -0.4911 
2025-07-10 07:59:42.639017: Pseudo dice [np.float32(0.8323)] 
2025-07-10 07:59:42.639260: Epoch time: 46.16 s 
2025-07-10 07:59:43.844626:  
2025-07-10 07:59:43.844842: Epoch 843 
2025-07-10 07:59:43.845176: Current learning rate: 0.00189 
2025-07-10 08:00:30.884238: train_loss -0.4951 
2025-07-10 08:00:30.884768: val_loss -0.4884 
2025-07-10 08:00:30.884848: Pseudo dice [np.float32(0.7803)] 
2025-07-10 08:00:30.884963: Epoch time: 47.04 s 
2025-07-10 08:00:32.069835:  
2025-07-10 08:00:32.070230: Epoch 844 
2025-07-10 08:00:32.070408: Current learning rate: 0.00188 
2025-07-10 08:01:18.587670: train_loss -0.489 
2025-07-10 08:01:18.588180: val_loss -0.4928 
2025-07-10 08:01:18.588283: Pseudo dice [np.float32(0.816)] 
2025-07-10 08:01:18.588392: Epoch time: 46.52 s 
2025-07-10 08:01:19.771775:  
2025-07-10 08:01:19.772196: Epoch 845 
2025-07-10 08:01:19.772474: Current learning rate: 0.00187 
2025-07-10 08:02:06.075534: train_loss -0.4918 
2025-07-10 08:02:06.075990: val_loss -0.4933 
2025-07-10 08:02:06.076084: Pseudo dice [np.float32(0.8062)] 
2025-07-10 08:02:06.076181: Epoch time: 46.3 s 
2025-07-10 08:02:07.209615:  
2025-07-10 08:02:07.209817: Epoch 846 
2025-07-10 08:02:07.209960: Current learning rate: 0.00186 
2025-07-10 08:02:53.449684: train_loss -0.4489 
2025-07-10 08:02:53.450199: val_loss -0.4463 
2025-07-10 08:02:53.450291: Pseudo dice [np.float32(0.7494)] 
2025-07-10 08:02:53.450419: Epoch time: 46.24 s 
2025-07-10 08:02:54.601511:  
2025-07-10 08:02:54.601718: Epoch 847 
2025-07-10 08:02:54.601843: Current learning rate: 0.00185 
2025-07-10 08:03:41.004237: train_loss -0.4532 
2025-07-10 08:03:41.004583: val_loss -0.4128 
2025-07-10 08:03:41.004659: Pseudo dice [np.float32(0.5692)] 
2025-07-10 08:03:41.004757: Epoch time: 46.4 s 
2025-07-10 08:03:42.181570:  
2025-07-10 08:03:42.182148: Epoch 848 
2025-07-10 08:03:42.182386: Current learning rate: 0.00184 
2025-07-10 08:04:28.120927: train_loss -0.4639 
2025-07-10 08:04:28.121382: val_loss -0.4644 
2025-07-10 08:04:28.121466: Pseudo dice [np.float32(0.6896)] 
2025-07-10 08:04:28.121580: Epoch time: 45.94 s 
2025-07-10 08:04:29.291151:  
2025-07-10 08:04:29.291527: Epoch 849 
2025-07-10 08:04:29.291684: Current learning rate: 0.00182 
2025-07-10 08:05:16.719595: train_loss -0.4783 
2025-07-10 08:05:16.719975: val_loss -0.4892 
2025-07-10 08:05:16.720056: Pseudo dice [np.float32(0.7769)] 
2025-07-10 08:05:16.720205: Epoch time: 47.43 s 
2025-07-10 08:05:18.984629:  
2025-07-10 08:05:18.985143: Epoch 850 
2025-07-10 08:05:18.985319: Current learning rate: 0.00181 
2025-07-10 08:06:05.871854: train_loss -0.4885 
2025-07-10 08:06:05.873019: val_loss -0.4661 
2025-07-10 08:06:05.873191: Pseudo dice [np.float32(0.7148)] 
2025-07-10 08:06:05.873400: Epoch time: 46.89 s 
2025-07-10 08:06:07.082273:  
2025-07-10 08:06:07.082696: Epoch 851 
2025-07-10 08:06:07.082903: Current learning rate: 0.0018 
2025-07-10 08:06:53.563763: train_loss -0.4671 
2025-07-10 08:06:53.564616: val_loss -0.4795 
2025-07-10 08:06:53.564732: Pseudo dice [np.float32(0.8071)] 
2025-07-10 08:06:53.564876: Epoch time: 46.48 s 
2025-07-10 08:06:54.847478:  
2025-07-10 08:06:54.847774: Epoch 852 
2025-07-10 08:06:54.847928: Current learning rate: 0.00179 
2025-07-10 08:07:41.585264: train_loss -0.4852 
2025-07-10 08:07:41.585659: val_loss -0.4767 
2025-07-10 08:07:41.585744: Pseudo dice [np.float32(0.7917)] 
2025-07-10 08:07:41.585851: Epoch time: 46.74 s 
2025-07-10 08:07:42.734001:  
2025-07-10 08:07:42.734582: Epoch 853 
2025-07-10 08:07:42.734743: Current learning rate: 0.00178 
2025-07-10 08:08:29.946450: train_loss -0.4823 
2025-07-10 08:08:29.947092: val_loss -0.4708 
2025-07-10 08:08:29.947181: Pseudo dice [np.float32(0.8434)] 
2025-07-10 08:08:29.947304: Epoch time: 47.21 s 
2025-07-10 08:08:31.576766:  
2025-07-10 08:08:31.576933: Epoch 854 
2025-07-10 08:08:31.577052: Current learning rate: 0.00177 
2025-07-10 08:09:17.763529: train_loss -0.4908 
2025-07-10 08:09:17.764268: val_loss -0.5261 
2025-07-10 08:09:17.764382: Pseudo dice [np.float32(0.8383)] 
2025-07-10 08:09:17.764516: Epoch time: 46.19 s 
2025-07-10 08:09:18.916055:  
2025-07-10 08:09:18.916389: Epoch 855 
2025-07-10 08:09:18.916619: Current learning rate: 0.00176 
2025-07-10 08:10:05.022856: train_loss -0.4864 
2025-07-10 08:10:05.023681: val_loss -0.491 
2025-07-10 08:10:05.023783: Pseudo dice [np.float32(0.8063)] 
2025-07-10 08:10:05.023952: Epoch time: 46.11 s 
2025-07-10 08:10:06.293021:  
2025-07-10 08:10:06.293384: Epoch 856 
2025-07-10 08:10:06.293628: Current learning rate: 0.00175 
2025-07-10 08:10:52.635278: train_loss -0.4972 
2025-07-10 08:10:52.635666: val_loss -0.4768 
2025-07-10 08:10:52.635745: Pseudo dice [np.float32(0.7982)] 
2025-07-10 08:10:52.635843: Epoch time: 46.34 s 
2025-07-10 08:10:53.812201:  
2025-07-10 08:10:53.812474: Epoch 857 
2025-07-10 08:10:53.812664: Current learning rate: 0.00174 
2025-07-10 08:11:39.738301: train_loss -0.4929 
2025-07-10 08:11:39.739888: val_loss -0.4949 
2025-07-10 08:11:39.740097: Pseudo dice [np.float32(0.8082)] 
2025-07-10 08:11:39.740230: Epoch time: 45.93 s 
2025-07-10 08:11:40.977977:  
2025-07-10 08:11:40.978364: Epoch 858 
2025-07-10 08:11:40.978483: Current learning rate: 0.00173 
2025-07-10 08:12:27.773448: train_loss -0.4939 
2025-07-10 08:12:27.773844: val_loss -0.4989 
2025-07-10 08:12:27.773918: Pseudo dice [np.float32(0.819)] 
2025-07-10 08:12:27.774017: Epoch time: 46.8 s 
2025-07-10 08:12:28.898250:  
2025-07-10 08:12:28.898611: Epoch 859 
2025-07-10 08:12:28.898908: Current learning rate: 0.00172 
2025-07-10 08:13:15.144942: train_loss -0.4934 
2025-07-10 08:13:15.145504: val_loss -0.4828 
2025-07-10 08:13:15.146842: Pseudo dice [np.float32(0.7723)] 
2025-07-10 08:13:15.146958: Epoch time: 46.25 s 
2025-07-10 08:13:16.258515:  
2025-07-10 08:13:16.258859: Epoch 860 
2025-07-10 08:13:16.259011: Current learning rate: 0.0017 
2025-07-10 08:14:03.086921: train_loss -0.4925 
2025-07-10 08:14:03.087801: val_loss -0.4834 
2025-07-10 08:14:03.087878: Pseudo dice [np.float32(0.7743)] 
2025-07-10 08:14:03.088007: Epoch time: 46.83 s 
2025-07-10 08:14:04.244573:  
2025-07-10 08:14:04.244814: Epoch 861 
2025-07-10 08:14:04.244912: Current learning rate: 0.00169 
2025-07-10 08:14:50.932032: train_loss -0.4898 
2025-07-10 08:14:50.932624: val_loss -0.5166 
2025-07-10 08:14:50.932706: Pseudo dice [np.float32(0.8551)] 
2025-07-10 08:14:50.932809: Epoch time: 46.69 s 
2025-07-10 08:14:52.047167:  
2025-07-10 08:14:52.047610: Epoch 862 
2025-07-10 08:14:52.047743: Current learning rate: 0.00168 
2025-07-10 08:15:39.261858: train_loss -0.4943 
2025-07-10 08:15:39.262265: val_loss -0.482 
2025-07-10 08:15:39.262346: Pseudo dice [np.float32(0.7812)] 
2025-07-10 08:15:39.262448: Epoch time: 47.22 s 
2025-07-10 08:15:40.420803:  
2025-07-10 08:15:40.421132: Epoch 863 
2025-07-10 08:15:40.421392: Current learning rate: 0.00167 
2025-07-10 08:16:27.296191: train_loss -0.4935 
2025-07-10 08:16:27.296660: val_loss -0.5282 
2025-07-10 08:16:27.296757: Pseudo dice [np.float32(0.8282)] 
2025-07-10 08:16:27.296876: Epoch time: 46.88 s 
2025-07-10 08:16:28.489247:  
2025-07-10 08:16:28.489616: Epoch 864 
2025-07-10 08:16:28.489755: Current learning rate: 0.00166 
2025-07-10 08:17:15.338153: train_loss -0.5026 
2025-07-10 08:17:15.338708: val_loss -0.5171 
2025-07-10 08:17:15.338792: Pseudo dice [np.float32(0.8223)] 
2025-07-10 08:17:15.338895: Epoch time: 46.85 s 
2025-07-10 08:17:16.502236:  
2025-07-10 08:17:16.503086: Epoch 865 
2025-07-10 08:17:16.503320: Current learning rate: 0.00165 
2025-07-10 08:18:02.212069: train_loss -0.4963 
2025-07-10 08:18:02.213042: val_loss -0.5037 
2025-07-10 08:18:02.213316: Pseudo dice [np.float32(0.7804)] 
2025-07-10 08:18:02.213491: Epoch time: 45.71 s 
2025-07-10 08:18:04.096468:  
2025-07-10 08:18:04.096867: Epoch 866 
2025-07-10 08:18:04.097003: Current learning rate: 0.00164 
2025-07-10 08:18:51.028735: train_loss -0.4962 
2025-07-10 08:18:51.029490: val_loss -0.5075 
2025-07-10 08:18:51.029627: Pseudo dice [np.float32(0.8174)] 
2025-07-10 08:18:51.029765: Epoch time: 46.93 s 
2025-07-10 08:18:52.233967:  
2025-07-10 08:18:52.234386: Epoch 867 
2025-07-10 08:18:52.234519: Current learning rate: 0.00163 
2025-07-10 08:19:37.796015: train_loss -0.479 
2025-07-10 08:19:37.797509: val_loss -0.4875 
2025-07-10 08:19:37.797773: Pseudo dice [np.float32(0.7812)] 
2025-07-10 08:19:37.798090: Epoch time: 45.56 s 
2025-07-10 08:19:39.101370:  
2025-07-10 08:19:39.101897: Epoch 868 
2025-07-10 08:19:39.102046: Current learning rate: 0.00162 
2025-07-10 08:20:25.501741: train_loss -0.4629 
2025-07-10 08:20:25.502407: val_loss -0.455 
2025-07-10 08:20:25.502484: Pseudo dice [np.float32(0.772)] 
2025-07-10 08:20:25.502620: Epoch time: 46.4 s 
2025-07-10 08:20:26.668513:  
2025-07-10 08:20:26.669106: Epoch 869 
2025-07-10 08:20:26.669423: Current learning rate: 0.00161 
2025-07-10 08:21:13.192376: train_loss -0.4706 
2025-07-10 08:21:13.192815: val_loss -0.4617 
2025-07-10 08:21:13.193070: Pseudo dice [np.float32(0.7163)] 
2025-07-10 08:21:13.193196: Epoch time: 46.52 s 
2025-07-10 08:21:14.413142:  
2025-07-10 08:21:14.413475: Epoch 870 
2025-07-10 08:21:14.413617: Current learning rate: 0.00159 
2025-07-10 08:22:00.574148: train_loss -0.4832 
2025-07-10 08:22:00.574551: val_loss -0.4909 
2025-07-10 08:22:00.574636: Pseudo dice [np.float32(0.806)] 
2025-07-10 08:22:00.574755: Epoch time: 46.16 s 
2025-07-10 08:22:01.725476:  
2025-07-10 08:22:01.726110: Epoch 871 
2025-07-10 08:22:01.726268: Current learning rate: 0.00158 
2025-07-10 08:22:47.971046: train_loss -0.4723 
2025-07-10 08:22:47.971704: val_loss -0.4599 
2025-07-10 08:22:47.971871: Pseudo dice [np.float32(0.8055)] 
2025-07-10 08:22:47.971985: Epoch time: 46.25 s 
2025-07-10 08:22:49.103366:  
2025-07-10 08:22:49.103708: Epoch 872 
2025-07-10 08:22:49.103872: Current learning rate: 0.00157 
2025-07-10 08:23:35.610084: train_loss -0.4752 
2025-07-10 08:23:35.610638: val_loss -0.4939 
2025-07-10 08:23:35.610724: Pseudo dice [np.float32(0.7712)] 
2025-07-10 08:23:35.610840: Epoch time: 46.51 s 
2025-07-10 08:23:36.763211:  
2025-07-10 08:23:36.763513: Epoch 873 
2025-07-10 08:23:36.763840: Current learning rate: 0.00156 
2025-07-10 08:24:22.963953: train_loss -0.4888 
2025-07-10 08:24:22.964721: val_loss -0.4849 
2025-07-10 08:24:22.964910: Pseudo dice [np.float32(0.8282)] 
2025-07-10 08:24:22.965155: Epoch time: 46.2 s 
2025-07-10 08:24:24.133746:  
2025-07-10 08:24:24.134128: Epoch 874 
2025-07-10 08:24:24.134261: Current learning rate: 0.00155 
2025-07-10 08:25:11.050321: train_loss -0.4871 
2025-07-10 08:25:11.050844: val_loss -0.4755 
2025-07-10 08:25:11.054326: Pseudo dice [np.float32(0.8126)] 
2025-07-10 08:25:11.054617: Epoch time: 46.92 s 
2025-07-10 08:25:12.233644:  
2025-07-10 08:25:12.233898: Epoch 875 
2025-07-10 08:25:12.234026: Current learning rate: 0.00154 
2025-07-10 08:25:59.717747: train_loss -0.4818 
2025-07-10 08:25:59.718271: val_loss -0.4824 
2025-07-10 08:25:59.718352: Pseudo dice [np.float32(0.7844)] 
2025-07-10 08:25:59.718476: Epoch time: 47.49 s 
2025-07-10 08:26:00.866817:  
2025-07-10 08:26:00.867079: Epoch 876 
2025-07-10 08:26:00.867455: Current learning rate: 0.00153 
2025-07-10 08:26:47.492502: train_loss -0.4717 
2025-07-10 08:26:47.492922: val_loss -0.4415 
2025-07-10 08:26:47.493003: Pseudo dice [np.float32(0.7533)] 
2025-07-10 08:26:47.493114: Epoch time: 46.63 s 
2025-07-10 08:26:48.632326:  
2025-07-10 08:26:48.633043: Epoch 877 
2025-07-10 08:26:48.633221: Current learning rate: 0.00152 
2025-07-10 08:27:34.612732: train_loss -0.4635 
2025-07-10 08:27:34.613055: val_loss -0.4925 
2025-07-10 08:27:34.613137: Pseudo dice [np.float32(0.7754)] 
2025-07-10 08:27:34.613259: Epoch time: 45.98 s 
2025-07-10 08:27:36.424994:  
2025-07-10 08:27:36.425421: Epoch 878 
2025-07-10 08:27:36.425608: Current learning rate: 0.00151 
2025-07-10 08:28:22.486244: train_loss -0.495 
2025-07-10 08:28:22.487155: val_loss -0.4887 
2025-07-10 08:28:22.487311: Pseudo dice [np.float32(0.7541)] 
2025-07-10 08:28:22.487485: Epoch time: 46.06 s 
2025-07-10 08:28:23.692263:  
2025-07-10 08:28:23.692651: Epoch 879 
2025-07-10 08:28:23.692773: Current learning rate: 0.00149 
2025-07-10 08:29:09.978267: train_loss -0.4869 
2025-07-10 08:29:09.979069: val_loss -0.498 
2025-07-10 08:29:09.979182: Pseudo dice [np.float32(0.8536)] 
2025-07-10 08:29:09.979371: Epoch time: 46.29 s 
2025-07-10 08:29:11.278872:  
2025-07-10 08:29:11.279134: Epoch 880 
2025-07-10 08:29:11.279319: Current learning rate: 0.00148 
2025-07-10 08:29:58.420563: train_loss -0.4818 
2025-07-10 08:29:58.421184: val_loss -0.5002 
2025-07-10 08:29:58.421278: Pseudo dice [np.float32(0.8102)] 
2025-07-10 08:29:58.421410: Epoch time: 47.14 s 
2025-07-10 08:29:59.576369:  
2025-07-10 08:29:59.576731: Epoch 881 
2025-07-10 08:29:59.576916: Current learning rate: 0.00147 
2025-07-10 08:30:45.871094: train_loss -0.4904 
2025-07-10 08:30:45.872042: val_loss -0.4802 
2025-07-10 08:30:45.872252: Pseudo dice [np.float32(0.8195)] 
2025-07-10 08:30:45.872380: Epoch time: 46.3 s 
2025-07-10 08:30:47.072520:  
2025-07-10 08:30:47.072768: Epoch 882 
2025-07-10 08:30:47.072928: Current learning rate: 0.00146 
2025-07-10 08:31:33.441921: train_loss -0.4747 
2025-07-10 08:31:33.442398: val_loss -0.4641 
2025-07-10 08:31:33.442521: Pseudo dice [np.float32(0.7347)] 
2025-07-10 08:31:33.442648: Epoch time: 46.37 s 
2025-07-10 08:31:34.611852:  
2025-07-10 08:31:34.612213: Epoch 883 
2025-07-10 08:31:34.612355: Current learning rate: 0.00145 
2025-07-10 08:32:21.047955: train_loss -0.4936 
2025-07-10 08:32:21.048520: val_loss -0.4661 
2025-07-10 08:32:21.048625: Pseudo dice [np.float32(0.7538)] 
2025-07-10 08:32:21.048752: Epoch time: 46.44 s 
2025-07-10 08:32:22.236032:  
2025-07-10 08:32:22.236211: Epoch 884 
2025-07-10 08:32:22.236339: Current learning rate: 0.00144 
2025-07-10 08:33:08.583618: train_loss -0.479 
2025-07-10 08:33:08.584881: val_loss -0.5064 
2025-07-10 08:33:08.585078: Pseudo dice [np.float32(0.8295)] 
2025-07-10 08:33:08.585245: Epoch time: 46.35 s 
2025-07-10 08:33:09.745528:  
2025-07-10 08:33:09.745728: Epoch 885 
2025-07-10 08:33:09.745852: Current learning rate: 0.00143 
2025-07-10 08:33:56.500479: train_loss -0.4827 
2025-07-10 08:33:56.500895: val_loss -0.4894 
2025-07-10 08:33:56.500979: Pseudo dice [np.float32(0.7915)] 
2025-07-10 08:33:56.501090: Epoch time: 46.76 s 
2025-07-10 08:33:57.644316:  
2025-07-10 08:33:57.645111: Epoch 886 
2025-07-10 08:33:57.645355: Current learning rate: 0.00142 
2025-07-10 08:34:44.672460: train_loss -0.4987 
2025-07-10 08:34:44.672886: val_loss -0.498 
2025-07-10 08:34:44.672964: Pseudo dice [np.float32(0.8152)] 
2025-07-10 08:34:44.673074: Epoch time: 47.03 s 
2025-07-10 08:34:45.845526:  
2025-07-10 08:34:45.845993: Epoch 887 
2025-07-10 08:34:45.846173: Current learning rate: 0.00141 
2025-07-10 08:35:32.151157: train_loss -0.499 
2025-07-10 08:35:32.151904: val_loss -0.4823 
2025-07-10 08:35:32.151990: Pseudo dice [np.float32(0.7725)] 
2025-07-10 08:35:32.152156: Epoch time: 46.31 s 
2025-07-10 08:35:33.321444:  
2025-07-10 08:35:33.321806: Epoch 888 
2025-07-10 08:35:33.322049: Current learning rate: 0.00139 
2025-07-10 08:36:20.759953: train_loss -0.496 
2025-07-10 08:36:20.760554: val_loss -0.5084 
2025-07-10 08:36:20.760640: Pseudo dice [np.float32(0.8267)] 
2025-07-10 08:36:20.760751: Epoch time: 47.44 s 
2025-07-10 08:36:21.980809:  
2025-07-10 08:36:21.981335: Epoch 889 
2025-07-10 08:36:21.981506: Current learning rate: 0.00138 
2025-07-10 08:37:08.474204: train_loss -0.5046 
2025-07-10 08:37:08.474763: val_loss -0.5004 
2025-07-10 08:37:08.474850: Pseudo dice [np.float32(0.8003)] 
2025-07-10 08:37:08.474966: Epoch time: 46.49 s 
2025-07-10 08:37:10.287256:  
2025-07-10 08:37:10.287947: Epoch 890 
2025-07-10 08:37:10.288161: Current learning rate: 0.00137 
2025-07-10 08:37:56.501795: train_loss -0.5132 
2025-07-10 08:37:56.502250: val_loss -0.4912 
2025-07-10 08:37:56.502332: Pseudo dice [np.float32(0.7981)] 
2025-07-10 08:37:56.502440: Epoch time: 46.22 s 
2025-07-10 08:37:57.675470:  
2025-07-10 08:37:57.675704: Epoch 891 
2025-07-10 08:37:57.675838: Current learning rate: 0.00136 
2025-07-10 08:38:44.483455: train_loss -0.5055 
2025-07-10 08:38:44.483982: val_loss -0.5052 
2025-07-10 08:38:44.484065: Pseudo dice [np.float32(0.8101)] 
2025-07-10 08:38:44.484171: Epoch time: 46.81 s 
2025-07-10 08:38:45.656039:  
2025-07-10 08:38:45.656511: Epoch 892 
2025-07-10 08:38:45.656672: Current learning rate: 0.00135 
2025-07-10 08:39:32.182516: train_loss -0.4956 
2025-07-10 08:39:32.183229: val_loss -0.4911 
2025-07-10 08:39:32.183323: Pseudo dice [np.float32(0.8118)] 
2025-07-10 08:39:32.183450: Epoch time: 46.53 s 
2025-07-10 08:39:33.383809:  
2025-07-10 08:39:33.384260: Epoch 893 
2025-07-10 08:39:33.384699: Current learning rate: 0.00134 
2025-07-10 08:40:19.454651: train_loss -0.5004 
2025-07-10 08:40:19.455092: val_loss -0.5047 
2025-07-10 08:40:19.455173: Pseudo dice [np.float32(0.8213)] 
2025-07-10 08:40:19.455312: Epoch time: 46.07 s 
2025-07-10 08:40:20.717495:  
2025-07-10 08:40:20.718170: Epoch 894 
2025-07-10 08:40:20.718548: Current learning rate: 0.00133 
2025-07-10 08:41:07.008512: train_loss -0.4993 
2025-07-10 08:41:07.009079: val_loss -0.4817 
2025-07-10 08:41:07.009168: Pseudo dice [np.float32(0.754)] 
2025-07-10 08:41:07.009293: Epoch time: 46.29 s 
2025-07-10 08:41:08.188017:  
2025-07-10 08:41:08.188336: Epoch 895 
2025-07-10 08:41:08.188496: Current learning rate: 0.00132 
2025-07-10 08:41:55.104329: train_loss -0.4914 
2025-07-10 08:41:55.104898: val_loss -0.5018 
2025-07-10 08:41:55.104990: Pseudo dice [np.float32(0.8096)] 
2025-07-10 08:41:55.105110: Epoch time: 46.92 s 
2025-07-10 08:41:56.263318:  
2025-07-10 08:41:56.263485: Epoch 896 
2025-07-10 08:41:56.263616: Current learning rate: 0.0013 
2025-07-10 08:42:42.967460: train_loss -0.502 
2025-07-10 08:42:42.968290: val_loss -0.4896 
2025-07-10 08:42:42.968391: Pseudo dice [np.float32(0.8029)] 
2025-07-10 08:42:42.968520: Epoch time: 46.71 s 
2025-07-10 08:42:44.144926:  
2025-07-10 08:42:44.145197: Epoch 897 
2025-07-10 08:42:44.145435: Current learning rate: 0.00129 
2025-07-10 08:43:30.177708: train_loss -0.4977 
2025-07-10 08:43:30.178380: val_loss -0.4915 
2025-07-10 08:43:30.178461: Pseudo dice [np.float32(0.795)] 
2025-07-10 08:43:30.178596: Epoch time: 46.03 s 
2025-07-10 08:43:31.352841:  
2025-07-10 08:43:31.353435: Epoch 898 
2025-07-10 08:43:31.353650: Current learning rate: 0.00128 
2025-07-10 08:44:16.994295: train_loss -0.4983 
2025-07-10 08:44:16.995322: val_loss -0.491 
2025-07-10 08:44:16.995408: Pseudo dice [np.float32(0.8129)] 
2025-07-10 08:44:16.995582: Epoch time: 45.64 s 
2025-07-10 08:44:18.148335:  
2025-07-10 08:44:18.148981: Epoch 899 
2025-07-10 08:44:18.149134: Current learning rate: 0.00127 
2025-07-10 08:45:05.018081: train_loss -0.4971 
2025-07-10 08:45:05.018647: val_loss -0.5045 
2025-07-10 08:45:05.018747: Pseudo dice [np.float32(0.8155)] 
2025-07-10 08:45:05.018873: Epoch time: 46.87 s 
2025-07-10 08:45:07.209118:  
2025-07-10 08:45:07.209589: Epoch 900 
2025-07-10 08:45:07.209809: Current learning rate: 0.00126 
2025-07-10 08:45:52.844002: train_loss -0.5008 
2025-07-10 08:45:52.844401: val_loss -0.4946 
2025-07-10 08:45:52.844634: Pseudo dice [np.float32(0.8045)] 
2025-07-10 08:45:52.844759: Epoch time: 45.64 s 
2025-07-10 08:45:54.039714:  
2025-07-10 08:45:54.040142: Epoch 901 
2025-07-10 08:45:54.040277: Current learning rate: 0.00125 
2025-07-10 08:46:39.795608: train_loss -0.5044 
2025-07-10 08:46:39.796185: val_loss -0.4959 
2025-07-10 08:46:39.796270: Pseudo dice [np.float32(0.8113)] 
2025-07-10 08:46:39.796380: Epoch time: 45.76 s 
2025-07-10 08:46:41.612941:  
2025-07-10 08:46:41.613410: Epoch 902 
2025-07-10 08:46:41.613557: Current learning rate: 0.00124 
2025-07-10 08:47:28.109181: train_loss -0.4962 
2025-07-10 08:47:28.110060: val_loss -0.5113 
2025-07-10 08:47:28.110202: Pseudo dice [np.float32(0.7929)] 
2025-07-10 08:47:28.110345: Epoch time: 46.5 s 
2025-07-10 08:47:29.260373:  
2025-07-10 08:47:29.260740: Epoch 903 
2025-07-10 08:47:29.260941: Current learning rate: 0.00122 
2025-07-10 08:48:15.736514: train_loss -0.5066 
2025-07-10 08:48:15.736969: val_loss -0.5139 
2025-07-10 08:48:15.737045: Pseudo dice [np.float32(0.8292)] 
2025-07-10 08:48:15.737146: Epoch time: 46.48 s 
2025-07-10 08:48:16.941819:  
2025-07-10 08:48:16.942503: Epoch 904 
2025-07-10 08:48:16.942688: Current learning rate: 0.00121 
2025-07-10 08:49:02.382896: train_loss -0.5046 
2025-07-10 08:49:02.383764: val_loss -0.5036 
2025-07-10 08:49:02.383855: Pseudo dice [np.float32(0.8182)] 
2025-07-10 08:49:02.383978: Epoch time: 45.44 s 
2025-07-10 08:49:03.547856:  
2025-07-10 08:49:03.548375: Epoch 905 
2025-07-10 08:49:03.548560: Current learning rate: 0.0012 
2025-07-10 08:49:49.996677: train_loss -0.5021 
2025-07-10 08:49:49.997202: val_loss -0.5045 
2025-07-10 08:49:49.997282: Pseudo dice [np.float32(0.8511)] 
2025-07-10 08:49:49.997390: Epoch time: 46.45 s 
2025-07-10 08:49:51.177246:  
2025-07-10 08:49:51.177574: Epoch 906 
2025-07-10 08:49:51.177691: Current learning rate: 0.00119 
2025-07-10 08:50:37.790231: train_loss -0.501 
2025-07-10 08:50:37.790752: val_loss -0.5227 
2025-07-10 08:50:37.790833: Pseudo dice [np.float32(0.8519)] 
2025-07-10 08:50:37.790943: Epoch time: 46.61 s 
2025-07-10 08:50:38.943586:  
2025-07-10 08:50:38.943846: Epoch 907 
2025-07-10 08:50:38.943977: Current learning rate: 0.00118 
2025-07-10 08:51:24.806501: train_loss -0.4977 
2025-07-10 08:51:24.807385: val_loss -0.5139 
2025-07-10 08:51:24.807492: Pseudo dice [np.float32(0.8105)] 
2025-07-10 08:51:24.807653: Epoch time: 45.86 s 
2025-07-10 08:51:26.048932:  
2025-07-10 08:51:26.049558: Epoch 908 
2025-07-10 08:51:26.049737: Current learning rate: 0.00117 
2025-07-10 08:52:11.906147: train_loss -0.5099 
2025-07-10 08:52:11.907363: val_loss -0.5116 
2025-07-10 08:52:11.907505: Pseudo dice [np.float32(0.8514)] 
2025-07-10 08:52:11.907732: Epoch time: 45.86 s 
2025-07-10 08:52:13.175704:  
2025-07-10 08:52:13.176031: Epoch 909 
2025-07-10 08:52:13.176161: Current learning rate: 0.00116 
2025-07-10 08:52:59.603689: train_loss -0.5074 
2025-07-10 08:52:59.604205: val_loss -0.5215 
2025-07-10 08:52:59.604283: Pseudo dice [np.float32(0.8027)] 
2025-07-10 08:52:59.604391: Epoch time: 46.43 s 
2025-07-10 08:53:00.778471:  
2025-07-10 08:53:00.778778: Epoch 910 
2025-07-10 08:53:00.778910: Current learning rate: 0.00115 
2025-07-10 08:53:46.843386: train_loss -0.5136 
2025-07-10 08:53:46.844075: val_loss -0.5049 
2025-07-10 08:53:46.844180: Pseudo dice [np.float32(0.7836)] 
2025-07-10 08:53:46.844305: Epoch time: 46.07 s 
2025-07-10 08:53:48.026845:  
2025-07-10 08:53:48.027106: Epoch 911 
2025-07-10 08:53:48.027227: Current learning rate: 0.00113 
2025-07-10 08:54:35.236057: train_loss -0.5117 
2025-07-10 08:54:35.236595: val_loss -0.5207 
2025-07-10 08:54:35.236673: Pseudo dice [np.float32(0.842)] 
2025-07-10 08:54:35.236789: Epoch time: 47.21 s 
2025-07-10 08:54:36.394680:  
2025-07-10 08:54:36.395112: Epoch 912 
2025-07-10 08:54:36.395237: Current learning rate: 0.00112 
2025-07-10 08:55:22.652413: train_loss -0.4978 
2025-07-10 08:55:22.653037: val_loss -0.5132 
2025-07-10 08:55:22.653121: Pseudo dice [np.float32(0.8359)] 
2025-07-10 08:55:22.653233: Epoch time: 46.26 s 
2025-07-10 08:55:23.905154:  
2025-07-10 08:55:23.905486: Epoch 913 
2025-07-10 08:55:23.905629: Current learning rate: 0.00111 
2025-07-10 08:56:09.973666: train_loss -0.5112 
2025-07-10 08:56:09.974069: val_loss -0.5072 
2025-07-10 08:56:09.974145: Pseudo dice [np.float32(0.8161)] 
2025-07-10 08:56:09.974262: Epoch time: 46.07 s 
2025-07-10 08:56:11.198123:  
2025-07-10 08:56:11.198493: Epoch 914 
2025-07-10 08:56:11.198636: Current learning rate: 0.0011 
2025-07-10 08:56:57.407448: train_loss -0.5133 
2025-07-10 08:56:57.408069: val_loss -0.5142 
2025-07-10 08:56:57.408152: Pseudo dice [np.float32(0.8112)] 
2025-07-10 08:56:57.408270: Epoch time: 46.21 s 
2025-07-10 08:56:59.275064:  
2025-07-10 08:56:59.275952: Epoch 915 
2025-07-10 08:56:59.276146: Current learning rate: 0.00109 
2025-07-10 08:57:45.595917: train_loss -0.5087 
2025-07-10 08:57:45.596506: val_loss -0.5028 
2025-07-10 08:57:45.596611: Pseudo dice [np.float32(0.7598)] 
2025-07-10 08:57:45.596762: Epoch time: 46.32 s 
2025-07-10 08:57:46.730201:  
2025-07-10 08:57:46.730774: Epoch 916 
2025-07-10 08:57:46.730981: Current learning rate: 0.00108 
2025-07-10 08:58:32.185328: train_loss -0.5034 
2025-07-10 08:58:32.185951: val_loss -0.5135 
2025-07-10 08:58:32.186037: Pseudo dice [np.float32(0.8086)] 
2025-07-10 08:58:32.186152: Epoch time: 45.46 s 
2025-07-10 08:58:33.338557:  
2025-07-10 08:58:33.338931: Epoch 917 
2025-07-10 08:58:33.339149: Current learning rate: 0.00106 
2025-07-10 08:59:19.150365: train_loss -0.4947 
2025-07-10 08:59:19.150831: val_loss -0.4903 
2025-07-10 08:59:19.150907: Pseudo dice [np.float32(0.7966)] 
2025-07-10 08:59:19.151018: Epoch time: 45.81 s 
2025-07-10 08:59:20.293114:  
2025-07-10 08:59:20.293317: Epoch 918 
2025-07-10 08:59:20.293537: Current learning rate: 0.00105 
2025-07-10 09:00:05.824805: train_loss -0.497 
2025-07-10 09:00:05.825481: val_loss -0.4964 
2025-07-10 09:00:05.825576: Pseudo dice [np.float32(0.8381)] 
2025-07-10 09:00:05.825701: Epoch time: 45.53 s 
2025-07-10 09:00:07.017188:  
2025-07-10 09:00:07.017582: Epoch 919 
2025-07-10 09:00:07.017783: Current learning rate: 0.00104 
2025-07-10 09:00:53.085278: train_loss -0.5139 
2025-07-10 09:00:53.085738: val_loss -0.5003 
2025-07-10 09:00:53.085872: Pseudo dice [np.float32(0.777)] 
2025-07-10 09:00:53.086001: Epoch time: 46.07 s 
2025-07-10 09:00:54.253243:  
2025-07-10 09:00:54.253695: Epoch 920 
2025-07-10 09:00:54.253976: Current learning rate: 0.00103 
2025-07-10 09:01:40.271104: train_loss -0.5003 
2025-07-10 09:01:40.271895: val_loss -0.5307 
2025-07-10 09:01:40.272010: Pseudo dice [np.float32(0.8136)] 
2025-07-10 09:01:40.272176: Epoch time: 46.02 s 
2025-07-10 09:01:41.477746:  
2025-07-10 09:01:41.478200: Epoch 921 
2025-07-10 09:01:41.478382: Current learning rate: 0.00102 
2025-07-10 09:02:26.860877: train_loss -0.4977 
2025-07-10 09:02:26.861404: val_loss -0.4997 
2025-07-10 09:02:26.861498: Pseudo dice [np.float32(0.8301)] 
2025-07-10 09:02:26.861648: Epoch time: 45.38 s 
2025-07-10 09:02:28.030298:  
2025-07-10 09:02:28.030583: Epoch 922 
2025-07-10 09:02:28.030811: Current learning rate: 0.00101 
2025-07-10 09:03:14.288222: train_loss -0.5016 
2025-07-10 09:03:14.288808: val_loss -0.4906 
2025-07-10 09:03:14.288889: Pseudo dice [np.float32(0.793)] 
2025-07-10 09:03:14.288987: Epoch time: 46.26 s 
2025-07-10 09:03:15.466293:  
2025-07-10 09:03:15.466552: Epoch 923 
2025-07-10 09:03:15.466805: Current learning rate: 0.001 
2025-07-10 09:04:01.052039: train_loss -0.5125 
2025-07-10 09:04:01.052921: val_loss -0.5239 
2025-07-10 09:04:01.053015: Pseudo dice [np.float32(0.845)] 
2025-07-10 09:04:01.053195: Epoch time: 45.59 s 
2025-07-10 09:04:02.199125:  
2025-07-10 09:04:02.199642: Epoch 924 
2025-07-10 09:04:02.199962: Current learning rate: 0.00098 
2025-07-10 09:04:48.236620: train_loss -0.5136 
2025-07-10 09:04:48.237137: val_loss -0.5109 
2025-07-10 09:04:48.237227: Pseudo dice [np.float32(0.8306)] 
2025-07-10 09:04:48.237348: Epoch time: 46.04 s 
2025-07-10 09:04:49.408423:  
2025-07-10 09:04:49.408943: Epoch 925 
2025-07-10 09:04:49.409204: Current learning rate: 0.00097 
2025-07-10 09:05:36.114201: train_loss -0.5068 
2025-07-10 09:05:36.114818: val_loss -0.517 
2025-07-10 09:05:36.114895: Pseudo dice [np.float32(0.8513)] 
2025-07-10 09:05:36.115007: Epoch time: 46.71 s 
2025-07-10 09:05:37.400104:  
2025-07-10 09:05:37.400607: Epoch 926 
2025-07-10 09:05:37.400756: Current learning rate: 0.00096 
2025-07-10 09:06:23.410283: train_loss -0.5065 
2025-07-10 09:06:23.410796: val_loss -0.4983 
2025-07-10 09:06:23.410884: Pseudo dice [np.float32(0.8404)] 
2025-07-10 09:06:23.411106: Epoch time: 46.01 s 
2025-07-10 09:06:25.286703:  
2025-07-10 09:06:25.287096: Epoch 927 
2025-07-10 09:06:25.287393: Current learning rate: 0.00095 
2025-07-10 09:07:10.292389: train_loss -0.5005 
2025-07-10 09:07:10.293067: val_loss -0.5017 
2025-07-10 09:07:10.293192: Pseudo dice [np.float32(0.8505)] 
2025-07-10 09:07:10.293329: Epoch time: 45.01 s 
2025-07-10 09:07:11.570424:  
2025-07-10 09:07:11.570867: Epoch 928 
2025-07-10 09:07:11.570996: Current learning rate: 0.00094 
2025-07-10 09:07:57.191776: train_loss -0.5013 
2025-07-10 09:07:57.192129: val_loss -0.4991 
2025-07-10 09:07:57.192290: Pseudo dice [np.float32(0.8389)] 
2025-07-10 09:07:57.192428: Epoch time: 45.62 s 
2025-07-10 09:07:58.379034:  
2025-07-10 09:07:58.379352: Epoch 929 
2025-07-10 09:07:58.379518: Current learning rate: 0.00092 
2025-07-10 09:08:44.362859: train_loss -0.5086 
2025-07-10 09:08:44.363311: val_loss -0.5117 
2025-07-10 09:08:44.363403: Pseudo dice [np.float32(0.8474)] 
2025-07-10 09:08:44.363644: Epoch time: 45.98 s 
2025-07-10 09:08:45.544799:  
2025-07-10 09:08:45.545142: Epoch 930 
2025-07-10 09:08:45.545269: Current learning rate: 0.00091 
2025-07-10 09:09:31.377994: train_loss -0.4995 
2025-07-10 09:09:31.379384: val_loss -0.5256 
2025-07-10 09:09:31.383077: Pseudo dice [np.float32(0.8395)] 
2025-07-10 09:09:31.383488: Epoch time: 45.83 s 
2025-07-10 09:09:32.580991:  
2025-07-10 09:09:32.581419: Epoch 931 
2025-07-10 09:09:32.581867: Current learning rate: 0.0009 
2025-07-10 09:10:18.226178: train_loss -0.5172 
2025-07-10 09:10:18.226887: val_loss -0.4909 
2025-07-10 09:10:18.226989: Pseudo dice [np.float32(0.8209)] 
2025-07-10 09:10:18.227144: Epoch time: 45.65 s 
2025-07-10 09:10:19.393951:  
2025-07-10 09:10:19.394593: Epoch 932 
2025-07-10 09:10:19.394729: Current learning rate: 0.00089 
2025-07-10 09:11:05.097000: train_loss -0.508 
2025-07-10 09:11:05.097446: val_loss -0.4909 
2025-07-10 09:11:05.097526: Pseudo dice [np.float32(0.794)] 
2025-07-10 09:11:05.097647: Epoch time: 45.7 s 
2025-07-10 09:11:06.335116:  
2025-07-10 09:11:06.335567: Epoch 933 
2025-07-10 09:11:06.335995: Current learning rate: 0.00088 
2025-07-10 09:11:51.262187: train_loss -0.5068 
2025-07-10 09:11:51.263752: val_loss -0.517 
2025-07-10 09:11:51.263875: Pseudo dice [np.float32(0.8353)] 
2025-07-10 09:11:51.264167: Epoch time: 44.93 s 
2025-07-10 09:11:52.439246:  
2025-07-10 09:11:52.439610: Epoch 934 
2025-07-10 09:11:52.439864: Current learning rate: 0.00087 
2025-07-10 09:12:38.536794: train_loss -0.5114 
2025-07-10 09:12:38.537492: val_loss -0.5046 
2025-07-10 09:12:38.537601: Pseudo dice [np.float32(0.8231)] 
2025-07-10 09:12:38.537742: Epoch time: 46.1 s 
2025-07-10 09:12:39.703909:  
2025-07-10 09:12:39.704322: Epoch 935 
2025-07-10 09:12:39.704450: Current learning rate: 0.00085 
2025-07-10 09:13:25.918423: train_loss -0.5122 
2025-07-10 09:13:25.918936: val_loss -0.5019 
2025-07-10 09:13:25.919020: Pseudo dice [np.float32(0.8256)] 
2025-07-10 09:13:25.919154: Epoch time: 46.22 s 
2025-07-10 09:13:27.096660:  
2025-07-10 09:13:27.096901: Epoch 936 
2025-07-10 09:13:27.097039: Current learning rate: 0.00084 
2025-07-10 09:14:13.303665: train_loss -0.5134 
2025-07-10 09:14:13.304298: val_loss -0.5302 
2025-07-10 09:14:13.304384: Pseudo dice [np.float32(0.8465)] 
2025-07-10 09:14:13.304506: Epoch time: 46.21 s 
2025-07-10 09:14:14.488915:  
2025-07-10 09:14:14.489221: Epoch 937 
2025-07-10 09:14:14.489416: Current learning rate: 0.00083 
2025-07-10 09:15:00.146924: train_loss -0.5134 
2025-07-10 09:15:00.147497: val_loss -0.5199 
2025-07-10 09:15:00.147595: Pseudo dice [np.float32(0.851)] 
2025-07-10 09:15:00.147722: Epoch time: 45.66 s 
2025-07-10 09:15:01.361331:  
2025-07-10 09:15:01.361754: Epoch 938 
2025-07-10 09:15:01.361902: Current learning rate: 0.00082 
2025-07-10 09:15:46.814714: train_loss -0.5093 
2025-07-10 09:15:46.815227: val_loss -0.5012 
2025-07-10 09:15:46.815303: Pseudo dice [np.float32(0.8033)] 
2025-07-10 09:15:46.815412: Epoch time: 45.45 s 
2025-07-10 09:15:48.703048:  
2025-07-10 09:15:48.703454: Epoch 939 
2025-07-10 09:15:48.703779: Current learning rate: 0.00081 
2025-07-10 09:16:34.368100: train_loss -0.5137 
2025-07-10 09:16:34.369028: val_loss -0.5207 
2025-07-10 09:16:34.369104: Pseudo dice [np.float32(0.8111)] 
2025-07-10 09:16:34.369280: Epoch time: 45.67 s 
2025-07-10 09:16:35.556921:  
2025-07-10 09:16:35.557252: Epoch 940 
2025-07-10 09:16:35.557385: Current learning rate: 0.00079 
2025-07-10 09:17:21.141655: train_loss -0.5155 
2025-07-10 09:17:21.142141: val_loss -0.5132 
2025-07-10 09:17:21.142221: Pseudo dice [np.float32(0.8296)] 
2025-07-10 09:17:21.142332: Epoch time: 45.59 s 
2025-07-10 09:17:22.296122:  
2025-07-10 09:17:22.296431: Epoch 941 
2025-07-10 09:17:22.296603: Current learning rate: 0.00078 
2025-07-10 09:18:07.519459: train_loss -0.5185 
2025-07-10 09:18:07.521043: val_loss -0.5195 
2025-07-10 09:18:07.521271: Pseudo dice [np.float32(0.8331)] 
2025-07-10 09:18:07.521391: Epoch time: 45.22 s 
2025-07-10 09:18:08.708834:  
2025-07-10 09:18:08.709167: Epoch 942 
2025-07-10 09:18:08.709444: Current learning rate: 0.00077 
2025-07-10 09:18:54.404473: train_loss -0.521 
2025-07-10 09:18:54.404873: val_loss -0.5294 
2025-07-10 09:18:54.404950: Pseudo dice [np.float32(0.8336)] 
2025-07-10 09:18:54.405061: Epoch time: 45.7 s 
2025-07-10 09:18:55.540155:  
2025-07-10 09:18:55.540416: Epoch 943 
2025-07-10 09:18:55.540591: Current learning rate: 0.00076 
2025-07-10 09:19:40.877214: train_loss -0.516 
2025-07-10 09:19:40.877640: val_loss -0.5108 
2025-07-10 09:19:40.877719: Pseudo dice [np.float32(0.8159)] 
2025-07-10 09:19:40.877850: Epoch time: 45.34 s 
2025-07-10 09:19:42.102933:  
2025-07-10 09:19:42.103140: Epoch 944 
2025-07-10 09:19:42.103263: Current learning rate: 0.00075 
2025-07-10 09:20:27.745978: train_loss -0.5155 
2025-07-10 09:20:27.746536: val_loss -0.5058 
2025-07-10 09:20:27.746654: Pseudo dice [np.float32(0.828)] 
2025-07-10 09:20:27.746781: Epoch time: 45.64 s 
2025-07-10 09:20:28.942065:  
2025-07-10 09:20:28.942446: Epoch 945 
2025-07-10 09:20:28.942593: Current learning rate: 0.00074 
2025-07-10 09:21:14.781676: train_loss -0.5183 
2025-07-10 09:21:14.782295: val_loss -0.5014 
2025-07-10 09:21:14.782387: Pseudo dice [np.float32(0.8204)] 
2025-07-10 09:21:14.782503: Epoch time: 45.84 s 
2025-07-10 09:21:15.930145:  
2025-07-10 09:21:15.930562: Epoch 946 
2025-07-10 09:21:15.930691: Current learning rate: 0.00072 
2025-07-10 09:22:01.611228: train_loss -0.5145 
2025-07-10 09:22:01.611598: val_loss -0.5058 
2025-07-10 09:22:01.611865: Pseudo dice [np.float32(0.8297)] 
2025-07-10 09:22:01.611982: Epoch time: 45.68 s 
2025-07-10 09:22:02.760342:  
2025-07-10 09:22:02.760997: Epoch 947 
2025-07-10 09:22:02.761211: Current learning rate: 0.00071 
2025-07-10 09:22:48.494160: train_loss -0.5176 
2025-07-10 09:22:48.494753: val_loss -0.5513 
2025-07-10 09:22:48.494844: Pseudo dice [np.float32(0.8467)] 
2025-07-10 09:22:48.494952: Epoch time: 45.73 s 
2025-07-10 09:22:49.667733:  
2025-07-10 09:22:49.668125: Epoch 948 
2025-07-10 09:22:49.668281: Current learning rate: 0.0007 
2025-07-10 09:23:35.284879: train_loss -0.5135 
2025-07-10 09:23:35.285369: val_loss -0.5342 
2025-07-10 09:23:35.285532: Pseudo dice [np.float32(0.8409)] 
2025-07-10 09:23:35.285689: Epoch time: 45.62 s 
2025-07-10 09:23:36.544682:  
2025-07-10 09:23:36.545071: Epoch 949 
2025-07-10 09:23:36.545208: Current learning rate: 0.00069 
2025-07-10 09:24:22.662527: train_loss -0.516 
2025-07-10 09:24:22.663111: val_loss -0.5295 
2025-07-10 09:24:22.663189: Pseudo dice [np.float32(0.8223)] 
2025-07-10 09:24:22.663303: Epoch time: 46.12 s 
2025-07-10 09:24:24.951672:  
2025-07-10 09:24:24.951949: Epoch 950 
2025-07-10 09:24:24.952078: Current learning rate: 0.00067 
2025-07-10 09:25:12.296020: train_loss -0.5171 
2025-07-10 09:25:12.296357: val_loss -0.5216 
2025-07-10 09:25:12.296431: Pseudo dice [np.float32(0.8302)] 
2025-07-10 09:25:12.296535: Epoch time: 47.35 s 
2025-07-10 09:25:14.078372:  
2025-07-10 09:25:14.078830: Epoch 951 
2025-07-10 09:25:14.079113: Current learning rate: 0.00066 
2025-07-10 09:26:01.134436: train_loss -0.5083 
2025-07-10 09:26:01.134931: val_loss -0.4923 
2025-07-10 09:26:01.135010: Pseudo dice [np.float32(0.8175)] 
2025-07-10 09:26:01.135113: Epoch time: 47.06 s 
2025-07-10 09:26:02.352441:  
2025-07-10 09:26:02.352886: Epoch 952 
2025-07-10 09:26:02.353043: Current learning rate: 0.00065 
2025-07-10 09:26:48.779079: train_loss -0.507 
2025-07-10 09:26:48.779462: val_loss -0.5131 
2025-07-10 09:26:48.779552: Pseudo dice [np.float32(0.8402)] 
2025-07-10 09:26:48.779657: Epoch time: 46.43 s 
2025-07-10 09:26:49.895280:  
2025-07-10 09:26:49.895715: Epoch 953 
2025-07-10 09:26:49.895940: Current learning rate: 0.00064 
2025-07-10 09:27:37.084188: train_loss -0.5045 
2025-07-10 09:27:37.084695: val_loss -0.521 
2025-07-10 09:27:37.084774: Pseudo dice [np.float32(0.8175)] 
2025-07-10 09:27:37.084876: Epoch time: 47.19 s 
2025-07-10 09:27:38.265444:  
2025-07-10 09:27:38.265817: Epoch 954 
2025-07-10 09:27:38.265965: Current learning rate: 0.00063 
2025-07-10 09:28:24.867632: train_loss -0.5227 
2025-07-10 09:28:24.868218: val_loss -0.5208 
2025-07-10 09:28:24.868297: Pseudo dice [np.float32(0.8503)] 
2025-07-10 09:28:24.868405: Epoch time: 46.6 s 
2025-07-10 09:28:26.112774:  
2025-07-10 09:28:26.113245: Epoch 955 
2025-07-10 09:28:26.113382: Current learning rate: 0.00061 
2025-07-10 09:29:13.464718: train_loss -0.5175 
2025-07-10 09:29:13.465171: val_loss -0.5255 
2025-07-10 09:29:13.465281: Pseudo dice [np.float32(0.8135)] 
2025-07-10 09:29:13.465447: Epoch time: 47.35 s 
2025-07-10 09:29:14.662745:  
2025-07-10 09:29:14.663004: Epoch 956 
2025-07-10 09:29:14.663181: Current learning rate: 0.0006 
2025-07-10 09:30:00.483329: train_loss -0.5221 
2025-07-10 09:30:00.484459: val_loss -0.5263 
2025-07-10 09:30:00.484614: Pseudo dice [np.float32(0.831)] 
2025-07-10 09:30:00.484735: Epoch time: 45.82 s 
2025-07-10 09:30:01.676232:  
2025-07-10 09:30:01.676726: Epoch 957 
2025-07-10 09:30:01.676847: Current learning rate: 0.00059 
2025-07-10 09:30:48.119045: train_loss -0.5202 
2025-07-10 09:30:48.119409: val_loss -0.5331 
2025-07-10 09:30:48.119537: Pseudo dice [np.float32(0.8516)] 
2025-07-10 09:30:48.119665: Epoch time: 46.44 s 
2025-07-10 09:30:48.119797: Yayy! New best EMA pseudo Dice: 0.8309999704360962 
2025-07-10 09:30:50.164775:  
2025-07-10 09:30:50.165618: Epoch 958 
2025-07-10 09:30:50.165905: Current learning rate: 0.00058 
2025-07-10 09:31:38.445654: train_loss -0.5153 
2025-07-10 09:31:38.446001: val_loss -0.4968 
2025-07-10 09:31:38.446089: Pseudo dice [np.float32(0.8042)] 
2025-07-10 09:31:38.446198: Epoch time: 48.28 s 
2025-07-10 09:31:39.718489:  
2025-07-10 09:31:39.719089: Epoch 959 
2025-07-10 09:31:39.719335: Current learning rate: 0.00056 
2025-07-10 09:32:26.971159: train_loss -0.513 
2025-07-10 09:32:26.971664: val_loss -0.497 
2025-07-10 09:32:26.971757: Pseudo dice [np.float32(0.8319)] 
2025-07-10 09:32:26.971869: Epoch time: 47.25 s 
2025-07-10 09:32:28.156789:  
2025-07-10 09:32:28.157253: Epoch 960 
2025-07-10 09:32:28.157419: Current learning rate: 0.00055 
2025-07-10 09:33:15.423059: train_loss -0.5231 
2025-07-10 09:33:15.424090: val_loss -0.5104 
2025-07-10 09:33:15.424201: Pseudo dice [np.float32(0.8044)] 
2025-07-10 09:33:15.424357: Epoch time: 47.27 s 
2025-07-10 09:33:16.689915:  
2025-07-10 09:33:16.690060: Epoch 961 
2025-07-10 09:33:16.690163: Current learning rate: 0.00054 
2025-07-10 09:34:03.257680: train_loss -0.5221 
2025-07-10 09:34:03.258134: val_loss -0.5323 
2025-07-10 09:34:03.258290: Pseudo dice [np.float32(0.8392)] 
2025-07-10 09:34:03.258485: Epoch time: 46.57 s 
2025-07-10 09:34:04.534248:  
2025-07-10 09:34:04.534808: Epoch 962 
2025-07-10 09:34:04.535021: Current learning rate: 0.00053 
2025-07-10 09:34:51.751711: train_loss -0.5175 
2025-07-10 09:34:51.752238: val_loss -0.5227 
2025-07-10 09:34:51.752328: Pseudo dice [np.float32(0.8641)] 
2025-07-10 09:34:51.752439: Epoch time: 47.22 s 
2025-07-10 09:34:51.752513: Yayy! New best EMA pseudo Dice: 0.8312000036239624 
2025-07-10 09:34:54.562037:  
2025-07-10 09:34:54.562641: Epoch 963 
2025-07-10 09:34:54.562870: Current learning rate: 0.00051 
2025-07-10 09:35:41.517646: train_loss -0.5152 
2025-07-10 09:35:41.518236: val_loss -0.5255 
2025-07-10 09:35:41.518384: Pseudo dice [np.float32(0.8566)] 
2025-07-10 09:35:41.518492: Epoch time: 46.96 s 
2025-07-10 09:35:41.518579: Yayy! New best EMA pseudo Dice: 0.8337000012397766 
2025-07-10 09:35:43.694637:  
2025-07-10 09:35:43.695008: Epoch 964 
2025-07-10 09:35:43.695182: Current learning rate: 0.0005 
2025-07-10 09:36:30.205193: train_loss -0.523 
2025-07-10 09:36:30.205786: val_loss -0.5212 
2025-07-10 09:36:30.205863: Pseudo dice [np.float32(0.8452)] 
2025-07-10 09:36:30.205974: Epoch time: 46.51 s 
2025-07-10 09:36:30.206052: Yayy! New best EMA pseudo Dice: 0.8349000215530396 
2025-07-10 09:36:32.450091:  
2025-07-10 09:36:32.450718: Epoch 965 
2025-07-10 09:36:32.450915: Current learning rate: 0.00049 
2025-07-10 09:37:19.137123: train_loss -0.5157 
2025-07-10 09:37:19.137614: val_loss -0.526 
2025-07-10 09:37:19.137699: Pseudo dice [np.float32(0.8406)] 
2025-07-10 09:37:19.137816: Epoch time: 46.69 s 
2025-07-10 09:37:19.137894: Yayy! New best EMA pseudo Dice: 0.8355000019073486 
2025-07-10 09:37:21.268583:  
2025-07-10 09:37:21.268783: Epoch 966 
2025-07-10 09:37:21.268909: Current learning rate: 0.00048 
2025-07-10 09:38:07.707267: train_loss -0.5197 
2025-07-10 09:38:07.707867: val_loss -0.5299 
2025-07-10 09:38:07.708014: Pseudo dice [np.float32(0.8219)] 
2025-07-10 09:38:07.708123: Epoch time: 46.44 s 
2025-07-10 09:38:08.938043:  
2025-07-10 09:38:08.938492: Epoch 967 
2025-07-10 09:38:08.938724: Current learning rate: 0.00046 
2025-07-10 09:38:55.481316: train_loss -0.511 
2025-07-10 09:38:55.481679: val_loss -0.5198 
2025-07-10 09:38:55.481757: Pseudo dice [np.float32(0.8505)] 
2025-07-10 09:38:55.481861: Epoch time: 46.54 s 
2025-07-10 09:38:55.482042: Yayy! New best EMA pseudo Dice: 0.8357999920845032 
2025-07-10 09:38:57.747112:  
2025-07-10 09:38:57.747499: Epoch 968 
2025-07-10 09:38:57.747685: Current learning rate: 0.00045 
2025-07-10 09:39:43.857866: train_loss -0.5226 
2025-07-10 09:39:43.858550: val_loss -0.5464 
2025-07-10 09:39:43.858647: Pseudo dice [np.float32(0.839)] 
2025-07-10 09:39:43.858766: Epoch time: 46.11 s 
2025-07-10 09:39:43.858844: Yayy! New best EMA pseudo Dice: 0.8360999822616577 
2025-07-10 09:39:46.116745:  
2025-07-10 09:39:46.117136: Epoch 969 
2025-07-10 09:39:46.117302: Current learning rate: 0.00044 
2025-07-10 09:40:33.016037: train_loss -0.5192 
2025-07-10 09:40:33.016641: val_loss -0.523 
2025-07-10 09:40:33.016747: Pseudo dice [np.float32(0.8533)] 
2025-07-10 09:40:33.016859: Epoch time: 46.9 s 
2025-07-10 09:40:33.016944: Yayy! New best EMA pseudo Dice: 0.8378000259399414 
2025-07-10 09:40:35.187732:  
2025-07-10 09:40:35.188035: Epoch 970 
2025-07-10 09:40:35.188283: Current learning rate: 0.00043 
2025-07-10 09:41:21.832989: train_loss -0.5121 
2025-07-10 09:41:21.833243: val_loss -0.53 
2025-07-10 09:41:21.833313: Pseudo dice [np.float32(0.8384)] 
2025-07-10 09:41:21.833399: Epoch time: 46.65 s 
2025-07-10 09:41:21.833467: Yayy! New best EMA pseudo Dice: 0.8378999829292297 
2025-07-10 09:41:23.932786:  
2025-07-10 09:41:23.933246: Epoch 971 
2025-07-10 09:41:23.933372: Current learning rate: 0.00041 
2025-07-10 09:42:09.766637: train_loss -0.5121 
2025-07-10 09:42:09.767228: val_loss -0.5034 
2025-07-10 09:42:09.767312: Pseudo dice [np.float32(0.8254)] 
2025-07-10 09:42:09.767437: Epoch time: 45.83 s 
2025-07-10 09:42:10.978250:  
2025-07-10 09:42:10.978566: Epoch 972 
2025-07-10 09:42:10.978738: Current learning rate: 0.0004 
2025-07-10 09:42:57.410563: train_loss -0.5116 
2025-07-10 09:42:57.411137: val_loss -0.5272 
2025-07-10 09:42:57.411303: Pseudo dice [np.float32(0.8235)] 
2025-07-10 09:42:57.411434: Epoch time: 46.43 s 
2025-07-10 09:42:58.736867:  
2025-07-10 09:42:58.737255: Epoch 973 
2025-07-10 09:42:58.737383: Current learning rate: 0.00039 
2025-07-10 09:43:45.249562: train_loss -0.5152 
2025-07-10 09:43:45.250146: val_loss -0.5231 
2025-07-10 09:43:45.250315: Pseudo dice [np.float32(0.8399)] 
2025-07-10 09:43:45.250421: Epoch time: 46.51 s 
2025-07-10 09:43:47.079870:  
2025-07-10 09:43:47.080127: Epoch 974 
2025-07-10 09:43:47.080318: Current learning rate: 0.00037 
2025-07-10 09:44:32.456301: train_loss -0.5123 
2025-07-10 09:44:32.457436: val_loss -0.5287 
2025-07-10 09:44:32.457620: Pseudo dice [np.float32(0.8405)] 
2025-07-10 09:44:32.457800: Epoch time: 45.38 s 
2025-07-10 09:44:33.707728:  
2025-07-10 09:44:33.708287: Epoch 975 
2025-07-10 09:44:33.708421: Current learning rate: 0.00036 
2025-07-10 09:45:20.060028: train_loss -0.5178 
2025-07-10 09:45:20.060600: val_loss -0.5427 
2025-07-10 09:45:20.060698: Pseudo dice [np.float32(0.8416)] 
2025-07-10 09:45:20.060818: Epoch time: 46.35 s 
2025-07-10 09:45:21.276486:  
2025-07-10 09:45:21.276884: Epoch 976 
2025-07-10 09:45:21.277008: Current learning rate: 0.00035 
2025-07-10 09:46:07.235575: train_loss -0.514 
2025-07-10 09:46:07.236336: val_loss -0.5189 
2025-07-10 09:46:07.236508: Pseudo dice [np.float32(0.8066)] 
2025-07-10 09:46:07.236636: Epoch time: 45.96 s 
2025-07-10 09:46:08.401899:  
2025-07-10 09:46:08.402318: Epoch 977 
2025-07-10 09:46:08.402537: Current learning rate: 0.00034 
2025-07-10 09:46:54.456047: train_loss -0.5162 
2025-07-10 09:46:54.456627: val_loss -0.5188 
2025-07-10 09:46:54.456740: Pseudo dice [np.float32(0.8523)] 
2025-07-10 09:46:54.456849: Epoch time: 46.06 s 
2025-07-10 09:46:55.659484:  
2025-07-10 09:46:55.659708: Epoch 978 
2025-07-10 09:46:55.659830: Current learning rate: 0.00032 
2025-07-10 09:47:41.454017: train_loss -0.5177 
2025-07-10 09:47:41.454808: val_loss -0.5318 
2025-07-10 09:47:41.454904: Pseudo dice [np.float32(0.8417)] 
2025-07-10 09:47:41.455022: Epoch time: 45.8 s 
2025-07-10 09:47:42.727728:  
2025-07-10 09:47:42.728138: Epoch 979 
2025-07-10 09:47:42.728270: Current learning rate: 0.00031 
2025-07-10 09:48:28.970814: train_loss -0.5196 
2025-07-10 09:48:28.971176: val_loss -0.5179 
2025-07-10 09:48:28.971248: Pseudo dice [np.float32(0.7979)] 
2025-07-10 09:48:28.971350: Epoch time: 46.24 s 
2025-07-10 09:48:30.151477:  
2025-07-10 09:48:30.151926: Epoch 980 
2025-07-10 09:48:30.152054: Current learning rate: 0.0003 
2025-07-10 09:49:17.392175: train_loss -0.5193 
2025-07-10 09:49:17.392755: val_loss -0.5377 
2025-07-10 09:49:17.392854: Pseudo dice [np.float32(0.8567)] 
2025-07-10 09:49:17.392976: Epoch time: 47.24 s 
2025-07-10 09:49:18.580305:  
2025-07-10 09:49:18.580681: Epoch 981 
2025-07-10 09:49:18.581020: Current learning rate: 0.00028 
2025-07-10 09:50:05.175902: train_loss -0.5231 
2025-07-10 09:50:05.176336: val_loss -0.5237 
2025-07-10 09:50:05.176424: Pseudo dice [np.float32(0.8515)] 
2025-07-10 09:50:05.176564: Epoch time: 46.6 s 
2025-07-10 09:50:06.355204:  
2025-07-10 09:50:06.355532: Epoch 982 
2025-07-10 09:50:06.355868: Current learning rate: 0.00027 
2025-07-10 09:50:52.920035: train_loss -0.5224 
2025-07-10 09:50:52.920523: val_loss -0.5472 
2025-07-10 09:50:52.920625: Pseudo dice [np.float32(0.8618)] 
2025-07-10 09:50:52.920761: Epoch time: 46.57 s 
2025-07-10 09:50:52.920838: Yayy! New best EMA pseudo Dice: 0.8389999866485596 
2025-07-10 09:50:55.220446:  
2025-07-10 09:50:55.220753: Epoch 983 
2025-07-10 09:50:55.220946: Current learning rate: 0.00026 
2025-07-10 09:51:41.973643: train_loss -0.5236 
2025-07-10 09:51:41.974086: val_loss -0.5301 
2025-07-10 09:51:41.974160: Pseudo dice [np.float32(0.8394)] 
2025-07-10 09:51:41.974264: Epoch time: 46.75 s 
2025-07-10 09:51:41.974339: Yayy! New best EMA pseudo Dice: 0.8391000032424927 
2025-07-10 09:51:44.273470:  
2025-07-10 09:51:44.273879: Epoch 984 
2025-07-10 09:51:44.274119: Current learning rate: 0.00024 
2025-07-10 09:52:30.905140: train_loss -0.5246 
2025-07-10 09:52:30.905720: val_loss -0.5226 
2025-07-10 09:52:30.905807: Pseudo dice [np.float32(0.85)] 
2025-07-10 09:52:30.905923: Epoch time: 46.63 s 
2025-07-10 09:52:30.906000: Yayy! New best EMA pseudo Dice: 0.8400999903678894 
2025-07-10 09:52:33.026375:  
2025-07-10 09:52:33.026613: Epoch 985 
2025-07-10 09:52:33.026760: Current learning rate: 0.00023 
2025-07-10 09:53:19.011681: train_loss -0.5258 
2025-07-10 09:53:19.012264: val_loss -0.5347 
2025-07-10 09:53:19.012342: Pseudo dice [np.float32(0.8343)] 
2025-07-10 09:53:19.012452: Epoch time: 45.99 s 
2025-07-10 09:53:20.811058:  
2025-07-10 09:53:20.811383: Epoch 986 
2025-07-10 09:53:20.811603: Current learning rate: 0.00021 
2025-07-10 09:54:06.268054: train_loss -0.5239 
2025-07-10 09:54:06.268932: val_loss -0.5305 
2025-07-10 09:54:06.269041: Pseudo dice [np.float32(0.8446)] 
2025-07-10 09:54:06.269204: Epoch time: 45.46 s 
2025-07-10 09:54:07.528236:  
2025-07-10 09:54:07.528620: Epoch 987 
2025-07-10 09:54:07.528841: Current learning rate: 0.0002 
2025-07-10 09:54:54.163651: train_loss -0.5279 
2025-07-10 09:54:54.164472: val_loss -0.5031 
2025-07-10 09:54:54.164570: Pseudo dice [np.float32(0.8432)] 
2025-07-10 09:54:54.164691: Epoch time: 46.64 s 
2025-07-10 09:54:54.164784: Yayy! New best EMA pseudo Dice: 0.840399980545044 
2025-07-10 09:54:56.384597:  
2025-07-10 09:54:56.384970: Epoch 988 
2025-07-10 09:54:56.385114: Current learning rate: 0.00019 
2025-07-10 09:55:42.390671: train_loss -0.5209 
2025-07-10 09:55:42.391062: val_loss -0.5424 
2025-07-10 09:55:42.391198: Pseudo dice [np.float32(0.8708)] 
2025-07-10 09:55:42.391351: Epoch time: 46.01 s 
2025-07-10 09:55:42.391515: Yayy! New best EMA pseudo Dice: 0.8434000015258789 
2025-07-10 09:55:44.629910:  
2025-07-10 09:55:44.630264: Epoch 989 
2025-07-10 09:55:44.630443: Current learning rate: 0.00017 
2025-07-10 09:56:31.262841: train_loss -0.5246 
2025-07-10 09:56:31.263181: val_loss -0.5443 
2025-07-10 09:56:31.263257: Pseudo dice [np.float32(0.8517)] 
2025-07-10 09:56:31.263365: Epoch time: 46.63 s 
2025-07-10 09:56:31.263438: Yayy! New best EMA pseudo Dice: 0.8442000150680542 
2025-07-10 09:56:33.416721:  
2025-07-10 09:56:33.417155: Epoch 990 
2025-07-10 09:56:33.417306: Current learning rate: 0.00016 
2025-07-10 09:57:20.032328: train_loss -0.5349 
2025-07-10 09:57:20.032885: val_loss -0.5352 
2025-07-10 09:57:20.032966: Pseudo dice [np.float32(0.8574)] 
2025-07-10 09:57:20.033099: Epoch time: 46.62 s 
2025-07-10 09:57:20.033174: Yayy! New best EMA pseudo Dice: 0.8456000089645386 
2025-07-10 09:57:22.187001:  
2025-07-10 09:57:22.187181: Epoch 991 
2025-07-10 09:57:22.187294: Current learning rate: 0.00014 
2025-07-10 09:58:10.041464: train_loss -0.5146 
2025-07-10 09:58:10.042455: val_loss -0.5369 
2025-07-10 09:58:10.042552: Pseudo dice [np.float32(0.8434)] 
2025-07-10 09:58:10.042684: Epoch time: 47.86 s 
2025-07-10 09:58:11.217683:  
2025-07-10 09:58:11.217894: Epoch 992 
2025-07-10 09:58:11.218130: Current learning rate: 0.00013 
2025-07-10 09:58:58.304852: train_loss -0.5304 
2025-07-10 09:58:58.305403: val_loss -0.5262 
2025-07-10 09:58:58.305492: Pseudo dice [np.float32(0.839)] 
2025-07-10 09:58:58.305616: Epoch time: 47.09 s 
2025-07-10 09:58:59.541883:  
2025-07-10 09:58:59.542233: Epoch 993 
2025-07-10 09:58:59.542426: Current learning rate: 0.00011 
2025-07-10 09:59:46.192901: train_loss -0.5325 
2025-07-10 09:59:46.193403: val_loss -0.5491 
2025-07-10 09:59:46.193482: Pseudo dice [np.float32(0.864)] 
2025-07-10 09:59:46.193612: Epoch time: 46.65 s 
2025-07-10 09:59:46.193697: Yayy! New best EMA pseudo Dice: 0.8465999960899353 
2025-07-10 09:59:48.424659:  
2025-07-10 09:59:48.425103: Epoch 994 
2025-07-10 09:59:48.425232: Current learning rate: 0.0001 
2025-07-10 10:00:34.566560: train_loss -0.5244 
2025-07-10 10:00:34.566951: val_loss -0.5198 
2025-07-10 10:00:34.567054: Pseudo dice [np.float32(0.8572)] 
2025-07-10 10:00:34.567170: Epoch time: 46.14 s 
2025-07-10 10:00:34.567320: Yayy! New best EMA pseudo Dice: 0.8476999998092651 
2025-07-10 10:00:36.755529:  
2025-07-10 10:00:36.755781: Epoch 995 
2025-07-10 10:00:36.755903: Current learning rate: 8e-05 
2025-07-10 10:01:22.842484: train_loss -0.5261 
2025-07-10 10:01:22.843022: val_loss -0.5466 
2025-07-10 10:01:22.843109: Pseudo dice [np.float32(0.8519)] 
2025-07-10 10:01:22.843221: Epoch time: 46.09 s 
2025-07-10 10:01:22.843299: Yayy! New best EMA pseudo Dice: 0.8481000065803528 
2025-07-10 10:01:25.686700:  
2025-07-10 10:01:25.687152: Epoch 996 
2025-07-10 10:01:25.687299: Current learning rate: 7e-05 
2025-07-10 10:02:12.158618: train_loss -0.5232 
2025-07-10 10:02:12.159458: val_loss -0.521 
2025-07-10 10:02:12.159651: Pseudo dice [np.float32(0.8645)] 
2025-07-10 10:02:12.159756: Epoch time: 46.47 s 
2025-07-10 10:02:12.159827: Yayy! New best EMA pseudo Dice: 0.8497999906539917 
2025-07-10 10:02:14.170099:  
2025-07-10 10:02:14.170431: Epoch 997 
2025-07-10 10:02:14.170640: Current learning rate: 5e-05 
2025-07-10 10:03:01.162223: train_loss -0.5315 
2025-07-10 10:03:01.162942: val_loss -0.5295 
2025-07-10 10:03:01.163044: Pseudo dice [np.float32(0.8643)] 
2025-07-10 10:03:01.163164: Epoch time: 46.99 s 
2025-07-10 10:03:01.163259: Yayy! New best EMA pseudo Dice: 0.8511999845504761 
2025-07-10 10:03:03.378587:  
2025-07-10 10:03:03.378921: Epoch 998 
2025-07-10 10:03:03.379182: Current learning rate: 4e-05 
2025-07-10 10:03:48.926424: train_loss -0.526 
2025-07-10 10:03:48.927016: val_loss -0.5115 
2025-07-10 10:03:48.927111: Pseudo dice [np.float32(0.8271)] 
2025-07-10 10:03:48.927237: Epoch time: 45.55 s 
2025-07-10 10:03:50.102364:  
2025-07-10 10:03:50.102897: Epoch 999 
2025-07-10 10:03:50.103046: Current learning rate: 2e-05 
2025-07-10 10:04:36.310854: train_loss -0.5233 
2025-07-10 10:04:36.311259: val_loss -0.5506 
2025-07-10 10:04:36.311334: Pseudo dice [np.float32(0.8418)] 
2025-07-10 10:04:36.311431: Epoch time: 46.21 s 
2025-07-10 10:04:37.824019: Training done. 
2025-07-10 10:04:37.844949: predicting BraTS-PED-00001-000 
2025-07-10 10:04:37.901094: BraTS-PED-00001-000, shape torch.Size([4, 112, 112, 112]), rank 0 
2025-07-10 10:04:40.811575: predicting BraTS-PED-00002-000 
2025-07-10 10:04:40.819345: BraTS-PED-00002-000, shape torch.Size([4, 53, 53, 53]), rank 0 
2025-07-10 10:04:40.861209: predicting BraTS-PED-00003-000 
2025-07-10 10:04:40.910212: BraTS-PED-00003-000, shape torch.Size([4, 124, 124, 124]), rank 0 
2025-07-10 10:04:41.620404: predicting BraTS-PED-00004-000 
2025-07-10 10:04:41.658907: BraTS-PED-00004-000, shape torch.Size([4, 114, 114, 114]), rank 0 
2025-07-10 10:04:41.869159: predicting BraTS-PED-00005-000 
2025-07-10 10:04:41.874972: BraTS-PED-00005-000, shape torch.Size([4, 64, 64, 64]), rank 0 
2025-07-10 10:04:41.909250: predicting BraTS-PED-00006-000 
2025-07-10 10:04:41.915159: BraTS-PED-00006-000, shape torch.Size([4, 57, 57, 57]), rank 0 
2025-07-10 10:04:41.949111: predicting BraTS-PED-00008-000 
2025-07-10 10:04:41.970917: BraTS-PED-00008-000, shape torch.Size([4, 104, 104, 104]), rank 0 
2025-07-10 10:04:42.139278: predicting BraTS-PED-00009-000 
2025-07-10 10:04:42.168625: BraTS-PED-00009-000, shape torch.Size([4, 109, 109, 109]), rank 0 
2025-07-10 10:04:42.338881: predicting BraTS-PED-00010-000 
2025-07-10 10:04:42.355426: BraTS-PED-00010-000, shape torch.Size([4, 24, 179, 171]), rank 0 
2025-07-10 10:04:42.706061: predicting BraTS-PED-00013-000 
2025-07-10 10:04:42.719240: BraTS-PED-00013-000, shape torch.Size([4, 81, 81, 81]), rank 0 
2025-07-10 10:04:42.885890: predicting BraTS-PED-00014-000 
2025-07-10 10:04:42.893751: BraTS-PED-00014-000, shape torch.Size([4, 66, 66, 66]), rank 0 
2025-07-10 10:04:42.927835: predicting BraTS-PED-00015-000 
2025-07-10 10:04:42.943910: BraTS-PED-00015-000, shape torch.Size([4, 96, 96, 96]), rank 0 
2025-07-10 10:04:43.110967: predicting BraTS-PED-00016-000 
2025-07-10 10:04:43.125869: BraTS-PED-00016-000, shape torch.Size([4, 85, 85, 85]), rank 0 
2025-07-10 10:04:43.294836: predicting BraTS-PED-00017-000 
2025-07-10 10:04:43.349042: BraTS-PED-00017-000, shape torch.Size([4, 144, 144, 144]), rank 0 
2025-07-10 10:04:43.886804: predicting BraTS-PED-00018-000 
2025-07-10 10:04:43.912766: BraTS-PED-00018-000, shape torch.Size([4, 112, 112, 112]), rank 0 
2025-07-10 10:04:44.083945: predicting BraTS-PED-00019-000 
2025-07-10 10:04:44.145154: BraTS-PED-00019-000, shape torch.Size([4, 144, 144, 144]), rank 0 
2025-07-10 10:04:44.687683: predicting BraTS-PED-00020-000 
2025-07-10 10:04:44.696837: BraTS-PED-00020-000, shape torch.Size([4, 71, 71, 71]), rank 0 
2025-07-10 10:04:44.730273: predicting BraTS-PED-00021-000 
2025-07-10 10:04:44.769105: BraTS-PED-00021-000, shape torch.Size([4, 123, 123, 123]), rank 0 
2025-07-10 10:04:45.310683: predicting BraTS-PED-00022-000 
2025-07-10 10:04:45.338169: BraTS-PED-00022-000, shape torch.Size([4, 110, 110, 110]), rank 0 
2025-07-10 10:04:45.508097: predicting BraTS-PED-00023-000 
2025-07-10 10:04:45.532109: BraTS-PED-00023-000, shape torch.Size([4, 112, 112, 112]), rank 0 
2025-07-10 10:04:45.702559: predicting BraTS-PED-00024-000 
2025-07-10 10:04:45.721956: BraTS-PED-00024-000, shape torch.Size([4, 98, 102, 102]), rank 0 
2025-07-10 10:04:45.891145: predicting BraTS-PED-00025-000 
2025-07-10 10:04:45.900598: BraTS-PED-00025-000, shape torch.Size([4, 76, 76, 76]), rank 0 
2025-07-10 10:04:45.934340: predicting BraTS-PED-00026-000 
2025-07-10 10:04:45.939984: BraTS-PED-00026-000, shape torch.Size([4, 60, 60, 60]), rank 0 
2025-07-10 10:04:45.972997: predicting BraTS-PED-00027-000 
2025-07-10 10:04:45.979867: BraTS-PED-00027-000, shape torch.Size([4, 63, 63, 63]), rank 0 
2025-07-10 10:04:46.015967: predicting BraTS-PED-00028-000 
2025-07-10 10:04:46.053078: BraTS-PED-00028-000, shape torch.Size([4, 122, 122, 122]), rank 0 
2025-07-10 10:04:46.590609: predicting BraTS-PED-00029-000 
2025-07-10 10:04:46.593962: BraTS-PED-00029-000, shape torch.Size([4, 48, 48, 48]), rank 0 
2025-07-10 10:04:46.625510: predicting BraTS-PED-00030-000 
2025-07-10 10:04:46.657105: BraTS-PED-00030-000, shape torch.Size([4, 120, 120, 120]), rank 0 
2025-07-10 10:04:46.831154: predicting BraTS-PED-00031-000 
2025-07-10 10:04:46.858505: BraTS-PED-00031-000, shape torch.Size([4, 107, 107, 107]), rank 0 
2025-07-10 10:04:47.025622: predicting BraTS-PED-00032-000 
2025-07-10 10:04:47.042092: BraTS-PED-00032-000, shape torch.Size([4, 90, 90, 90]), rank 0 
2025-07-10 10:04:47.208971: predicting BraTS-PED-00033-000 
2025-07-10 10:04:47.237715: BraTS-PED-00033-000, shape torch.Size([4, 108, 108, 108]), rank 0 
2025-07-10 10:04:47.405643: predicting BraTS-PED-00034-000 
2025-07-10 10:04:47.428116: BraTS-PED-00034-000, shape torch.Size([4, 103, 103, 103]), rank 0 
2025-07-10 10:04:47.596075: predicting BraTS-PED-00035-000 
2025-07-10 10:04:47.627685: BraTS-PED-00035-000, shape torch.Size([4, 116, 116, 116]), rank 0 
2025-07-10 10:04:47.796214: predicting BraTS-PED-00036-000 
2025-07-10 10:04:47.806106: BraTS-PED-00036-000, shape torch.Size([4, 76, 76, 76]), rank 0 
2025-07-10 10:04:47.839922: predicting BraTS-PED-00037-000 
2025-07-10 10:04:47.848753: BraTS-PED-00037-000, shape torch.Size([4, 66, 66, 66]), rank 0 
2025-07-10 10:04:47.881535: predicting BraTS-PED-00038-000 
2025-07-10 10:04:47.885505: BraTS-PED-00038-000, shape torch.Size([4, 53, 53, 53]), rank 0 
2025-07-10 10:04:47.917232: predicting BraTS-PED-00039-000 
2025-07-10 10:04:47.927518: BraTS-PED-00039-000, shape torch.Size([4, 78, 78, 78]), rank 0 
2025-07-10 10:04:47.959757: predicting BraTS-PED-00040-000 
2025-07-10 10:04:47.970731: BraTS-PED-00040-000, shape torch.Size([4, 78, 78, 78]), rank 0 
2025-07-10 10:04:48.003890: predicting BraTS-PED-00041-000 
2025-07-10 10:04:48.018333: BraTS-PED-00041-000, shape torch.Size([4, 86, 86, 86]), rank 0 
2025-07-10 10:04:48.184628: predicting BraTS-PED-00042-000 
2025-07-10 10:04:48.244766: BraTS-PED-00042-000, shape torch.Size([4, 144, 144, 144]), rank 0 
2025-07-10 10:04:48.782141: predicting BraTS-PED-00043-000 
2025-07-10 10:04:48.814486: BraTS-PED-00043-000, shape torch.Size([4, 120, 120, 120]), rank 0 
2025-07-10 10:04:48.985108: predicting BraTS-PED-00044-000 
2025-07-10 10:04:48.993217: BraTS-PED-00044-000, shape torch.Size([4, 68, 68, 68]), rank 0 
2025-07-10 10:04:49.027827: predicting BraTS-PED-00045-000 
2025-07-10 10:04:49.037833: BraTS-PED-00045-000, shape torch.Size([4, 75, 75, 75]), rank 0 
2025-07-10 10:04:49.070511: predicting BraTS-PED-00046-000 
2025-07-10 10:04:49.079121: BraTS-PED-00046-000, shape torch.Size([4, 69, 69, 69]), rank 0 
2025-07-10 10:04:49.111871: predicting BraTS-PED-00047-000 
2025-07-10 10:04:49.118394: BraTS-PED-00047-000, shape torch.Size([4, 63, 63, 63]), rank 0 
2025-07-10 10:04:49.151357: predicting BraTS-PED-00048-000 
2025-07-10 10:04:49.211418: BraTS-PED-00048-000, shape torch.Size([4, 142, 142, 142]), rank 0 
2025-07-10 10:04:49.747753: predicting BraTS-PED-00049-000 
2025-07-10 10:04:49.784376: BraTS-PED-00049-000, shape torch.Size([4, 124, 124, 124]), rank 0 
2025-07-10 10:04:50.321867: predicting BraTS-PED-00050-000 
2025-07-10 10:04:50.339253: BraTS-PED-00050-000, shape torch.Size([4, 96, 96, 96]), rank 0 
2025-07-10 10:04:50.506941: predicting BraTS-PED-00051-000 
2025-07-10 10:04:50.551678: BraTS-PED-00051-000, shape torch.Size([4, 131, 131, 131]), rank 0 
2025-07-10 10:04:51.088282: predicting BraTS-PED-00052-000 
2025-07-10 10:04:51.096732: BraTS-PED-00052-000, shape torch.Size([4, 68, 68, 68]), rank 0 
2025-07-10 10:04:51.130522: predicting BraTS-PED-00053-000 
2025-07-10 10:04:51.136858: BraTS-PED-00053-000, shape torch.Size([4, 62, 62, 62]), rank 0 
2025-07-10 10:04:51.170614: predicting BraTS-PED-00054-000 
2025-07-10 10:04:51.195774: BraTS-PED-00054-000, shape torch.Size([4, 112, 112, 112]), rank 0 
2025-07-10 10:04:51.362608: predicting BraTS-PED-00055-000 
2025-07-10 10:04:51.366385: BraTS-PED-00055-000, shape torch.Size([4, 48, 48, 48]), rank 0 
2025-07-10 10:04:51.397828: predicting BraTS-PED-00056-000 
2025-07-10 10:04:51.413405: BraTS-PED-00056-000, shape torch.Size([4, 89, 89, 89]), rank 0 
2025-07-10 10:04:51.579698: predicting BraTS-PED-00057-000 
2025-07-10 10:04:51.589817: BraTS-PED-00057-000, shape torch.Size([4, 77, 77, 77]), rank 0 
2025-07-10 10:04:51.622536: predicting BraTS-PED-00058-000 
2025-07-10 10:04:51.645019: BraTS-PED-00058-000, shape torch.Size([4, 102, 102, 102]), rank 0 
2025-07-10 10:04:51.811520: predicting BraTS-PED-00059-000 
2025-07-10 10:04:51.826474: BraTS-PED-00059-000, shape torch.Size([4, 86, 86, 86]), rank 0 
2025-07-10 10:04:51.996382: predicting BraTS-PED-00060-000 
2025-07-10 10:04:52.029928: BraTS-PED-00060-000, shape torch.Size([4, 120, 120, 120]), rank 0 
2025-07-10 10:04:52.199025: predicting BraTS-PED-00061-000 
2025-07-10 10:04:52.206666: BraTS-PED-00061-000, shape torch.Size([4, 69, 69, 69]), rank 0 
2025-07-10 10:04:52.239252: predicting BraTS-PED-00062-000 
2025-07-10 10:04:52.258705: BraTS-PED-00062-000, shape torch.Size([4, 92, 92, 92]), rank 0 
2025-07-10 10:04:52.424144: predicting BraTS-PED-00063-000 
2025-07-10 10:04:52.455321: BraTS-PED-00063-000, shape torch.Size([4, 120, 120, 120]), rank 0 
2025-07-10 10:04:52.625316: predicting BraTS-PED-00064-000 
2025-07-10 10:04:52.656272: BraTS-PED-00064-000, shape torch.Size([4, 120, 120, 120]), rank 0 
2025-07-10 10:04:52.825722: predicting BraTS-PED-00065-000 
2025-07-10 10:04:52.857815: BraTS-PED-00065-000, shape torch.Size([4, 114, 114, 114]), rank 0 
2025-07-10 10:04:53.026449: predicting BraTS-PED-00066-000 
2025-07-10 10:04:53.081293: BraTS-PED-00066-000, shape torch.Size([4, 138, 138, 138]), rank 0 
2025-07-10 10:04:53.623099: predicting BraTS-PED-00067-000 
2025-07-10 10:04:53.631246: BraTS-PED-00067-000, shape torch.Size([4, 67, 67, 67]), rank 0 
2025-07-10 10:04:53.666752: predicting BraTS-PED-00068-000 
2025-07-10 10:04:53.671192: BraTS-PED-00068-000, shape torch.Size([4, 53, 53, 53]), rank 0 
2025-07-10 10:04:53.707343: predicting BraTS-PED-00069-000 
2025-07-10 10:04:53.721740: BraTS-PED-00069-000, shape torch.Size([4, 87, 87, 87]), rank 0 
2025-07-10 10:04:53.887033: predicting BraTS-PED-00070-000 
2025-07-10 10:04:53.892751: BraTS-PED-00070-000, shape torch.Size([4, 59, 59, 59]), rank 0 
2025-07-10 10:04:53.925295: predicting BraTS-PED-00071-000 
2025-07-10 10:04:53.934652: BraTS-PED-00071-000, shape torch.Size([4, 66, 66, 66]), rank 0 
2025-07-10 10:04:53.966208: predicting BraTS-PED-00072-000 
2025-07-10 10:04:53.971627: BraTS-PED-00072-000, shape torch.Size([4, 57, 57, 57]), rank 0 
2025-07-10 10:04:54.003488: predicting BraTS-PED-00073-000 
2025-07-10 10:04:54.035091: BraTS-PED-00073-000, shape torch.Size([4, 114, 114, 114]), rank 0 
2025-07-10 10:04:54.207958: predicting BraTS-PED-00074-000 
2025-07-10 10:04:54.211996: BraTS-PED-00074-000, shape torch.Size([4, 50, 50, 50]), rank 0 
2025-07-10 10:04:54.245280: predicting BraTS-PED-00075-000 
2025-07-10 10:04:54.249225: BraTS-PED-00075-000, shape torch.Size([4, 49, 49, 49]), rank 0 
2025-07-10 10:04:54.282110: predicting BraTS-PED-00076-000 
2025-07-10 10:04:54.299892: BraTS-PED-00076-000, shape torch.Size([4, 93, 93, 93]), rank 0 
2025-07-10 10:04:54.466192: predicting BraTS-PED-00077-000 
2025-07-10 10:04:54.470737: BraTS-PED-00077-000, shape torch.Size([4, 55, 55, 55]), rank 0 
2025-07-10 10:04:54.503396: predicting BraTS-PED-00078-000 
2025-07-10 10:04:54.513078: BraTS-PED-00078-000, shape torch.Size([4, 73, 73, 73]), rank 0 
2025-07-10 10:04:54.544576: predicting BraTS-PED-00079-000 
2025-07-10 10:04:54.570016: BraTS-PED-00079-000, shape torch.Size([4, 111, 111, 111]), rank 0 
2025-07-10 10:04:54.737603: predicting BraTS-PED-00080-000 
2025-07-10 10:04:54.745078: BraTS-PED-00080-000, shape torch.Size([4, 66, 66, 66]), rank 0 
2025-07-10 10:04:54.777200: predicting BraTS-PED-00081-000 
2025-07-10 10:04:54.785226: BraTS-PED-00081-000, shape torch.Size([4, 69, 69, 69]), rank 0 
2025-07-10 10:04:54.818725: predicting BraTS-PED-00082-000 
2025-07-10 10:04:54.829246: BraTS-PED-00082-000, shape torch.Size([4, 74, 74, 74]), rank 0 
2025-07-10 10:04:54.860810: predicting BraTS-PED-00083-000 
2025-07-10 10:04:54.869535: BraTS-PED-00083-000, shape torch.Size([4, 16, 171, 171]), rank 0 
2025-07-10 10:04:55.215449: predicting BraTS-PED-00084-000 
2025-07-10 10:04:55.223589: BraTS-PED-00084-000, shape torch.Size([4, 70, 70, 70]), rank 0 
2025-07-10 10:04:55.256095: predicting BraTS-PED-00085-000 
2025-07-10 10:04:55.261683: BraTS-PED-00085-000, shape torch.Size([4, 62, 62, 62]), rank 0 
2025-07-10 10:04:55.294511: predicting BraTS-PED-00086-000 
2025-07-10 10:04:55.301976: BraTS-PED-00086-000, shape torch.Size([4, 65, 65, 65]), rank 0 
2025-07-10 10:04:55.333342: predicting BraTS-PED-00087-000 
2025-07-10 10:04:55.339484: BraTS-PED-00087-000, shape torch.Size([4, 59, 59, 59]), rank 0 
2025-07-10 10:04:55.371640: predicting BraTS-PED-00088-000 
2025-07-10 10:04:55.387136: BraTS-PED-00088-000, shape torch.Size([4, 90, 90, 90]), rank 0 
2025-07-10 10:04:55.551980: predicting BraTS-PED-00089-000 
2025-07-10 10:04:55.568076: BraTS-PED-00089-000, shape torch.Size([4, 95, 95, 95]), rank 0 
2025-07-10 10:04:55.737433: predicting BraTS-PED-00091-000 
2025-07-10 10:04:55.793816: BraTS-PED-00091-000, shape torch.Size([4, 139, 139, 139]), rank 0 
2025-07-10 10:04:56.334024: predicting BraTS-PED-00092-000 
2025-07-10 10:04:56.347812: BraTS-PED-00092-000, shape torch.Size([4, 83, 83, 83]), rank 0 
2025-07-10 10:04:56.515590: predicting BraTS-PED-00093-000 
2025-07-10 10:04:56.542913: BraTS-PED-00093-000, shape torch.Size([4, 35, 190, 169]), rank 0 
2025-07-10 10:04:56.892179: predicting BraTS-PED-00094-000 
2025-07-10 10:04:56.896263: BraTS-PED-00094-000, shape torch.Size([4, 56, 56, 56]), rank 0 
2025-07-10 10:04:56.928101: predicting BraTS-PED-00095-000 
2025-07-10 10:04:56.933901: BraTS-PED-00095-000, shape torch.Size([4, 60, 60, 60]), rank 0 
2025-07-10 10:04:56.966130: predicting BraTS-PED-00096-000 
2025-07-10 10:04:56.982928: BraTS-PED-00096-000, shape torch.Size([4, 29, 184, 184]), rank 0 
2025-07-10 10:04:57.332513: predicting BraTS-PED-00097-000 
2025-07-10 10:04:57.352843: BraTS-PED-00097-000, shape torch.Size([4, 103, 103, 103]), rank 0 
2025-07-10 10:04:57.520235: predicting BraTS-PED-00098-000 
2025-07-10 10:04:57.531152: BraTS-PED-00098-000, shape torch.Size([4, 79, 79, 79]), rank 0 
2025-07-10 10:04:57.567578: predicting BraTS-PED-00099-000 
2025-07-10 10:04:57.575980: BraTS-PED-00099-000, shape torch.Size([4, 65, 65, 65]), rank 0 
2025-07-10 10:04:57.608818: predicting BraTS-PED-00100-000 
2025-07-10 10:04:57.663495: BraTS-PED-00100-000, shape torch.Size([4, 144, 144, 144]), rank 0 
2025-07-10 10:04:58.201384: predicting BraTS-PED-00101-000 
2025-07-10 10:04:58.223910: BraTS-PED-00101-000, shape torch.Size([4, 103, 103, 103]), rank 0 
2025-07-10 10:04:58.399330: predicting BraTS-PED-00102-000 
2025-07-10 10:04:58.402161: BraTS-PED-00102-000, shape torch.Size([4, 48, 48, 48]), rank 0 
2025-07-10 10:04:58.433640: predicting BraTS-PED-00103-000 
2025-07-10 10:04:58.466686: BraTS-PED-00103-000, shape torch.Size([4, 120, 120, 120]), rank 0 
2025-07-10 10:04:58.638347: predicting BraTS-PED-00104-000 
2025-07-10 10:04:58.715797: BraTS-PED-00104-000, shape torch.Size([4, 153, 153, 153]), rank 0 
2025-07-10 10:04:59.263526: predicting BraTS-PED-00105-000 
2025-07-10 10:04:59.275157: BraTS-PED-00105-000, shape torch.Size([4, 78, 78, 78]), rank 0 
2025-07-10 10:04:59.309848: predicting BraTS-PED-00106-000 
2025-07-10 10:04:59.320011: BraTS-PED-00106-000, shape torch.Size([4, 73, 73, 73]), rank 0 
2025-07-10 10:04:59.351666: predicting BraTS-PED-00107-000 
2025-07-10 10:04:59.368021: BraTS-PED-00107-000, shape torch.Size([4, 94, 94, 94]), rank 0 
2025-07-10 10:04:59.534783: predicting BraTS-PED-00108-000 
2025-07-10 10:04:59.556347: BraTS-PED-00108-000, shape torch.Size([4, 98, 98, 98]), rank 0 
2025-07-10 10:04:59.724155: predicting BraTS-PED-00109-000 
2025-07-10 10:04:59.739312: BraTS-PED-00109-000, shape torch.Size([4, 93, 93, 93]), rank 0 
2025-07-10 10:04:59.904614: predicting BraTS-PED-00110-000 
2025-07-10 10:04:59.918092: BraTS-PED-00110-000, shape torch.Size([4, 87, 87, 87]), rank 0 
2025-07-10 10:05:00.085525: predicting BraTS-PED-00112-000 
2025-07-10 10:05:00.093057: BraTS-PED-00112-000, shape torch.Size([4, 70, 70, 70]), rank 0 
2025-07-10 10:05:00.126449: predicting BraTS-PED-00113-000 
2025-07-10 10:05:00.130640: BraTS-PED-00113-000, shape torch.Size([4, 51, 51, 51]), rank 0 
2025-07-10 10:05:00.162574: predicting BraTS-PED-00114-000 
2025-07-10 10:05:00.171089: BraTS-PED-00114-000, shape torch.Size([4, 70, 70, 70]), rank 0 
2025-07-10 10:05:00.202561: predicting BraTS-PED-00115-000 
2025-07-10 10:05:00.212975: BraTS-PED-00115-000, shape torch.Size([4, 76, 76, 76]), rank 0 
2025-07-10 10:05:00.244575: predicting BraTS-PED-00116-000 
2025-07-10 10:05:00.261174: BraTS-PED-00116-000, shape torch.Size([4, 26, 181, 176]), rank 0 
2025-07-10 10:05:00.608128: predicting BraTS-PED-00117-000 
2025-07-10 10:05:00.633848: BraTS-PED-00117-000, shape torch.Size([4, 109, 109, 109]), rank 0 
2025-07-10 10:05:00.801563: predicting BraTS-PED-00118-000 
2025-07-10 10:05:00.811416: BraTS-PED-00118-000, shape torch.Size([4, 78, 78, 78]), rank 0 
2025-07-10 10:05:00.844054: predicting BraTS-PED-00119-000 
2025-07-10 10:05:00.867414: BraTS-PED-00119-000, shape torch.Size([4, 112, 112, 112]), rank 0 
2025-07-10 10:05:01.037474: predicting BraTS-PED-00120-000 
2025-07-10 10:05:01.046132: BraTS-PED-00120-000, shape torch.Size([4, 69, 69, 69]), rank 0 
2025-07-10 10:05:01.078873: predicting BraTS-PED-00121-000 
2025-07-10 10:05:01.118742: BraTS-PED-00121-000, shape torch.Size([4, 126, 126, 126]), rank 0 
2025-07-10 10:05:01.655344: predicting BraTS-PED-00122-000 
2025-07-10 10:05:01.698778: BraTS-PED-00122-000, shape torch.Size([4, 131, 131, 131]), rank 0 
2025-07-10 10:05:02.235732: predicting BraTS-PED-00123-000 
2025-07-10 10:05:02.243823: BraTS-PED-00123-000, shape torch.Size([4, 71, 71, 71]), rank 0 
2025-07-10 10:05:02.275398: predicting BraTS-PED-00124-000 
2025-07-10 10:05:02.289144: BraTS-PED-00124-000, shape torch.Size([4, 85, 85, 85]), rank 0 
2025-07-10 10:05:02.455369: predicting BraTS-PED-00125-000 
2025-07-10 10:05:02.471905: BraTS-PED-00125-000, shape torch.Size([4, 96, 96, 96]), rank 0 
2025-07-10 10:05:02.637870: predicting BraTS-PED-00126-000 
2025-07-10 10:05:02.650598: BraTS-PED-00126-000, shape torch.Size([4, 84, 84, 84]), rank 0 
2025-07-10 10:05:02.815639: predicting BraTS-PED-00127-000 
2025-07-10 10:05:02.833045: BraTS-PED-00127-000, shape torch.Size([4, 92, 92, 92]), rank 0 
2025-07-10 10:05:03.001377: predicting BraTS-PED-00128-000 
2025-07-10 10:05:03.005293: BraTS-PED-00128-000, shape torch.Size([4, 54, 54, 54]), rank 0 
2025-07-10 10:05:03.036982: predicting BraTS-PED-00129-000 
2025-07-10 10:05:03.046905: BraTS-PED-00129-000, shape torch.Size([4, 80, 80, 80]), rank 0 
2025-07-10 10:05:03.076598: predicting BraTS-PED-00130-000 
2025-07-10 10:05:03.102752: BraTS-PED-00130-000, shape torch.Size([4, 111, 111, 111]), rank 0 
2025-07-10 10:05:03.269749: predicting BraTS-PED-00131-000 
2025-07-10 10:05:03.281414: BraTS-PED-00131-000, shape torch.Size([4, 88, 88, 88]), rank 0 
2025-07-10 10:05:03.447428: predicting BraTS-PED-00132-000 
2025-07-10 10:05:03.452424: BraTS-PED-00132-000, shape torch.Size([4, 57, 57, 57]), rank 0 
2025-07-10 10:05:03.484950: predicting BraTS-PED-00133-000 
2025-07-10 10:05:03.507404: BraTS-PED-00133-000, shape torch.Size([4, 112, 112, 112]), rank 0 
2025-07-10 10:05:03.675262: predicting BraTS-PED-00134-000 
2025-07-10 10:05:03.682577: BraTS-PED-00134-000, shape torch.Size([4, 72, 72, 72]), rank 0 
2025-07-10 10:05:03.714751: predicting BraTS-PED-00135-000 
2025-07-10 10:05:03.750445: BraTS-PED-00135-000, shape torch.Size([4, 124, 124, 123]), rank 0 
2025-07-10 10:05:04.286372: predicting BraTS-PED-00136-000 
2025-07-10 10:05:04.311809: BraTS-PED-00136-000, shape torch.Size([4, 108, 108, 108]), rank 0 
2025-07-10 10:05:04.480283: predicting BraTS-PED-00137-000 
2025-07-10 10:05:04.492050: BraTS-PED-00137-000, shape torch.Size([4, 83, 83, 83]), rank 0 
2025-07-10 10:05:04.662597: predicting BraTS-PED-00138-000 
2025-07-10 10:05:04.681047: BraTS-PED-00138-000, shape torch.Size([4, 97, 97, 97]), rank 0 
2025-07-10 10:05:04.851890: predicting BraTS-PED-00139-000 
2025-07-10 10:05:04.861830: BraTS-PED-00139-000, shape torch.Size([4, 78, 78, 78]), rank 0 
2025-07-10 10:05:04.895329: predicting BraTS-PED-00140-000 
2025-07-10 10:05:04.899407: BraTS-PED-00140-000, shape torch.Size([4, 56, 56, 56]), rank 0 
2025-07-10 10:05:04.931666: predicting BraTS-PED-00141-000 
2025-07-10 10:05:04.951167: BraTS-PED-00141-000, shape torch.Size([4, 102, 102, 102]), rank 0 
2025-07-10 10:05:05.118876: predicting BraTS-PED-00142-000 
2025-07-10 10:05:05.134327: BraTS-PED-00142-000, shape torch.Size([4, 85, 85, 85]), rank 0 
2025-07-10 10:05:05.302773: predicting BraTS-PED-00143-000 
2025-07-10 10:05:05.318610: BraTS-PED-00143-000, shape torch.Size([4, 90, 90, 90]), rank 0 
2025-07-10 10:05:05.485002: predicting BraTS-PED-00144-000 
2025-07-10 10:05:05.512450: BraTS-PED-00144-000, shape torch.Size([4, 114, 114, 114]), rank 0 
2025-07-10 10:05:05.680114: predicting BraTS-PED-00145-000 
2025-07-10 10:05:05.688054: BraTS-PED-00145-000, shape torch.Size([4, 71, 71, 71]), rank 0 
2025-07-10 10:05:05.722800: predicting BraTS-PED-00146-000 
2025-07-10 10:05:05.739415: BraTS-PED-00146-000, shape torch.Size([4, 94, 94, 94]), rank 0 
2025-07-10 10:05:05.906013: predicting BraTS-PED-00147-000 
2025-07-10 10:05:05.910740: BraTS-PED-00147-000, shape torch.Size([4, 55, 55, 55]), rank 0 
2025-07-10 10:05:05.942904: predicting BraTS-PED-00148-000 
2025-07-10 10:05:05.963444: BraTS-PED-00148-000, shape torch.Size([4, 103, 103, 103]), rank 0 
2025-07-10 10:05:06.130161: predicting BraTS-PED-00149-000 
2025-07-10 10:05:06.137661: BraTS-PED-00149-000, shape torch.Size([4, 67, 67, 67]), rank 0 
2025-07-10 10:05:06.170927: predicting BraTS-PED-00150-000 
2025-07-10 10:05:06.183777: BraTS-PED-00150-000, shape torch.Size([4, 82, 82, 82]), rank 0 
2025-07-10 10:05:06.348891: predicting BraTS-PED-00151-000 
2025-07-10 10:05:06.356158: BraTS-PED-00151-000, shape torch.Size([4, 66, 66, 66]), rank 0 
2025-07-10 10:05:06.388568: predicting BraTS-PED-00152-000 
2025-07-10 10:05:06.396199: BraTS-PED-00152-000, shape torch.Size([4, 70, 70, 70]), rank 0 
2025-07-10 10:05:06.428094: predicting BraTS-PED-00153-000 
2025-07-10 10:05:06.462401: BraTS-PED-00153-000, shape torch.Size([4, 121, 121, 121]), rank 0 
2025-07-10 10:05:06.997548: predicting BraTS-PED-00154-000 
2025-07-10 10:05:07.035107: BraTS-PED-00154-000, shape torch.Size([4, 124, 124, 124]), rank 0 
2025-07-10 10:05:07.572585: predicting BraTS-PED-00155-000 
2025-07-10 10:05:07.589017: BraTS-PED-00155-000, shape torch.Size([4, 91, 91, 91]), rank 0 
2025-07-10 10:05:07.755836: predicting BraTS-PED-00156-000 
2025-07-10 10:05:07.802148: BraTS-PED-00156-000, shape torch.Size([4, 130, 130, 126]), rank 0 
2025-07-10 10:05:08.340658: predicting BraTS-PED-00157-000 
2025-07-10 10:05:08.346317: BraTS-PED-00157-000, shape torch.Size([4, 57, 57, 57]), rank 0 
2025-07-10 10:05:08.380265: predicting BraTS-PED-00158-000 
2025-07-10 10:05:08.388479: BraTS-PED-00158-000, shape torch.Size([4, 69, 69, 69]), rank 0 
2025-07-10 10:05:08.422431: predicting BraTS-PED-00159-000 
2025-07-10 10:05:08.432608: BraTS-PED-00159-000, shape torch.Size([4, 78, 78, 78]), rank 0 
2025-07-10 10:05:08.463597: predicting BraTS-PED-00160-000 
2025-07-10 10:05:08.469632: BraTS-PED-00160-000, shape torch.Size([4, 59, 59, 59]), rank 0 
2025-07-10 10:05:08.501443: predicting BraTS-PED-00161-000 
2025-07-10 10:05:08.507389: BraTS-PED-00161-000, shape torch.Size([4, 62, 62, 62]), rank 0 
2025-07-10 10:05:08.539169: predicting BraTS-PED-00162-000 
2025-07-10 10:05:08.544417: BraTS-PED-00162-000, shape torch.Size([4, 61, 61, 61]), rank 0 
2025-07-10 10:05:08.576503: predicting BraTS-PED-00163-000 
2025-07-10 10:05:08.617159: BraTS-PED-00163-000, shape torch.Size([4, 135, 135, 128]), rank 0 
2025-07-10 10:05:09.152896: predicting BraTS-PED-00164-000 
2025-07-10 10:05:09.156410: BraTS-PED-00164-000, shape torch.Size([4, 48, 48, 48]), rank 0 
2025-07-10 10:05:09.188336: predicting BraTS-PED-00165-000 
2025-07-10 10:05:09.193956: BraTS-PED-00165-000, shape torch.Size([4, 63, 63, 63]), rank 0 
2025-07-10 10:05:09.224768: predicting BraTS-PED-00166-000 
2025-07-10 10:05:09.233995: BraTS-PED-00166-000, shape torch.Size([4, 69, 69, 69]), rank 0 
2025-07-10 10:05:09.266699: predicting BraTS-PED-00167-000 
2025-07-10 10:05:09.297400: BraTS-PED-00167-000, shape torch.Size([4, 116, 116, 116]), rank 0 
2025-07-10 10:05:09.466577: predicting BraTS-PED-00168-000 
2025-07-10 10:05:09.475468: BraTS-PED-00168-000, shape torch.Size([4, 70, 70, 70]), rank 0 
2025-07-10 10:05:09.508427: predicting BraTS-PED-00169-000 
2025-07-10 10:05:09.513815: BraTS-PED-00169-000, shape torch.Size([4, 64, 64, 64]), rank 0 
2025-07-10 10:05:09.546989: predicting BraTS-PED-00170-000 
2025-07-10 10:05:09.595663: BraTS-PED-00170-000, shape torch.Size([4, 129, 129, 129]), rank 0 
2025-07-10 10:05:10.131464: predicting BraTS-PED-00171-000 
2025-07-10 10:05:10.144416: BraTS-PED-00171-000, shape torch.Size([4, 81, 81, 81]), rank 0 
2025-07-10 10:05:10.311733: predicting BraTS-PED-00172-000 
2025-07-10 10:05:10.328375: BraTS-PED-00172-000, shape torch.Size([4, 93, 93, 93]), rank 0 
2025-07-10 10:05:10.494887: predicting BraTS-PED-00173-000 
2025-07-10 10:05:10.501425: BraTS-PED-00173-000, shape torch.Size([4, 65, 65, 65]), rank 0 
2025-07-10 10:05:10.538179: predicting BraTS-PED-00174-000 
2025-07-10 10:05:10.558409: BraTS-PED-00174-000, shape torch.Size([4, 104, 104, 104]), rank 0 
2025-07-10 10:05:10.724842: predicting BraTS-PED-00175-000 
2025-07-10 10:05:10.730015: BraTS-PED-00175-000, shape torch.Size([4, 64, 64, 64]), rank 0 
2025-07-10 10:05:10.765167: predicting BraTS-PED-00176-000 
2025-07-10 10:05:10.812564: BraTS-PED-00176-000, shape torch.Size([4, 134, 134, 124]), rank 0 
2025-07-10 10:05:11.348569: predicting BraTS-PED-00177-000 
2025-07-10 10:05:11.360917: BraTS-PED-00177-000, shape torch.Size([4, 82, 82, 82]), rank 0 
2025-07-10 10:05:11.528508: predicting BraTS-PED-00178-000 
2025-07-10 10:05:11.538367: BraTS-PED-00178-000, shape torch.Size([4, 78, 78, 78]), rank 0 
2025-07-10 10:05:11.570214: predicting BraTS-PED-00179-000 
2025-07-10 10:05:11.601302: BraTS-PED-00179-000, shape torch.Size([4, 115, 115, 115]), rank 0 
2025-07-10 10:05:11.773784: predicting BraTS-PED-00180-000 
2025-07-10 10:05:11.779175: BraTS-PED-00180-000, shape torch.Size([4, 57, 57, 57]), rank 0 
2025-07-10 10:05:11.811148: predicting BraTS-PED-00181-000 
2025-07-10 10:05:11.816087: BraTS-PED-00181-000, shape torch.Size([4, 58, 58, 58]), rank 0 
2025-07-10 10:05:11.848470: predicting BraTS-PED-00182-000 
2025-07-10 10:05:11.902365: BraTS-PED-00182-000, shape torch.Size([4, 144, 144, 144]), rank 0 
2025-07-10 10:05:12.438640: predicting BraTS-PED-00183-000 
2025-07-10 10:05:12.446145: BraTS-PED-00183-000, shape torch.Size([4, 72, 72, 72]), rank 0 
2025-07-10 10:05:12.479117: predicting BraTS-PED-00184-000 
2025-07-10 10:05:12.486764: BraTS-PED-00184-000, shape torch.Size([4, 67, 67, 67]), rank 0 
2025-07-10 10:05:12.517875: predicting BraTS-PED-00185-000 
2025-07-10 10:05:12.548771: BraTS-PED-00185-000, shape torch.Size([4, 117, 117, 117]), rank 0 
2025-07-10 10:05:12.717232: predicting BraTS-PED-00186-000 
2025-07-10 10:05:12.775052: BraTS-PED-00186-000, shape torch.Size([4, 141, 141, 141]), rank 0 
2025-07-10 10:05:13.312466: predicting BraTS-PED-00187-000 
2025-07-10 10:05:13.318020: BraTS-PED-00187-000, shape torch.Size([4, 60, 60, 60]), rank 0 
2025-07-10 10:05:13.353958: predicting BraTS-PED-00188-000 
2025-07-10 10:05:13.373044: BraTS-PED-00188-000, shape torch.Size([4, 92, 92, 92]), rank 0 
2025-07-10 10:05:13.540616: predicting BraTS-PED-00189-000 
2025-07-10 10:05:13.544472: BraTS-PED-00189-000, shape torch.Size([4, 52, 52, 52]), rank 0 
2025-07-10 10:05:13.580393: predicting BraTS-PED-00190-000 
2025-07-10 10:05:13.593785: BraTS-PED-00190-000, shape torch.Size([4, 83, 83, 83]), rank 0 
2025-07-10 10:05:13.758386: predicting BraTS-PED-00191-000 
2025-07-10 10:05:13.768031: BraTS-PED-00191-000, shape torch.Size([4, 73, 73, 73]), rank 0 
2025-07-10 10:05:13.800094: predicting BraTS-PED-00192-000 
2025-07-10 10:05:13.807112: BraTS-PED-00192-000, shape torch.Size([4, 68, 68, 68]), rank 0 
2025-07-10 10:05:13.839388: predicting BraTS-PED-00193-000 
2025-07-10 10:05:13.849733: BraTS-PED-00193-000, shape torch.Size([4, 75, 75, 75]), rank 0 
2025-07-10 10:05:13.881018: predicting BraTS-PED-00194-000 
2025-07-10 10:05:13.884913: BraTS-PED-00194-000, shape torch.Size([4, 49, 49, 49]), rank 0 
2025-07-10 10:05:13.916523: predicting BraTS-PED-00195-000 
2025-07-10 10:05:13.924031: BraTS-PED-00195-000, shape torch.Size([4, 66, 66, 66]), rank 0 
2025-07-10 10:05:13.955205: predicting BraTS-PED-00196-000 
2025-07-10 10:05:13.959838: BraTS-PED-00196-000, shape torch.Size([4, 55, 55, 55]), rank 0 
2025-07-10 10:05:13.991312: predicting BraTS-PED-00197-000 
2025-07-10 10:05:13.999233: BraTS-PED-00197-000, shape torch.Size([4, 69, 69, 69]), rank 0 
2025-07-10 10:05:14.031217: predicting BraTS-PED-00198-000 
2025-07-10 10:05:14.037249: BraTS-PED-00198-000, shape torch.Size([4, 61, 61, 61]), rank 0 
2025-07-10 10:05:14.070042: predicting BraTS-PED-00199-000 
2025-07-10 10:05:14.075317: BraTS-PED-00199-000, shape torch.Size([4, 59, 59, 59]), rank 0 
2025-07-10 10:05:14.107219: predicting BraTS-PED-00200-000 
2025-07-10 10:05:14.113386: BraTS-PED-00200-000, shape torch.Size([4, 63, 63, 63]), rank 0 
2025-07-10 10:05:14.145702: predicting BraTS-PED-00201-000 
2025-07-10 10:05:14.156041: BraTS-PED-00201-000, shape torch.Size([4, 73, 73, 73]), rank 0 
2025-07-10 10:05:14.187703: predicting BraTS-PED-00202-000 
2025-07-10 10:05:14.194273: BraTS-PED-00202-000, shape torch.Size([4, 63, 63, 63]), rank 0 
2025-07-10 10:05:14.226569: predicting BraTS-PED-00203-000 
2025-07-10 10:05:14.237483: BraTS-PED-00203-000, shape torch.Size([4, 79, 79, 79]), rank 0 
2025-07-10 10:05:14.268497: predicting BraTS-PED-00204-000 
2025-07-10 10:05:14.271613: BraTS-PED-00204-000, shape torch.Size([4, 48, 48, 48]), rank 0 
2025-07-10 10:05:14.303437: predicting BraTS-PED-00205-000 
2025-07-10 10:05:14.311400: BraTS-PED-00205-000, shape torch.Size([4, 66, 66, 66]), rank 0 
2025-07-10 10:05:14.342325: predicting BraTS-PED-00206-000 
2025-07-10 10:05:14.348014: BraTS-PED-00206-000, shape torch.Size([4, 58, 58, 58]), rank 0 
2025-07-10 10:05:14.379359: predicting BraTS-PED-00207-000 
2025-07-10 10:05:14.389414: BraTS-PED-00207-000, shape torch.Size([4, 74, 74, 74]), rank 0 
2025-07-10 10:05:14.424110: predicting BraTS-PED-00208-000 
2025-07-10 10:05:14.430038: BraTS-PED-00208-000, shape torch.Size([4, 61, 61, 61]), rank 0 
2025-07-10 10:05:14.462379: predicting BraTS-PED-00209-000 
2025-07-10 10:05:14.470612: BraTS-PED-00209-000, shape torch.Size([4, 66, 66, 66]), rank 0 
2025-07-10 10:05:14.503155: predicting BraTS-PED-00210-000 
2025-07-10 10:05:14.511233: BraTS-PED-00210-000, shape torch.Size([4, 65, 65, 65]), rank 0 
2025-07-10 10:05:14.544114: predicting BraTS-PED-00211-000 
2025-07-10 10:05:14.611163: BraTS-PED-00211-000, shape torch.Size([4, 153, 153, 153]), rank 0 
2025-07-10 10:05:15.149403: predicting BraTS-PED-00212-000 
2025-07-10 10:05:15.159060: BraTS-PED-00212-000, shape torch.Size([4, 73, 73, 73]), rank 0 
2025-07-10 10:05:15.191874: predicting BraTS-PED-00213-000 
2025-07-10 10:05:15.199521: BraTS-PED-00213-000, shape torch.Size([4, 68, 68, 68]), rank 0 
2025-07-10 10:05:15.231800: predicting BraTS-PED-00214-000 
2025-07-10 10:05:15.240885: BraTS-PED-00214-000, shape torch.Size([4, 68, 68, 68]), rank 0 
2025-07-10 10:05:15.272462: predicting BraTS-PED-00215-000 
2025-07-10 10:05:15.280260: BraTS-PED-00215-000, shape torch.Size([4, 70, 70, 70]), rank 0 
2025-07-10 10:05:15.315703: predicting BraTS-PED-00216-000 
2025-07-10 10:05:15.324452: BraTS-PED-00216-000, shape torch.Size([4, 69, 69, 69]), rank 0 
2025-07-10 10:05:15.357353: predicting BraTS-PED-00217-000 
2025-07-10 10:05:15.365931: BraTS-PED-00217-000, shape torch.Size([4, 69, 69, 69]), rank 0 
2025-07-10 10:05:15.396906: predicting BraTS-PED-00218-000 
2025-07-10 10:05:15.399953: BraTS-PED-00218-000, shape torch.Size([4, 48, 48, 48]), rank 0 
2025-07-10 10:05:15.433981: predicting BraTS-PED-00219-000 
2025-07-10 10:05:15.440205: BraTS-PED-00219-000, shape torch.Size([4, 59, 59, 59]), rank 0 
2025-07-10 10:05:15.471339: predicting BraTS-PED-00220-000 
2025-07-10 10:05:15.475799: BraTS-PED-00220-000, shape torch.Size([4, 56, 56, 56]), rank 0 
2025-07-10 10:05:15.507497: predicting BraTS-PED-00221-000 
2025-07-10 10:05:15.514810: BraTS-PED-00221-000, shape torch.Size([4, 65, 65, 65]), rank 0 
2025-07-10 10:05:15.545511: predicting BraTS-PED-00222-000 
2025-07-10 10:05:15.553001: BraTS-PED-00222-000, shape torch.Size([4, 68, 68, 68]), rank 0 
2025-07-10 10:05:15.584992: predicting BraTS-PED-00223-000 
2025-07-10 10:05:15.589051: BraTS-PED-00223-000, shape torch.Size([4, 50, 50, 50]), rank 0 
2025-07-10 10:05:15.620685: predicting BraTS-PED-00224-000 
2025-07-10 10:05:15.647172: BraTS-PED-00224-000, shape torch.Size([4, 107, 107, 107]), rank 0 
2025-07-10 10:05:15.815173: predicting BraTS-PED-00225-000 
2025-07-10 10:05:15.818966: BraTS-PED-00225-000, shape torch.Size([4, 49, 49, 49]), rank 0 
2025-07-10 10:05:15.851405: predicting BraTS-PED-00226-000 
2025-07-10 10:05:15.858238: BraTS-PED-00226-000, shape torch.Size([4, 63, 63, 63]), rank 0 
2025-07-10 10:05:15.890138: predicting BraTS-PED-00227-000 
2025-07-10 10:05:15.895036: BraTS-PED-00227-000, shape torch.Size([4, 57, 57, 57]), rank 0 
2025-07-10 10:05:15.927616: predicting BraTS-PED-00228-000 
2025-07-10 10:05:15.935520: BraTS-PED-00228-000, shape torch.Size([4, 65, 65, 65]), rank 0 
2025-07-10 10:05:15.967488: predicting BraTS-PED-00229-000 
2025-07-10 10:05:15.973178: BraTS-PED-00229-000, shape torch.Size([4, 60, 60, 60]), rank 0 
2025-07-10 10:05:16.005905: predicting BraTS-PED-00230-000 
2025-07-10 10:05:16.015374: BraTS-PED-00230-000, shape torch.Size([4, 74, 74, 74]), rank 0 
2025-07-10 10:05:16.047176: predicting BraTS-PED-00231-000 
2025-07-10 10:05:16.056154: BraTS-PED-00231-000, shape torch.Size([4, 70, 70, 70]), rank 0 
2025-07-10 10:05:16.087650: predicting BraTS-PED-00232-000 
2025-07-10 10:05:16.098508: BraTS-PED-00232-000, shape torch.Size([4, 74, 74, 74]), rank 0 
2025-07-10 10:05:16.129783: predicting BraTS-PED-00233-000 
2025-07-10 10:05:16.136909: BraTS-PED-00233-000, shape torch.Size([4, 65, 65, 65]), rank 0 
2025-07-10 10:05:16.168696: predicting BraTS-PED-00234-000 
2025-07-10 10:05:16.178668: BraTS-PED-00234-000, shape torch.Size([4, 73, 73, 73]), rank 0 
2025-07-10 10:05:16.210489: predicting BraTS-PED-00235-000 
2025-07-10 10:05:16.221534: BraTS-PED-00235-000, shape torch.Size([4, 76, 76, 76]), rank 0 
2025-07-10 10:05:16.253367: predicting BraTS-PED-00236-000 
2025-07-10 10:05:16.301849: BraTS-PED-00236-000, shape torch.Size([4, 135, 135, 135]), rank 0 
2025-07-10 10:05:16.839071: predicting BraTS-PED-00237-000 
2025-07-10 10:05:16.847208: BraTS-PED-00237-000, shape torch.Size([4, 67, 67, 67]), rank 0 
2025-07-10 10:05:16.880809: predicting BraTS-PED-00238-000 
2025-07-10 10:05:16.887162: BraTS-PED-00238-000, shape torch.Size([4, 63, 63, 63]), rank 0 
2025-07-10 10:05:16.923250: predicting BraTS-PED-00239-000 
2025-07-10 10:05:16.934560: BraTS-PED-00239-000, shape torch.Size([4, 79, 79, 79]), rank 0 
2025-07-10 10:05:16.966285: predicting BraTS-PED-00240-000 
2025-07-10 10:05:16.976149: BraTS-PED-00240-000, shape torch.Size([4, 73, 73, 73]), rank 0 
2025-07-10 10:05:17.007674: predicting BraTS-PED-00241-000 
2025-07-10 10:05:17.016474: BraTS-PED-00241-000, shape torch.Size([4, 70, 70, 70]), rank 0 
2025-07-10 10:05:17.047894: predicting BraTS-PED-00242-000 
2025-07-10 10:05:17.053840: BraTS-PED-00242-000, shape torch.Size([4, 60, 60, 60]), rank 0 
2025-07-10 10:05:17.085914: predicting BraTS-PED-00243-000 
2025-07-10 10:05:17.095939: BraTS-PED-00243-000, shape torch.Size([4, 73, 73, 73]), rank 0 
2025-07-10 10:05:17.128424: predicting BraTS-PED-00244-000 
2025-07-10 10:05:17.137222: BraTS-PED-00244-000, shape torch.Size([4, 71, 71, 71]), rank 0 
2025-07-10 10:05:17.168529: predicting BraTS-PED-00245-000 
2025-07-10 10:05:17.177126: BraTS-PED-00245-000, shape torch.Size([4, 68, 68, 68]), rank 0 
2025-07-10 10:05:17.208524: predicting BraTS-PED-00246-000 
2025-07-10 10:05:17.216680: BraTS-PED-00246-000, shape torch.Size([4, 72, 72, 72]), rank 0 
2025-07-10 10:05:17.248486: predicting BraTS-PED-00247-000 
2025-07-10 10:05:17.251399: BraTS-PED-00247-000, shape torch.Size([4, 48, 48, 48]), rank 0 
2025-07-10 10:05:17.282995: predicting BraTS-PED-00248-000 
2025-07-10 10:05:17.288298: BraTS-PED-00248-000, shape torch.Size([4, 58, 58, 58]), rank 0 
2025-07-10 10:05:17.321910: predicting BraTS-PED-00249-000 
2025-07-10 10:05:17.330039: BraTS-PED-00249-000, shape torch.Size([4, 69, 69, 69]), rank 0 
2025-07-10 10:05:17.361361: predicting BraTS-PED-00250-000 
2025-07-10 10:05:17.369072: BraTS-PED-00250-000, shape torch.Size([4, 71, 71, 71]), rank 0 
2025-07-10 10:05:17.401630: predicting BraTS-PED-00251-000 
2025-07-10 10:05:17.406937: BraTS-PED-00251-000, shape torch.Size([4, 59, 59, 59]), rank 0 
2025-07-10 10:05:17.439536: predicting BraTS-PED-00252-000 
2025-07-10 10:05:17.447823: BraTS-PED-00252-000, shape torch.Size([4, 67, 67, 67]), rank 0 
2025-07-10 10:05:17.479638: predicting BraTS-PED-00253-000 
2025-07-10 10:05:17.484861: BraTS-PED-00253-000, shape torch.Size([4, 58, 58, 58]), rank 0 
2025-07-10 10:05:17.517274: predicting BraTS-PED-00254-000 
2025-07-10 10:05:17.525000: BraTS-PED-00254-000, shape torch.Size([4, 66, 66, 66]), rank 0 
2025-07-10 10:05:17.557189: predicting BraTS-PED-00255-000 
2025-07-10 10:05:17.572675: BraTS-PED-00255-000, shape torch.Size([4, 93, 93, 93]), rank 0 
2025-07-10 10:05:17.737554: predicting BraTS-PED-00256-000 
2025-07-10 10:05:17.746869: BraTS-PED-00256-000, shape torch.Size([4, 73, 73, 73]), rank 0 
2025-07-10 10:05:17.779730: predicting BraTS-PED-00257-000 
2025-07-10 10:05:17.785143: BraTS-PED-00257-000, shape torch.Size([4, 58, 58, 58]), rank 0 
2025-07-10 10:05:17.816704: predicting BraTS-PED-00258-000 
2025-07-10 10:05:17.824955: BraTS-PED-00258-000, shape torch.Size([4, 68, 68, 68]), rank 0 
2025-07-10 10:05:17.856524: predicting BraTS-PED-00259-000 
2025-07-10 10:05:17.860764: BraTS-PED-00259-000, shape torch.Size([4, 53, 53, 53]), rank 0 
2025-07-10 10:05:17.892614: predicting BraTS-PED-00260-000 
2025-07-10 10:05:17.898148: BraTS-PED-00260-000, shape torch.Size([4, 64, 64, 64]), rank 0 
2025-07-10 10:05:17.929940: predicting BraTS-PED-00261-000 
2025-07-10 10:05:17.940423: BraTS-PED-00261-000, shape torch.Size([4, 80, 80, 80]), rank 0 
2025-07-10 10:05:17.971907: predicting BraTS-PED-00262-000 
2025-07-10 10:05:17.979650: BraTS-PED-00262-000, shape torch.Size([4, 66, 66, 66]), rank 0 
2025-07-10 10:05:18.012636: predicting BraTS-PED-00263-000 
2025-07-10 10:05:18.022383: BraTS-PED-00263-000, shape torch.Size([4, 75, 75, 75]), rank 0 
2025-07-10 10:05:18.054378: predicting BraTS-PED-00264-000 
2025-07-10 10:05:18.060086: BraTS-PED-00264-000, shape torch.Size([4, 60, 60, 60]), rank 0 
2025-07-10 10:05:18.091943: predicting BraTS-PED-00265-000 
2025-07-10 10:05:18.096193: BraTS-PED-00265-000, shape torch.Size([4, 52, 52, 52]), rank 0 
2025-07-10 10:05:18.127898: predicting BraTS-PED-00266-000 
2025-07-10 10:05:18.135738: BraTS-PED-00266-000, shape torch.Size([4, 67, 67, 67]), rank 0 
2025-07-10 10:05:22.950448: Validation complete 
2025-07-10 10:05:22.950550: Mean Validation Dice:  0.45708100585556394 
